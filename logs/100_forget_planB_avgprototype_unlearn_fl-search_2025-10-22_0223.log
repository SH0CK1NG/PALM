nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=1.0, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:21<17:20, 21.23s/it]  4%|▍         | 2/50 [00:36<13:56, 17.43s/it]  6%|▌         | 3/50 [00:50<12:34, 16.06s/it]  8%|▊         | 4/50 [01:05<11:52, 15.50s/it] 10%|█         | 5/50 [01:19<11:26, 15.26s/it] 12%|█▏        | 6/50 [01:34<11:05, 15.12s/it] 14%|█▍        | 7/50 [01:49<10:44, 14.99s/it] 16%|█▌        | 8/50 [02:04<10:24, 14.87s/it][loss] ep 0 it 0 total=11.9406 mle=1.5709 pcon=5.2950 forget=6.8774 favg=-1.8027 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=11.6143 mle=1.5425 pcon=5.2879 forget=7.0066 favg=-2.2227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=11.7358 mle=1.7004 pcon=5.2809 forget=6.8698 favg=-2.1152 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=11.7830 mle=1.8996 pcon=5.2738 forget=6.8479 favg=-2.2383 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=11.9088 mle=1.7128 pcon=5.2670 forget=6.9124 favg=-1.9834 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=11.5575 mle=1.5022 pcon=5.2603 forget=6.8906 favg=-2.0957 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=11.8718 mle=1.5595 pcon=5.2540 forget=6.9079 favg=-1.8496 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=11.5620 mle=1.6809 pcon=5.2476 forget=6.9440 favg=-2.3105 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=11.4659 mle=1.6718 pcon=5.2408 forget=7.0415 favg=-2.4883 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=11.2642 mle=1.6372 pcon=5.2344 forget=6.8203 favg=-2.4277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=10.7189 mle=1.5143 pcon=5.2281 forget=6.9042 favg=-2.9277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=9.4376 mle=1.7802 pcon=5.2218 forget=6.8926 favg=-4.4570 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=7.2556 mle=1.7773 pcon=5.2153 forget=7.0208 favg=-6.7578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=5.4411 mle=1.6129 pcon=5.2088 forget=7.2210 favg=-8.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=4.6875 mle=1.7372 pcon=5.2021 forget=7.5295 favg=-9.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=4.7293 mle=1.9618 pcon=5.1959 forget=7.7279 favg=-10.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=4.6873 mle=1.7033 pcon=5.1901 forget=7.9501 favg=-10.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=6.7736 mle=2.0921 pcon=5.1847 forget=8.1999 favg=-8.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=18.6022 mle=1.9070 pcon=5.1791 forget=8.7056 favg=2.8105 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=25.0345 mle=1.6333 pcon=5.1734 forget=8.9700 favg=9.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=24.0160 mle=1.6673 pcon=5.1675 forget=8.4625 favg=8.7188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=19.2775 mle=1.8655 pcon=5.1622 forget=7.2732 favg=4.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=15.4250 mle=1.6011 pcon=5.1573 forget=6.9175 favg=1.7490 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=13.4289 mle=1.8280 pcon=5.1528 forget=6.9200 favg=-0.4719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 30 total=9.5452 mle=1.8238 pcon=5.1487 forget=7.1900 favg=-4.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.9479 mle=1.8140 pcon=5.1457 forget=7.5312 favg=-5.5430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=17.3090 mle=1.8688 pcon=5.1427 forget=7.3717 favg=2.9258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=15.5611 mle=1.9749 pcon=5.1397 forget=6.8078 favg=1.6387 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=11.0655 mle=1.5664 pcon=5.1358 forget=7.1191 favg=-2.7559 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=5.8169 mle=1.8893 pcon=5.1308 forget=7.6797 favg=-8.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=20.5328 mle=1.9236 pcon=5.1260 forget=8.2723 favg=5.2109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=20.3077 mle=1.7368 pcon=5.1216 forget=7.7265 favg=5.7227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 40 total=16.8147 mle=1.6755 pcon=5.1178 forget=6.7753 favg=3.2461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=17.2008 mle=1.7974 pcon=5.1145 forget=6.9528 favg=3.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=14.2473 mle=1.7599 pcon=5.1117 forget=7.2907 favg=0.0850 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=7.3323 mle=1.4744 pcon=5.1083 forget=6.8199 favg=-6.0703 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=23.2196 mle=1.9029 pcon=5.1042 forget=7.7829 favg=8.4297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=19.6207 mle=1.5075 pcon=5.1005 forget=7.5948 favg=5.4180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=13.8738 mle=1.9406 pcon=5.0975 forget=6.8479 favg=-0.0122 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=6.9630 mle=2.0101 pcon=5.0956 forget=6.9784 favg=-7.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=20.6012 mle=2.0511 pcon=5.0935 forget=7.2417 favg=6.2148 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=23.6119 mle=1.7041 pcon=5.0915 forget=7.0507 favg=9.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=16.7435 mle=1.5830 pcon=5.0885 forget=6.9508 favg=3.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=10.6173 mle=1.6811 pcon=5.0854 forget=6.7669 favg=-2.9160 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=7.7222 mle=1.7951 pcon=5.0825 forget=6.6376 favg=-5.7930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=4.2494 mle=1.6435 pcon=5.0796 forget=6.7372 favg=-9.2109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=6.1267 mle=1.9159 pcon=5.0772 forget=7.1571 favg=-8.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=20.6583 mle=1.6733 pcon=5.0745 forget=7.7191 favg=6.1914 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=23.2702 mle=1.6001 pcon=5.0717 forget=7.4031 favg=9.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=20.3394 mle=1.6463 pcon=5.0691 forget=6.8896 favg=6.7344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=6.9054 mle=1.8545 pcon=5.0668 forget=7.0856 favg=-7.1016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=3.5889 mle=1.8847 pcon=5.0651 forget=6.7797 favg=-10.1406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=24.0605 mle=1.8728 pcon=5.0632 forget=6.8745 favg=10.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=22.1902 mle=1.5979 pcon=5.0620 forget=6.9444 favg=8.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=16.8145 mle=1.6981 pcon=5.0604 forget=6.7631 favg=3.2930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=6.3956 mle=1.8139 pcon=5.0581 forget=6.6291 favg=-7.1055 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=3.8103 mle=2.0393 pcon=5.0553 forget=6.4891 favg=-9.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=22.4994 mle=1.9708 pcon=5.0521 forget=7.2030 favg=8.2734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=23.6205 mle=1.6269 pcon=5.0491 forget=8.0226 favg=8.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=13.9382 mle=1.6494 pcon=5.0469 forget=7.1466 favg=0.0953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=7.5923 mle=1.9152 pcon=5.0463 forget=6.6386 favg=-6.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=4.5041 mle=1.9804 pcon=5.0459 forget=6.6419 favg=-9.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=21.8398 mle=1.7433 pcon=5.0449 forget=6.8719 favg=8.1797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 30 total=21.6169 mle=1.6761 pcon=5.0431 forget=7.3820 favg=7.5156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=15.6940 mle=1.7186 pcon=5.0410 forget=7.0116 favg=1.9229 nr=64 nf=64 protos=540 fproto_sim=NA
 18%|█▊        | 9/50 [02:18<10:05, 14.78s/it] 20%|██        | 10/50 [02:33<09:52, 14.82s/it] 22%|██▏       | 11/50 [02:48<09:36, 14.79s/it] 24%|██▍       | 12/50 [03:08<10:24, 16.42s/it] 26%|██▌       | 13/50 [03:33<11:45, 19.08s/it] 28%|██▊       | 14/50 [03:57<12:20, 20.57s/it] 30%|███       | 15/50 [04:22<12:39, 21.71s/it] 32%|███▏      | 16/50 [04:47<12:52, 22.73s/it][loss] ep 8 it 130 total=8.0089 mle=1.7031 pcon=5.0395 forget=6.5710 favg=-5.3047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=4.8949 mle=1.9897 pcon=5.0390 forget=6.4756 favg=-8.6094 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=19.2986 mle=1.7500 pcon=5.0384 forget=7.2212 favg=5.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=21.4557 mle=1.9368 pcon=5.0366 forget=7.3143 favg=7.1680 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=18.0173 mle=1.8390 pcon=5.0343 forget=6.8901 favg=4.2539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=11.3371 mle=1.5763 pcon=5.0323 forget=6.6914 favg=-1.9629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 40 total=5.1831 mle=2.1915 pcon=5.0312 forget=6.8978 favg=-8.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=19.9882 mle=2.0043 pcon=5.0304 forget=6.7932 favg=6.1602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=17.3183 mle=1.8831 pcon=5.0296 forget=6.7240 favg=3.6816 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=15.6845 mle=1.6591 pcon=5.0277 forget=6.7301 favg=2.2676 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=11.1531 mle=1.8527 pcon=5.0254 forget=6.7769 favg=-2.5020 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=17.1418 mle=2.0887 pcon=5.0234 forget=6.7621 favg=3.2676 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=18.0802 mle=1.6837 pcon=5.0221 forget=6.9994 favg=4.3750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=14.1958 mle=1.7657 pcon=5.0204 forget=6.7778 favg=0.6318 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=12.4721 mle=1.7279 pcon=5.0183 forget=6.6346 favg=-0.9087 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=10.4506 mle=1.9321 pcon=5.0163 forget=6.7111 favg=-3.2090 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=16.6458 mle=1.9866 pcon=5.0143 forget=6.7621 favg=2.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=19.3546 mle=1.8816 pcon=5.0118 forget=6.8284 favg=5.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=15.5669 mle=1.7296 pcon=5.0090 forget=6.7522 favg=2.0762 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=13.8133 mle=1.6845 pcon=5.0066 forget=6.6873 favg=0.4351 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=11.3015 mle=1.7547 pcon=5.0042 forget=6.6442 favg=-2.1016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=7.5713 mle=1.7834 pcon=5.0023 forget=6.5629 favg=-5.7773 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=11.6125 mle=1.8351 pcon=5.0006 forget=6.6069 favg=-1.8301 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=14.1658 mle=1.8317 pcon=4.9988 forget=6.7220 favg=0.6133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=16.2873 mle=1.7642 pcon=4.9961 forget=6.8083 favg=2.7188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=18.7214 mle=1.7762 pcon=4.9930 forget=6.7841 favg=5.1680 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=20.4213 mle=1.9267 pcon=4.9900 forget=6.7742 favg=6.7305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=17.9799 mle=2.0974 pcon=4.9869 forget=6.8683 favg=4.0273 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=11.5604 mle=1.7573 pcon=4.9845 forget=6.8655 favg=-2.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=9.2954 mle=1.7002 pcon=4.9821 forget=6.8436 favg=-4.2305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.1545 mle=1.8084 pcon=4.9798 forget=6.7609 favg=-6.3945 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0317 mle=1.7780 pcon=4.9775 forget=6.8153 favg=-5.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=13.2272 mle=1.9251 pcon=4.9749 forget=6.9199 favg=-0.5928 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=16.2356 mle=1.7834 pcon=4.9719 forget=7.0740 favg=2.4062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=17.1007 mle=1.7492 pcon=4.9691 forget=7.1519 favg=3.2305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=16.3723 mle=1.6015 pcon=4.9660 forget=7.1467 favg=2.6582 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=13.5522 mle=1.8481 pcon=4.9631 forget=7.0201 favg=-0.2791 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=9.2554 mle=1.6337 pcon=4.9606 forget=6.8251 favg=-4.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=7.7997 mle=1.6258 pcon=4.9584 forget=6.8366 favg=-5.6211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=7.3449 mle=1.6635 pcon=4.9559 forget=6.9872 favg=-6.2617 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=6.9878 mle=1.7335 pcon=4.9534 forget=7.1174 favg=-6.8164 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=6.5341 mle=1.6701 pcon=4.9504 forget=7.1831 favg=-7.2695 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=6.5566 mle=1.6382 pcon=4.9471 forget=7.2329 favg=-7.2617 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=10.6035 mle=1.7629 pcon=4.9437 forget=7.2895 favg=-3.3926 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=14.7872 mle=1.7470 pcon=4.9406 forget=7.3682 favg=0.7314 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=16.1312 mle=1.9393 pcon=4.9374 forget=7.3815 favg=1.8730 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=14.3344 mle=1.8325 pcon=4.9348 forget=7.2819 favg=0.2852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=8.8918 mle=1.6615 pcon=4.9324 forget=7.0870 favg=-4.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=5.9684 mle=1.8394 pcon=4.9298 forget=7.0586 favg=-7.8594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=8.1549 mle=1.6614 pcon=4.9272 forget=7.3202 favg=-5.7539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=8.6600 mle=1.6588 pcon=4.9240 forget=7.4834 favg=-5.4062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8172 mle=1.7525 pcon=4.9207 forget=7.5581 favg=-6.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=6.4363 mle=1.7803 pcon=4.9174 forget=7.5980 favg=-7.8594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=6.6961 mle=1.7230 pcon=4.9138 forget=7.7468 favg=-7.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=8.3496 mle=1.6863 pcon=4.9104 forget=7.9482 favg=-6.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=9.3041 mle=1.8486 pcon=4.9071 forget=8.0875 favg=-5.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.9260 mle=1.6765 pcon=4.9039 forget=8.1737 favg=-6.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=5.7224 mle=1.8988 pcon=4.9006 forget=8.2589 favg=-9.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=5.0540 mle=1.6670 pcon=4.8976 forget=8.4269 favg=-9.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=6.3530 mle=1.6948 pcon=4.8944 forget=8.6701 favg=-8.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 16 it 10 total=6.9156 mle=1.6238 pcon=4.8910 forget=8.8617 favg=-8.4609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=6.4745 mle=1.5923 pcon=4.8876 forget=8.9790 favg=-8.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=5.3951 mle=1.7018 pcon=4.8844 forget=9.0042 favg=-10.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=4.3342 mle=1.5855 pcon=4.8808 forget=8.9460 favg=-11.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=4.0178 mle=1.6719 pcon=4.8773 forget=8.9686 favg=-11.5000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=4.6531 mle=1.9353 pcon=4.8738 forget=8.9767 favg=-11.1328 nr=64 nf=64 protos=540 fproto_sim=NA
 34%|███▍      | 17/50 [05:12<12:57, 23.56s/it] 36%|███▌      | 18/50 [05:52<15:08, 28.39s/it] 38%|███▊      | 19/50 [06:33<16:35, 32.12s/it] 40%|████      | 20/50 [07:12<17:13, 34.46s/it] 42%|████▏     | 21/50 [07:55<17:50, 36.90s/it] 44%|████▍     | 22/50 [08:35<17:41, 37.92s/it] 46%|████▌     | 23/50 [09:16<17:30, 38.89s/it] 48%|████▊     | 24/50 [09:58<17:14, 39.79s/it] 50%|█████     | 25/50 [10:39<16:42, 40.10s/it][loss] ep 16 it 310 total=5.0360 mle=1.9717 pcon=4.8704 forget=9.1001 favg=-10.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=4.9998 mle=1.7218 pcon=4.8671 forget=9.1766 favg=-10.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 17 it 20 total=5.0482 mle=1.9179 pcon=4.8635 forget=9.2902 favg=-11.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=4.8183 mle=1.9310 pcon=4.8603 forget=9.4020 favg=-11.3750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=4.3169 mle=1.6405 pcon=4.8569 forget=9.4133 favg=-11.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=4.5072 mle=1.7018 pcon=4.8534 forget=9.4989 favg=-11.5469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=4.5750 mle=1.7209 pcon=4.8501 forget=9.6291 favg=-11.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=4.5405 mle=1.5818 pcon=4.8472 forget=9.7365 favg=-11.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=4.9008 mle=1.8938 pcon=4.8440 forget=9.8192 favg=-11.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=4.7870 mle=1.7938 pcon=4.8407 forget=9.8634 favg=-11.7109 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 18 it 30 total=4.6376 mle=1.7130 pcon=4.8378 forget=9.9071 favg=-11.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=4.6265 mle=1.7302 pcon=4.8348 forget=9.9365 favg=-11.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=4.6665 mle=1.7430 pcon=4.8318 forget=9.9745 favg=-11.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=4.5874 mle=1.7143 pcon=4.8289 forget=10.0754 favg=-12.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=4.7332 mle=1.7509 pcon=4.8258 forget=10.1330 favg=-11.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=4.8814 mle=1.7549 pcon=4.8230 forget=10.1785 favg=-11.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=5.0458 mle=1.8204 pcon=4.8203 forget=10.2411 favg=-11.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=5.1053 mle=1.8230 pcon=4.8176 forget=10.3084 favg=-11.8438 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 40 total=4.9353 mle=1.6313 pcon=4.8151 forget=10.3795 favg=-11.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=5.1002 mle=1.8137 pcon=4.8126 forget=10.4192 favg=-11.9453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=4.9450 mle=1.6708 pcon=4.8099 forget=10.4330 favg=-11.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=4.9640 mle=1.7238 pcon=4.8074 forget=10.4875 favg=-12.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=5.2044 mle=1.9193 pcon=4.8049 forget=10.4881 favg=-12.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=5.2332 mle=1.8765 pcon=4.8026 forget=10.5072 favg=-11.9531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=4.9308 mle=1.5727 pcon=4.8002 forget=10.5188 favg=-11.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=5.1009 mle=1.7572 pcon=4.7978 forget=10.5772 favg=-12.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=5.0727 mle=1.6981 pcon=4.7953 forget=10.5949 favg=-12.0156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=5.2920 mle=1.8611 pcon=4.7930 forget=10.5833 favg=-11.9453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=5.2650 mle=1.8778 pcon=4.7905 forget=10.6280 favg=-12.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=5.0020 mle=1.5829 pcon=4.7880 forget=10.6467 favg=-12.0156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=5.4793 mle=1.9910 pcon=4.7856 forget=10.6636 favg=-11.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=5.5051 mle=1.9954 pcon=4.7832 forget=10.7108 favg=-11.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=5.1345 mle=1.5850 pcon=4.7810 forget=10.7450 favg=-11.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=5.2012 mle=1.6198 pcon=4.7788 forget=10.7479 favg=-11.9453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=5.3155 mle=1.6787 pcon=4.7767 forget=10.7585 favg=-11.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=5.2717 mle=1.6299 pcon=4.7746 forget=10.7656 favg=-11.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=5.4072 mle=1.8108 pcon=4.7726 forget=10.8238 favg=-12.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=5.4755 mle=1.8391 pcon=4.7707 forget=10.8032 favg=-11.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=5.3765 mle=1.7590 pcon=4.7687 forget=10.8722 favg=-12.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=5.2823 mle=1.6596 pcon=4.7666 forget=10.8874 favg=-12.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=5.5778 mle=1.6570 pcon=4.7646 forget=10.8281 favg=-11.6719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=5.4769 mle=1.7626 pcon=4.7626 forget=10.8814 favg=-11.9297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=5.4862 mle=1.8391 pcon=4.7605 forget=10.9178 favg=-12.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=5.5684 mle=1.7662 pcon=4.7586 forget=10.8561 favg=-11.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=5.3149 mle=1.6255 pcon=4.7567 forget=10.9092 favg=-11.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=5.3431 mle=1.6729 pcon=4.7550 forget=10.9152 favg=-12.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=5.3023 mle=1.5143 pcon=4.7531 forget=10.8395 favg=-11.8047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=5.4472 mle=1.7287 pcon=4.7515 forget=10.9357 favg=-11.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=5.8325 mle=2.0271 pcon=4.7497 forget=10.8057 favg=-11.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 30 total=5.2703 mle=1.5238 pcon=4.7482 forget=10.9045 favg=-11.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=5.4965 mle=1.6951 pcon=4.7466 forget=10.8908 favg=-11.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=5.4380 mle=1.6229 pcon=4.7449 forget=10.9453 favg=-11.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=5.5766 mle=1.7855 pcon=4.7432 forget=10.9697 favg=-11.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=5.5142 mle=1.6517 pcon=4.7418 forget=10.8942 favg=-11.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=5.5368 mle=1.7769 pcon=4.7402 forget=10.9494 favg=-11.9297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=5.4729 mle=1.6881 pcon=4.7387 forget=10.9289 favg=-11.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=5.5041 mle=1.6709 pcon=4.7373 forget=10.8928 favg=-11.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=5.4300 mle=1.6836 pcon=4.7359 forget=10.9402 favg=-11.9297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=5.4722 mle=1.7539 pcon=4.7345 forget=10.8744 favg=-11.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=5.4294 mle=1.7577 pcon=4.7332 forget=10.8760 favg=-11.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=5.4282 mle=1.7249 pcon=4.7319 forget=10.8621 favg=-11.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=5.2076 mle=1.5499 pcon=4.7306 forget=10.8490 favg=-11.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=5.4386 mle=1.7698 pcon=4.7293 forget=10.8145 favg=-11.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=5.4386 mle=1.7047 pcon=4.7280 forget=10.8028 favg=-11.7969 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▏    | 26/50 [11:22<16:18, 40.77s/it] 54%|█████▍    | 27/50 [12:03<15:43, 41.02s/it] 56%|█████▌    | 28/50 [12:45<15:04, 41.12s/it] 58%|█████▊    | 29/50 [13:25<14:22, 41.05s/it] 60%|██████    | 30/50 [14:07<13:42, 41.12s/it] 62%|██████▏   | 31/50 [14:48<13:03, 41.25s/it] 64%|██████▍   | 32/50 [15:31<12:28, 41.59s/it] 66%|██████▌   | 33/50 [16:12<11:45, 41.48s/it][loss] ep 25 it 0 total=5.3845 mle=1.6959 pcon=4.7267 forget=10.8212 favg=-11.8594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=5.5390 mle=1.8307 pcon=4.7255 forget=10.8030 favg=-11.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=5.4166 mle=1.6603 pcon=4.7242 forget=10.8056 favg=-11.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=5.6845 mle=1.8811 pcon=4.7232 forget=10.8068 favg=-11.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=5.9864 mle=1.9601 pcon=4.7219 forget=10.7186 favg=-11.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=5.7995 mle=1.6629 pcon=4.7206 forget=10.7286 favg=-11.3125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=5.9009 mle=1.7109 pcon=4.7194 forget=10.7675 favg=-11.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=5.9608 mle=1.6645 pcon=4.7184 forget=10.7576 favg=-11.1797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=6.1526 mle=1.7049 pcon=4.7173 forget=10.7851 favg=-11.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=6.3478 mle=1.6655 pcon=4.7161 forget=10.7865 favg=-10.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=6.4650 mle=1.7392 pcon=4.7150 forget=10.7530 favg=-10.7422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=6.2557 mle=1.6169 pcon=4.7138 forget=10.7766 favg=-10.8516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=6.3235 mle=1.7631 pcon=4.7126 forget=10.7462 favg=-10.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=6.0525 mle=1.7185 pcon=4.7114 forget=10.6695 favg=-11.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=6.0284 mle=1.8468 pcon=4.7104 forget=10.5572 favg=-11.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=5.8830 mle=1.5827 pcon=4.7091 forget=10.4661 favg=-10.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=6.6790 mle=1.7053 pcon=4.7081 forget=10.4609 favg=-10.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=8.3832 mle=1.7143 pcon=4.7068 forget=10.4620 favg=-8.5000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=8.6419 mle=1.6534 pcon=4.7056 forget=10.5641 favg=-8.2812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=9.0222 mle=1.5919 pcon=4.7045 forget=10.5618 favg=-7.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=9.9482 mle=1.5744 pcon=4.7034 forget=10.7291 favg=-7.0586 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=10.0046 mle=1.6437 pcon=4.7022 forget=10.8422 favg=-7.1836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=9.3305 mle=1.7783 pcon=4.7013 forget=10.9289 favg=-8.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=8.2465 mle=1.8502 pcon=4.7004 forget=10.8600 favg=-9.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=10.0470 mle=1.7405 pcon=4.6996 forget=10.9428 favg=-7.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=10.7775 mle=1.7497 pcon=4.6989 forget=10.9539 favg=-6.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=10.4525 mle=1.7225 pcon=4.6981 forget=10.9733 favg=-6.9414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=9.7347 mle=1.6375 pcon=4.6974 forget=10.9857 favg=-7.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=8.1610 mle=1.5036 pcon=4.6965 forget=10.9531 favg=-8.9922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=9.8709 mle=1.5917 pcon=4.6957 forget=10.9741 favg=-7.3906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=10.6478 mle=1.9971 pcon=4.6949 forget=11.1003 favg=-7.1445 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=11.6015 mle=1.7862 pcon=4.6941 forget=10.9766 favg=-5.8555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=10.2811 mle=1.7047 pcon=4.6932 forget=10.9065 favg=-7.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=10.7111 mle=1.6544 pcon=4.6923 forget=10.9660 favg=-6.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=10.8666 mle=1.7182 pcon=4.6917 forget=11.0427 favg=-6.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=8.4639 mle=1.6647 pcon=4.6911 forget=11.1316 favg=-9.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=8.0146 mle=1.6605 pcon=4.6905 forget=11.1324 favg=-9.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=11.1570 mle=1.7631 pcon=4.6900 forget=11.1336 favg=-6.4297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=9.6622 mle=1.6467 pcon=4.6893 forget=10.9200 favg=-7.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=10.4099 mle=1.7193 pcon=4.6886 forget=10.9278 favg=-6.9258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=13.7061 mle=1.7060 pcon=4.6880 forget=11.0231 favg=-3.7109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=11.1064 mle=1.6927 pcon=4.6874 forget=11.1443 favg=-6.4180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.4928 mle=1.8268 pcon=4.6867 forget=11.2372 favg=-10.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=9.3901 mle=1.5279 pcon=4.6860 forget=11.2309 favg=-8.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=10.8734 mle=1.8350 pcon=4.6854 forget=11.1382 favg=-6.7852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=7.9416 mle=1.5618 pcon=4.6847 forget=10.9919 favg=-9.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=9.3327 mle=1.7698 pcon=4.6841 forget=10.9179 favg=-8.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=11.8195 mle=1.7019 pcon=4.6835 forget=11.0748 favg=-5.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=11.6035 mle=1.6118 pcon=4.6829 forget=11.1838 favg=-5.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=9.4694 mle=1.7929 pcon=4.6824 forget=11.3066 favg=-8.3125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=8.0104 mle=1.6604 pcon=4.6820 forget=11.4414 favg=-9.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=8.4815 mle=1.5844 pcon=4.6815 forget=11.5593 favg=-9.3438 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=8.5922 mle=1.5319 pcon=4.6810 forget=11.4808 favg=-9.1016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=8.2260 mle=1.6784 pcon=4.6804 forget=11.2812 favg=-9.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=8.9940 mle=1.6537 pcon=4.6798 forget=11.3090 favg=-8.6484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=11.6360 mle=1.7249 pcon=4.6792 forget=11.3842 favg=-6.1523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=12.4592 mle=1.5957 pcon=4.6786 forget=11.4428 favg=-5.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=11.6019 mle=1.6979 pcon=4.6781 forget=11.4838 favg=-6.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=10.2734 mle=1.6250 pcon=4.6777 forget=11.5841 favg=-7.6133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=10.7555 mle=1.7410 pcon=4.6772 forget=11.7865 favg=-7.4492 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=10.8947 mle=1.6429 pcon=4.6769 forget=11.8522 favg=-7.2773 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=9.8142 mle=1.5942 pcon=4.6765 forget=11.7388 favg=-8.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.6877 mle=1.5365 pcon=4.6763 forget=11.5999 favg=-10.1250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=9.1567 mle=1.7764 pcon=4.6759 forget=11.6107 favg=-8.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=12.8678 mle=2.0061 pcon=4.6755 forget=11.7486 favg=-5.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=13.6178 mle=1.5722 pcon=4.6751 forget=11.8119 favg=-4.4414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=10.9214 mle=1.7486 pcon=4.6747 forget=11.7481 favg=-7.2500 nr=64 nf=64 protos=540 fproto_sim=NA
 68%|██████▊   | 34/50 [16:53<11:03, 41.47s/it] 70%|███████   | 35/50 [17:36<10:26, 41.73s/it] 72%|███████▏  | 36/50 [18:18<09:46, 41.86s/it] 74%|███████▍  | 37/50 [19:01<09:08, 42.20s/it] 76%|███████▌  | 38/50 [19:41<08:20, 41.74s/it] 78%|███████▊  | 39/50 [20:24<07:41, 41.92s/it] 80%|████████  | 40/50 [21:06<07:00, 42.03s/it] 82%|████████▏ | 41/50 [21:46<06:13, 41.51s/it] 84%|████████▍ | 42/50 [22:28<05:31, 41.45s/it][loss] ep 33 it 230 total=8.7858 mle=1.6884 pcon=4.6743 forget=11.7591 favg=-9.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=10.4941 mle=1.6894 pcon=4.6739 forget=11.8926 favg=-7.7617 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=11.9753 mle=1.7924 pcon=4.6736 forget=11.7944 favg=-6.2852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=10.9103 mle=1.6869 pcon=4.6733 forget=11.7766 favg=-7.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=8.7281 mle=1.7618 pcon=4.6728 forget=11.7779 favg=-9.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=8.0720 mle=1.5919 pcon=4.6724 forget=11.8937 favg=-10.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=10.3085 mle=1.6845 pcon=4.6720 forget=11.9989 favg=-8.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=12.8002 mle=1.7021 pcon=4.6717 forget=12.0670 favg=-5.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=12.9617 mle=1.7664 pcon=4.6713 forget=11.9928 favg=-5.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=10.1285 mle=1.7022 pcon=4.6708 forget=11.8337 favg=-8.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=9.2641 mle=1.7553 pcon=4.6704 forget=11.8775 favg=-9.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=10.1692 mle=1.6960 pcon=4.6700 forget=11.8813 favg=-8.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=11.0125 mle=1.6709 pcon=4.6697 forget=11.8984 favg=-7.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=11.1018 mle=1.8474 pcon=4.6692 forget=11.7219 favg=-7.1367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=10.2990 mle=1.6883 pcon=4.6689 forget=11.8323 favg=-7.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=9.5108 mle=1.6318 pcon=4.6686 forget=11.8744 favg=-8.6641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=9.4166 mle=1.7223 pcon=4.6682 forget=11.9792 favg=-8.9531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=9.2890 mle=1.6138 pcon=4.6678 forget=12.0308 favg=-9.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=9.6327 mle=1.8015 pcon=4.6675 forget=11.9606 favg=-8.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=9.6759 mle=1.8282 pcon=4.6672 forget=12.0087 favg=-8.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=9.1825 mle=1.5653 pcon=4.6669 forget=12.0362 favg=-9.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=9.3157 mle=1.6233 pcon=4.6666 forget=11.9242 favg=-8.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=9.3184 mle=1.6924 pcon=4.6663 forget=11.8660 favg=-8.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=9.1108 mle=1.6112 pcon=4.6660 forget=11.7867 favg=-8.9531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=9.0071 mle=1.6947 pcon=4.6659 forget=11.6465 favg=-9.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=9.6571 mle=1.6933 pcon=4.6655 forget=11.5952 favg=-8.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=10.5706 mle=1.6772 pcon=4.6652 forget=11.7399 favg=-7.5117 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=11.1810 mle=1.6578 pcon=4.6647 forget=11.8311 favg=-6.9727 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=11.4835 mle=1.7571 pcon=4.6645 forget=11.8041 favg=-6.7422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=10.8402 mle=1.6934 pcon=4.6641 forget=11.8615 favg=-7.3789 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=9.7621 mle=1.7291 pcon=4.6637 forget=11.9631 favg=-8.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=8.8046 mle=1.8535 pcon=4.6633 forget=11.8582 favg=-9.5703 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=8.4329 mle=1.6585 pcon=4.6629 forget=12.0725 favg=-9.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=9.3799 mle=1.7035 pcon=4.6626 forget=12.0450 favg=-9.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=10.8276 mle=1.7150 pcon=4.6625 forget=11.9970 favg=-7.5469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=11.0734 mle=1.7253 pcon=4.6624 forget=11.8654 favg=-7.1797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=9.6359 mle=1.5700 pcon=4.6622 forget=11.7552 favg=-8.3516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=8.3874 mle=1.6902 pcon=4.6620 forget=11.7853 favg=-9.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=8.6860 mle=1.6948 pcon=4.6617 forget=11.7514 favg=-9.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=10.9483 mle=1.6410 pcon=4.6616 forget=11.8215 favg=-7.1758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=12.9212 mle=1.6913 pcon=4.6613 forget=11.8615 favg=-5.2930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=13.6081 mle=1.6141 pcon=4.6610 forget=11.9815 favg=-4.6484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=13.0400 mle=1.5451 pcon=4.6608 forget=12.0294 favg=-5.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=11.4296 mle=1.7331 pcon=4.6607 forget=12.0592 favg=-7.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=9.6193 mle=1.6614 pcon=4.6604 forget=11.9382 favg=-8.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=9.1559 mle=1.7133 pcon=4.6602 forget=11.9308 favg=-9.1484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=9.3476 mle=1.5471 pcon=4.6600 forget=12.1093 favg=-8.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=10.8165 mle=1.6543 pcon=4.6598 forget=12.1158 favg=-7.6133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=11.6126 mle=1.4973 pcon=4.6596 forget=12.1119 favg=-6.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=12.1583 mle=1.6456 pcon=4.6596 forget=12.1227 favg=-6.2695 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=11.3790 mle=1.6029 pcon=4.6593 forget=12.0230 favg=-6.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=9.8605 mle=1.7321 pcon=4.6592 forget=11.9536 favg=-8.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=8.8359 mle=1.6617 pcon=4.6588 forget=11.9685 favg=-9.4531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=10.0439 mle=1.5729 pcon=4.6587 forget=12.0310 favg=-8.2188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=12.5873 mle=1.8242 pcon=4.6585 forget=11.8312 favg=-5.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=14.6746 mle=1.8712 pcon=4.6583 forget=11.9148 favg=-3.7695 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=15.0809 mle=1.6486 pcon=4.6581 forget=12.0456 favg=-3.2715 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=14.3520 mle=1.4803 pcon=4.6579 forget=12.0263 favg=-3.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=12.6166 mle=1.5470 pcon=4.6577 forget=12.0955 favg=-5.6836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=11.4078 mle=1.9297 pcon=4.6576 forget=11.9807 favg=-7.1602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=10.0116 mle=1.6348 pcon=4.6573 forget=12.1414 favg=-8.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=9.9623 mle=1.6377 pcon=4.6572 forget=12.1284 favg=-8.4609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=10.5199 mle=1.7311 pcon=4.6570 forget=12.1396 favg=-8.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=10.8994 mle=1.5569 pcon=4.6571 forget=12.1659 favg=-7.4805 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=11.2727 mle=1.5867 pcon=4.6571 forget=12.2281 favg=-7.1992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=11.4022 mle=1.7031 pcon=4.6570 forget=12.1984 favg=-7.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=10.8058 mle=1.6875 pcon=4.6570 forget=12.0746 favg=-7.6133 nr=64 nf=64 protos=540 fproto_sim=NA
 86%|████████▌ | 43/50 [23:09<04:49, 41.39s/it] 88%|████████▊ | 44/50 [23:51<04:09, 41.66s/it] 90%|█████████ | 45/50 [24:31<03:25, 41.17s/it] 92%|█████████▏| 46/50 [25:12<02:44, 41.19s/it] 94%|█████████▍| 47/50 [25:51<02:01, 40.41s/it] 96%|█████████▌| 48/50 [26:31<01:20, 40.14s/it] 98%|█████████▊| 49/50 [27:12<00:40, 40.51s/it]100%|██████████| 50/50 [27:52<00:00, 40.36s/it]100%|██████████| 50/50 [27:52<00:00, 33.45s/it]
[loss] ep 42 it 70 total=10.0778 mle=1.7116 pcon=4.6568 forget=12.1470 favg=-8.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=9.3083 mle=1.8787 pcon=4.6566 forget=12.1323 favg=-9.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=8.2655 mle=1.6341 pcon=4.6565 forget=11.9906 favg=-10.0156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=8.0507 mle=1.6868 pcon=4.6565 forget=12.0277 favg=-10.3203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.5647 mle=1.7985 pcon=4.6564 forget=12.0941 favg=-9.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=9.7931 mle=1.7523 pcon=4.6564 forget=12.0094 favg=-8.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=11.0836 mle=1.6756 pcon=4.6564 forget=11.9781 favg=-7.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=12.3078 mle=1.6775 pcon=4.6563 forget=12.0014 favg=-6.0273 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=13.0524 mle=1.6759 pcon=4.6561 forget=12.0445 favg=-5.3242 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=13.4151 mle=1.7385 pcon=4.6561 forget=12.0128 favg=-4.9922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=13.1437 mle=1.6104 pcon=4.6559 forget=11.9985 favg=-5.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=12.4483 mle=1.5918 pcon=4.6557 forget=12.0367 favg=-5.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=11.5604 mle=1.5730 pcon=4.6556 forget=12.0389 favg=-6.7070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=10.4821 mle=1.5674 pcon=4.6553 forget=12.0953 favg=-7.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=9.7074 mle=1.5613 pcon=4.6552 forget=12.0769 favg=-8.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=9.6770 mle=1.7618 pcon=4.6550 forget=12.0572 favg=-8.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=9.6889 mle=1.6924 pcon=4.6548 forget=12.1699 favg=-8.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=10.2127 mle=1.6904 pcon=4.6546 forget=12.0786 favg=-8.2109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=10.6420 mle=1.5716 pcon=4.6545 forget=12.2011 favg=-7.7852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=11.1043 mle=1.6056 pcon=4.6544 forget=12.0513 favg=-7.2070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=11.5550 mle=1.7992 pcon=4.6543 forget=12.0234 favg=-6.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=11.6663 mle=1.7864 pcon=4.6542 forget=12.1436 favg=-6.9180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=11.5388 mle=1.6536 pcon=4.6541 forget=12.1062 favg=-6.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=11.2537 mle=1.6107 pcon=4.6540 forget=12.1804 favg=-7.1914 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=10.7880 mle=1.6268 pcon=4.6539 forget=12.1557 favg=-7.6484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=10.3476 mle=1.5816 pcon=4.6537 forget=12.1904 favg=-8.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=10.0040 mle=1.6493 pcon=4.6537 forget=12.1776 favg=-8.4766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=9.3746 mle=1.6361 pcon=4.6536 forget=12.1708 favg=-9.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=8.7731 mle=1.6433 pcon=4.6534 forget=12.1717 favg=-9.6953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=8.3655 mle=1.5995 pcon=4.6534 forget=12.1205 favg=-10.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=7.9335 mle=1.5531 pcon=4.6534 forget=12.1098 favg=-10.3828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=7.6075 mle=1.5774 pcon=4.6533 forget=12.2440 favg=-10.8672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=7.7234 mle=1.8348 pcon=4.6533 forget=12.1416 favg=-10.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=7.4102 mle=1.5147 pcon=4.6532 forget=12.2110 favg=-10.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=7.9231 mle=1.8215 pcon=4.6531 forget=12.1516 favg=-10.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=7.9701 mle=1.7364 pcon=4.6530 forget=12.2135 favg=-10.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=8.2742 mle=1.5633 pcon=4.6530 forget=12.2219 favg=-10.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=8.9778 mle=1.7368 pcon=4.6529 forget=12.1428 favg=-9.5547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=9.2442 mle=1.5999 pcon=4.6527 forget=12.1166 favg=-9.1250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=9.7601 mle=1.6122 pcon=4.6527 forget=12.1983 favg=-8.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=10.4836 mle=1.6996 pcon=4.6525 forget=12.1628 favg=-8.0312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=11.0713 mle=1.6399 pcon=4.6523 forget=12.2010 favg=-7.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=11.5753 mle=1.5126 pcon=4.6523 forget=12.2190 favg=-6.8086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=12.2210 mle=1.6948 pcon=4.6522 forget=12.1318 favg=-6.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=12.8764 mle=1.6551 pcon=4.6521 forget=12.1942 favg=-5.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=13.4432 mle=1.7308 pcon=4.6521 forget=12.1971 favg=-5.1367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=13.7684 mle=1.6205 pcon=4.6521 forget=12.2341 favg=-4.7383 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=14.3671 mle=1.6621 pcon=4.6520 forget=12.2522 favg=-4.1992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=14.9132 mle=1.7969 pcon=4.6519 forget=12.2398 favg=-3.7754 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=14.9349 mle=1.7143 pcon=4.6520 forget=12.1194 favg=-3.5508 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=15.3540 mle=1.7649 pcon=4.6520 forget=12.2925 favg=-3.3555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=15.3946 mle=1.6767 pcon=4.6519 forget=12.2223 favg=-3.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=15.4619 mle=1.6098 pcon=4.6518 forget=12.3175 favg=-3.1172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=15.6100 mle=1.5995 pcon=4.6516 forget=12.2691 favg=-2.9102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=15.8245 mle=1.6461 pcon=4.6516 forget=12.2612 favg=-2.7344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=15.9786 mle=1.6576 pcon=4.6516 forget=12.3159 favg=-2.6465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=16.0850 mle=1.6124 pcon=4.6515 forget=12.2507 favg=-2.4297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=16.2631 mle=1.7558 pcon=4.6514 forget=12.2036 favg=-2.3477 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=16.4487 mle=1.7658 pcon=4.6512 forget=12.2993 favg=-2.2676 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=16.2464 mle=1.6709 pcon=4.6511 forget=12.3014 favg=-2.3770 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=16.2837 mle=1.6169 pcon=4.6511 forget=12.2657 favg=-2.2500 nr=64 nf=64 protos=540 fproto_sim=NA
runner.sh: line 89: _w: command not found
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:52,  2.26it/s]  2%|▏         | 7/391 [00:00<00:23, 16.13it/s]  4%|▎         | 14/391 [00:00<00:13, 28.31it/s]  5%|▌         | 21/391 [00:00<00:09, 38.27it/s]  7%|▋         | 27/391 [00:00<00:08, 43.93it/s]  8%|▊         | 33/391 [00:00<00:07, 47.26it/s] 10%|▉         | 39/391 [00:01<00:07, 50.11it/s] 12%|█▏        | 45/391 [00:01<00:06, 51.70it/s] 13%|█▎        | 52/391 [00:01<00:06, 53.90it/s] 15%|█▍        | 58/391 [00:01<00:06, 55.41it/s] 16%|█▋        | 64/391 [00:01<00:05, 56.15it/s] 18%|█▊        | 70/391 [00:01<00:05, 55.60it/s] 19%|█▉        | 76/391 [00:01<00:05, 55.45it/s] 21%|██        | 82/391 [00:01<00:05, 53.48it/s] 23%|██▎       | 88/391 [00:01<00:05, 53.74it/s] 24%|██▍       | 95/391 [00:02<00:05, 55.93it/s] 26%|██▌       | 102/391 [00:02<00:05, 57.43it/s] 28%|██▊       | 109/391 [00:02<00:04, 56.89it/s] 30%|██▉       | 116/391 [00:02<00:04, 60.14it/s] 31%|███▏      | 123/391 [00:02<00:04, 59.35it/s] 33%|███▎      | 129/391 [00:02<00:04, 58.40it/s] 35%|███▍      | 136/391 [00:02<00:04, 58.11it/s] 36%|███▋      | 142/391 [00:02<00:04, 56.00it/s] 38%|███▊      | 149/391 [00:03<00:04, 56.95it/s] 40%|███▉      | 156/391 [00:03<00:03, 59.36it/s] 41%|████▏     | 162/391 [00:03<00:03, 59.09it/s] 43%|████▎     | 168/391 [00:03<00:03, 57.30it/s] 45%|████▍     | 174/391 [00:03<00:03, 57.55it/s] 46%|████▋     | 181/391 [00:03<00:03, 58.47it/s] 48%|████▊     | 189/391 [00:03<00:03, 58.77it/s] 50%|█████     | 196/391 [00:03<00:03, 58.83it/s] 52%|█████▏    | 203/391 [00:03<00:03, 58.83it/s] 54%|█████▎    | 210/391 [00:04<00:03, 60.08it/s] 55%|█████▌    | 217/391 [00:04<00:02, 60.56it/s] 57%|█████▋    | 224/391 [00:04<00:02, 61.19it/s] 59%|█████▉    | 231/391 [00:04<00:02, 59.93it/s] 61%|██████    | 238/391 [00:04<00:02, 59.92it/s] 63%|██████▎   | 245/391 [00:04<00:02, 59.21it/s] 64%|██████▍   | 251/391 [00:04<00:02, 57.35it/s] 66%|██████▌   | 258/391 [00:04<00:02, 57.79it/s] 68%|██████▊   | 264/391 [00:04<00:02, 57.69it/s] 69%|██████▉   | 271/391 [00:05<00:02, 59.74it/s] 71%|███████   | 277/391 [00:05<00:01, 58.51it/s] 72%|███████▏  | 283/391 [00:05<00:01, 58.23it/s] 74%|███████▍  | 289/391 [00:05<00:01, 58.23it/s] 75%|███████▌  | 295/391 [00:05<00:01, 57.31it/s] 77%|███████▋  | 301/391 [00:05<00:01, 57.69it/s] 79%|███████▉  | 308/391 [00:05<00:01, 56.60it/s] 80%|████████  | 314/391 [00:05<00:01, 56.81it/s] 82%|████████▏ | 321/391 [00:05<00:01, 57.06it/s] 84%|████████▍ | 328/391 [00:06<00:01, 59.42it/s] 85%|████████▌ | 334/391 [00:06<00:00, 57.78it/s] 87%|████████▋ | 341/391 [00:06<00:00, 59.72it/s] 89%|████████▉ | 348/391 [00:06<00:00, 59.87it/s] 91%|█████████ | 354/391 [00:06<00:00, 57.87it/s] 92%|█████████▏| 360/391 [00:06<00:00, 57.93it/s] 94%|█████████▎| 366/391 [00:06<00:00, 57.71it/s] 95%|█████████▌| 372/391 [00:06<00:00, 56.16it/s] 97%|█████████▋| 378/391 [00:06<00:00, 56.86it/s] 98%|█████████▊| 384/391 [00:07<00:00, 56.52it/s]100%|██████████| 391/391 [00:07<00:00, 57.78it/s]100%|██████████| 391/391 [00:07<00:00, 54.61it/s]
50000 images processed, 7.336303234100342 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.01it/s] 10%|█         | 8/79 [00:00<00:04, 16.42it/s] 19%|█▉        | 15/79 [00:00<00:02, 27.43it/s] 27%|██▋       | 21/79 [00:00<00:01, 34.72it/s] 34%|███▍      | 27/79 [00:00<00:01, 40.12it/s] 42%|████▏     | 33/79 [00:01<00:01, 45.13it/s] 51%|█████     | 40/79 [00:01<00:00, 49.23it/s] 59%|█████▉    | 47/79 [00:01<00:00, 51.42it/s] 67%|██████▋   | 53/79 [00:01<00:00, 51.52it/s] 76%|███████▌  | 60/79 [00:01<00:00, 54.62it/s] 84%|████████▎ | 66/79 [00:01<00:00, 55.78it/s] 92%|█████████▏| 73/79 [00:01<00:00, 56.83it/s]100%|██████████| 79/79 [00:02<00:00, 23.05it/s]100%|██████████| 79/79 [00:02<00:00, 32.88it/s]
10000 images processed, 2.4553136825561523 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:36,  2.09it/s]  4%|▍         | 8/204 [00:00<00:11, 17.49it/s]  7%|▋         | 14/204 [00:00<00:06, 27.27it/s] 10%|▉         | 20/204 [00:00<00:05, 34.83it/s] 12%|█▏        | 25/204 [00:00<00:04, 37.83it/s] 15%|█▌        | 31/204 [00:01<00:04, 42.54it/s] 18%|█▊        | 37/204 [00:01<00:03, 45.46it/s] 21%|██        | 43/204 [00:01<00:03, 47.46it/s] 24%|██▍       | 49/204 [00:01<00:03, 50.06it/s] 27%|██▋       | 55/204 [00:01<00:02, 50.28it/s] 30%|███       | 62/204 [00:01<00:02, 52.83it/s] 34%|███▍      | 69/204 [00:01<00:02, 53.68it/s] 37%|███▋      | 76/204 [00:01<00:02, 56.97it/s] 40%|████      | 82/204 [00:01<00:02, 55.67it/s] 43%|████▎     | 88/204 [00:02<00:02, 55.00it/s] 47%|████▋     | 95/204 [00:02<00:01, 57.42it/s] 50%|█████     | 102/204 [00:02<00:01, 59.30it/s] 53%|█████▎    | 108/204 [00:02<00:01, 58.48it/s] 56%|█████▌    | 114/204 [00:02<00:01, 56.92it/s] 59%|█████▉    | 120/204 [00:02<00:01, 56.86it/s] 62%|██████▏   | 126/204 [00:02<00:01, 56.53it/s] 65%|██████▍   | 132/204 [00:02<00:01, 56.95it/s] 68%|██████▊   | 139/204 [00:02<00:01, 59.18it/s] 72%|███████▏  | 147/204 [00:03<00:00, 60.70it/s] 75%|███████▌  | 154/204 [00:03<00:00, 59.25it/s] 78%|███████▊  | 160/204 [00:03<00:00, 57.33it/s] 81%|████████▏ | 166/204 [00:03<00:00, 57.27it/s] 84%|████████▍ | 172/204 [00:03<00:00, 56.39it/s] 88%|████████▊ | 179/204 [00:03<00:00, 57.65it/s] 91%|█████████ | 185/204 [00:03<00:00, 57.21it/s] 94%|█████████▍| 192/204 [00:03<00:00, 59.13it/s] 98%|█████████▊| 200/204 [00:03<00:00, 60.17it/s]100%|██████████| 204/204 [00:04<00:00, 50.66it/s]
26032 images processed, 4.093298435211182 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:49,  1.57it/s]  9%|▉         | 7/79 [00:00<00:06, 11.96it/s] 15%|█▌        | 12/79 [00:00<00:03, 19.24it/s] 22%|██▏       | 17/79 [00:00<00:02, 25.77it/s] 28%|██▊       | 22/79 [00:01<00:01, 30.86it/s] 34%|███▍      | 27/79 [00:01<00:01, 32.16it/s] 42%|████▏     | 33/79 [00:01<00:01, 34.66it/s] 48%|████▊     | 38/79 [00:01<00:01, 38.24it/s] 54%|█████▍    | 43/79 [00:01<00:00, 40.01it/s] 62%|██████▏   | 49/79 [00:01<00:00, 40.69it/s] 70%|██████▉   | 55/79 [00:01<00:00, 44.26it/s] 76%|███████▌  | 60/79 [00:01<00:00, 41.43it/s] 84%|████████▎ | 66/79 [00:02<00:00, 44.99it/s] 91%|█████████ | 72/79 [00:02<00:00, 46.89it/s] 97%|█████████▋| 77/79 [00:02<00:00, 43.44it/s]100%|██████████| 79/79 [00:02<00:00, 33.39it/s]
10000 images processed, 2.40533185005188 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:37,  2.07it/s]  8%|▊         | 6/79 [00:00<00:05, 12.96it/s] 14%|█▍        | 11/79 [00:00<00:03, 21.50it/s] 22%|██▏       | 17/79 [00:00<00:02, 30.29it/s] 29%|██▉       | 23/79 [00:00<00:01, 36.47it/s] 37%|███▋      | 29/79 [00:01<00:01, 42.12it/s] 47%|████▋     | 37/79 [00:01<00:00, 51.11it/s] 54%|█████▍    | 43/79 [00:01<00:00, 52.00it/s] 62%|██████▏   | 49/79 [00:01<00:00, 53.91it/s] 70%|██████▉   | 55/79 [00:01<00:00, 53.45it/s] 77%|███████▋  | 61/79 [00:01<00:00, 53.38it/s] 85%|████████▍ | 67/79 [00:01<00:00, 51.79it/s] 92%|█████████▏| 73/79 [00:01<00:00, 51.82it/s]100%|██████████| 79/79 [00:01<00:00, 41.73it/s]
10000 images processed, 1.9230091571807861 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:28,  2.46it/s]  7%|▋         | 5/70 [00:00<00:05, 12.01it/s] 16%|█▌        | 11/70 [00:00<00:02, 24.10it/s] 24%|██▍       | 17/70 [00:00<00:01, 33.15it/s] 34%|███▍      | 24/70 [00:00<00:01, 41.91it/s] 43%|████▎     | 30/70 [00:00<00:00, 46.36it/s] 51%|█████▏    | 36/70 [00:01<00:00, 47.01it/s] 60%|██████    | 42/70 [00:01<00:00, 47.73it/s] 69%|██████▊   | 48/70 [00:01<00:00, 49.55it/s] 77%|███████▋  | 54/70 [00:01<00:00, 51.94it/s] 89%|████████▊ | 62/70 [00:01<00:00, 55.70it/s]100%|██████████| 70/70 [00:01<00:00, 60.73it/s]100%|██████████| 70/70 [00:01<00:00, 42.58it/s]
8925 images processed, 1.6758496761322021 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:47,  1.07s/it]  7%|▋         | 3/45 [00:01<00:13,  3.14it/s] 20%|██        | 9/45 [00:01<00:04,  8.42it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.85it/s] 31%|███       | 14/45 [00:01<00:02, 11.24it/s] 38%|███▊      | 17/45 [00:02<00:02, 10.10it/s] 49%|████▉     | 22/45 [00:02<00:01, 13.97it/s] 56%|█████▌    | 25/45 [00:02<00:01, 11.63it/s] 60%|██████    | 27/45 [00:02<00:01, 12.33it/s] 67%|██████▋   | 30/45 [00:03<00:01, 13.82it/s] 73%|███████▎  | 33/45 [00:03<00:01, 10.31it/s] 78%|███████▊  | 35/45 [00:03<00:00, 10.66it/s] 89%|████████▉ | 40/45 [00:03<00:00, 13.40it/s] 93%|█████████▎| 42/45 [00:04<00:00,  8.36it/s]100%|██████████| 45/45 [00:04<00:00,  9.84it/s]
5640 images processed, 4.650133371353149 seconds used

26.513543128967285
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.78  98.97
places365     76.59  79.16
LSUN          30.54  94.50
iSUN          80.63  78.83
dtd           45.50  89.93
AVG           47.61  88.28
Retain-Acc: 0.7331
Forget-as-OOD (retain known vs forget novel):
  FPR: 74.40 AUROC: 87.94 AUIN: 98.49
44.52539539337158
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
