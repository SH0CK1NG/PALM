nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='ga', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [00:34<02:17, 34.47s/it] 40%|████      | 2/5 [00:50<01:11, 23.79s/it] 60%|██████    | 3/5 [01:06<00:40, 20.13s/it] 80%|████████  | 4/5 [01:22<00:18, 18.41s/it]100%|██████████| 5/5 [01:38<00:00, 17.53s/it]100%|██████████| 5/5 [01:38<00:00, 19.66s/it]
[loss-ga] ep 0 it 0 total=-0.0698 ce_r=0.0852 ce_f=0.1551
[loss-ga] ep 0 it 50 total=-0.0689 ce_r=0.0789 ce_f=0.1478
[loss-ga] ep 0 it 100 total=-0.0159 ce_r=0.0292 ce_f=0.0451
[loss-ga] ep 0 it 150 total=-0.0358 ce_r=0.1281 ce_f=0.1639
[loss-ga] ep 0 it 200 total=-0.0158 ce_r=0.0449 ce_f=0.0607
[loss-ga] ep 0 it 250 total=-0.0020 ce_r=0.0601 ce_f=0.0621
[loss-ga] ep 0 it 300 total=-0.1184 ce_r=0.1405 ce_f=0.2589
[loss-ga] ep 0 it 350 total=-0.0239 ce_r=0.0331 ce_f=0.0570
[loss-ga] ep 1 it 10 total=-0.0768 ce_r=0.0837 ce_f=0.1605
[loss-ga] ep 1 it 60 total=-0.1589 ce_r=0.1828 ce_f=0.3417
[loss-ga] ep 1 it 110 total=-0.4962 ce_r=0.5572 ce_f=1.0534
[loss-ga] ep 1 it 160 total=-1.1900 ce_r=1.2127 ce_f=2.4027
[loss-ga] ep 1 it 210 total=-1.4102 ce_r=1.4520 ce_f=2.8622
[loss-ga] ep 1 it 260 total=-2.6398 ce_r=2.6820 ce_f=5.3218
[loss-ga] ep 1 it 310 total=-3.1891 ce_r=3.3288 ce_f=6.5179
[loss-ga] ep 1 it 360 total=-3.4528 ce_r=3.5459 ce_f=6.9987
[loss-ga] ep 2 it 20 total=-4.3343 ce_r=4.5649 ce_f=8.8992
[loss-ga] ep 2 it 70 total=-4.0002 ce_r=4.3188 ce_f=8.3191
[loss-ga] ep 2 it 120 total=-4.6714 ce_r=4.7215 ce_f=9.3929
[loss-ga] ep 2 it 170 total=-4.4115 ce_r=4.7631 ce_f=9.1746
[loss-ga] ep 2 it 220 total=-5.1681 ce_r=5.4463 ce_f=10.6145
[loss-ga] ep 2 it 270 total=-5.4771 ce_r=5.5641 ce_f=11.0413
[loss-ga] ep 2 it 320 total=-5.5187 ce_r=5.8458 ce_f=11.3645
[loss-ga] ep 2 it 370 total=-6.6269 ce_r=6.8915 ce_f=13.5185
[loss-ga] ep 3 it 30 total=-6.4378 ce_r=6.6665 ce_f=13.1043
[loss-ga] ep 3 it 80 total=-6.6664 ce_r=6.7110 ce_f=13.3773
[loss-ga] ep 3 it 130 total=-6.6498 ce_r=6.9244 ce_f=13.5742
[loss-ga] ep 3 it 180 total=-6.4742 ce_r=6.6911 ce_f=13.1652
[loss-ga] ep 3 it 230 total=-6.8700 ce_r=7.0432 ce_f=13.9132
[loss-ga] ep 3 it 280 total=-6.7028 ce_r=6.9501 ce_f=13.6529
[loss-ga] ep 3 it 330 total=-6.6726 ce_r=6.9962 ce_f=13.6689
[loss-ga] ep 3 it 380 total=-6.9973 ce_r=7.2912 ce_f=14.2884
[loss-ga] ep 4 it 40 total=-7.0210 ce_r=7.1956 ce_f=14.2166
[loss-ga] ep 4 it 90 total=-6.9962 ce_r=7.2027 ce_f=14.1989
[loss-ga] ep 4 it 140 total=-7.2236 ce_r=7.2727 ce_f=14.4964
[loss-ga] ep 4 it 190 total=-7.1720 ce_r=7.4256 ce_f=14.5976
[loss-ga] ep 4 it 240 total=-7.2896 ce_r=7.4995 ce_f=14.7892
[loss-ga] ep 4 it 290 total=-7.2625 ce_r=7.4197 ce_f=14.6822
[loss-ga] ep 4 it 340 total=-7.4654 ce_r=7.5445 ce_f=15.0099
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10.pt
resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:37,  1.79it/s]  3%|▎         | 11/391 [00:00<00:17, 21.78it/s]  5%|▌         | 21/391 [00:00<00:09, 39.10it/s]  8%|▊         | 31/391 [00:00<00:06, 53.37it/s] 10%|█         | 41/391 [00:00<00:05, 63.20it/s] 13%|█▎        | 50/391 [00:01<00:05, 62.05it/s] 15%|█▍        | 58/391 [00:01<00:05, 66.25it/s] 17%|█▋        | 66/391 [00:01<00:05, 61.79it/s] 19%|█▉        | 74/391 [00:01<00:04, 65.63it/s] 21%|██▏       | 84/391 [00:01<00:04, 73.44it/s] 24%|██▍       | 94/391 [00:01<00:03, 78.80it/s] 27%|██▋       | 105/391 [00:01<00:03, 85.07it/s] 29%|██▉       | 115/391 [00:01<00:03, 88.38it/s] 32%|███▏      | 125/391 [00:02<00:02, 91.42it/s] 35%|███▍      | 135/391 [00:02<00:02, 93.13it/s] 37%|███▋      | 145/391 [00:02<00:02, 82.65it/s] 39%|███▉      | 154/391 [00:02<00:03, 69.70it/s] 41%|████▏     | 162/391 [00:02<00:03, 66.19it/s] 43%|████▎     | 170/391 [00:02<00:03, 68.25it/s] 46%|████▌     | 180/391 [00:02<00:02, 76.15it/s] 49%|████▉     | 191/391 [00:02<00:02, 83.08it/s] 52%|█████▏    | 202/391 [00:03<00:02, 87.96it/s] 54%|█████▍    | 212/391 [00:03<00:01, 90.41it/s] 57%|█████▋    | 222/391 [00:03<00:02, 75.58it/s] 59%|█████▉    | 231/391 [00:03<00:02, 74.11it/s] 62%|██████▏   | 241/391 [00:03<00:01, 80.45it/s] 64%|██████▍   | 251/391 [00:03<00:01, 85.50it/s] 67%|██████▋   | 261/391 [00:03<00:01, 89.03it/s] 69%|██████▉   | 271/391 [00:03<00:01, 92.01it/s] 72%|███████▏  | 281/391 [00:03<00:01, 94.02it/s] 75%|███████▍  | 292/391 [00:04<00:01, 95.99it/s] 77%|███████▋  | 303/391 [00:04<00:00, 97.22it/s] 80%|████████  | 313/391 [00:04<00:00, 97.49it/s] 83%|████████▎ | 323/391 [00:04<00:00, 97.00it/s] 85%|████████▌ | 333/391 [00:04<00:00, 97.47it/s] 88%|████████▊ | 343/391 [00:04<00:00, 97.52it/s] 90%|█████████ | 353/391 [00:04<00:00, 97.38it/s] 93%|█████████▎| 363/391 [00:04<00:00, 97.72it/s] 96%|█████████▌| 374/391 [00:04<00:00, 99.06it/s] 98%|█████████▊| 385/391 [00:04<00:00, 100.05it/s]100%|██████████| 391/391 [00:05<00:00, 77.50it/s] 
50000 images processed, 5.15797758102417 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:55,  1.40it/s] 14%|█▍        | 11/79 [00:00<00:03, 17.77it/s] 27%|██▋       | 21/79 [00:00<00:01, 33.41it/s] 39%|███▉      | 31/79 [00:01<00:01, 47.57it/s] 52%|█████▏    | 41/79 [00:01<00:00, 59.76it/s] 65%|██████▍   | 51/79 [00:01<00:00, 69.81it/s] 78%|███████▊  | 62/79 [00:01<00:00, 78.43it/s] 92%|█████████▏| 73/79 [00:01<00:00, 84.74it/s]100%|██████████| 79/79 [00:01<00:00, 43.73it/s]
10000 images processed, 1.8467247486114502 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:12,  1.53it/s]  5%|▌         | 11/204 [00:00<00:10, 19.03it/s] 10%|█         | 21/204 [00:00<00:05, 35.39it/s] 15%|█▌        | 31/204 [00:00<00:03, 49.58it/s] 20%|██        | 41/204 [00:01<00:02, 61.00it/s] 25%|██▌       | 51/204 [00:01<00:02, 69.88it/s] 30%|██▉       | 61/204 [00:01<00:01, 77.41it/s] 35%|███▍      | 71/204 [00:01<00:01, 83.27it/s] 40%|███▉      | 81/204 [00:01<00:01, 87.64it/s] 45%|████▍     | 91/204 [00:01<00:01, 90.34it/s] 50%|████▉     | 101/204 [00:01<00:01, 92.40it/s] 54%|█████▍    | 111/204 [00:01<00:00, 93.94it/s] 59%|█████▉    | 121/204 [00:01<00:00, 95.19it/s] 64%|██████▍   | 131/204 [00:01<00:00, 93.74it/s] 69%|██████▉   | 141/204 [00:02<00:00, 91.87it/s] 74%|███████▍  | 151/204 [00:02<00:00, 93.76it/s] 79%|███████▉  | 161/204 [00:02<00:00, 95.09it/s] 84%|████████▍ | 171/204 [00:02<00:00, 96.19it/s] 89%|████████▉ | 182/204 [00:02<00:00, 97.44it/s] 95%|█████████▍| 193/204 [00:02<00:00, 98.50it/s]100%|██████████| 204/204 [00:02<00:00, 98.39it/s]100%|██████████| 204/204 [00:02<00:00, 74.26it/s]
26032 images processed, 2.7931880950927734 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:59,  1.32it/s] 11%|█▏        | 9/79 [00:00<00:05, 13.76it/s] 24%|██▍       | 19/79 [00:00<00:02, 29.26it/s] 37%|███▋      | 29/79 [00:01<00:01, 43.69it/s] 49%|████▉     | 39/79 [00:01<00:00, 56.26it/s] 61%|██████    | 48/79 [00:01<00:00, 51.25it/s] 71%|███████   | 56/79 [00:01<00:00, 54.86it/s] 80%|███████▉  | 63/79 [00:01<00:00, 54.26it/s] 91%|█████████ | 72/79 [00:01<00:00, 54.30it/s]100%|██████████| 79/79 [00:01<00:00, 48.34it/s]100%|██████████| 79/79 [00:01<00:00, 39.81it/s]
10000 images processed, 2.0081939697265625 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:56,  1.38it/s] 14%|█▍        | 11/79 [00:00<00:03, 17.35it/s] 25%|██▌       | 20/79 [00:00<00:01, 30.91it/s] 38%|███▊      | 30/79 [00:01<00:01, 45.20it/s] 51%|█████     | 40/79 [00:01<00:00, 57.30it/s] 63%|██████▎   | 50/79 [00:01<00:00, 66.35it/s] 77%|███████▋  | 61/79 [00:01<00:00, 75.70it/s] 91%|█████████ | 72/79 [00:01<00:00, 82.74it/s]100%|██████████| 79/79 [00:01<00:00, 51.54it/s]
10000 images processed, 1.5542891025543213 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:43,  1.59it/s] 16%|█▌        | 11/70 [00:00<00:03, 19.63it/s] 30%|███       | 21/70 [00:00<00:01, 36.16it/s] 44%|████▍     | 31/70 [00:00<00:00, 50.18it/s] 59%|█████▊    | 41/70 [00:01<00:00, 62.22it/s] 74%|███████▍  | 52/70 [00:01<00:00, 72.81it/s] 90%|█████████ | 63/70 [00:01<00:00, 80.71it/s]100%|██████████| 70/70 [00:01<00:00, 52.53it/s]
8925 images processed, 1.3641328811645508 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:53,  1.21s/it]  4%|▍         | 2/45 [00:01<00:27,  1.58it/s] 27%|██▋       | 12/45 [00:01<00:02, 13.05it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.66it/s] 47%|████▋     | 21/45 [00:01<00:01, 16.76it/s] 71%|███████   | 32/45 [00:02<00:00, 30.82it/s] 84%|████████▍ | 38/45 [00:02<00:00, 17.31it/s]100%|██████████| 45/45 [00:02<00:00, 15.71it/s]
5640 images processed, 2.883881092071533 seconds used

19.374454259872437
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           8.44  98.16  95.12
places365     72.85  78.71  75.88
LSUN          35.12  92.71  92.72
iSUN          70.17  82.63  84.74
dtd           52.11  87.66  91.85
AVG           47.74  87.97  88.06
Retain-Acc: 0.7261
7.9785308837890625
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10_domain.png
