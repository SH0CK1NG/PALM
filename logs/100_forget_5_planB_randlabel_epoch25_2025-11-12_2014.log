nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=25, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/25 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
  4%|▍         | 1/25 [00:30<12:02, 30.09s/it]  8%|▊         | 2/25 [00:45<08:10, 21.31s/it] 12%|█▏        | 3/25 [01:00<06:45, 18.44s/it] 16%|█▌        | 4/25 [01:15<06:02, 17.25s/it] 20%|██        | 5/25 [01:32<05:41, 17.10s/it] 24%|██▍       | 6/25 [01:49<05:22, 16.97s/it] 28%|██▊       | 7/25 [02:04<04:56, 16.48s/it] 32%|███▏      | 8/25 [02:20<04:38, 16.39s/it] 36%|███▌      | 9/25 [02:36<04:19, 16.23s/it] 40%|████      | 10/25 [02:52<04:02, 16.17s/it] 44%|████▍     | 11/25 [03:08<03:43, 15.95s/it] 48%|████▊     | 12/25 [03:23<03:24, 15.75s/it] 52%|█████▏    | 13/25 [03:39<03:09, 15.81s/it] 56%|█████▌    | 14/25 [03:55<02:54, 15.83s/it] 60%|██████    | 15/25 [04:11<02:40, 16.04s/it][loss-randlabel] ep 0 it 0 total=9.7105 ce_r=0.0867 ce_f=9.6239
[loss-randlabel] ep 0 it 50 total=9.0392 ce_r=0.3193 ce_f=8.7199
[loss-randlabel] ep 0 it 100 total=7.5903 ce_r=0.9971 ce_f=6.5933
[loss-randlabel] ep 0 it 150 total=6.6708 ce_r=1.0214 ce_f=5.6495
[loss-randlabel] ep 0 it 200 total=6.4478 ce_r=1.0577 ce_f=5.3902
[loss-randlabel] ep 0 it 250 total=6.3228 ce_r=0.8487 ce_f=5.4741
[loss-randlabel] ep 0 it 300 total=6.2400 ce_r=0.8546 ce_f=5.3854
[loss-randlabel] ep 0 it 350 total=6.2011 ce_r=0.7706 ce_f=5.4304
[loss-randlabel] ep 1 it 10 total=5.9977 ce_r=0.8329 ce_f=5.1648
[loss-randlabel] ep 1 it 60 total=6.1042 ce_r=0.8569 ce_f=5.2473
[loss-randlabel] ep 1 it 110 total=6.1284 ce_r=0.8366 ce_f=5.2918
[loss-randlabel] ep 1 it 160 total=5.9012 ce_r=0.6548 ce_f=5.2463
[loss-randlabel] ep 1 it 210 total=5.8439 ce_r=0.7524 ce_f=5.0915
[loss-randlabel] ep 1 it 260 total=5.9732 ce_r=0.7255 ce_f=5.2477
[loss-randlabel] ep 1 it 310 total=6.0969 ce_r=0.9125 ce_f=5.1844
[loss-randlabel] ep 1 it 360 total=5.6958 ce_r=0.6249 ce_f=5.0709
[loss-randlabel] ep 2 it 20 total=5.8352 ce_r=0.7519 ce_f=5.0833
[loss-randlabel] ep 2 it 70 total=5.8015 ce_r=0.7945 ce_f=5.0070
[loss-randlabel] ep 2 it 120 total=5.7741 ce_r=0.6926 ce_f=5.0815
[loss-randlabel] ep 2 it 170 total=5.8699 ce_r=0.7097 ce_f=5.1602
[loss-randlabel] ep 2 it 220 total=5.6509 ce_r=0.6384 ce_f=5.0125
[loss-randlabel] ep 2 it 270 total=5.7830 ce_r=0.7804 ce_f=5.0026
[loss-randlabel] ep 2 it 320 total=5.9473 ce_r=0.7910 ce_f=5.1563
[loss-randlabel] ep 2 it 370 total=5.7448 ce_r=0.5843 ce_f=5.1605
[loss-randlabel] ep 3 it 30 total=5.7068 ce_r=0.7081 ce_f=4.9987
[loss-randlabel] ep 3 it 80 total=5.8014 ce_r=0.6691 ce_f=5.1324
[loss-randlabel] ep 3 it 130 total=5.8536 ce_r=0.6463 ce_f=5.2073
[loss-randlabel] ep 3 it 180 total=5.8671 ce_r=0.7309 ce_f=5.1362
[loss-randlabel] ep 3 it 230 total=5.7072 ce_r=0.8131 ce_f=4.8941
[loss-randlabel] ep 3 it 280 total=5.7224 ce_r=0.6053 ce_f=5.1171
[loss-randlabel] ep 3 it 330 total=5.7724 ce_r=0.6575 ce_f=5.1149
[loss-randlabel] ep 3 it 380 total=5.7814 ce_r=0.6417 ce_f=5.1397
[loss-randlabel] ep 4 it 40 total=5.6255 ce_r=0.6182 ce_f=5.0072
[loss-randlabel] ep 4 it 90 total=5.7278 ce_r=0.6251 ce_f=5.1027
[loss-randlabel] ep 4 it 140 total=5.7330 ce_r=0.7803 ce_f=4.9527
[loss-randlabel] ep 4 it 190 total=5.6764 ce_r=0.5805 ce_f=5.0959
[loss-randlabel] ep 4 it 240 total=5.7120 ce_r=0.6279 ce_f=5.0841
[loss-randlabel] ep 4 it 290 total=5.6326 ce_r=0.6915 ce_f=4.9410
[loss-randlabel] ep 4 it 340 total=5.7663 ce_r=0.6872 ce_f=5.0791
[loss-randlabel] ep 5 it 0 total=5.7817 ce_r=0.6820 ce_f=5.0997
[loss-randlabel] ep 5 it 50 total=5.7784 ce_r=0.7775 ce_f=5.0009
[loss-randlabel] ep 5 it 100 total=5.7109 ce_r=0.5878 ce_f=5.1231
[loss-randlabel] ep 5 it 150 total=5.6511 ce_r=0.6080 ce_f=5.0430
[loss-randlabel] ep 5 it 200 total=5.7581 ce_r=0.7241 ce_f=5.0340
[loss-randlabel] ep 5 it 250 total=5.8249 ce_r=0.8742 ce_f=4.9507
[loss-randlabel] ep 5 it 300 total=5.6703 ce_r=0.5971 ce_f=5.0732
[loss-randlabel] ep 5 it 350 total=5.6816 ce_r=0.6123 ce_f=5.0693
[loss-randlabel] ep 6 it 10 total=5.7342 ce_r=0.6363 ce_f=5.0980
[loss-randlabel] ep 6 it 60 total=5.5373 ce_r=0.6775 ce_f=4.8598
[loss-randlabel] ep 6 it 110 total=5.7453 ce_r=0.6050 ce_f=5.1403
[loss-randlabel] ep 6 it 160 total=5.6855 ce_r=0.5766 ce_f=5.1089
[loss-randlabel] ep 6 it 210 total=5.6480 ce_r=0.5953 ce_f=5.0527
[loss-randlabel] ep 6 it 260 total=5.7668 ce_r=0.6851 ce_f=5.0817
[loss-randlabel] ep 6 it 310 total=5.6773 ce_r=0.6285 ce_f=5.0487
[loss-randlabel] ep 6 it 360 total=5.5495 ce_r=0.5871 ce_f=4.9624
[loss-randlabel] ep 7 it 20 total=5.5617 ce_r=0.6033 ce_f=4.9584
[loss-randlabel] ep 7 it 70 total=5.7553 ce_r=0.6433 ce_f=5.1120
[loss-randlabel] ep 7 it 120 total=5.7378 ce_r=0.6146 ce_f=5.1232
[loss-randlabel] ep 7 it 170 total=5.7083 ce_r=0.6300 ce_f=5.0782
[loss-randlabel] ep 7 it 220 total=5.6358 ce_r=0.5760 ce_f=5.0598
[loss-randlabel] ep 7 it 270 total=5.6661 ce_r=0.6043 ce_f=5.0619
[loss-randlabel] ep 7 it 320 total=5.6563 ce_r=0.5942 ce_f=5.0621
[loss-randlabel] ep 7 it 370 total=5.7358 ce_r=0.5724 ce_f=5.1634
[loss-randlabel] ep 8 it 30 total=5.7070 ce_r=0.5581 ce_f=5.1489
[loss-randlabel] ep 8 it 80 total=5.5836 ce_r=0.6547 ce_f=4.9289
[loss-randlabel] ep 8 it 130 total=5.8040 ce_r=0.5955 ce_f=5.2084
[loss-randlabel] ep 8 it 180 total=5.5883 ce_r=0.6002 ce_f=4.9881
[loss-randlabel] ep 8 it 230 total=5.7086 ce_r=0.6765 ce_f=5.0321
[loss-randlabel] ep 8 it 280 total=5.6656 ce_r=0.5484 ce_f=5.1172
[loss-randlabel] ep 8 it 330 total=5.6548 ce_r=0.6346 ce_f=5.0202
[loss-randlabel] ep 8 it 380 total=5.5712 ce_r=0.6235 ce_f=4.9477
[loss-randlabel] ep 9 it 40 total=5.5109 ce_r=0.5061 ce_f=5.0048
[loss-randlabel] ep 9 it 90 total=5.6233 ce_r=0.6225 ce_f=5.0007
[loss-randlabel] ep 9 it 140 total=5.6536 ce_r=0.6170 ce_f=5.0366
[loss-randlabel] ep 9 it 190 total=5.6633 ce_r=0.5580 ce_f=5.1053
[loss-randlabel] ep 9 it 240 total=5.6294 ce_r=0.6349 ce_f=4.9944
[loss-randlabel] ep 9 it 290 total=5.6515 ce_r=0.6198 ce_f=5.0317
[loss-randlabel] ep 9 it 340 total=5.6884 ce_r=0.5824 ce_f=5.1060
[loss-randlabel] ep 10 it 0 total=5.6599 ce_r=0.6180 ce_f=5.0419
[loss-randlabel] ep 10 it 50 total=5.7266 ce_r=0.6801 ce_f=5.0465
[loss-randlabel] ep 10 it 100 total=5.6857 ce_r=0.5736 ce_f=5.1121
[loss-randlabel] ep 10 it 150 total=5.6381 ce_r=0.6446 ce_f=4.9935
[loss-randlabel] ep 10 it 200 total=5.7585 ce_r=0.6855 ce_f=5.0730
[loss-randlabel] ep 10 it 250 total=5.5930 ce_r=0.6083 ce_f=4.9847
[loss-randlabel] ep 10 it 300 total=5.6874 ce_r=0.5764 ce_f=5.1111
[loss-randlabel] ep 10 it 350 total=5.5841 ce_r=0.5991 ce_f=4.9849
[loss-randlabel] ep 11 it 10 total=5.5479 ce_r=0.5752 ce_f=4.9727
[loss-randlabel] ep 11 it 60 total=5.6229 ce_r=0.5856 ce_f=5.0373
[loss-randlabel] ep 11 it 110 total=5.6648 ce_r=0.6414 ce_f=5.0234
[loss-randlabel] ep 11 it 160 total=5.6799 ce_r=0.5673 ce_f=5.1126
[loss-randlabel] ep 11 it 210 total=5.7005 ce_r=0.6639 ce_f=5.0366
[loss-randlabel] ep 11 it 260 total=5.6230 ce_r=0.5585 ce_f=5.0644
[loss-randlabel] ep 11 it 310 total=5.7022 ce_r=0.6170 ce_f=5.0852
[loss-randlabel] ep 11 it 360 total=5.6633 ce_r=0.6946 ce_f=4.9687
[loss-randlabel] ep 12 it 20 total=5.5806 ce_r=0.5970 ce_f=4.9836
[loss-randlabel] ep 12 it 70 total=5.6339 ce_r=0.6463 ce_f=4.9877
[loss-randlabel] ep 12 it 120 total=5.6804 ce_r=0.6017 ce_f=5.0787
[loss-randlabel] ep 12 it 170 total=5.5141 ce_r=0.5660 ce_f=4.9481
[loss-randlabel] ep 12 it 220 total=5.7243 ce_r=0.6611 ce_f=5.0633
[loss-randlabel] ep 12 it 270 total=5.5419 ce_r=0.5373 ce_f=5.0046
[loss-randlabel] ep 12 it 320 total=5.7312 ce_r=0.6670 ce_f=5.0642
[loss-randlabel] ep 12 it 370 total=5.6936 ce_r=0.6948 ce_f=4.9988
[loss-randlabel] ep 13 it 30 total=5.6005 ce_r=0.6119 ce_f=4.9887
[loss-randlabel] ep 13 it 80 total=5.4972 ce_r=0.6118 ce_f=4.8854
[loss-randlabel] ep 13 it 130 total=5.5739 ce_r=0.5478 ce_f=5.0261
[loss-randlabel] ep 13 it 180 total=5.6147 ce_r=0.6111 ce_f=5.0036
[loss-randlabel] ep 13 it 230 total=5.5273 ce_r=0.5394 ce_f=4.9879
[loss-randlabel] ep 13 it 280 total=5.6560 ce_r=0.6283 ce_f=5.0277
[loss-randlabel] ep 13 it 330 total=5.6323 ce_r=0.6374 ce_f=4.9949
[loss-randlabel] ep 13 it 380 total=5.6478 ce_r=0.6444 ce_f=5.0034
[loss-randlabel] ep 14 it 40 total=5.5328 ce_r=0.5834 ce_f=4.9494
[loss-randlabel] ep 14 it 90 total=5.5242 ce_r=0.5836 ce_f=4.9406
[loss-randlabel] ep 14 it 140 total=5.6353 ce_r=0.6067 ce_f=5.0286
[loss-randlabel] ep 14 it 190 total=5.5762 ce_r=0.5938 ce_f=4.9824
[loss-randlabel] ep 14 it 240 total=5.6419 ce_r=0.5890 ce_f=5.0530
[loss-randlabel] ep 14 it 290 total=5.5590 ce_r=0.6155 ce_f=4.9435
[loss-randlabel] ep 14 it 340 total=5.5911 ce_r=0.6330 ce_f=4.9581
[loss-randlabel] ep 15 it 0 total=5.5771 ce_r=0.6352 ce_f=4.9419
[loss-randlabel] ep 15 it 50 total=5.6103 ce_r=0.5422 ce_f=5.0680
[loss-randlabel] ep 15 it 100 total=5.5989 ce_r=0.5297 ce_f=5.0691
[loss-randlabel] ep 15 it 150 total=5.5686 ce_r=0.6733 ce_f=4.8953
[loss-randlabel] ep 15 it 200 total=5.5980 ce_r=0.5744 ce_f=5.0236
[loss-randlabel] ep 15 it 250 total=5.5668 ce_r=0.6103 ce_f=4.9565
 64%|██████▍   | 16/25 [04:27<02:22, 15.87s/it] 68%|██████▊   | 17/25 [04:43<02:08, 16.06s/it] 72%|███████▏  | 18/25 [04:59<01:51, 15.87s/it] 76%|███████▌  | 19/25 [05:15<01:35, 15.85s/it] 80%|████████  | 20/25 [05:30<01:19, 15.82s/it] 84%|████████▍ | 21/25 [05:46<01:03, 15.82s/it] 88%|████████▊ | 22/25 [06:01<00:46, 15.62s/it] 92%|█████████▏| 23/25 [06:16<00:30, 15.35s/it] 96%|█████████▌| 24/25 [06:31<00:15, 15.32s/it]100%|██████████| 25/25 [06:47<00:00, 15.46s/it]100%|██████████| 25/25 [06:47<00:00, 16.30s/it]
[loss-randlabel] ep 15 it 300 total=5.5820 ce_r=0.6161 ce_f=4.9660
[loss-randlabel] ep 15 it 350 total=5.6449 ce_r=0.5611 ce_f=5.0838
[loss-randlabel] ep 16 it 10 total=5.5929 ce_r=0.5665 ce_f=5.0263
[loss-randlabel] ep 16 it 60 total=5.6733 ce_r=0.6752 ce_f=4.9982
[loss-randlabel] ep 16 it 110 total=5.6825 ce_r=0.6188 ce_f=5.0637
[loss-randlabel] ep 16 it 160 total=5.5246 ce_r=0.5567 ce_f=4.9679
[loss-randlabel] ep 16 it 210 total=5.5579 ce_r=0.6175 ce_f=4.9404
[loss-randlabel] ep 16 it 260 total=5.5298 ce_r=0.6156 ce_f=4.9143
[loss-randlabel] ep 16 it 310 total=5.6017 ce_r=0.5646 ce_f=5.0371
[loss-randlabel] ep 16 it 360 total=5.5681 ce_r=0.5931 ce_f=4.9750
[loss-randlabel] ep 17 it 20 total=5.6468 ce_r=0.6114 ce_f=5.0354
[loss-randlabel] ep 17 it 70 total=5.6318 ce_r=0.6105 ce_f=5.0213
[loss-randlabel] ep 17 it 120 total=5.6551 ce_r=0.5971 ce_f=5.0580
[loss-randlabel] ep 17 it 170 total=5.5912 ce_r=0.6285 ce_f=4.9627
[loss-randlabel] ep 17 it 220 total=5.6287 ce_r=0.5643 ce_f=5.0645
[loss-randlabel] ep 17 it 270 total=5.5813 ce_r=0.5648 ce_f=5.0165
[loss-randlabel] ep 17 it 320 total=5.5390 ce_r=0.6145 ce_f=4.9245
[loss-randlabel] ep 17 it 370 total=5.6315 ce_r=0.5817 ce_f=5.0498
[loss-randlabel] ep 18 it 30 total=5.6190 ce_r=0.6268 ce_f=4.9922
[loss-randlabel] ep 18 it 80 total=5.6638 ce_r=0.5880 ce_f=5.0758
[loss-randlabel] ep 18 it 130 total=5.6284 ce_r=0.6235 ce_f=5.0048
[loss-randlabel] ep 18 it 180 total=5.4038 ce_r=0.5604 ce_f=4.8434
[loss-randlabel] ep 18 it 230 total=5.6190 ce_r=0.6277 ce_f=4.9913
[loss-randlabel] ep 18 it 280 total=5.5986 ce_r=0.6524 ce_f=4.9462
[loss-randlabel] ep 18 it 330 total=5.6645 ce_r=0.6126 ce_f=5.0518
[loss-randlabel] ep 18 it 380 total=5.6079 ce_r=0.5976 ce_f=5.0102
[loss-randlabel] ep 19 it 40 total=5.6255 ce_r=0.6035 ce_f=5.0220
[loss-randlabel] ep 19 it 90 total=5.6478 ce_r=0.5958 ce_f=5.0520
[loss-randlabel] ep 19 it 140 total=5.6036 ce_r=0.5772 ce_f=5.0264
[loss-randlabel] ep 19 it 190 total=5.6490 ce_r=0.6262 ce_f=5.0228
[loss-randlabel] ep 19 it 240 total=5.6484 ce_r=0.6344 ce_f=5.0140
[loss-randlabel] ep 19 it 290 total=5.5989 ce_r=0.5972 ce_f=5.0016
[loss-randlabel] ep 19 it 340 total=5.6808 ce_r=0.6365 ce_f=5.0442
[loss-randlabel] ep 20 it 0 total=5.6616 ce_r=0.6090 ce_f=5.0526
[loss-randlabel] ep 20 it 50 total=5.6055 ce_r=0.5894 ce_f=5.0162
[loss-randlabel] ep 20 it 100 total=5.6634 ce_r=0.5927 ce_f=5.0707
[loss-randlabel] ep 20 it 150 total=5.6320 ce_r=0.5620 ce_f=5.0700
[loss-randlabel] ep 20 it 200 total=5.5451 ce_r=0.5231 ce_f=5.0219
[loss-randlabel] ep 20 it 250 total=5.6551 ce_r=0.5851 ce_f=5.0699
[loss-randlabel] ep 20 it 300 total=5.7051 ce_r=0.5694 ce_f=5.1357
[loss-randlabel] ep 20 it 350 total=5.5987 ce_r=0.5718 ce_f=5.0269
[loss-randlabel] ep 21 it 10 total=5.6493 ce_r=0.5815 ce_f=5.0678
[loss-randlabel] ep 21 it 60 total=5.5457 ce_r=0.5743 ce_f=4.9713
[loss-randlabel] ep 21 it 110 total=5.5558 ce_r=0.5664 ce_f=4.9894
[loss-randlabel] ep 21 it 160 total=5.5161 ce_r=0.5688 ce_f=4.9473
[loss-randlabel] ep 21 it 210 total=5.5162 ce_r=0.5715 ce_f=4.9447
[loss-randlabel] ep 21 it 260 total=5.4709 ce_r=0.6443 ce_f=4.8266
[loss-randlabel] ep 21 it 310 total=5.6371 ce_r=0.6305 ce_f=5.0066
[loss-randlabel] ep 21 it 360 total=5.6073 ce_r=0.6044 ce_f=5.0029
[loss-randlabel] ep 22 it 20 total=5.6222 ce_r=0.5540 ce_f=5.0683
[loss-randlabel] ep 22 it 70 total=5.6191 ce_r=0.5921 ce_f=5.0271
[loss-randlabel] ep 22 it 120 total=5.6128 ce_r=0.5654 ce_f=5.0474
[loss-randlabel] ep 22 it 170 total=5.5992 ce_r=0.5153 ce_f=5.0840
[loss-randlabel] ep 22 it 220 total=5.7695 ce_r=0.6527 ce_f=5.1167
[loss-randlabel] ep 22 it 270 total=5.6585 ce_r=0.6012 ce_f=5.0573
[loss-randlabel] ep 22 it 320 total=5.6537 ce_r=0.6281 ce_f=5.0256
[loss-randlabel] ep 22 it 370 total=5.6336 ce_r=0.6479 ce_f=4.9858
[loss-randlabel] ep 23 it 30 total=5.5804 ce_r=0.5979 ce_f=4.9825
[loss-randlabel] ep 23 it 80 total=5.4759 ce_r=0.6221 ce_f=4.8539
[loss-randlabel] ep 23 it 130 total=5.6079 ce_r=0.5946 ce_f=5.0133
[loss-randlabel] ep 23 it 180 total=5.6460 ce_r=0.5434 ce_f=5.1026
[loss-randlabel] ep 23 it 230 total=5.6011 ce_r=0.6191 ce_f=4.9820
[loss-randlabel] ep 23 it 280 total=5.6101 ce_r=0.5950 ce_f=5.0151
[loss-randlabel] ep 23 it 330 total=5.6465 ce_r=0.5564 ce_f=5.0900
[loss-randlabel] ep 23 it 380 total=5.4501 ce_r=0.5889 ce_f=4.8612
[loss-randlabel] ep 24 it 40 total=5.4883 ce_r=0.6439 ce_f=4.8445
[loss-randlabel] ep 24 it 90 total=5.5313 ce_r=0.5966 ce_f=4.9347
[loss-randlabel] ep 24 it 140 total=5.5842 ce_r=0.5748 ce_f=5.0094
[loss-randlabel] ep 24 it 190 total=5.5655 ce_r=0.5589 ce_f=5.0067
[loss-randlabel] ep 24 it 240 total=5.5803 ce_r=0.5482 ce_f=5.0321
[loss-randlabel] ep 24 it 290 total=5.6303 ce_r=0.5601 ce_f=5.0702
[loss-randlabel] ep 24 it 340 total=5.6743 ce_r=0.5626 ce_f=5.1117
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:03,  2.13it/s]  2%|▏         | 6/391 [00:00<00:29, 13.18it/s]  4%|▍         | 16/391 [00:00<00:10, 34.33it/s]  7%|▋         | 26/391 [00:00<00:07, 50.23it/s]  9%|▉         | 36/391 [00:00<00:05, 62.84it/s] 12%|█▏        | 47/391 [00:00<00:04, 73.99it/s] 15%|█▍        | 58/391 [00:01<00:04, 82.07it/s] 17%|█▋        | 68/391 [00:01<00:03, 86.97it/s] 20%|█▉        | 78/391 [00:01<00:03, 90.60it/s] 23%|██▎       | 88/391 [00:01<00:03, 93.23it/s] 25%|██▌       | 99/391 [00:01<00:03, 95.42it/s] 28%|██▊       | 109/391 [00:01<00:02, 96.20it/s] 31%|███       | 120/391 [00:01<00:02, 97.59it/s] 33%|███▎      | 130/391 [00:01<00:02, 97.43it/s] 36%|███▌      | 140/391 [00:01<00:02, 98.06it/s] 38%|███▊      | 150/391 [00:02<00:02, 95.36it/s] 41%|████      | 161/391 [00:02<00:02, 97.08it/s] 44%|████▎     | 171/391 [00:02<00:02, 96.46it/s] 47%|████▋     | 182/391 [00:02<00:02, 97.80it/s] 49%|████▉     | 193/391 [00:02<00:02, 98.45it/s] 52%|█████▏    | 203/391 [00:02<00:01, 97.82it/s] 55%|█████▍    | 214/391 [00:02<00:01, 98.74it/s] 58%|█████▊    | 225/391 [00:02<00:01, 99.50it/s] 60%|██████    | 236/391 [00:02<00:01, 99.91it/s] 63%|██████▎   | 247/391 [00:03<00:01, 98.84it/s] 66%|██████▌   | 257/391 [00:03<00:01, 98.69it/s] 68%|██████▊   | 267/391 [00:03<00:01, 98.99it/s] 71%|███████   | 277/391 [00:03<00:01, 98.88it/s] 74%|███████▎  | 288/391 [00:03<00:01, 99.34it/s] 76%|███████▋  | 299/391 [00:03<00:00, 98.50it/s] 79%|███████▉  | 309/391 [00:03<00:00, 98.88it/s] 82%|████████▏ | 319/391 [00:03<00:00, 98.84it/s] 84%|████████▍ | 330/391 [00:03<00:00, 99.18it/s] 87%|████████▋ | 340/391 [00:03<00:00, 98.96it/s] 90%|████████▉ | 351/391 [00:04<00:00, 99.01it/s] 92%|█████████▏| 361/391 [00:04<00:00, 98.80it/s] 95%|█████████▌| 372/391 [00:04<00:00, 99.82it/s] 98%|█████████▊| 383/391 [00:04<00:00, 100.63it/s]100%|██████████| 391/391 [00:04<00:00, 87.39it/s] 
50000 images processed, 4.5804479122161865 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:29,  2.62it/s] 14%|█▍        | 11/79 [00:00<00:02, 28.81it/s] 27%|██▋       | 21/79 [00:00<00:01, 48.12it/s] 39%|███▉      | 31/79 [00:00<00:00, 61.75it/s] 52%|█████▏    | 41/79 [00:00<00:00, 72.00it/s] 65%|██████▍   | 51/79 [00:00<00:00, 79.31it/s] 77%|███████▋  | 61/79 [00:01<00:00, 84.83it/s] 90%|████████▉ | 71/79 [00:01<00:00, 88.95it/s]100%|██████████| 79/79 [00:01<00:00, 65.63it/s]
10000 images processed, 1.2260196208953857 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:29,  2.27it/s]  5%|▍         | 10/204 [00:00<00:08, 23.46it/s]  9%|▉         | 19/204 [00:00<00:04, 40.26it/s] 13%|█▎        | 26/204 [00:00<00:03, 45.47it/s] 16%|█▌        | 33/204 [00:00<00:03, 46.14it/s] 21%|██        | 43/204 [00:01<00:02, 59.49it/s] 26%|██▌       | 53/204 [00:01<00:02, 68.85it/s] 31%|███       | 63/204 [00:01<00:01, 76.77it/s] 35%|███▌      | 72/204 [00:01<00:01, 80.24it/s] 40%|████      | 82/204 [00:01<00:01, 85.82it/s] 46%|████▌     | 93/204 [00:01<00:01, 90.20it/s] 50%|█████     | 103/204 [00:01<00:01, 92.04it/s] 55%|█████▌    | 113/204 [00:01<00:00, 94.29it/s] 60%|██████    | 123/204 [00:01<00:00, 95.17it/s] 65%|██████▌   | 133/204 [00:01<00:00, 93.86it/s] 70%|███████   | 143/204 [00:02<00:00, 92.45it/s] 75%|███████▌  | 153/204 [00:02<00:00, 93.35it/s] 80%|███████▉  | 163/204 [00:02<00:00, 91.67it/s] 85%|████████▍ | 173/204 [00:02<00:00, 93.63it/s] 90%|█████████ | 184/204 [00:02<00:00, 96.02it/s] 96%|█████████▌| 195/204 [00:02<00:00, 97.79it/s]100%|██████████| 204/204 [00:02<00:00, 75.71it/s]
26032 images processed, 2.743912696838379 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:43,  1.80it/s]  9%|▉         | 7/79 [00:00<00:05, 13.61it/s] 22%|██▏       | 17/79 [00:00<00:01, 32.53it/s] 30%|███       | 24/79 [00:00<00:01, 40.01it/s] 43%|████▎     | 34/79 [00:00<00:00, 53.61it/s] 53%|█████▎    | 42/79 [00:01<00:00, 37.33it/s] 67%|██████▋   | 53/79 [00:01<00:00, 49.91it/s] 81%|████████  | 64/79 [00:01<00:00, 61.19it/s] 95%|█████████▍| 75/79 [00:01<00:00, 70.82it/s]100%|██████████| 79/79 [00:01<00:00, 46.72it/s]
10000 images processed, 1.725508451461792 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:34,  2.27it/s] 11%|█▏        | 9/79 [00:00<00:03, 20.98it/s] 24%|██▍       | 19/79 [00:00<00:01, 40.84it/s] 37%|███▋      | 29/79 [00:00<00:00, 56.51it/s] 49%|████▉     | 39/79 [00:00<00:00, 68.47it/s] 62%|██████▏   | 49/79 [00:00<00:00, 77.29it/s] 76%|███████▌  | 60/79 [00:01<00:00, 84.75it/s] 90%|████████▉ | 71/79 [00:01<00:00, 89.92it/s]100%|██████████| 79/79 [00:01<00:00, 63.73it/s]
10000 images processed, 1.2575626373291016 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:32,  2.15it/s] 13%|█▎        | 9/70 [00:00<00:03, 17.50it/s] 27%|██▋       | 19/70 [00:00<00:01, 35.42it/s] 41%|████▏     | 29/70 [00:00<00:00, 50.21it/s] 56%|█████▌    | 39/70 [00:00<00:00, 61.21it/s] 71%|███████▏  | 50/70 [00:01<00:00, 72.24it/s] 87%|████████▋ | 61/70 [00:01<00:00, 80.58it/s]100%|██████████| 70/70 [00:01<00:00, 55.31it/s]
8925 images processed, 1.2914729118347168 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:38,  1.14it/s]  7%|▋         | 3/45 [00:00<00:11,  3.77it/s] 29%|██▉       | 13/45 [00:01<00:01, 19.59it/s] 40%|████      | 18/45 [00:01<00:01, 18.25it/s] 51%|█████     | 23/45 [00:01<00:00, 22.37it/s] 71%|███████   | 32/45 [00:01<00:00, 20.49it/s] 93%|█████████▎| 42/45 [00:02<00:00, 31.04it/s]100%|██████████| 45/45 [00:02<00:00, 21.05it/s]
5640 images processed, 2.156569004058838 seconds used

16.503396034240723
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.64  99.33  98.20
places365     67.80  80.32  77.82
LSUN          18.18  96.03  96.12
iSUN          75.32  81.00  84.16
dtd           42.06  90.67  94.16
AVG           41.20  89.47  90.09
Retain-Acc: 0.7358
Forget-as-OOD (retain known vs forget novel):
  FPR: 38.40 AUROC: 91.63 AUIN: 99.45
8.032155513763428
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget5_rf.png
