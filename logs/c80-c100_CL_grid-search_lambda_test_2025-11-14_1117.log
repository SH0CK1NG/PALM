nohup: ignoring input
[Grid Search Continual] Searching over: lambda_pcon(0.1) × lrs(0.001) × epochs(1) × lora_r(8)
[Grid Search Continual] Stages: 0,8,11,40,51 66,67,88,94,57 59,58,44,93,10 64,22,42,9,90

==========================================
[Run] lambda_pcon=0.1 lr=0.001 epochs=1 lora_r=8
==========================================
==== Stage 1: inc={0,8,11,40,51}; seen={}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:17<00:00, 17.61s/it]100%|██████████| 1/1 [00:17<00:00, 17.61s/it]
[loss] ep 0 it 0 total=4.6428 mle=4.0803 pcon=0.5626 forget=0.0000 orth=0.0000 favg=0.0000 nr=122 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=5.0013 mle=4.4386 pcon=0.5628 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=5.0627 mle=4.4998 pcon=0.5629 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=5.6154 mle=5.0523 pcon=0.5631 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=4.3042 mle=3.7409 pcon=0.5634 forget=0.0000 orth=0.0000 favg=0.0000 nr=118 nf=10 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=4.8997 mle=4.3362 pcon=0.5635 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=4.5206 mle=3.9569 pcon=0.5637 forget=0.0000 orth=0.0000 favg=0.0000 nr=120 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=4.9443 mle=4.3805 pcon=0.5638 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=4.8929 mle=4.3289 pcon=0.5640 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
==== Stage 2: inc={66,67,88,94,57}; seen={0,8,11,40,51}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:22<00:00, 22.08s/it]100%|██████████| 1/1 [00:22<00:00, 22.08s/it]
[loss] ep 0 it 0 total=5.9808 mle=4.0774 pcon=0.8978 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3368 mle=4.4331 pcon=0.8980 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.3998 mle=4.4959 pcon=0.8983 forget=0.0000 orth=1.0056 favg=0.0000 nr=114 nf=9 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=6.9513 mle=5.0473 pcon=0.8984 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.6409 mle=3.7368 pcon=0.8985 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=1 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2342 mle=4.3299 pcon=0.8987 forget=0.0000 orth=1.0055 favg=0.0000 nr=116 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.8550 mle=3.9507 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=114 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.2799 mle=4.3756 pcon=0.8989 forget=0.0000 orth=1.0055 favg=0.0000 nr=110 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2260 mle=4.3217 pcon=0.8989 forget=0.0000 orth=1.0054 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
==== Stage 3: inc={59,58,44,93,10}; seen={0,8,11,40,51,66,67,88,94,57}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='59,58,44,93,10', forget_classes_seen='0,8,11,40,51,66,67,88,94,57', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:21<00:00, 21.80s/it]100%|██████████| 1/1 [00:21<00:00, 21.80s/it]
[loss] ep 0 it 0 total=6.0456 mle=4.0715 pcon=0.9689 forget=0.0000 orth=1.0052 favg=0.0000 nr=112 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3983 mle=4.4240 pcon=0.9691 forget=0.0000 orth=1.0052 favg=0.0000 nr=111 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4634 mle=4.4889 pcon=0.9694 forget=0.0000 orth=1.0052 favg=0.0000 nr=109 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0128 mle=5.0381 pcon=0.9696 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7035 mle=3.7287 pcon=0.9698 forget=0.0000 orth=1.0051 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2928 mle=4.3178 pcon=0.9699 forget=0.0000 orth=1.0051 favg=0.0000 nr=111 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9133 mle=3.9382 pcon=0.9701 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3397 mle=4.3645 pcon=0.9701 forget=0.0000 orth=1.0050 favg=0.0000 nr=105 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2795 mle=4.3044 pcon=0.9702 forget=0.0000 orth=1.0049 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
==== Stage 4: inc={64,22,42,9,90}; seen={0,8,11,40,51,66,67,88,94,57,59,58,44,93,10}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='64,22,42,9,90', forget_classes_seen='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:22<00:00, 22.03s/it]100%|██████████| 1/1 [00:22<00:00, 22.03s/it]
[loss] ep 0 it 0 total=6.0703 mle=4.0565 pcon=1.0090 forget=0.0000 orth=1.0048 favg=0.0000 nr=105 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.4169 mle=4.4029 pcon=1.0092 forget=0.0000 orth=1.0047 favg=0.0000 nr=103 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4854 mle=4.4712 pcon=1.0094 forget=0.0000 orth=1.0047 favg=0.0000 nr=105 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0304 mle=5.0161 pcon=1.0096 forget=0.0000 orth=1.0047 favg=0.0000 nr=100 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7244 mle=3.7099 pcon=1.0098 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.3046 mle=4.2900 pcon=1.0099 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9254 mle=3.9107 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=102 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3517 mle=4.3370 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=99 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2753 mle=4.2606 pcon=1.0102 forget=0.0000 orth=1.0045 favg=0.0000 nr=97 nf=9 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4
[Result] AVG-AUROC=89.03 AVG-FPR=43.69 Final-Top1=N/A Average=N/A Score=N/A

[Grid Search Continual] Completed. Results saved to: evaluation_results/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-continual-continual-grid_runs.csv
