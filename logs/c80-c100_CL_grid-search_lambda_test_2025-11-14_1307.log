nohup: ignoring input
[Grid Search Continual] Searching over: lambda_pcon(0.1) × lrs(0.001) × epochs(1) × lora_r(8)
[Grid Search Continual] Stages: 0,8,11,40,51 66,67,88,94,57 59,58,44,93,10 64,22,42,9,90

==========================================
[Run] lambda_pcon=0.1 lr=0.001 epochs=1 lora_r=8
==========================================
==== Stage 1: inc={0,8,11,40,51}; seen={}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:16<00:00, 16.83s/it]100%|██████████| 1/1 [00:16<00:00, 16.83s/it]
[loss] ep 0 it 0 total=4.6428 mle=4.0803 pcon=0.5626 forget=0.0000 orth=0.0000 favg=0.0000 nr=122 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=5.0013 mle=4.4386 pcon=0.5628 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=5.0627 mle=4.4998 pcon=0.5629 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=5.6154 mle=5.0523 pcon=0.5631 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=4.3042 mle=3.7409 pcon=0.5634 forget=0.0000 orth=0.0000 favg=0.0000 nr=118 nf=10 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=4.8997 mle=4.3362 pcon=0.5635 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=4.5206 mle=3.9569 pcon=0.5637 forget=0.0000 orth=0.0000 favg=0.0000 nr=120 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=4.9443 mle=4.3805 pcon=0.5638 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=4.8929 mle=4.3289 pcon=0.5640 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stage1-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:00<03:56,  1.81it/s]  3%|▎         | 11/430 [00:00<00:19, 21.70it/s]  5%|▍         | 21/430 [00:00<00:10, 38.77it/s]  7%|▋         | 31/430 [00:00<00:07, 52.95it/s] 10%|▉         | 41/430 [00:00<00:06, 63.55it/s] 12%|█▏        | 51/430 [00:01<00:05, 72.22it/s] 14%|█▍        | 61/430 [00:01<00:04, 78.57it/s] 17%|█▋        | 71/430 [00:01<00:04, 82.95it/s] 19%|█▉        | 81/430 [00:01<00:04, 86.36it/s] 21%|██        | 91/430 [00:01<00:03, 88.70it/s] 23%|██▎       | 101/430 [00:01<00:03, 90.13it/s] 26%|██▌       | 111/430 [00:01<00:03, 91.69it/s] 28%|██▊       | 121/430 [00:01<00:03, 92.88it/s] 30%|███       | 131/430 [00:01<00:03, 93.33it/s] 33%|███▎      | 141/430 [00:02<00:03, 93.23it/s] 35%|███▌      | 151/430 [00:02<00:02, 93.94it/s] 37%|███▋      | 161/430 [00:02<00:02, 94.10it/s] 40%|███▉      | 171/430 [00:02<00:02, 86.39it/s] 42%|████▏     | 181/430 [00:02<00:02, 88.81it/s] 44%|████▍     | 191/430 [00:02<00:02, 90.80it/s] 47%|████▋     | 201/430 [00:02<00:02, 91.94it/s] 49%|████▉     | 211/430 [00:02<00:02, 92.69it/s] 51%|█████▏    | 221/430 [00:02<00:02, 92.95it/s] 54%|█████▎    | 231/430 [00:03<00:02, 93.54it/s] 56%|█████▌    | 241/430 [00:03<00:02, 87.35it/s] 58%|█████▊    | 251/430 [00:03<00:01, 89.62it/s] 61%|██████    | 261/430 [00:03<00:01, 90.80it/s] 63%|██████▎   | 271/430 [00:03<00:01, 91.94it/s] 65%|██████▌   | 281/430 [00:03<00:01, 92.91it/s] 68%|██████▊   | 291/430 [00:03<00:01, 90.22it/s] 70%|███████   | 301/430 [00:03<00:01, 91.74it/s] 72%|███████▏  | 311/430 [00:03<00:01, 89.47it/s] 74%|███████▍  | 320/430 [00:04<00:01, 87.30it/s] 77%|███████▋  | 330/430 [00:04<00:01, 88.55it/s] 79%|███████▉  | 340/430 [00:04<00:00, 90.32it/s] 81%|████████▏ | 350/430 [00:04<00:00, 87.58it/s] 83%|████████▎ | 359/430 [00:04<00:00, 87.95it/s] 86%|████████▌ | 369/430 [00:04<00:00, 89.27it/s] 88%|████████▊ | 379/430 [00:04<00:00, 91.06it/s] 90%|█████████ | 389/430 [00:04<00:00, 91.93it/s] 93%|█████████▎| 399/430 [00:04<00:00, 91.66it/s] 95%|█████████▌| 409/430 [00:04<00:00, 93.13it/s] 97%|█████████▋| 419/430 [00:05<00:00, 84.52it/s]100%|█████████▉| 428/430 [00:05<00:00, 83.62it/s]100%|██████████| 430/430 [00:05<00:00, 81.39it/s]
55000 images processed, 5.3293023109436035 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<01:02,  1.36it/s] 13%|█▎        | 11/86 [00:00<00:04, 17.23it/s] 24%|██▍       | 21/86 [00:00<00:02, 32.33it/s] 36%|███▌      | 31/86 [00:01<00:01, 45.90it/s] 48%|████▊     | 41/86 [00:01<00:00, 57.23it/s] 59%|█████▉    | 51/86 [00:01<00:00, 66.27it/s] 71%|███████   | 61/86 [00:01<00:00, 74.06it/s] 83%|████████▎ | 71/86 [00:01<00:00, 80.22it/s] 94%|█████████▍| 81/86 [00:01<00:00, 84.87it/s]100%|██████████| 86/86 [00:01<00:00, 52.59it/s]
11000 images processed, 1.6644330024719238 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:58,  1.72it/s]  5%|▌         | 11/204 [00:00<00:09, 20.70it/s] 10%|█         | 21/204 [00:00<00:04, 37.20it/s] 15%|█▍        | 30/204 [00:00<00:03, 49.40it/s] 20%|█▉        | 40/204 [00:01<00:02, 60.66it/s] 25%|██▍       | 50/204 [00:01<00:02, 69.60it/s] 29%|██▉       | 59/204 [00:01<00:01, 74.50it/s] 34%|███▍      | 69/204 [00:01<00:01, 79.73it/s] 38%|███▊      | 78/204 [00:01<00:01, 81.80it/s] 43%|████▎     | 88/204 [00:01<00:01, 85.19it/s] 48%|████▊     | 97/204 [00:01<00:01, 86.07it/s] 52%|█████▏    | 106/204 [00:01<00:01, 85.12it/s] 56%|█████▋    | 115/204 [00:01<00:01, 86.21it/s] 61%|██████▏   | 125/204 [00:01<00:00, 88.26it/s] 66%|██████▌   | 135/204 [00:02<00:00, 89.70it/s] 71%|███████   | 145/204 [00:02<00:00, 87.94it/s] 75%|███████▌  | 154/204 [00:02<00:00, 80.77it/s] 80%|███████▉  | 163/204 [00:02<00:00, 69.42it/s] 84%|████████▍ | 172/204 [00:02<00:00, 73.28it/s] 89%|████████▉ | 182/204 [00:02<00:00, 79.23it/s] 94%|█████████▍| 192/204 [00:02<00:00, 83.94it/s] 99%|█████████▉| 202/204 [00:02<00:00, 87.48it/s]100%|██████████| 204/204 [00:02<00:00, 69.53it/s]
26032 images processed, 2.973325252532959 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:09,  1.12it/s]  5%|▌         | 4/79 [00:00<00:14,  5.07it/s] 18%|█▊        | 14/79 [00:01<00:03, 20.33it/s] 29%|██▉       | 23/79 [00:01<00:01, 32.78it/s] 42%|████▏     | 33/79 [00:01<00:00, 46.23it/s] 54%|█████▍    | 43/79 [00:01<00:00, 57.32it/s] 67%|██████▋   | 53/79 [00:01<00:00, 65.96it/s] 80%|███████▉  | 63/79 [00:01<00:00, 73.48it/s] 92%|█████████▏| 73/79 [00:01<00:00, 79.37it/s]100%|██████████| 79/79 [00:01<00:00, 43.27it/s]
10000 images processed, 1.854194164276123 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:50,  1.56it/s] 13%|█▎        | 10/79 [00:00<00:03, 17.36it/s] 25%|██▌       | 20/79 [00:00<00:01, 33.68it/s] 38%|███▊      | 30/79 [00:00<00:01, 47.74it/s] 51%|█████     | 40/79 [00:01<00:00, 59.03it/s] 62%|██████▏   | 49/79 [00:01<00:00, 66.43it/s] 75%|███████▍  | 59/79 [00:01<00:00, 74.34it/s] 87%|████████▋ | 69/79 [00:01<00:00, 80.28it/s]100%|██████████| 79/79 [00:01<00:00, 53.27it/s]
10000 images processed, 1.5086500644683838 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:48,  1.41it/s] 16%|█▌        | 11/70 [00:00<00:03, 17.70it/s] 30%|███       | 21/70 [00:00<00:01, 33.03it/s] 44%|████▍     | 31/70 [00:01<00:00, 46.47it/s] 59%|█████▊    | 41/70 [00:01<00:00, 57.97it/s] 73%|███████▎  | 51/70 [00:01<00:00, 67.50it/s] 87%|████████▋ | 61/70 [00:01<00:00, 75.01it/s]100%|██████████| 70/70 [00:01<00:00, 48.33it/s]
8925 images processed, 1.4904203414916992 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:59,  1.36s/it]  4%|▍         | 2/45 [00:01<00:26,  1.61it/s] 27%|██▋       | 12/45 [00:01<00:02, 13.23it/s] 38%|███▊      | 17/45 [00:02<00:02, 12.28it/s] 56%|█████▌    | 25/45 [00:02<00:00, 20.27it/s] 67%|██████▋   | 30/45 [00:02<00:00, 22.97it/s] 78%|███████▊  | 35/45 [00:02<00:00, 16.21it/s]100%|██████████| 45/45 [00:02<00:00, 25.97it/s]100%|██████████| 45/45 [00:02<00:00, 15.44it/s]
5640 images processed, 2.9393391609191895 seconds used

19.944426774978638
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.55  99.04  73.56
places365     49.40  89.47  51.32
LSUN          25.68  95.16  75.96
iSUN          25.80  95.00  73.65
dtd           24.45  94.42  71.69
AVG           25.78  94.62  69.23
[incremental] Overall: 0.8500 New: 0.8500 Old: nan
[incremental] Final(Top-1): 0.6220  Average: 0.7277
9.092159748077393
==== Stage 2: inc={66,67,88,94,57}; seen={0,8,11,40,51}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:23<00:00, 23.68s/it]100%|██████████| 1/1 [00:23<00:00, 23.68s/it]
[loss] ep 0 it 0 total=5.9808 mle=4.0774 pcon=0.8978 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3368 mle=4.4331 pcon=0.8980 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4000 mle=4.4961 pcon=0.8983 forget=0.0000 orth=1.0056 favg=0.0000 nr=114 nf=9 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=6.9514 mle=5.0474 pcon=0.8984 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.6408 mle=3.7368 pcon=0.8985 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=1 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2341 mle=4.3299 pcon=0.8987 forget=0.0000 orth=1.0055 favg=0.0000 nr=116 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.8548 mle=3.9506 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=114 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.2799 mle=4.3756 pcon=0.8989 forget=0.0000 orth=1.0055 favg=0.0000 nr=110 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2261 mle=4.3217 pcon=0.8989 forget=0.0000 orth=1.0054 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stage2-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:01<13:27,  1.88s/it]  3%|▎         | 11/430 [00:01<00:55,  7.52it/s]  5%|▍         | 21/430 [00:02<00:25, 15.88it/s]  7%|▋         | 31/430 [00:02<00:15, 25.30it/s] 10%|▉         | 41/430 [00:02<00:10, 35.43it/s] 12%|█▏        | 51/430 [00:02<00:08, 45.55it/s] 14%|█▍        | 61/430 [00:02<00:06, 55.16it/s] 17%|█▋        | 71/430 [00:02<00:05, 63.30it/s] 19%|█▉        | 81/430 [00:02<00:04, 70.75it/s] 21%|██        | 91/430 [00:02<00:04, 76.75it/s] 23%|██▎       | 101/430 [00:02<00:04, 80.87it/s] 26%|██▌       | 111/430 [00:03<00:03, 84.80it/s] 28%|██▊       | 121/430 [00:03<00:03, 87.82it/s] 30%|███       | 131/430 [00:03<00:03, 88.57it/s] 33%|███▎      | 141/430 [00:03<00:03, 90.58it/s] 35%|███▌      | 151/430 [00:03<00:03, 87.08it/s] 37%|███▋      | 160/430 [00:03<00:03, 86.77it/s] 40%|███▉      | 170/430 [00:03<00:02, 89.14it/s] 42%|████▏     | 180/430 [00:03<00:02, 86.65it/s] 44%|████▍     | 190/430 [00:03<00:02, 89.31it/s] 47%|████▋     | 200/430 [00:04<00:02, 90.95it/s] 49%|████▉     | 210/430 [00:04<00:02, 91.15it/s] 51%|█████     | 220/430 [00:04<00:02, 91.43it/s] 53%|█████▎    | 230/430 [00:04<00:02, 92.20it/s] 56%|█████▌    | 240/430 [00:04<00:02, 92.88it/s] 58%|█████▊    | 250/430 [00:04<00:01, 93.50it/s] 60%|██████    | 260/430 [00:04<00:01, 93.35it/s] 63%|██████▎   | 270/430 [00:04<00:01, 93.83it/s] 65%|██████▌   | 280/430 [00:04<00:01, 93.39it/s] 67%|██████▋   | 290/430 [00:05<00:01, 93.72it/s] 70%|██████▉   | 300/430 [00:05<00:01, 93.97it/s] 72%|███████▏  | 310/430 [00:05<00:01, 93.95it/s] 74%|███████▍  | 320/430 [00:05<00:01, 94.39it/s] 77%|███████▋  | 330/430 [00:05<00:01, 94.63it/s] 79%|███████▉  | 340/430 [00:05<00:00, 95.05it/s] 81%|████████▏ | 350/430 [00:05<00:00, 92.63it/s] 84%|████████▎ | 360/430 [00:05<00:00, 93.29it/s] 86%|████████▌ | 370/430 [00:05<00:00, 93.93it/s] 88%|████████▊ | 380/430 [00:05<00:00, 94.45it/s] 91%|█████████ | 390/430 [00:06<00:00, 94.26it/s] 93%|█████████▎| 400/430 [00:06<00:00, 94.23it/s] 95%|█████████▌| 410/430 [00:06<00:00, 93.54it/s] 98%|█████████▊| 420/430 [00:06<00:00, 94.38it/s]100%|██████████| 430/430 [00:06<00:00, 92.61it/s]100%|██████████| 430/430 [00:06<00:00, 66.17it/s]
55000 images processed, 6.572315454483032 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<00:43,  1.94it/s] 13%|█▎        | 11/86 [00:00<00:03, 22.89it/s] 24%|██▍       | 21/86 [00:00<00:01, 40.34it/s] 35%|███▍      | 30/86 [00:00<00:01, 52.50it/s] 47%|████▋     | 40/86 [00:00<00:00, 63.84it/s] 57%|█████▋    | 49/86 [00:01<00:00, 64.71it/s] 69%|██████▊   | 59/86 [00:01<00:00, 72.23it/s] 80%|████████  | 69/86 [00:01<00:00, 78.61it/s] 92%|█████████▏| 79/86 [00:01<00:00, 83.34it/s]100%|██████████| 86/86 [00:01<00:00, 58.18it/s]
11000 images processed, 1.5016388893127441 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:04,  1.63it/s]  5%|▌         | 11/204 [00:00<00:09, 19.81it/s] 10%|▉         | 20/204 [00:00<00:05, 33.81it/s] 14%|█▎        | 28/204 [00:00<00:03, 44.15it/s] 18%|█▊        | 37/204 [00:01<00:03, 55.19it/s] 23%|██▎       | 46/204 [00:01<00:02, 64.04it/s] 27%|██▋       | 56/204 [00:01<00:02, 72.56it/s] 32%|███▏      | 66/204 [00:01<00:01, 77.89it/s] 37%|███▋      | 76/204 [00:01<00:01, 82.22it/s] 42%|████▏     | 85/204 [00:01<00:01, 84.33it/s] 46%|████▌     | 94/204 [00:01<00:01, 85.86it/s] 51%|█████     | 104/204 [00:01<00:01, 88.26it/s] 56%|█████▌    | 114/204 [00:01<00:01, 89.80it/s] 61%|██████    | 124/204 [00:01<00:00, 91.06it/s] 66%|██████▌   | 134/204 [00:02<00:00, 83.92it/s] 70%|███████   | 143/204 [00:02<00:00, 71.63it/s] 74%|███████▍  | 151/204 [00:02<00:00, 66.33it/s] 78%|███████▊  | 160/204 [00:02<00:00, 71.70it/s] 83%|████████▎ | 170/204 [00:02<00:00, 77.30it/s] 88%|████████▊ | 180/204 [00:02<00:00, 82.03it/s] 93%|█████████▎| 190/204 [00:02<00:00, 85.97it/s] 98%|█████████▊| 200/204 [00:02<00:00, 88.84it/s]100%|██████████| 204/204 [00:03<00:00, 67.72it/s]
26032 images processed, 3.0571422576904297 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:01,  1.26it/s] 11%|█▏        | 9/79 [00:00<00:05, 13.14it/s] 24%|██▍       | 19/79 [00:01<00:02, 28.15it/s] 37%|███▋      | 29/79 [00:01<00:01, 41.96it/s] 48%|████▊     | 38/79 [00:01<00:00, 52.45it/s] 61%|██████    | 48/79 [00:01<00:00, 62.90it/s] 72%|███████▏  | 57/79 [00:01<00:00, 61.60it/s] 82%|████████▏ | 65/79 [00:01<00:00, 61.56it/s] 95%|█████████▍| 75/79 [00:01<00:00, 70.13it/s]100%|██████████| 79/79 [00:01<00:00, 44.83it/s]
10000 images processed, 1.7876319885253906 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:52,  1.47it/s] 13%|█▎        | 10/79 [00:00<00:04, 16.84it/s] 25%|██▌       | 20/79 [00:00<00:01, 32.79it/s] 38%|███▊      | 30/79 [00:00<00:01, 46.78it/s] 51%|█████     | 40/79 [00:01<00:00, 58.35it/s] 63%|██████▎   | 50/79 [00:01<00:00, 67.34it/s] 76%|███████▌  | 60/79 [00:01<00:00, 74.94it/s] 89%|████████▊ | 70/79 [00:01<00:00, 80.89it/s]100%|██████████| 79/79 [00:01<00:00, 50.08it/s]
10000 images processed, 1.652440071105957 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:43,  1.60it/s] 14%|█▍        | 10/70 [00:00<00:03, 17.95it/s] 27%|██▋       | 19/70 [00:00<00:01, 32.43it/s] 39%|███▊      | 27/70 [00:00<00:01, 42.71it/s] 53%|█████▎    | 37/70 [00:01<00:00, 55.55it/s] 67%|██████▋   | 47/70 [00:01<00:00, 66.01it/s] 81%|████████▏ | 57/70 [00:01<00:00, 74.24it/s] 96%|█████████▌| 67/70 [00:01<00:00, 80.35it/s]100%|██████████| 70/70 [00:01<00:00, 49.07it/s]
8925 images processed, 1.4624605178833008 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:53,  1.21s/it]  4%|▍         | 2/45 [00:01<00:26,  1.63it/s] 27%|██▋       | 12/45 [00:01<00:02, 13.43it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.24it/s] 47%|████▋     | 21/45 [00:02<00:01, 14.34it/s] 53%|█████▎    | 24/45 [00:02<00:01, 15.29it/s] 67%|██████▋   | 30/45 [00:02<00:00, 19.12it/s] 73%|███████▎  | 33/45 [00:02<00:00, 16.43it/s] 82%|████████▏ | 37/45 [00:02<00:00, 19.92it/s] 89%|████████▉ | 40/45 [00:02<00:00, 20.83it/s]100%|██████████| 45/45 [00:03<00:00, 14.82it/s]
5640 images processed, 3.086482524871826 seconds used

21.129608631134033
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.79  98.86  78.71
places365     52.75  85.08  47.05
LSUN          44.66  89.26  61.90
iSUN          35.83  91.28  65.27
dtd           32.80  92.10  73.34
AVG           33.97  91.32  65.25
[incremental] Overall: 0.7410 New: 0.7220 Old: 0.7600
[incremental] Final(Top-1): 0.6220  Average: 0.7277
17.207330465316772
==== Stage 3: inc={59,58,44,93,10}; seen={0,8,11,40,51,66,67,88,94,57}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='59,58,44,93,10', forget_classes_seen='0,8,11,40,51,66,67,88,94,57', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:22<00:00, 22.40s/it]100%|██████████| 1/1 [00:22<00:00, 22.40s/it]
[loss] ep 0 it 0 total=6.0456 mle=4.0715 pcon=0.9689 forget=0.0000 orth=1.0052 favg=0.0000 nr=112 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3981 mle=4.4238 pcon=0.9691 forget=0.0000 orth=1.0052 favg=0.0000 nr=111 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4634 mle=4.4889 pcon=0.9694 forget=0.0000 orth=1.0052 favg=0.0000 nr=109 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0128 mle=5.0380 pcon=0.9696 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7035 mle=3.7286 pcon=0.9698 forget=0.0000 orth=1.0051 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2930 mle=4.3180 pcon=0.9699 forget=0.0000 orth=1.0051 favg=0.0000 nr=111 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9134 mle=3.9382 pcon=0.9701 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3396 mle=4.3645 pcon=0.9701 forget=0.0000 orth=1.0050 favg=0.0000 nr=105 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2795 mle=4.3044 pcon=0.9702 forget=0.0000 orth=1.0049 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stage3-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:02<15:46,  2.21s/it]  2%|▏         | 9/430 [00:02<01:20,  5.24it/s]  4%|▍         | 19/430 [00:02<00:32, 12.68it/s]  7%|▋         | 29/430 [00:02<00:18, 21.43it/s]  9%|▉         | 39/430 [00:02<00:12, 31.00it/s] 11%|█▏        | 49/430 [00:02<00:09, 40.93it/s] 14%|█▎        | 59/430 [00:02<00:07, 50.96it/s] 16%|█▌        | 69/430 [00:02<00:06, 60.02it/s] 18%|█▊        | 79/430 [00:03<00:05, 68.10it/s] 21%|██        | 89/430 [00:03<00:04, 74.61it/s] 23%|██▎       | 99/430 [00:03<00:04, 80.06it/s] 25%|██▌       | 109/430 [00:03<00:03, 84.34it/s] 28%|██▊       | 119/430 [00:03<00:03, 87.46it/s] 30%|███       | 129/430 [00:03<00:03, 89.61it/s] 32%|███▏      | 139/430 [00:03<00:03, 91.57it/s] 35%|███▍      | 149/430 [00:03<00:03, 92.15it/s] 37%|███▋      | 159/430 [00:03<00:02, 92.30it/s] 39%|███▉      | 169/430 [00:04<00:02, 93.21it/s] 42%|████▏     | 179/430 [00:04<00:02, 93.27it/s] 44%|████▍     | 189/430 [00:04<00:02, 92.94it/s] 46%|████▋     | 199/430 [00:04<00:02, 93.71it/s] 49%|████▊     | 209/430 [00:04<00:02, 94.30it/s] 51%|█████     | 219/430 [00:04<00:02, 94.89it/s] 53%|█████▎    | 229/430 [00:04<00:02, 94.67it/s] 56%|█████▌    | 239/430 [00:04<00:02, 94.98it/s] 58%|█████▊    | 249/430 [00:04<00:01, 95.27it/s] 60%|██████    | 259/430 [00:04<00:01, 95.36it/s] 63%|██████▎   | 269/430 [00:05<00:01, 95.45it/s] 65%|██████▍   | 279/430 [00:05<00:01, 95.66it/s] 67%|██████▋   | 289/430 [00:05<00:01, 95.09it/s] 70%|██████▉   | 299/430 [00:05<00:01, 93.49it/s] 72%|███████▏  | 309/430 [00:05<00:01, 93.44it/s] 74%|███████▍  | 319/430 [00:05<00:01, 93.37it/s] 77%|███████▋  | 329/430 [00:05<00:01, 94.13it/s] 79%|███████▉  | 339/430 [00:05<00:00, 94.53it/s] 81%|████████  | 349/430 [00:05<00:00, 94.49it/s] 83%|████████▎ | 359/430 [00:06<00:00, 94.65it/s] 86%|████████▌ | 369/430 [00:06<00:00, 90.07it/s] 88%|████████▊ | 379/430 [00:06<00:00, 91.66it/s] 90%|█████████ | 389/430 [00:06<00:00, 92.88it/s] 93%|█████████▎| 399/430 [00:06<00:00, 93.02it/s] 95%|█████████▌| 409/430 [00:06<00:00, 94.26it/s] 97%|█████████▋| 419/430 [00:06<00:00, 90.75it/s]100%|█████████▉| 429/430 [00:06<00:00, 92.69it/s]100%|██████████| 430/430 [00:06<00:00, 63.19it/s]
55000 images processed, 7.048534870147705 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<00:42,  1.99it/s] 13%|█▎        | 11/86 [00:00<00:03, 23.42it/s] 24%|██▍       | 21/86 [00:00<00:01, 40.61it/s] 35%|███▍      | 30/86 [00:00<00:01, 50.37it/s] 44%|████▍     | 38/86 [00:00<00:00, 55.90it/s] 56%|█████▌    | 48/86 [00:01<00:00, 65.90it/s] 67%|██████▋   | 58/86 [00:01<00:00, 73.42it/s] 79%|███████▉  | 68/86 [00:01<00:00, 79.61it/s] 91%|█████████ | 78/86 [00:01<00:00, 82.92it/s]100%|██████████| 86/86 [00:01<00:00, 58.18it/s]
11000 images processed, 1.499499797821045 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:13,  1.52it/s]  5%|▌         | 11/204 [00:00<00:10, 18.89it/s] 10%|▉         | 20/204 [00:00<00:05, 32.80it/s] 15%|█▍        | 30/204 [00:00<00:03, 46.88it/s] 20%|█▉        | 40/204 [00:01<00:02, 58.63it/s] 25%|██▍       | 50/204 [00:01<00:02, 67.95it/s] 29%|██▉       | 59/204 [00:01<00:01, 73.03it/s] 33%|███▎      | 68/204 [00:01<00:01, 77.50it/s] 38%|███▊      | 78/204 [00:01<00:01, 82.25it/s] 43%|████▎     | 88/204 [00:01<00:01, 85.83it/s] 48%|████▊     | 98/204 [00:01<00:01, 88.41it/s] 53%|█████▎    | 108/204 [00:01<00:01, 90.01it/s] 58%|█████▊    | 118/204 [00:01<00:00, 90.51it/s] 63%|██████▎   | 128/204 [00:02<00:00, 91.31it/s] 68%|██████▊   | 138/204 [00:02<00:00, 91.93it/s] 73%|███████▎  | 148/204 [00:02<00:00, 92.74it/s] 77%|███████▋  | 158/204 [00:02<00:00, 92.93it/s] 82%|████████▏ | 168/204 [00:02<00:00, 93.45it/s] 87%|████████▋ | 178/204 [00:02<00:00, 93.30it/s] 92%|█████████▏| 188/204 [00:02<00:00, 94.30it/s] 97%|█████████▋| 198/204 [00:02<00:00, 94.94it/s]100%|██████████| 204/204 [00:02<00:00, 71.12it/s]
26032 images processed, 3.0406851768493652 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:07,  1.16it/s] 14%|█▍        | 11/79 [00:00<00:04, 15.11it/s] 25%|██▌       | 20/79 [00:01<00:02, 27.45it/s] 38%|███▊      | 30/79 [00:01<00:01, 40.92it/s] 49%|████▉     | 39/79 [00:01<00:00, 50.90it/s] 62%|██████▏   | 49/79 [00:01<00:00, 61.41it/s] 73%|███████▎  | 58/79 [00:01<00:00, 65.52it/s] 85%|████████▍ | 67/79 [00:01<00:00, 61.59it/s] 97%|█████████▋| 77/79 [00:01<00:00, 70.03it/s]100%|██████████| 79/79 [00:01<00:00, 43.84it/s]
10000 images processed, 1.8696794509887695 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:58,  1.33it/s] 13%|█▎        | 10/79 [00:00<00:04, 15.49it/s] 25%|██▌       | 20/79 [00:00<00:01, 30.85it/s] 38%|███▊      | 30/79 [00:01<00:01, 44.82it/s] 51%|█████     | 40/79 [00:01<00:00, 56.41it/s] 62%|██████▏   | 49/79 [00:01<00:00, 64.52it/s] 73%|███████▎  | 58/79 [00:01<00:00, 69.91it/s] 86%|████████▌ | 68/79 [00:01<00:00, 77.18it/s] 99%|█████████▊| 78/79 [00:01<00:00, 82.63it/s]100%|██████████| 79/79 [00:01<00:00, 49.79it/s]
10000 images processed, 1.6631085872650146 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:41,  1.67it/s] 10%|█         | 7/70 [00:00<00:04, 12.68it/s] 21%|██▏       | 15/70 [00:00<00:02, 26.81it/s] 36%|███▌      | 25/70 [00:00<00:01, 42.11it/s] 49%|████▊     | 34/70 [00:01<00:00, 52.98it/s] 63%|██████▎   | 44/70 [00:01<00:00, 63.86it/s] 77%|███████▋  | 54/70 [00:01<00:00, 72.66it/s] 91%|█████████▏| 64/70 [00:01<00:00, 79.25it/s]100%|██████████| 70/70 [00:01<00:00, 49.38it/s]
8925 images processed, 1.448298454284668 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:51,  1.17s/it]  4%|▍         | 2/45 [00:01<00:24,  1.74it/s] 27%|██▋       | 12/45 [00:01<00:02, 14.12it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.06it/s] 47%|████▋     | 21/45 [00:01<00:01, 16.17it/s] 64%|██████▍   | 29/45 [00:02<00:00, 25.70it/s] 76%|███████▌  | 34/45 [00:02<00:00, 16.67it/s] 93%|█████████▎| 42/45 [00:02<00:00, 21.85it/s]100%|██████████| 45/45 [00:02<00:00, 15.62it/s]
5640 images processed, 2.905170440673828 seconds used

21.595689296722412
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.89  98.75  81.53
places365     61.03  83.04  47.69
LSUN          45.92  89.12  67.91
iSUN          40.81  90.51  71.01
dtd           35.59  90.86  75.61
AVG           37.45  90.46  68.75
[incremental] Overall: 0.6980 New: 0.7040 Old: 0.6950
[incremental] Final(Top-1): 0.6220  Average: 0.7277
3.5213005542755127
==== Stage 4: inc={64,22,42,9,90}; seen={0,8,11,40,51,66,67,88,94,57,59,58,44,93,10}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='64,22,42,9,90', forget_classes_seen='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:20<00:00, 20.38s/it]100%|██████████| 1/1 [00:20<00:00, 20.38s/it]
[loss] ep 0 it 0 total=6.0701 mle=4.0564 pcon=1.0090 forget=0.0000 orth=1.0048 favg=0.0000 nr=105 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.4171 mle=4.4031 pcon=1.0092 forget=0.0000 orth=1.0047 favg=0.0000 nr=103 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4851 mle=4.4709 pcon=1.0094 forget=0.0000 orth=1.0047 favg=0.0000 nr=105 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0301 mle=5.0157 pcon=1.0096 forget=0.0000 orth=1.0047 favg=0.0000 nr=100 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7243 mle=3.7098 pcon=1.0098 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.3045 mle=4.2899 pcon=1.0099 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9253 mle=3.9106 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=102 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3522 mle=4.3376 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=99 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2751 mle=4.2604 pcon=1.0102 forget=0.0000 orth=1.0045 favg=0.0000 nr=97 nf=9 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stage4-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:00<04:18,  1.66it/s]  3%|▎         | 11/430 [00:00<00:20, 20.33it/s]  5%|▍         | 21/430 [00:00<00:11, 36.65it/s]  7%|▋         | 31/430 [00:00<00:07, 50.65it/s] 10%|▉         | 41/430 [00:01<00:06, 62.11it/s] 12%|█▏        | 51/430 [00:01<00:05, 70.46it/s] 14%|█▍        | 61/430 [00:01<00:04, 77.27it/s] 17%|█▋        | 71/430 [00:01<00:04, 79.08it/s] 19%|█▉        | 81/430 [00:01<00:04, 83.52it/s] 21%|██        | 91/430 [00:01<00:03, 86.85it/s] 23%|██▎       | 101/430 [00:01<00:03, 89.42it/s] 26%|██▌       | 111/430 [00:01<00:03, 91.20it/s] 28%|██▊       | 121/430 [00:01<00:03, 92.73it/s] 30%|███       | 131/430 [00:01<00:03, 93.52it/s] 33%|███▎      | 141/430 [00:02<00:03, 93.73it/s] 35%|███▌      | 151/430 [00:02<00:02, 93.61it/s] 37%|███▋      | 161/430 [00:02<00:02, 94.11it/s] 40%|███▉      | 171/430 [00:02<00:02, 94.59it/s] 42%|████▏     | 181/430 [00:02<00:02, 95.14it/s] 44%|████▍     | 191/430 [00:02<00:02, 95.33it/s] 47%|████▋     | 201/430 [00:02<00:02, 95.34it/s] 49%|████▉     | 211/430 [00:02<00:02, 95.58it/s] 51%|█████▏    | 221/430 [00:02<00:02, 95.77it/s] 54%|█████▎    | 231/430 [00:03<00:02, 95.80it/s] 56%|█████▌    | 241/430 [00:03<00:01, 95.95it/s] 58%|█████▊    | 251/430 [00:03<00:01, 95.78it/s] 61%|██████    | 261/430 [00:03<00:01, 95.78it/s] 63%|██████▎   | 271/430 [00:03<00:01, 95.49it/s] 65%|██████▌   | 281/430 [00:03<00:01, 95.38it/s] 68%|██████▊   | 291/430 [00:03<00:01, 95.03it/s] 70%|███████   | 301/430 [00:03<00:01, 95.17it/s] 72%|███████▏  | 311/430 [00:03<00:01, 94.32it/s] 75%|███████▍  | 321/430 [00:03<00:01, 94.53it/s] 77%|███████▋  | 331/430 [00:04<00:01, 94.81it/s] 79%|███████▉  | 341/430 [00:04<00:00, 94.93it/s] 82%|████████▏ | 351/430 [00:04<00:00, 95.08it/s] 84%|████████▍ | 361/430 [00:04<00:00, 95.12it/s] 86%|████████▋ | 371/430 [00:04<00:00, 94.77it/s] 89%|████████▊ | 381/430 [00:04<00:00, 94.90it/s] 91%|█████████ | 391/430 [00:04<00:00, 95.20it/s] 93%|█████████▎| 401/430 [00:04<00:00, 94.74it/s] 96%|█████████▌| 411/430 [00:04<00:00, 95.31it/s] 98%|█████████▊| 421/430 [00:05<00:00, 95.90it/s]100%|██████████| 430/430 [00:05<00:00, 83.79it/s]
55000 images processed, 5.207459211349487 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<00:43,  1.97it/s] 13%|█▎        | 11/86 [00:00<00:03, 23.15it/s] 24%|██▍       | 21/86 [00:00<00:01, 40.79it/s] 36%|███▌      | 31/86 [00:00<00:01, 54.41it/s] 48%|████▊     | 41/86 [00:00<00:00, 65.33it/s] 59%|█████▉    | 51/86 [00:01<00:00, 72.61it/s] 71%|███████   | 61/86 [00:01<00:00, 78.99it/s] 83%|████████▎ | 71/86 [00:01<00:00, 83.89it/s] 94%|█████████▍| 81/86 [00:01<00:00, 87.56it/s]100%|██████████| 86/86 [00:01<00:00, 60.59it/s]
11000 images processed, 1.4398257732391357 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:10,  1.56it/s]  5%|▌         | 11/204 [00:00<00:10, 19.23it/s] 10%|█         | 21/204 [00:00<00:05, 35.28it/s] 15%|█▌        | 31/204 [00:00<00:03, 49.02it/s] 20%|██        | 41/204 [00:01<00:02, 60.36it/s] 25%|██▌       | 51/204 [00:01<00:02, 69.21it/s] 30%|██▉       | 61/204 [00:01<00:01, 76.24it/s] 35%|███▍      | 71/204 [00:01<00:01, 81.20it/s] 40%|███▉      | 81/204 [00:01<00:01, 84.86it/s] 45%|████▍     | 91/204 [00:01<00:01, 87.39it/s] 50%|████▉     | 101/204 [00:01<00:01, 88.92it/s] 54%|█████▍    | 111/204 [00:01<00:01, 90.53it/s] 59%|█████▉    | 121/204 [00:01<00:00, 91.48it/s] 64%|██████▍   | 131/204 [00:02<00:00, 92.33it/s] 69%|██████▉   | 141/204 [00:02<00:00, 92.94it/s] 74%|███████▍  | 151/204 [00:02<00:00, 93.37it/s] 79%|███████▉  | 161/204 [00:02<00:00, 93.76it/s] 84%|████████▍ | 171/204 [00:02<00:00, 93.05it/s] 89%|████████▊ | 181/204 [00:02<00:00, 93.55it/s] 94%|█████████▎| 191/204 [00:02<00:00, 94.35it/s] 99%|█████████▊| 201/204 [00:02<00:00, 84.02it/s]100%|██████████| 204/204 [00:02<00:00, 70.32it/s]
26032 images processed, 2.989057779312134 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:00,  1.28it/s] 11%|█▏        | 9/79 [00:00<00:05, 13.24it/s] 24%|██▍       | 19/79 [00:00<00:02, 28.36it/s] 37%|███▋      | 29/79 [00:01<00:01, 42.38it/s] 47%|████▋     | 37/79 [00:01<00:00, 47.93it/s] 59%|█████▉    | 47/79 [00:01<00:00, 58.70it/s] 70%|██████▉   | 55/79 [00:01<00:00, 61.16it/s] 82%|████████▏ | 65/79 [00:01<00:00, 70.16it/s] 95%|█████████▍| 75/79 [00:01<00:00, 77.14it/s]100%|██████████| 79/79 [00:01<00:00, 45.99it/s]
10000 images processed, 1.7544779777526855 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:59,  1.32it/s] 11%|█▏        | 9/79 [00:00<00:05, 13.75it/s] 24%|██▍       | 19/79 [00:00<00:02, 29.21it/s] 37%|███▋      | 29/79 [00:01<00:01, 42.68it/s] 48%|████▊     | 38/79 [00:01<00:00, 51.82it/s] 59%|█████▉    | 47/79 [00:01<00:00, 60.00it/s] 72%|███████▏  | 57/79 [00:01<00:00, 69.32it/s] 85%|████████▍ | 67/79 [00:01<00:00, 76.69it/s] 97%|█████████▋| 77/79 [00:01<00:00, 82.21it/s]100%|██████████| 79/79 [00:01<00:00, 48.67it/s]
10000 images processed, 1.6521995067596436 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:36,  1.87it/s] 14%|█▍        | 10/70 [00:00<00:02, 20.21it/s] 29%|██▊       | 20/70 [00:00<00:01, 38.00it/s] 43%|████▎     | 30/70 [00:00<00:00, 52.48it/s] 57%|█████▋    | 40/70 [00:00<00:00, 63.86it/s] 71%|███████▏  | 50/70 [00:01<00:00, 72.79it/s] 86%|████████▌ | 60/70 [00:01<00:00, 79.56it/s]100%|██████████| 70/70 [00:01<00:00, 83.50it/s]100%|██████████| 70/70 [00:01<00:00, 55.07it/s]
8925 images processed, 1.2974300384521484 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:52,  1.20s/it] 24%|██▍       | 11/45 [00:01<00:02, 11.34it/s] 38%|███▊      | 17/45 [00:01<00:02, 10.76it/s] 60%|██████    | 27/45 [00:02<00:00, 19.78it/s] 73%|███████▎  | 33/45 [00:02<00:00, 14.76it/s] 96%|█████████▌| 43/45 [00:02<00:00, 22.96it/s]100%|██████████| 45/45 [00:02<00:00, 16.22it/s]
5640 images processed, 2.798203945159912 seconds used

19.155253887176514
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.18  98.70  84.51
places365     73.26  79.67  48.99
LSUN          49.12  88.47  71.16
iSUN          50.80  88.26  71.62
dtd           41.06  90.05  77.99
AVG           43.69  89.03  70.85
[incremental] Overall: 0.6220 New: 0.6220 Old: 0.6220
[incremental] Final(Top-1): 0.6220  Average: 0.7277
12.877442836761475
[DEBUG] Eval output (last 30 lines):
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:14,  1.05it/s] 11%|█▏        | 9/79 [00:01<00:06, 11.33it/s] 24%|██▍       | 19/79 [00:01<00:02, 25.04it/s] 37%|███▋      | 29/79 [00:01<00:01, 38.07it/s] 48%|████▊     | 38/79 [00:01<00:00, 47.20it/s] 58%|█████▊    | 46/79 [00:01<00:00, 47.43it/s] 67%|██████▋   | 53/79 [00:01<00:00, 45.64it/s] 76%|███████▌  | 60/79 [00:01<00:00, 49.59it/s] 85%|████████▍ | 67/79 [00:01<00:00, 51.83it/s] 97%|█████████▋| 77/79 [00:02<00:00, 62.77it/s]100%|██████████| 79/79 [00:02<00:00, 38.23it/s]
10000 images processed, 2.0860917568206787 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:49,  1.38it/s] 14%|█▍        | 10/70 [00:00<00:03, 15.77it/s] 29%|██▊       | 20/70 [00:00<00:01, 31.31it/s] 43%|████▎     | 30/70 [00:01<00:00, 45.06it/s] 57%|█████▋    | 40/70 [00:01<00:00, 56.93it/s] 71%|███████▏  | 50/70 [00:01<00:00, 66.82it/s] 86%|████████▌ | 60/70 [00:01<00:00, 74.54it/s]100%|██████████| 70/70 [00:01<00:00, 78.58it/s]100%|██████████| 70/70 [00:01<00:00, 47.57it/s]
8925 images processed, 1.5186119079589844 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:09,  1.58s/it] 20%|██        | 9/45 [00:01<00:05,  7.14it/s] 38%|███▊      | 17/45 [00:02<00:02, 10.53it/s] 51%|█████     | 23/45 [00:02<00:01, 13.96it/s] 73%|███████▎  | 33/45 [00:02<00:00, 15.86it/s] 96%|█████████▌| 43/45 [00:03<00:00, 23.94it/s]100%|██████████| 45/45 [00:03<00:00, 14.78it/s]
5640 images processed, 3.0674378871917725 seconds used

21.183828353881836
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.18  98.70  84.51
places365     73.26  79.67  48.99
LSUN          49.12  88.47  71.16
iSUN          50.80  88.26  71.62
dtd           41.06  90.05  77.99
AVG           43.69  89.03  70.85
[incremental] Overall: 0.6220 New: 0.6220 Old: 0.6220
[incremental] Final(Top-1): 0.6220  Average: 0.7277
5.1600470542907715
[DEBUG] Parsed: avg_fpr=43.69 avg_auroc=89.03 final_top1=0.6220 average=0.7277
[Result] AVG-AUROC=89.03 AVG-FPR=43.69 Final-Top1=0.6220 Average=0.7277 Score=70.08

[Grid Search Continual] Completed. Results saved to: evaluation_results/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-continual-continual-grid_runs.csv
