nohup: ignoring input
[Grid Search Continual] Searching over: lambda_pcon(0.1) × lrs(0.001) × epochs(1) × lora_r(8)
[Grid Search Continual] Stages: 0,8,11,40,51 66,67,88,94,57 59,58,44,93,10 64,22,42,9,90

==========================================
[Run] lambda_pcon=0.1 lr=0.001 epochs=1 lora_r=8
==========================================
==== Stage 1: inc={0,8,11,40,51}; seen={}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:22<00:00, 22.97s/it]100%|██████████| 1/1 [00:22<00:00, 22.97s/it]
[loss] ep 0 it 0 total=4.6430 mle=4.0804 pcon=0.5626 forget=0.0000 orth=0.0000 favg=0.0000 nr=122 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=5.0011 mle=4.4384 pcon=0.5628 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=5.0627 mle=4.4998 pcon=0.5629 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=5.6153 mle=5.0521 pcon=0.5631 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=4.3043 mle=3.7410 pcon=0.5634 forget=0.0000 orth=0.0000 favg=0.0000 nr=118 nf=10 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=4.8998 mle=4.3362 pcon=0.5635 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=4.5204 mle=3.9567 pcon=0.5637 forget=0.0000 orth=0.0000 favg=0.0000 nr=120 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=4.9444 mle=4.3806 pcon=0.5638 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=4.8929 mle=4.3289 pcon=0.5640 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
==== Stage 2: inc={66,67,88,94,57}; seen={0,8,11,40,51}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:20<00:00, 20.46s/it]100%|██████████| 1/1 [00:20<00:00, 20.46s/it]
[loss] ep 0 it 0 total=5.9808 mle=4.0774 pcon=0.8978 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3369 mle=4.4332 pcon=0.8980 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.3998 mle=4.4959 pcon=0.8982 forget=0.0000 orth=1.0056 favg=0.0000 nr=114 nf=9 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=6.9513 mle=5.0473 pcon=0.8984 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.6407 mle=3.7367 pcon=0.8985 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=1 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2342 mle=4.3299 pcon=0.8987 forget=0.0000 orth=1.0055 favg=0.0000 nr=116 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.8548 mle=3.9505 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=114 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.2800 mle=4.3757 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=110 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2260 mle=4.3216 pcon=0.8989 forget=0.0000 orth=1.0054 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
==== Stage 3: inc={59,58,44,93,10}; seen={0,8,11,40,51,66,67,88,94,57}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='59,58,44,93,10', forget_classes_seen='0,8,11,40,51,66,67,88,94,57', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:28<00:00, 28.45s/it]100%|██████████| 1/1 [00:28<00:00, 28.45s/it]
[loss] ep 0 it 0 total=6.0454 mle=4.0713 pcon=0.9689 forget=0.0000 orth=1.0052 favg=0.0000 nr=112 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3981 mle=4.4238 pcon=0.9691 forget=0.0000 orth=1.0052 favg=0.0000 nr=111 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4634 mle=4.4889 pcon=0.9694 forget=0.0000 orth=1.0052 favg=0.0000 nr=109 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0127 mle=5.0379 pcon=0.9696 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7035 mle=3.7286 pcon=0.9698 forget=0.0000 orth=1.0051 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2929 mle=4.3179 pcon=0.9699 forget=0.0000 orth=1.0051 favg=0.0000 nr=111 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9135 mle=3.9384 pcon=0.9701 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3396 mle=4.3645 pcon=0.9701 forget=0.0000 orth=1.0050 favg=0.0000 nr=105 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2798 mle=4.3046 pcon=0.9702 forget=0.0000 orth=1.0049 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
==== Stage 4: inc={64,22,42,9,90}; seen={0,8,11,40,51,66,67,88,94,57,59,58,44,93,10}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='64,22,42,9,90', forget_classes_seen='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:22<00:00, 22.59s/it]100%|██████████| 1/1 [00:22<00:00, 22.59s/it]
[loss] ep 0 it 0 total=6.0699 mle=4.0562 pcon=1.0090 forget=0.0000 orth=1.0048 favg=0.0000 nr=105 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.4170 mle=4.4031 pcon=1.0092 forget=0.0000 orth=1.0047 favg=0.0000 nr=103 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4853 mle=4.4711 pcon=1.0094 forget=0.0000 orth=1.0047 favg=0.0000 nr=105 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0303 mle=5.0160 pcon=1.0096 forget=0.0000 orth=1.0047 favg=0.0000 nr=100 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7239 mle=3.7094 pcon=1.0098 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.3045 mle=4.2899 pcon=1.0099 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9256 mle=3.9109 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=102 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3519 mle=4.3372 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=99 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2753 mle=4.2606 pcon=1.0102 forget=0.0000 orth=1.0045 favg=0.0000 nr=97 nf=9 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4
[DEBUG] Eval output (last 30 lines):
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:55,  1.41it/s] 10%|█         | 8/79 [00:00<00:05, 12.64it/s] 20%|██        | 16/79 [00:00<00:02, 24.90it/s] 30%|███       | 24/79 [00:01<00:01, 35.56it/s] 41%|████      | 32/79 [00:01<00:01, 43.56it/s] 49%|████▉     | 39/79 [00:01<00:00, 49.11it/s] 58%|█████▊    | 46/79 [00:01<00:00, 53.31it/s] 68%|██████▊   | 54/79 [00:01<00:00, 57.97it/s] 77%|███████▋  | 61/79 [00:01<00:00, 60.64it/s] 87%|████████▋ | 69/79 [00:01<00:00, 63.12it/s] 96%|█████████▌| 76/79 [00:01<00:00, 64.38it/s]100%|██████████| 79/79 [00:01<00:00, 42.75it/s]
10000 images processed, 1.8747200965881348 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:46,  1.50it/s] 11%|█▏        | 8/70 [00:00<00:04, 13.54it/s] 21%|██▏       | 15/70 [00:00<00:02, 24.03it/s] 33%|███▎      | 23/70 [00:01<00:01, 34.95it/s] 44%|████▍     | 31/70 [00:01<00:00, 44.40it/s] 54%|█████▍    | 38/70 [00:01<00:00, 50.40it/s] 64%|██████▍   | 45/70 [00:01<00:00, 54.96it/s] 74%|███████▍  | 52/70 [00:01<00:00, 58.32it/s] 86%|████████▌ | 60/70 [00:01<00:00, 61.56it/s] 97%|█████████▋| 68/70 [00:01<00:00, 63.98it/s]100%|██████████| 70/70 [00:01<00:00, 41.63it/s]
8925 images processed, 1.7120888233184814 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:52,  1.19s/it]  4%|▍         | 2/45 [00:01<00:25,  1.71it/s] 20%|██        | 9/45 [00:01<00:03, 10.27it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.08it/s] 44%|████▍     | 20/45 [00:01<00:01, 15.83it/s] 51%|█████     | 23/45 [00:02<00:01, 15.18it/s] 67%|██████▋   | 30/45 [00:02<00:00, 23.64it/s] 76%|███████▌  | 34/45 [00:02<00:00, 15.26it/s] 91%|█████████ | 41/45 [00:02<00:00, 22.30it/s]100%|██████████| 45/45 [00:02<00:00, 15.11it/s]
5640 images processed, 2.997368097305298 seconds used

24.909420251846313
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.18  98.70  84.51
places365     73.27  79.67  48.99
LSUN          49.13  88.47  71.16
iSUN          50.80  88.26  71.62
dtd           41.08  90.05  77.99
AVG           43.69  89.03  70.85
[incremental] Overall: 0.6220 New: 0.6220 Old: 0.6220
[incremental] Final(Top-1): 0.6220  Average: 0.7277
7.015022277832031
[DEBUG] Parsed: avg_fpr=43.69 avg_auroc=89.03 final_top1=0.6220 average=0.7277
[Result] AVG-AUROC=89.03 AVG-FPR=43.69 Final-Top1=0.6220 Average=0.7277 Score=70.08

[Grid Search Continual] Completed. Results saved to: evaluation_results/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-continual-continual-grid_runs.csv
