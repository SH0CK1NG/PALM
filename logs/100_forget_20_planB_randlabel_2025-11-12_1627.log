nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget20.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10,64,22,42,9,90', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [00:43<02:55, 44.00s/it] 40%|████      | 2/5 [01:09<01:38, 32.90s/it] 60%|██████    | 3/5 [01:34<00:59, 29.63s/it] 80%|████████  | 4/5 [01:59<00:27, 27.52s/it]100%|██████████| 5/5 [02:24<00:00, 26.63s/it]100%|██████████| 5/5 [02:24<00:00, 28.84s/it]
[loss-randlabel] ep 0 it 0 total=10.0435 ce_r=0.0326 ce_f=10.0109
[loss-randlabel] ep 0 it 50 total=10.2826 ce_r=0.0165 ce_f=10.2662
[loss-randlabel] ep 0 it 100 total=9.7586 ce_r=0.0404 ce_f=9.7183
[loss-randlabel] ep 0 it 150 total=9.1941 ce_r=0.0853 ce_f=9.1088
[loss-randlabel] ep 0 it 200 total=7.2801 ce_r=0.6675 ce_f=6.6125
[loss-randlabel] ep 0 it 250 total=6.6560 ce_r=0.9716 ce_f=5.6845
[loss-randlabel] ep 0 it 300 total=6.8678 ce_r=0.9811 ce_f=5.8867
[loss-randlabel] ep 0 it 350 total=6.2600 ce_r=0.8210 ce_f=5.4390
[loss-randlabel] ep 1 it 10 total=6.2118 ce_r=0.8162 ce_f=5.3956
[loss-randlabel] ep 1 it 60 total=6.2536 ce_r=0.7244 ce_f=5.5292
[loss-randlabel] ep 1 it 110 total=6.0013 ce_r=0.8884 ce_f=5.1129
[loss-randlabel] ep 1 it 160 total=6.2781 ce_r=1.0117 ce_f=5.2664
[loss-randlabel] ep 1 it 210 total=6.2427 ce_r=0.7865 ce_f=5.4562
[loss-randlabel] ep 1 it 260 total=6.1777 ce_r=0.7041 ce_f=5.4736
[loss-randlabel] ep 1 it 310 total=6.1497 ce_r=0.8580 ce_f=5.2917
[loss-randlabel] ep 1 it 360 total=6.2071 ce_r=0.8196 ce_f=5.3875
[loss-randlabel] ep 2 it 20 total=6.1363 ce_r=0.9432 ce_f=5.1930
[loss-randlabel] ep 2 it 70 total=5.9629 ce_r=0.6476 ce_f=5.3153
[loss-randlabel] ep 2 it 120 total=5.9039 ce_r=0.5757 ce_f=5.3282
[loss-randlabel] ep 2 it 170 total=6.0239 ce_r=0.8727 ce_f=5.1512
[loss-randlabel] ep 2 it 220 total=5.9574 ce_r=0.7178 ce_f=5.2397
[loss-randlabel] ep 2 it 270 total=6.1162 ce_r=0.9323 ce_f=5.1839
[loss-randlabel] ep 2 it 320 total=5.8008 ce_r=0.7582 ce_f=5.0426
[loss-randlabel] ep 2 it 370 total=5.8429 ce_r=0.6028 ce_f=5.2401
[loss-randlabel] ep 3 it 30 total=5.8386 ce_r=0.8815 ce_f=4.9570
[loss-randlabel] ep 3 it 80 total=5.8658 ce_r=0.8307 ce_f=5.0351
[loss-randlabel] ep 3 it 130 total=6.0581 ce_r=0.8397 ce_f=5.2184
[loss-randlabel] ep 3 it 180 total=5.9211 ce_r=0.8724 ce_f=5.0487
[loss-randlabel] ep 3 it 230 total=5.8426 ce_r=0.7804 ce_f=5.0622
[loss-randlabel] ep 3 it 280 total=5.8774 ce_r=0.8381 ce_f=5.0392
[loss-randlabel] ep 3 it 330 total=5.8871 ce_r=0.8316 ce_f=5.0555
[loss-randlabel] ep 3 it 380 total=5.9334 ce_r=0.7997 ce_f=5.1337
[loss-randlabel] ep 4 it 40 total=5.8696 ce_r=0.6844 ce_f=5.1853
[loss-randlabel] ep 4 it 90 total=5.9559 ce_r=0.7641 ce_f=5.1918
[loss-randlabel] ep 4 it 140 total=5.7423 ce_r=0.7543 ce_f=4.9880
[loss-randlabel] ep 4 it 190 total=5.7670 ce_r=0.6540 ce_f=5.1130
[loss-randlabel] ep 4 it 240 total=5.6724 ce_r=0.7178 ce_f=4.9546
[loss-randlabel] ep 4 it 290 total=5.7165 ce_r=0.7197 ce_f=4.9969
[loss-randlabel] ep 4 it 340 total=5.8482 ce_r=0.5773 ce_f=5.2709
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget20: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:44,  2.37it/s]  2%|▏         | 9/391 [00:00<00:18, 21.20it/s]  4%|▎         | 14/391 [00:00<00:14, 26.02it/s]  6%|▌         | 22/391 [00:00<00:09, 38.58it/s]  8%|▊         | 32/391 [00:00<00:06, 53.23it/s] 10%|█         | 41/391 [00:00<00:05, 62.69it/s] 13%|█▎        | 49/391 [00:01<00:06, 56.89it/s] 14%|█▍        | 56/391 [00:01<00:06, 53.78it/s] 16%|█▌        | 62/391 [00:01<00:06, 51.41it/s] 17%|█▋        | 68/391 [00:01<00:06, 49.95it/s] 19%|█▉        | 74/391 [00:01<00:06, 51.11it/s] 21%|██▏       | 84/391 [00:01<00:04, 62.18it/s] 24%|██▍       | 94/391 [00:01<00:04, 70.28it/s] 27%|██▋       | 104/391 [00:02<00:03, 76.24it/s] 29%|██▉       | 114/391 [00:02<00:03, 80.61it/s] 31%|███▏      | 123/391 [00:02<00:03, 69.46it/s] 34%|███▎      | 131/391 [00:02<00:04, 61.64it/s] 35%|███▌      | 138/391 [00:02<00:04, 59.40it/s] 37%|███▋      | 145/391 [00:02<00:04, 59.13it/s] 39%|███▉      | 152/391 [00:02<00:04, 56.48it/s] 41%|████      | 160/391 [00:02<00:03, 61.45it/s] 43%|████▎     | 170/391 [00:03<00:03, 69.42it/s] 46%|████▌     | 179/391 [00:03<00:02, 74.77it/s] 48%|████▊     | 187/391 [00:03<00:03, 65.86it/s] 50%|████▉     | 194/391 [00:03<00:03, 59.74it/s] 51%|█████▏    | 201/391 [00:03<00:03, 56.01it/s] 53%|█████▎    | 207/391 [00:03<00:03, 54.33it/s] 54%|█████▍    | 213/391 [00:03<00:03, 52.33it/s] 57%|█████▋    | 223/391 [00:03<00:02, 62.86it/s] 60%|█████▉    | 233/391 [00:04<00:02, 70.56it/s] 62%|██████▏   | 243/391 [00:04<00:01, 76.48it/s] 65%|██████▍   | 253/391 [00:04<00:01, 80.79it/s] 67%|██████▋   | 262/391 [00:04<00:01, 71.74it/s] 69%|██████▉   | 270/391 [00:04<00:01, 62.96it/s] 71%|███████   | 277/391 [00:04<00:01, 58.50it/s] 73%|███████▎  | 284/391 [00:04<00:01, 58.18it/s] 74%|███████▍  | 290/391 [00:05<00:01, 55.15it/s] 77%|███████▋  | 300/391 [00:05<00:01, 64.85it/s] 79%|███████▉  | 310/391 [00:05<00:01, 72.34it/s] 82%|████████▏ | 320/391 [00:05<00:00, 77.89it/s] 84%|████████▍ | 330/391 [00:05<00:00, 82.00it/s] 87%|████████▋ | 339/391 [00:05<00:00, 79.28it/s] 89%|████████▉ | 348/391 [00:05<00:00, 65.53it/s] 91%|█████████ | 356/391 [00:05<00:00, 59.35it/s] 93%|█████████▎| 363/391 [00:06<00:00, 58.69it/s] 95%|█████████▍| 370/391 [00:06<00:00, 55.17it/s] 96%|█████████▋| 377/391 [00:06<00:00, 56.18it/s] 98%|█████████▊| 383/391 [00:06<00:00, 52.81it/s] 99%|█████████▉| 389/391 [00:06<00:00, 51.26it/s]100%|██████████| 391/391 [00:06<00:00, 58.96it/s]
50000 images processed, 6.73339581489563 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:43,  1.81it/s]  6%|▋         | 5/79 [00:00<00:07,  9.60it/s] 13%|█▎        | 10/79 [00:00<00:03, 18.48it/s] 19%|█▉        | 15/79 [00:00<00:02, 25.75it/s] 25%|██▌       | 20/79 [00:00<00:01, 31.48it/s] 33%|███▎      | 26/79 [00:01<00:01, 38.66it/s] 39%|███▉      | 31/79 [00:01<00:01, 41.12it/s] 48%|████▊     | 38/79 [00:01<00:00, 48.86it/s] 59%|█████▉    | 47/79 [00:01<00:00, 60.17it/s] 72%|███████▏  | 57/79 [00:01<00:00, 69.95it/s] 85%|████████▍ | 67/79 [00:01<00:00, 76.60it/s] 96%|█████████▌| 76/79 [00:01<00:00, 79.03it/s]100%|██████████| 79/79 [00:01<00:00, 44.63it/s]
10000 images processed, 1.8033642768859863 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget20/CIFAR-100/forget
8.543523073196411
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Traceback (most recent call last):
  File "/home/shaokun/PALM/eval_cifar.py", line 19, in <module>
    eval_maha(args)
  File "/home/shaokun/PALM/util/evaluations/mahalanobis.py", line 189, in eval_maha
    metrics.print_all_results(all_results, eval_names, 'SSD+')
  File "/home/shaokun/PALM/util/evaluations/metrics.py", line 160, in print_all_results
    avg_results = compute_average_results(results)
  File "/home/shaokun/PALM/util/evaluations/metrics.py", line 190, in compute_average_results
    avg_results[mtype] /= float(len(all_results))
ZeroDivisionError: float division by zero
