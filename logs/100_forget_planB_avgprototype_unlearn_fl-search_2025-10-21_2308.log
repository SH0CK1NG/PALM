nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.3, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:27<22:03, 27.00s/it]  4%|▍         | 2/50 [00:46<17:54, 22.39s/it]  6%|▌         | 3/50 [01:05<16:27, 21.00s/it]  8%|▊         | 4/50 [01:27<16:18, 21.28s/it] 10%|█         | 5/50 [01:53<17:22, 23.17s/it] 12%|█▏        | 6/50 [02:13<16:04, 21.93s/it] 14%|█▍        | 7/50 [02:32<15:02, 20.98s/it] 16%|█▌        | 8/50 [02:48<13:43, 19.61s/it][loss] ep 0 it 0 total=8.3883 mle=1.5710 pcon=5.2950 forget=2.0632 favg=-0.5410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.2662 mle=1.5424 pcon=5.2879 forget=2.1020 favg=-0.6660 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4091 mle=1.7005 pcon=5.2809 forget=2.0610 favg=-0.6333 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.5574 mle=1.8995 pcon=5.2738 forget=2.0544 favg=-0.6704 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.4608 mle=1.7132 pcon=5.2670 forget=2.0739 favg=-0.5933 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.2062 mle=1.5019 pcon=5.2603 forget=2.0675 favg=-0.6235 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.3397 mle=1.5597 pcon=5.2540 forget=2.0728 favg=-0.5469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.3400 mle=1.6809 pcon=5.2476 forget=2.0843 favg=-0.6729 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=8.3249 mle=1.6714 pcon=5.2409 forget=2.1148 favg=-0.7021 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2974 mle=1.6370 pcon=5.2346 forget=2.0503 favg=-0.6245 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.2322 mle=1.5167 pcon=5.2284 forget=2.0838 favg=-0.5967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.4699 mle=1.7802 pcon=5.2224 forget=2.0835 favg=-0.6162 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.3897 mle=1.7648 pcon=5.2166 forget=2.0772 favg=-0.6689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.3133 mle=1.6039 pcon=5.2112 forget=2.0510 favg=-0.5527 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.4223 mle=1.7227 pcon=5.2055 forget=2.0654 favg=-0.5713 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3731 mle=1.7940 pcon=5.2001 forget=2.0762 favg=-0.6973 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=8.0777 mle=1.5526 pcon=5.1948 forget=2.0607 favg=-0.7305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.2807 mle=1.8869 pcon=5.1896 forget=2.0285 favg=-0.8242 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.1662 mle=1.7436 pcon=5.1842 forget=2.0528 favg=-0.8145 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=7.6784 mle=1.5266 pcon=5.1788 forget=2.0277 favg=-1.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=7.4415 mle=1.5962 pcon=5.1733 forget=2.0735 favg=-1.4014 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=7.2936 mle=1.8701 pcon=5.1679 forget=2.0593 favg=-1.8037 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=6.5824 mle=1.5652 pcon=5.1622 forget=2.0972 favg=-2.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=6.6043 mle=1.8248 pcon=5.1565 forget=2.1542 favg=-2.5312 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 3 it 30 total=6.3762 mle=1.7340 pcon=5.1508 forget=2.2179 favg=-2.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=6.2868 mle=1.7490 pcon=5.1457 forget=2.2730 favg=-2.8809 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=6.3076 mle=1.7754 pcon=5.1405 forget=2.3098 favg=-2.9180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=6.6132 mle=1.9854 pcon=5.1358 forget=2.3494 favg=-2.8574 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=6.8967 mle=1.6523 pcon=5.1312 forget=2.4119 favg=-2.2988 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=10.8515 mle=1.9414 pcon=5.1264 forget=2.5005 favg=1.2832 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=12.2008 mle=1.8187 pcon=5.1214 forget=2.5204 favg=2.7402 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=11.9742 mle=1.7057 pcon=5.1170 forget=2.4483 favg=2.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 40 total=11.3336 mle=1.6332 pcon=5.1124 forget=2.2871 favg=2.3008 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=10.7052 mle=1.7351 pcon=5.1080 forget=2.1767 favg=1.6855 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=9.9263 mle=1.6636 pcon=5.1042 forget=2.1175 favg=1.0410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=9.4131 mle=1.4485 pcon=5.1008 forget=2.0998 favg=0.7642 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=9.4594 mle=1.7670 pcon=5.0970 forget=2.0666 favg=0.5288 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=9.1792 mle=1.4929 pcon=5.0936 forget=2.0644 favg=0.5283 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=9.5922 mle=1.8734 pcon=5.0903 forget=2.0846 favg=0.5439 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=9.6216 mle=1.8705 pcon=5.0871 forget=2.0791 favg=0.5850 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=9.0050 mle=1.7756 pcon=5.0837 forget=2.0507 favg=0.0949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2626 mle=1.5958 pcon=5.0810 forget=2.0985 favg=-0.5127 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=9.0368 mle=1.6103 pcon=5.0781 forget=2.1011 favg=0.2473 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.7907 mle=1.6897 pcon=5.0756 forget=2.0606 favg=-0.0352 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.3800 mle=1.7653 pcon=5.0727 forget=2.0415 favg=-0.4995 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=7.8930 mle=1.5870 pcon=5.0696 forget=2.0645 favg=-0.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=7.5395 mle=1.7392 pcon=5.0665 forget=2.1273 favg=-1.3936 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=7.1927 mle=1.4296 pcon=5.0633 forget=2.2213 favg=-1.5215 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=11.0328 mle=1.5326 pcon=5.0602 forget=2.1979 favg=2.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=10.8601 mle=1.5993 pcon=5.0572 forget=2.1645 favg=2.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=9.4241 mle=1.6572 pcon=5.0542 forget=2.0584 favg=0.6543 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.7449 mle=1.6255 pcon=5.0520 forget=2.0491 favg=0.0184 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.4599 mle=1.8184 pcon=5.0492 forget=2.0716 favg=-0.4792 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=6.9039 mle=1.5230 pcon=5.0470 forget=2.0761 favg=-1.7422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=7.0191 mle=1.6686 pcon=5.0448 forget=2.0499 favg=-1.7441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=10.0840 mle=1.6450 pcon=5.0422 forget=2.1526 favg=1.2441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=10.1290 mle=1.7252 pcon=5.0395 forget=2.1875 favg=1.1768 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=9.0677 mle=1.5869 pcon=5.0364 forget=2.1314 favg=0.3130 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.0760 mle=1.5862 pcon=5.0337 forget=2.0674 favg=-0.6113 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=9.3516 mle=1.6712 pcon=5.0320 forget=2.0767 favg=0.5718 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=10.2649 mle=1.8132 pcon=5.0307 forget=2.1201 favg=1.3008 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=8.7166 mle=1.7334 pcon=5.0290 forget=2.0865 favg=-0.1323 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=7.5834 mle=1.6434 pcon=5.0273 forget=2.0484 favg=-1.1357 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 30 total=6.5868 mle=1.5400 pcon=5.0255 forget=2.0975 favg=-2.0762 nr=64 nf=64 protos=540 fproto_sim=NA
 18%|█▊        | 9/50 [03:05<12:40, 18.56s/it] 20%|██        | 10/50 [03:21<11:52, 17.81s/it] 22%|██▏       | 11/50 [03:37<11:14, 17.30s/it] 24%|██▍       | 12/50 [03:54<10:50, 17.11s/it] 26%|██▌       | 13/50 [04:10<10:25, 16.90s/it] 28%|██▊       | 14/50 [04:35<11:32, 19.23s/it] 30%|███       | 15/50 [04:53<11:07, 19.08s/it] 32%|███▏      | 16/50 [05:10<10:22, 18.32s/it][loss] ep 8 it 80 total=6.8470 mle=1.6018 pcon=5.0234 forget=2.1847 favg=-1.9629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.6438 mle=1.5180 pcon=5.0212 forget=2.2381 favg=-0.1334 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=10.1662 mle=1.7543 pcon=5.0191 forget=2.1927 favg=1.2002 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=10.0739 mle=1.5093 pcon=5.0176 forget=2.0801 favg=1.4668 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=9.9739 mle=1.7060 pcon=5.0160 forget=2.0674 favg=1.1846 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.6968 mle=1.7539 pcon=5.0144 forget=2.1158 favg=-0.1873 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=7.6512 mle=1.5253 pcon=5.0130 forget=2.0382 favg=-0.9253 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 40 total=8.6133 mle=1.6737 pcon=5.0114 forget=2.0516 favg=-0.1235 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.8468 mle=1.6902 pcon=5.0095 forget=2.1126 favg=0.0345 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.8536 mle=1.8336 pcon=5.0081 forget=2.0895 favg=-0.0776 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=9.1563 mle=1.6116 pcon=5.0067 forget=2.0331 favg=0.5049 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=10.3910 mle=1.6353 pcon=5.0055 forget=2.0608 favg=1.6895 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=9.9704 mle=1.5965 pcon=5.0038 forget=2.0771 favg=1.2930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=8.0671 mle=1.5703 pcon=5.0025 forget=2.0432 favg=-0.5488 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=6.9631 mle=1.6226 pcon=5.0010 forget=1.9968 favg=-1.6572 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=6.8944 mle=1.6170 pcon=4.9997 forget=2.0072 favg=-1.7295 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0895 mle=1.7670 pcon=4.9987 forget=2.0787 favg=-0.7549 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=9.9757 mle=1.8949 pcon=4.9976 forget=2.1681 favg=0.9150 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=10.8730 mle=1.9239 pcon=4.9964 forget=2.2183 favg=1.7344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=10.6912 mle=1.5987 pcon=4.9950 forget=2.1649 favg=1.9326 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=10.4097 mle=1.6191 pcon=4.9939 forget=2.1023 favg=1.6943 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=9.6695 mle=1.6890 pcon=4.9926 forget=2.1061 favg=0.8818 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=7.6732 mle=1.6056 pcon=4.9912 forget=2.0373 favg=-0.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=6.0700 mle=1.7635 pcon=4.9897 forget=1.9691 favg=-2.6523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=6.6550 mle=1.7009 pcon=4.9884 forget=2.0066 favg=-2.0410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=9.7695 mle=1.7589 pcon=4.9869 forget=2.1130 favg=0.9106 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=10.5610 mle=1.8021 pcon=4.9860 forget=2.1225 favg=1.6504 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=10.4929 mle=1.6581 pcon=4.9853 forget=2.1026 favg=1.7471 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=10.8514 mle=2.0175 pcon=4.9840 forget=2.0697 favg=1.7803 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=10.3610 mle=1.7385 pcon=4.9827 forget=2.0461 favg=1.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=9.7960 mle=1.6152 pcon=4.9810 forget=2.0407 favg=1.1592 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=8.9081 mle=1.8546 pcon=4.9792 forget=2.0093 favg=0.0649 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=7.7706 mle=1.7394 pcon=4.9776 forget=2.0155 favg=-0.9619 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=7.6890 mle=1.9228 pcon=4.9766 forget=2.0015 favg=-1.2119 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=9.2919 mle=1.8525 pcon=4.9760 forget=2.0043 favg=0.4590 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=9.8803 mle=1.6400 pcon=4.9763 forget=2.0101 favg=1.2539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=9.9583 mle=1.5769 pcon=4.9758 forget=2.0160 favg=1.3896 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=9.5697 mle=1.8548 pcon=4.9750 forget=2.0173 favg=0.7227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=8.7668 mle=1.5476 pcon=4.9737 forget=1.9926 favg=0.2529 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1163 mle=1.5866 pcon=4.9719 forget=1.9759 favg=-0.4180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.1730 mle=1.6399 pcon=4.9697 forget=1.9746 favg=-0.4111 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.7745 mle=1.6533 pcon=4.9680 forget=1.9958 favg=0.1573 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=9.0572 mle=1.7537 pcon=4.9669 forget=2.0016 favg=0.3350 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=8.7905 mle=1.6095 pcon=4.9662 forget=1.9851 favg=0.2297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.9665 mle=1.6622 pcon=4.9656 forget=1.9957 favg=0.3430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=9.4418 mle=1.7040 pcon=4.9651 forget=2.0017 favg=0.7710 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=10.3227 mle=1.8509 pcon=4.9640 forget=2.0088 favg=1.4990 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=10.4058 mle=1.8481 pcon=4.9629 forget=2.0070 favg=1.5879 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=9.6949 mle=1.6620 pcon=4.9615 forget=1.9943 favg=1.0771 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=8.7978 mle=1.8375 pcon=4.9594 forget=1.9751 favg=0.0258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.1543 mle=1.7186 pcon=4.9576 forget=1.9420 favg=-1.4639 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=6.4877 mle=1.6977 pcon=4.9559 forget=1.9181 favg=-2.0840 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=6.6437 mle=1.7637 pcon=4.9544 forget=1.9276 favg=-2.0020 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.7631 mle=1.8027 pcon=4.9532 forget=1.9544 favg=-0.9473 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=9.8584 mle=1.5593 pcon=4.9516 forget=1.9842 favg=1.3633 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=11.0431 mle=1.6309 pcon=4.9499 forget=2.0287 favg=2.4336 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=11.1948 mle=1.7097 pcon=4.9476 forget=2.0746 favg=2.4629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=10.7037 mle=1.6162 pcon=4.9448 forget=2.0841 favg=2.0586 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=9.4069 mle=2.0175 pcon=4.9414 forget=2.0660 favg=0.3821 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=6.8708 mle=1.6502 pcon=4.9379 forget=1.9643 favg=-1.6816 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=6.6759 mle=1.7139 pcon=4.9350 forget=1.9733 favg=-1.9463 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=7.5875 mle=1.5952 pcon=4.9324 forget=1.9569 favg=-0.8970 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=8.6410 mle=1.6118 pcon=4.9303 forget=1.9683 favg=0.1306 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=9.0116 mle=1.6546 pcon=4.9284 forget=1.9921 favg=0.4365 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=8.8395 mle=1.5200 pcon=4.9258 forget=2.0082 favg=0.3855 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=8.9221 mle=1.6537 pcon=4.9228 forget=1.9985 favg=0.3472 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=9.2078 mle=1.8807 pcon=4.9192 forget=1.9782 favg=0.4297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=9.6881 mle=1.8160 pcon=4.9156 forget=1.9657 favg=0.9907 nr=64 nf=64 protos=540 fproto_sim=NA
 34%|███▍      | 17/50 [05:27<09:54, 18.00s/it] 36%|███▌      | 18/50 [05:45<09:33, 17.93s/it] 38%|███▊      | 19/50 [06:03<09:12, 17.81s/it] 40%|████      | 20/50 [06:20<08:47, 17.59s/it] 42%|████▏     | 21/50 [06:37<08:26, 17.46s/it] 44%|████▍     | 22/50 [06:55<08:16, 17.73s/it] 46%|████▌     | 23/50 [07:21<09:04, 20.16s/it] 48%|████▊     | 24/50 [07:39<08:28, 19.56s/it] 50%|█████     | 25/50 [07:56<07:52, 18.88s/it][loss] ep 16 it 360 total=10.2141 mle=1.7107 pcon=4.9120 forget=1.9780 favg=1.6133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 20 total=10.4431 mle=1.8363 pcon=4.9084 forget=1.9981 favg=1.7002 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=9.9782 mle=1.7830 pcon=4.9056 forget=1.9986 favg=1.2910 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=8.7711 mle=1.6182 pcon=4.9028 forget=1.9812 favg=0.2688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.7444 mle=1.6442 pcon=4.9000 forget=1.9541 favg=-0.7539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=7.0139 mle=1.6401 pcon=4.8975 forget=1.9480 favg=-1.4717 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=6.5582 mle=1.5691 pcon=4.8954 forget=1.9434 favg=-1.8496 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.6760 mle=1.8034 pcon=4.8927 forget=1.9683 favg=-0.9883 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=10.0197 mle=1.8321 pcon=4.8896 forget=1.9895 favg=1.3086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 30 total=10.7501 mle=1.6027 pcon=4.8869 forget=2.0046 favg=2.2559 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=10.8688 mle=1.7056 pcon=4.8839 forget=2.0292 favg=2.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=10.1888 mle=1.6535 pcon=4.8809 forget=2.0206 favg=1.6338 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=9.3585 mle=1.6144 pcon=4.8778 forget=1.9864 favg=0.8799 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=8.0007 mle=1.6590 pcon=4.8746 forget=1.9505 favg=-0.4834 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=6.7606 mle=1.7473 pcon=4.8715 forget=1.9046 favg=-1.7627 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=6.1391 mle=1.7786 pcon=4.8687 forget=1.8864 favg=-2.3945 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=6.0392 mle=1.7985 pcon=4.8662 forget=1.8980 favg=-2.5234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 40 total=6.4874 mle=1.6948 pcon=4.8639 forget=1.9286 favg=-2.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=9.4067 mle=1.7576 pcon=4.8619 forget=1.9704 favg=0.8169 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=11.1991 mle=1.6122 pcon=4.8596 forget=2.0106 favg=2.7168 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=11.7003 mle=1.7485 pcon=4.8572 forget=2.0341 favg=3.0605 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=11.8742 mle=1.8607 pcon=4.8549 forget=2.0668 favg=3.0918 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=11.2836 mle=1.6827 pcon=4.8526 forget=2.0900 favg=2.6582 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=10.8091 mle=1.5467 pcon=4.8499 forget=2.1019 favg=2.3105 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=9.9084 mle=1.6684 pcon=4.8466 forget=2.0732 favg=1.3203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=6.7549 mle=1.6900 pcon=4.8427 forget=1.9508 favg=-1.7285 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=5.6165 mle=1.7817 pcon=4.8388 forget=1.9178 favg=-2.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=5.6197 mle=1.8397 pcon=4.8351 forget=1.9234 favg=-2.9785 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=6.6791 mle=1.7038 pcon=4.8319 forget=1.9501 favg=-1.8066 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=9.5231 mle=2.0036 pcon=4.8292 forget=1.9877 favg=0.7026 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=9.7779 mle=1.8195 pcon=4.8269 forget=2.0241 favg=1.1074 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=9.2654 mle=1.5497 pcon=4.8250 forget=2.0201 favg=0.8706 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=8.7662 mle=1.5396 pcon=4.8230 forget=2.0128 favg=0.3909 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=8.1671 mle=1.6431 pcon=4.8207 forget=1.9928 favg=-0.2896 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.6512 mle=1.5691 pcon=4.8183 forget=1.9660 favg=-0.7021 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.7534 mle=1.6147 pcon=4.8156 forget=1.9628 favg=-0.6396 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=9.1541 mle=1.7446 pcon=4.8128 forget=1.9937 favg=0.6030 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=10.8385 mle=1.7332 pcon=4.8099 forget=2.0611 favg=2.2344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=11.2993 mle=1.5941 pcon=4.8070 forget=2.1229 favg=2.7754 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=11.2592 mle=1.5916 pcon=4.8044 forget=2.1699 favg=2.6934 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=10.9343 mle=1.6904 pcon=4.8019 forget=2.1881 favg=2.2539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=9.8917 mle=1.6689 pcon=4.7995 forget=2.1538 favg=1.2695 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.9478 mle=1.6099 pcon=4.7969 forget=2.0971 favg=-0.5562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=6.0776 mle=1.6388 pcon=4.7944 forget=1.9334 favg=-2.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=5.4216 mle=1.6223 pcon=4.7921 forget=1.8979 favg=-2.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=5.2313 mle=1.5708 pcon=4.7897 forget=1.9177 favg=-3.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=5.4759 mle=1.7999 pcon=4.7876 forget=1.9392 favg=-3.0508 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=6.4479 mle=2.0214 pcon=4.7855 forget=1.9868 favg=-2.3457 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 23 it 30 total=8.4286 mle=1.5989 pcon=4.7839 forget=2.0053 favg=0.0404 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=10.2236 mle=1.6576 pcon=4.7821 forget=2.0281 favg=1.7559 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=10.7739 mle=1.6253 pcon=4.7801 forget=2.0463 favg=2.3223 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=11.0389 mle=1.6925 pcon=4.7781 forget=2.0605 favg=2.5078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=10.9673 mle=1.6081 pcon=4.7761 forget=2.0869 favg=2.4961 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=10.8777 mle=1.5935 pcon=4.7739 forget=2.0982 favg=2.4121 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=10.6219 mle=1.6481 pcon=4.7716 forget=2.1142 favg=2.0879 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=10.1643 mle=1.6162 pcon=4.7694 forget=2.1303 favg=1.6484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=9.5079 mle=1.5767 pcon=4.7672 forget=2.1493 favg=1.0146 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=8.6839 mle=1.7144 pcon=4.7651 forget=2.1262 favg=0.0782 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.9672 mle=1.6852 pcon=4.7631 forget=2.0873 favg=-0.5684 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.8350 mle=1.6771 pcon=4.7616 forget=2.0560 favg=-0.6597 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.9202 mle=1.5663 pcon=4.7600 forget=2.0641 favg=-0.4702 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.8570 mle=1.7205 pcon=4.7586 forget=2.0834 favg=-0.7056 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.1634 mle=1.6322 pcon=4.7572 forget=2.0817 favg=-1.3076 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 0 total=6.6199 mle=1.6647 pcon=4.7554 forget=2.0465 favg=-1.8467 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=6.7847 mle=1.7518 pcon=4.7538 forget=2.0331 favg=-1.7539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.5117 mle=1.6215 pcon=4.7519 forget=2.0231 favg=-0.8848 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▏    | 26/50 [08:14<07:22, 18.44s/it] 54%|█████▍    | 27/50 [08:31<06:57, 18.17s/it] 56%|█████▌    | 28/50 [08:49<06:34, 17.95s/it] 58%|█████▊    | 29/50 [09:06<06:12, 17.71s/it] 60%|██████    | 30/50 [09:23<05:49, 17.47s/it] 62%|██████▏   | 31/50 [09:40<05:29, 17.33s/it] 64%|██████▍   | 32/50 [10:02<05:39, 18.84s/it] 66%|██████▌   | 33/50 [10:24<05:37, 19.83s/it][loss] ep 25 it 150 total=9.1504 mle=1.8125 pcon=4.7503 forget=2.0354 favg=0.5522 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=10.2671 mle=1.8380 pcon=4.7485 forget=2.0526 favg=1.6279 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=10.5084 mle=1.7320 pcon=4.7468 forget=2.0784 favg=1.9512 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=10.5074 mle=1.6498 pcon=4.7453 forget=2.0575 favg=2.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=10.2635 mle=1.5413 pcon=4.7441 forget=2.0504 favg=1.9277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=10.0192 mle=1.6494 pcon=4.7427 forget=2.0333 favg=1.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=9.5059 mle=1.6499 pcon=4.7413 forget=2.0180 favg=1.0967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=8.7669 mle=1.7252 pcon=4.7398 forget=2.0067 favg=0.2952 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.7345 mle=1.5642 pcon=4.7381 forget=1.9879 favg=-0.5557 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=6.8944 mle=1.7219 pcon=4.7363 forget=1.9987 favg=-1.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=6.5173 mle=1.6731 pcon=4.7348 forget=2.0157 favg=-1.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=9.2200 mle=1.9873 pcon=4.7335 forget=2.0227 favg=0.4766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=10.2191 mle=1.6399 pcon=4.7323 forget=2.0549 favg=1.7920 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=9.9888 mle=1.6646 pcon=4.7314 forget=2.0752 favg=1.5176 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=9.1023 mle=1.6380 pcon=4.7303 forget=2.0552 favg=0.6787 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=8.2663 mle=1.5729 pcon=4.7292 forget=2.0203 favg=-0.0561 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.6047 mle=1.5762 pcon=4.7279 forget=1.9895 favg=-0.6890 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.2283 mle=1.5544 pcon=4.7264 forget=1.9671 favg=-1.0195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.1145 mle=1.6325 pcon=4.7247 forget=1.9692 favg=-1.2119 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.2679 mle=1.7425 pcon=4.7232 forget=1.9828 favg=-1.1807 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.5607 mle=1.7288 pcon=4.7216 forget=2.0239 favg=-0.9136 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=8.1370 mle=1.7065 pcon=4.7202 forget=2.0379 favg=-0.3276 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=9.0895 mle=1.7071 pcon=4.7189 forget=2.0599 favg=0.6035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=9.9774 mle=1.6301 pcon=4.7177 forget=2.0700 favg=1.5596 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=10.5674 mle=1.6545 pcon=4.7166 forget=2.0966 favg=2.0996 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=10.5016 mle=1.4999 pcon=4.7154 forget=2.1320 favg=2.1543 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=10.4743 mle=1.6402 pcon=4.7143 forget=2.2047 favg=1.9150 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=10.0752 mle=1.8092 pcon=4.7132 forget=2.2305 favg=1.3223 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=9.2051 mle=1.7868 pcon=4.7121 forget=2.2756 favg=0.4307 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=8.2548 mle=1.7617 pcon=4.7108 forget=2.2383 favg=-0.4561 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.1615 mle=1.6215 pcon=4.7095 forget=2.1773 favg=-1.3467 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=6.6143 mle=1.6715 pcon=4.7082 forget=2.0764 favg=-1.8418 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=6.1460 mle=1.6399 pcon=4.7068 forget=2.0064 favg=-2.2070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=6.0446 mle=1.6059 pcon=4.7055 forget=1.9969 favg=-2.2637 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=6.5432 mle=1.7728 pcon=4.7043 forget=1.9938 favg=-1.9277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.3390 mle=1.6085 pcon=4.7031 forget=2.0230 favg=-0.9956 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 30 it 0 total=8.7597 mle=1.6934 pcon=4.7019 forget=2.0439 favg=0.3206 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=9.7904 mle=1.6882 pcon=4.7009 forget=2.0546 favg=1.3467 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=10.2429 mle=1.6108 pcon=4.7000 forget=2.0629 favg=1.8691 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=10.7297 mle=1.7776 pcon=4.6991 forget=2.0656 favg=2.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=10.4736 mle=1.5293 pcon=4.6983 forget=2.0938 favg=2.1523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=10.6380 mle=1.8333 pcon=4.6974 forget=2.0877 favg=2.0195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=10.0882 mle=1.5050 pcon=4.6967 forget=2.0916 favg=1.7949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=10.0542 mle=1.7978 pcon=4.6959 forget=2.1083 favg=1.4521 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=9.7179 mle=1.6561 pcon=4.6951 forget=2.1343 favg=1.2324 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=9.0911 mle=1.5911 pcon=4.6942 forget=2.1413 favg=0.6646 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=8.3998 mle=1.6776 pcon=4.6934 forget=2.1584 favg=-0.1295 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.6600 mle=1.5732 pcon=4.6924 forget=2.1649 favg=-0.7705 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=6.8123 mle=1.6226 pcon=4.6914 forget=2.1703 favg=-1.6719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=6.1451 mle=1.5420 pcon=4.6902 forget=2.1198 favg=-2.2070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=6.0504 mle=1.6485 pcon=4.6892 forget=2.1091 favg=-2.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=6.4512 mle=1.5986 pcon=4.6882 forget=2.1039 favg=-1.9395 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.2675 mle=1.7270 pcon=4.6873 forget=2.1130 favg=-1.2598 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.8412 mle=1.6196 pcon=4.6864 forget=2.1163 favg=-0.5811 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=8.2689 mle=1.5836 pcon=4.6857 forget=2.1185 favg=-0.1189 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=8.4567 mle=1.5800 pcon=4.6852 forget=2.1107 favg=0.0808 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=8.6609 mle=1.6943 pcon=4.6846 forget=2.0823 favg=0.1997 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=8.5409 mle=1.6355 pcon=4.6842 forget=2.0655 favg=0.1558 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=8.3718 mle=1.5191 pcon=4.6837 forget=2.0539 favg=0.1151 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=8.3998 mle=1.5073 pcon=4.6834 forget=2.0431 favg=0.1660 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=8.4116 mle=1.6402 pcon=4.6830 forget=2.0493 favg=0.0392 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=8.5524 mle=1.9503 pcon=4.6826 forget=2.0151 favg=-0.0955 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=8.1611 mle=1.5578 pcon=4.6822 forget=2.0131 favg=-0.0919 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=8.2894 mle=1.7024 pcon=4.6818 forget=2.0276 favg=-0.1224 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=8.5491 mle=1.6819 pcon=4.6814 forget=2.0260 favg=0.1598 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=8.9012 mle=1.7303 pcon=4.6811 forget=2.0282 favg=0.4617 nr=64 nf=64 protos=540 fproto_sim=NA
 68%|██████▊   | 34/50 [10:42<05:06, 19.16s/it] 70%|███████   | 35/50 [11:00<04:42, 18.80s/it] 72%|███████▏  | 36/50 [11:17<04:17, 18.40s/it] 74%|███████▍  | 37/50 [11:35<03:55, 18.14s/it] 76%|███████▌  | 38/50 [11:52<03:34, 17.86s/it] 78%|███████▊  | 39/50 [12:10<03:15, 17.74s/it] 80%|████████  | 40/50 [12:27<02:56, 17.70s/it] 82%|████████▏ | 41/50 [12:52<02:58, 19.87s/it] 84%|████████▍ | 42/50 [13:12<02:38, 19.82s/it][loss] ep 33 it 330 total=9.1465 mle=1.6774 pcon=4.6808 forget=2.0354 favg=0.7529 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=9.1640 mle=1.6769 pcon=4.6805 forget=2.0634 favg=0.7432 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=9.1342 mle=1.7256 pcon=4.6801 forget=2.0748 favg=0.6538 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=8.8557 mle=1.5345 pcon=4.6796 forget=2.0889 favg=0.5527 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=8.9540 mle=1.6403 pcon=4.6793 forget=2.0982 favg=0.5361 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=8.7725 mle=1.6722 pcon=4.6789 forget=2.1143 favg=0.3071 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=8.6723 mle=1.7403 pcon=4.6784 forget=2.1186 favg=0.1350 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=8.4660 mle=1.6231 pcon=4.6778 forget=2.1229 favg=0.0421 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=8.2792 mle=1.5807 pcon=4.6772 forget=2.1177 favg=-0.0964 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=8.1786 mle=1.6479 pcon=4.6765 forget=2.0804 favg=-0.2263 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=8.3559 mle=1.5949 pcon=4.6759 forget=2.0821 favg=0.0030 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=8.7722 mle=1.7748 pcon=4.6751 forget=2.0783 favg=0.2440 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=9.4057 mle=1.6732 pcon=4.6744 forget=2.0849 favg=0.9731 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=9.6771 mle=1.6171 pcon=4.6738 forget=2.0922 favg=1.2939 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=9.4378 mle=1.7049 pcon=4.6732 forget=2.1365 favg=0.9233 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=9.0464 mle=1.5625 pcon=4.6726 forget=2.1521 favg=0.6592 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=8.8392 mle=1.7404 pcon=4.6721 forget=2.1674 favg=0.2593 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=8.6701 mle=1.7883 pcon=4.6716 forget=2.1829 favg=0.0274 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.9988 mle=1.5619 pcon=4.6713 forget=2.1770 favg=-0.4114 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=7.6840 mle=1.5844 pcon=4.6707 forget=2.1936 favg=-0.7646 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.5600 mle=1.6854 pcon=4.6702 forget=2.1936 favg=-0.9893 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=7.0223 mle=1.5336 pcon=4.6698 forget=2.1851 favg=-1.3662 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=6.8543 mle=1.6121 pcon=4.6694 forget=2.1617 favg=-1.5889 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=6.7180 mle=1.6647 pcon=4.6689 forget=2.1501 favg=-1.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=6.5451 mle=1.6398 pcon=4.6684 forget=2.1354 favg=-1.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=6.3016 mle=1.5080 pcon=4.6678 forget=2.1219 favg=-1.9961 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=6.4467 mle=1.7382 pcon=4.6674 forget=2.1017 favg=-2.0605 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=6.4006 mle=1.6232 pcon=4.6670 forget=2.0977 favg=-1.9873 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=6.4520 mle=1.6388 pcon=4.6666 forget=2.0842 favg=-1.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=6.7645 mle=1.7553 pcon=4.6661 forget=2.0931 favg=-1.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=6.7185 mle=1.6068 pcon=4.6657 forget=2.0846 favg=-1.6387 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.0910 mle=1.6643 pcon=4.6655 forget=2.0835 favg=-1.3223 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.4586 mle=1.6523 pcon=4.6652 forget=2.1215 favg=-0.9805 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 38 it 30 total=7.8491 mle=1.7311 pcon=4.6652 forget=2.1203 favg=-0.6675 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=8.0432 mle=1.5392 pcon=4.6650 forget=2.1118 favg=-0.2727 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=8.4819 mle=1.6686 pcon=4.6647 forget=2.1119 favg=0.0367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=8.8771 mle=1.6547 pcon=4.6645 forget=2.1187 favg=0.4392 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=9.0754 mle=1.5451 pcon=4.6643 forget=2.1370 favg=0.7290 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=9.4924 mle=1.7037 pcon=4.6641 forget=2.1319 favg=0.9927 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=9.6982 mle=1.6121 pcon=4.6637 forget=2.1450 favg=1.2773 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=9.7454 mle=1.5149 pcon=4.6636 forget=2.1499 favg=1.4170 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=10.1380 mle=1.7212 pcon=4.6635 forget=2.1606 favg=1.5928 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=10.0500 mle=1.6536 pcon=4.6632 forget=2.1765 favg=1.5566 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=10.0794 mle=1.6460 pcon=4.6630 forget=2.1864 favg=1.5840 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=9.8796 mle=1.5016 pcon=4.6626 forget=2.1705 favg=1.5449 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=10.0206 mle=1.6470 pcon=4.6623 forget=2.2035 favg=1.5078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=9.7565 mle=1.5026 pcon=4.6620 forget=2.2100 favg=1.3818 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=9.7893 mle=1.6143 pcon=4.6617 forget=2.2046 favg=1.3086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=9.5453 mle=1.5552 pcon=4.6612 forget=2.1999 favg=1.1289 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=9.4636 mle=1.6244 pcon=4.6608 forget=2.2150 favg=0.9634 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=9.1812 mle=1.6581 pcon=4.6601 forget=2.1979 favg=0.6650 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=8.7688 mle=1.4790 pcon=4.6597 forget=2.2282 favg=0.4019 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=8.6724 mle=1.7075 pcon=4.6593 forget=2.2341 favg=0.0715 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=8.4704 mle=1.7956 pcon=4.6588 forget=2.2135 favg=-0.1976 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=7.9773 mle=1.5677 pcon=4.6585 forget=2.2126 favg=-0.4614 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=7.7620 mle=1.4686 pcon=4.6582 forget=2.2070 favg=-0.5718 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=7.5071 mle=1.5206 pcon=4.6579 forget=2.2021 favg=-0.8735 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=7.7487 mle=1.8613 pcon=4.6578 forget=2.2188 favg=-0.9893 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=7.3779 mle=1.5899 pcon=4.6575 forget=2.2106 favg=-1.0801 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=7.1982 mle=1.6069 pcon=4.6574 forget=2.2103 favg=-1.2764 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=7.1921 mle=1.6862 pcon=4.6572 forget=2.2177 favg=-1.3691 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=6.9378 mle=1.5198 pcon=4.6573 forget=2.2089 favg=-1.4482 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=6.9714 mle=1.5330 pcon=4.6573 forget=2.2127 favg=-1.4316 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=7.2174 mle=1.6936 pcon=4.6572 forget=2.2094 favg=-1.3428 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=7.3707 mle=1.6934 pcon=4.6571 forget=2.2184 favg=-1.1982 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=7.4315 mle=1.6081 pcon=4.6569 forget=2.2290 favg=-1.0625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=7.9281 mle=1.8482 pcon=4.6567 forget=2.2210 favg=-0.7979 nr=64 nf=64 protos=540 fproto_sim=NA
 86%|████████▌ | 43/50 [13:33<02:21, 20.17s/it] 88%|████████▊ | 44/50 [14:01<02:15, 22.61s/it] 90%|█████████ | 45/50 [14:30<02:01, 24.34s/it] 92%|█████████▏| 46/50 [14:59<01:44, 26.01s/it] 94%|█████████▍| 47/50 [15:36<01:27, 29.09s/it] 96%|█████████▌| 48/50 [16:16<01:05, 32.56s/it] 98%|█████████▊| 49/50 [16:50<00:32, 32.91s/it]100%|██████████| 50/50 [17:21<00:00, 32.17s/it]100%|██████████| 50/50 [17:21<00:00, 20.82s/it]
[loss] ep 42 it 170 total=8.0120 mle=1.6341 pcon=4.6566 forget=2.2029 favg=-0.4817 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=8.3594 mle=1.6130 pcon=4.6566 forget=2.2223 favg=-0.1324 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.8157 mle=1.7674 pcon=4.6565 forget=2.2378 favg=0.1539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=9.0492 mle=1.7075 pcon=4.6565 forget=2.2314 favg=0.4539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=9.1652 mle=1.5940 pcon=4.6565 forget=2.2316 favg=0.6831 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=9.3839 mle=1.6713 pcon=4.6564 forget=2.2681 favg=0.7881 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=9.3457 mle=1.6061 pcon=4.6563 forget=2.2684 favg=0.8149 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=9.4552 mle=1.6506 pcon=4.6562 forget=2.2612 favg=0.8872 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=9.3472 mle=1.5205 pcon=4.6562 forget=2.2795 favg=0.8911 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=9.2866 mle=1.5538 pcon=4.6560 forget=2.2576 favg=0.8193 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=9.2590 mle=1.5259 pcon=4.6559 forget=2.2750 favg=0.8022 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=9.3328 mle=1.5744 pcon=4.6557 forget=2.2858 favg=0.8169 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=9.2127 mle=1.5174 pcon=4.6555 forget=2.2879 favg=0.7520 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=9.2845 mle=1.6961 pcon=4.6553 forget=2.2778 favg=0.6553 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=9.1045 mle=1.5785 pcon=4.6551 forget=2.2830 favg=0.5879 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=9.1033 mle=1.6639 pcon=4.6549 forget=2.2920 favg=0.4924 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=8.8749 mle=1.5333 pcon=4.6548 forget=2.2880 favg=0.3989 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=8.8475 mle=1.5534 pcon=4.6546 forget=2.2835 favg=0.3560 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=8.9190 mle=1.7785 pcon=4.6544 forget=2.2966 favg=0.1895 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=8.8354 mle=1.7709 pcon=4.6543 forget=2.3026 favg=0.1077 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=8.5153 mle=1.5488 pcon=4.6541 forget=2.3072 favg=0.0052 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=8.4634 mle=1.5713 pcon=4.6539 forget=2.3079 favg=-0.0698 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=8.3420 mle=1.5679 pcon=4.6537 forget=2.2766 favg=-0.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=8.2554 mle=1.5385 pcon=4.6535 forget=2.3159 favg=-0.2524 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=8.1951 mle=1.5803 pcon=4.6533 forget=2.3074 favg=-0.3459 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=7.9064 mle=1.5594 pcon=4.6531 forget=2.3086 favg=-0.6147 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=7.8652 mle=1.6214 pcon=4.6528 forget=2.2936 favg=-0.7026 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=7.7653 mle=1.5366 pcon=4.6527 forget=2.2987 favg=-0.7227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=7.6584 mle=1.5057 pcon=4.6526 forget=2.2849 favg=-0.7847 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=7.4590 mle=1.4998 pcon=4.6524 forget=2.2990 favg=-0.9922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=7.6920 mle=1.6880 pcon=4.6522 forget=2.2942 favg=-0.9424 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=7.3959 mle=1.5051 pcon=4.6520 forget=2.2964 favg=-1.0576 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=7.5914 mle=1.7926 pcon=4.6518 forget=2.3101 favg=-1.1631 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=7.2399 mle=1.6592 pcon=4.6516 forget=2.3099 favg=-1.3809 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=7.1577 mle=1.5232 pcon=4.6515 forget=2.3014 favg=-1.3184 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=7.3539 mle=1.7490 pcon=4.6513 forget=2.3168 favg=-1.3633 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=7.1294 mle=1.5569 pcon=4.6510 forget=2.3082 favg=-1.3867 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=6.9606 mle=1.5715 pcon=4.6508 forget=2.3076 favg=-1.5693 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=7.0245 mle=1.6645 pcon=4.6506 forget=2.3159 favg=-1.6064 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=6.9925 mle=1.5680 pcon=4.6503 forget=2.3269 favg=-1.5527 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=6.8583 mle=1.5102 pcon=4.6502 forget=2.3366 favg=-1.6387 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=7.0991 mle=1.5872 pcon=4.6501 forget=2.3188 favg=-1.4570 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=7.0527 mle=1.5857 pcon=4.6500 forget=2.3425 favg=-1.5254 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=7.1423 mle=1.6520 pcon=4.6498 forget=2.3384 favg=-1.4980 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=7.1187 mle=1.5913 pcon=4.6498 forget=2.3316 favg=-1.4541 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=7.1652 mle=1.5920 pcon=4.6496 forget=2.3434 favg=-1.4199 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=7.1183 mle=1.6724 pcon=4.6496 forget=2.3354 favg=-1.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=7.2344 mle=1.6407 pcon=4.6495 forget=2.3328 favg=-1.3887 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=7.2753 mle=1.6935 pcon=4.6494 forget=2.3221 favg=-1.3896 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=7.1093 mle=1.5666 pcon=4.6493 forget=2.3387 favg=-1.4453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=7.1865 mle=1.5878 pcon=4.6492 forget=2.3216 favg=-1.3721 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=7.3677 mle=1.5386 pcon=4.6490 forget=2.3363 favg=-1.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=7.4281 mle=1.5689 pcon=4.6489 forget=2.3373 favg=-1.1270 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=7.4441 mle=1.6187 pcon=4.6489 forget=2.3416 favg=-1.1650 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=7.4730 mle=1.5883 pcon=4.6488 forget=2.3502 favg=-1.1143 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=7.7245 mle=1.7522 pcon=4.6485 forget=2.3414 favg=-1.0176 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=7.6571 mle=1.7143 pcon=4.6483 forget=2.3414 favg=-1.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=7.7677 mle=1.6285 pcon=4.6482 forget=2.3553 favg=-0.8643 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=7.6632 mle=1.5492 pcon=4.6482 forget=2.3472 favg=-0.8813 nr=64 nf=64 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:22,  1.93it/s]  2%|▏         | 9/391 [00:00<00:20, 18.54it/s]  4%|▍         | 16/391 [00:00<00:12, 29.63it/s]  6%|▌         | 23/391 [00:00<00:09, 38.86it/s]  8%|▊         | 31/391 [00:00<00:07, 47.84it/s] 10%|▉         | 38/391 [00:01<00:06, 52.66it/s] 12%|█▏        | 46/391 [00:01<00:05, 58.92it/s] 14%|█▍        | 54/391 [00:01<00:05, 61.75it/s] 16%|█▌        | 61/391 [00:01<00:05, 63.67it/s] 17%|█▋        | 68/391 [00:01<00:05, 63.89it/s] 19%|█▉        | 76/391 [00:01<00:04, 66.85it/s] 21%|██▏       | 84/391 [00:01<00:04, 69.04it/s] 24%|██▎       | 92/391 [00:01<00:04, 70.39it/s] 26%|██▌       | 100/391 [00:01<00:04, 71.82it/s] 28%|██▊       | 108/391 [00:02<00:04, 70.72it/s] 30%|██▉       | 116/391 [00:02<00:03, 69.68it/s] 32%|███▏      | 124/391 [00:02<00:03, 70.76it/s] 34%|███▍      | 132/391 [00:02<00:03, 70.87it/s] 36%|███▌      | 140/391 [00:02<00:03, 70.40it/s] 38%|███▊      | 148/391 [00:02<00:03, 69.44it/s] 40%|███▉      | 156/391 [00:02<00:03, 70.97it/s] 42%|████▏     | 164/391 [00:02<00:03, 71.42it/s] 44%|████▍     | 172/391 [00:02<00:03, 72.24it/s] 46%|████▌     | 180/391 [00:03<00:03, 70.29it/s] 48%|████▊     | 188/391 [00:03<00:02, 70.64it/s] 50%|█████     | 196/391 [00:03<00:02, 71.96it/s] 52%|█████▏    | 204/391 [00:03<00:02, 73.03it/s] 54%|█████▍    | 212/391 [00:03<00:02, 70.51it/s] 56%|█████▋    | 220/391 [00:03<00:02, 71.66it/s] 58%|█████▊    | 228/391 [00:03<00:02, 72.50it/s] 60%|██████    | 236/391 [00:03<00:02, 72.50it/s] 62%|██████▏   | 244/391 [00:03<00:02, 71.17it/s] 64%|██████▍   | 252/391 [00:04<00:01, 71.18it/s] 66%|██████▋   | 260/391 [00:04<00:01, 66.93it/s] 69%|██████▊   | 268/391 [00:04<00:01, 68.98it/s] 71%|███████   | 276/391 [00:04<00:01, 70.18it/s] 73%|███████▎  | 284/391 [00:04<00:01, 68.91it/s] 75%|███████▍  | 292/391 [00:04<00:01, 70.61it/s] 77%|███████▋  | 300/391 [00:04<00:01, 71.38it/s] 79%|███████▉  | 308/391 [00:04<00:01, 72.64it/s] 81%|████████  | 316/391 [00:04<00:01, 72.67it/s] 83%|████████▎ | 324/391 [00:05<00:00, 73.79it/s] 85%|████████▍ | 332/391 [00:05<00:00, 74.24it/s] 87%|████████▋ | 340/391 [00:05<00:00, 74.37it/s] 89%|████████▉ | 348/391 [00:05<00:00, 73.58it/s] 91%|█████████ | 356/391 [00:05<00:00, 74.90it/s] 93%|█████████▎| 364/391 [00:05<00:00, 75.09it/s] 95%|█████████▌| 372/391 [00:05<00:00, 73.96it/s] 97%|█████████▋| 380/391 [00:05<00:00, 74.41it/s] 99%|█████████▉| 388/391 [00:05<00:00, 75.28it/s]100%|██████████| 391/391 [00:05<00:00, 65.34it/s]
50000 images processed, 6.0636725425720215 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:25,  3.02it/s] 11%|█▏        | 9/79 [00:00<00:02, 25.76it/s] 22%|██▏       | 17/79 [00:00<00:01, 39.43it/s] 32%|███▏      | 25/79 [00:00<00:01, 49.50it/s] 41%|████      | 32/79 [00:00<00:00, 54.95it/s] 51%|█████     | 40/79 [00:00<00:00, 59.81it/s] 61%|██████    | 48/79 [00:00<00:00, 63.91it/s] 71%|███████   | 56/79 [00:01<00:00, 67.98it/s] 81%|████████  | 64/79 [00:01<00:00, 69.08it/s] 91%|█████████ | 72/79 [00:01<00:00, 70.69it/s]100%|██████████| 79/79 [00:01<00:00, 55.93it/s]
10000 images processed, 1.4356880187988281 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:12,  2.80it/s]  3%|▎         | 7/204 [00:00<00:10, 18.66it/s]  7%|▋         | 15/204 [00:00<00:05, 34.78it/s] 11%|█▏        | 23/204 [00:00<00:03, 45.65it/s] 15%|█▍        | 30/204 [00:00<00:03, 51.78it/s] 18%|█▊        | 37/204 [00:00<00:02, 56.64it/s] 22%|██▏       | 44/204 [00:01<00:02, 57.82it/s] 25%|██▌       | 51/204 [00:01<00:02, 60.34it/s] 28%|██▊       | 58/204 [00:01<00:02, 62.89it/s] 32%|███▏      | 65/204 [00:01<00:02, 62.55it/s] 35%|███▌      | 72/204 [00:01<00:02, 63.90it/s] 39%|███▊      | 79/204 [00:01<00:01, 64.89it/s] 43%|████▎     | 87/204 [00:01<00:01, 66.35it/s] 46%|████▌     | 94/204 [00:01<00:01, 66.01it/s] 50%|█████     | 102/204 [00:01<00:01, 67.48it/s] 54%|█████▍    | 110/204 [00:01<00:01, 67.66it/s] 57%|█████▋    | 117/204 [00:02<00:01, 68.00it/s] 61%|██████    | 124/204 [00:02<00:01, 65.75it/s] 64%|██████▍   | 131/204 [00:02<00:01, 65.57it/s] 68%|██████▊   | 138/204 [00:02<00:01, 65.32it/s] 71%|███████   | 145/204 [00:02<00:00, 65.35it/s] 75%|███████▍  | 152/204 [00:02<00:00, 65.50it/s] 78%|███████▊  | 160/204 [00:02<00:00, 67.76it/s] 82%|████████▏ | 167/204 [00:02<00:00, 67.96it/s] 86%|████████▌ | 175/204 [00:02<00:00, 69.85it/s] 89%|████████▉ | 182/204 [00:03<00:00, 69.66it/s] 93%|█████████▎| 190/204 [00:03<00:00, 70.37it/s] 97%|█████████▋| 198/204 [00:03<00:00, 70.16it/s]100%|██████████| 204/204 [00:03<00:00, 60.53it/s]
26032 images processed, 3.432649850845337 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:48,  1.60it/s]  8%|▊         | 6/79 [00:00<00:06, 10.56it/s] 13%|█▎        | 10/79 [00:00<00:04, 16.44it/s] 22%|██▏       | 17/79 [00:00<00:02, 26.73it/s] 28%|██▊       | 22/79 [00:01<00:01, 31.38it/s] 34%|███▍      | 27/79 [00:01<00:01, 30.89it/s] 43%|████▎     | 34/79 [00:01<00:01, 34.79it/s] 53%|█████▎    | 42/79 [00:01<00:00, 39.70it/s] 62%|██████▏   | 49/79 [00:01<00:00, 46.00it/s] 70%|██████▉   | 55/79 [00:01<00:00, 47.62it/s] 77%|███████▋  | 61/79 [00:01<00:00, 42.92it/s] 84%|████████▎ | 66/79 [00:02<00:00, 43.82it/s] 92%|█████████▏| 73/79 [00:02<00:00, 47.83it/s] 99%|█████████▊| 78/79 [00:02<00:00, 46.66it/s]100%|██████████| 79/79 [00:02<00:00, 34.22it/s]
10000 images processed, 2.347001552581787 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:31,  2.50it/s]  9%|▉         | 7/79 [00:00<00:04, 17.32it/s] 16%|█▋        | 13/79 [00:00<00:02, 28.83it/s] 25%|██▌       | 20/79 [00:00<00:01, 38.37it/s] 34%|███▍      | 27/79 [00:00<00:01, 46.33it/s] 43%|████▎     | 34/79 [00:00<00:00, 52.92it/s] 53%|█████▎    | 42/79 [00:01<00:00, 58.04it/s] 62%|██████▏   | 49/79 [00:01<00:00, 60.40it/s] 71%|███████   | 56/79 [00:01<00:00, 60.58it/s] 80%|███████▉  | 63/79 [00:01<00:00, 63.12it/s] 90%|████████▉ | 71/79 [00:01<00:00, 66.87it/s]100%|██████████| 79/79 [00:01<00:00, 50.27it/s]
10000 images processed, 1.5920131206512451 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:37,  1.85it/s] 11%|█▏        | 8/70 [00:00<00:03, 15.73it/s] 23%|██▎       | 16/70 [00:00<00:01, 29.57it/s] 33%|███▎      | 23/70 [00:00<00:01, 38.57it/s] 43%|████▎     | 30/70 [00:00<00:00, 46.45it/s] 53%|█████▎    | 37/70 [00:01<00:00, 52.32it/s] 63%|██████▎   | 44/70 [00:01<00:00, 56.06it/s] 73%|███████▎  | 51/70 [00:01<00:00, 58.94it/s] 84%|████████▍ | 59/70 [00:01<00:00, 63.76it/s] 96%|█████████▌| 67/70 [00:01<00:00, 66.60it/s]100%|██████████| 70/70 [00:01<00:00, 45.10it/s]
8925 images processed, 1.5936737060546875 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:43,  1.00it/s]  4%|▍         | 2/45 [00:01<00:20,  2.11it/s] 20%|██        | 9/45 [00:01<00:03,  9.25it/s] 24%|██▍       | 11/45 [00:01<00:04,  7.40it/s] 38%|███▊      | 17/45 [00:02<00:02, 12.70it/s] 42%|████▏     | 19/45 [00:02<00:02,  9.54it/s] 56%|█████▌    | 25/45 [00:02<00:01, 14.21it/s] 62%|██████▏   | 28/45 [00:03<00:01, 11.32it/s] 73%|███████▎  | 33/45 [00:03<00:00, 12.30it/s] 78%|███████▊  | 35/45 [00:03<00:01,  9.31it/s] 93%|█████████▎| 42/45 [00:04<00:00,  8.99it/s]100%|██████████| 45/45 [00:04<00:00,  9.55it/s]
5640 images processed, 4.735074996948242 seconds used

23.034809350967407
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           7.99  98.43
places365     76.36  79.34
LSUN          27.86  94.91
iSUN          82.13  78.77
dtd           47.57  89.68
AVG           48.38  88.23
Retain-Acc: 0.7218
Forget-as-OOD (retain known vs forget novel):
  FPR: 69.80 AUROC: 86.12 AUIN: 98.22
59.107733964920044
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.3-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
