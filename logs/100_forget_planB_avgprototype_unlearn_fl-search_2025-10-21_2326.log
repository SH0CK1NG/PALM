nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=1.0, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:55<45:20, 55.51s/it]  4%|▍         | 2/50 [01:51<44:35, 55.74s/it]  6%|▌         | 3/50 [02:54<46:20, 59.15s/it]  8%|▊         | 4/50 [03:52<44:58, 58.66s/it] 10%|█         | 5/50 [04:46<42:38, 56.86s/it] 12%|█▏        | 6/50 [05:31<38:54, 53.06s/it] 14%|█▍        | 7/50 [06:24<37:51, 52.82s/it] 16%|█▌        | 8/50 [07:15<36:39, 52.37s/it][loss] ep 0 it 0 total=11.9408 mle=1.5710 pcon=5.2950 forget=6.8775 favg=-1.8027 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=11.6142 mle=1.5424 pcon=5.2879 forget=7.0065 favg=-2.2227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=11.7358 mle=1.7004 pcon=5.2809 forget=6.8698 favg=-2.1152 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=11.7829 mle=1.8995 pcon=5.2738 forget=6.8478 favg=-2.2383 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=11.9089 mle=1.7130 pcon=5.2670 forget=6.9123 favg=-1.9834 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=11.5573 mle=1.5021 pcon=5.2603 forget=6.8906 favg=-2.0957 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=11.8719 mle=1.5596 pcon=5.2540 forget=6.9079 favg=-1.8496 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=11.5620 mle=1.6810 pcon=5.2476 forget=6.9440 favg=-2.3105 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=11.4663 mle=1.6721 pcon=5.2408 forget=7.0416 favg=-2.4883 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=11.2643 mle=1.6372 pcon=5.2344 forget=6.8204 favg=-2.4277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=10.7193 mle=1.5146 pcon=5.2281 forget=6.9043 favg=-2.9277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=9.4375 mle=1.7801 pcon=5.2218 forget=6.8926 favg=-4.4570 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=7.2557 mle=1.7775 pcon=5.2153 forget=7.0207 favg=-6.7578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=5.4412 mle=1.6130 pcon=5.2088 forget=7.2210 favg=-8.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=4.6877 mle=1.7374 pcon=5.2021 forget=7.5295 favg=-9.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=4.7294 mle=1.9618 pcon=5.1959 forget=7.7279 favg=-10.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=4.6873 mle=1.7033 pcon=5.1901 forget=7.9501 favg=-10.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=6.7737 mle=2.0922 pcon=5.1847 forget=8.1999 favg=-8.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=18.6005 mle=1.9071 pcon=5.1791 forget=8.7056 favg=2.8086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=25.0345 mle=1.6333 pcon=5.1734 forget=8.9700 favg=9.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=24.0162 mle=1.6674 pcon=5.1675 forget=8.4626 favg=8.7188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=19.2776 mle=1.8656 pcon=5.1622 forget=7.2733 favg=4.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=15.4250 mle=1.6011 pcon=5.1573 forget=6.9176 favg=1.7490 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=13.4289 mle=1.8280 pcon=5.1528 forget=6.9200 favg=-0.4719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 30 total=9.5451 mle=1.8236 pcon=5.1487 forget=7.1900 favg=-4.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.9477 mle=1.8138 pcon=5.1457 forget=7.5312 favg=-5.5430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=17.3088 mle=1.8687 pcon=5.1427 forget=7.3716 favg=2.9258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=15.5612 mle=1.9750 pcon=5.1397 forget=6.8077 favg=1.6387 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=11.0639 mle=1.5666 pcon=5.1358 forget=7.1193 favg=-2.7578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=5.8170 mle=1.8893 pcon=5.1308 forget=7.6797 favg=-8.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=20.5366 mle=1.9232 pcon=5.1260 forget=8.2725 favg=5.2148 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=20.3073 mle=1.7368 pcon=5.1216 forget=7.7262 favg=5.7227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 40 total=16.8127 mle=1.6755 pcon=5.1178 forget=6.7753 favg=3.2441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=17.2009 mle=1.7974 pcon=5.1145 forget=6.9530 favg=3.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=14.2447 mle=1.7602 pcon=5.1117 forget=7.2906 favg=0.0823 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=7.3403 mle=1.4744 pcon=5.1083 forget=6.8201 favg=-6.0625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=23.2123 mle=1.9029 pcon=5.1042 forget=7.7833 favg=8.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=19.6165 mle=1.5076 pcon=5.1005 forget=7.5943 favg=5.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=13.8711 mle=1.9404 pcon=5.0976 forget=6.8477 favg=-0.0145 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=6.9636 mle=2.0103 pcon=5.0956 forget=6.9788 favg=-7.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=20.6285 mle=2.0510 pcon=5.0935 forget=7.2417 favg=6.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=23.6115 mle=1.7041 pcon=5.0915 forget=7.0503 favg=9.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=16.7394 mle=1.5830 pcon=5.0885 forget=6.9508 favg=3.1172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=10.6156 mle=1.6811 pcon=5.0854 forget=6.7671 favg=-2.9180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=7.7064 mle=1.7952 pcon=5.0824 forget=6.6373 favg=-5.8086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=4.2415 mle=1.6438 pcon=5.0796 forget=6.7368 favg=-9.2188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=6.1337 mle=1.9167 pcon=5.0772 forget=7.1555 favg=-8.0156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=20.6863 mle=1.6730 pcon=5.0745 forget=7.7161 favg=6.2227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=23.2746 mle=1.6002 pcon=5.0717 forget=7.3996 favg=9.2031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=20.3511 mle=1.6464 pcon=5.0691 forget=6.8895 favg=6.7461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=6.9311 mle=1.8540 pcon=5.0668 forget=7.0845 favg=-7.0742 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=3.5313 mle=1.8838 pcon=5.0651 forget=6.7778 favg=-10.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=24.0689 mle=1.8731 pcon=5.0632 forget=6.8748 favg=10.2578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=22.2313 mle=1.5984 pcon=5.0620 forget=6.9460 favg=8.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=16.9123 mle=1.6976 pcon=5.0604 forget=6.7637 favg=3.3906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=6.4833 mle=1.8105 pcon=5.0581 forget=6.6343 favg=-7.0195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=3.7530 mle=2.0395 pcon=5.0553 forget=6.4864 favg=-9.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=22.4171 mle=1.9702 pcon=5.0521 forget=7.1839 favg=8.2109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=23.6520 mle=1.6283 pcon=5.0491 forget=8.0058 favg=8.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=14.1753 mle=1.6446 pcon=5.0468 forget=7.1812 favg=0.3027 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=7.6078 mle=1.9071 pcon=5.0461 forget=6.6429 favg=-5.9883 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=4.2710 mle=1.9784 pcon=5.0458 forget=6.6375 favg=-9.3906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=21.9495 mle=1.7493 pcon=5.0449 forget=6.8585 favg=8.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 30 total=21.8807 mle=1.6706 pcon=5.0431 forget=7.3818 favg=7.7852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=16.1757 mle=1.7049 pcon=5.0409 forget=7.0724 favg=2.3574 nr=64 nf=64 protos=540 fproto_sim=NA
 18%|█▊        | 9/50 [08:06<35:34, 52.06s/it] 20%|██        | 10/50 [08:59<34:48, 52.21s/it] 22%|██▏       | 11/50 [09:50<33:36, 51.71s/it] 24%|██▍       | 12/50 [10:43<33:01, 52.15s/it] 26%|██▌       | 13/50 [11:34<31:54, 51.74s/it] 28%|██▊       | 14/50 [12:20<30:01, 50.04s/it] 30%|███       | 15/50 [13:11<29:20, 50.30s/it] 32%|███▏      | 16/50 [14:01<28:36, 50.48s/it][loss] ep 8 it 130 total=7.9720 mle=1.6962 pcon=5.0393 forget=6.5920 favg=-5.3555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=4.5767 mle=1.9925 pcon=5.0388 forget=6.4594 favg=-8.9141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=18.3787 mle=1.7526 pcon=5.0383 forget=7.1387 favg=4.4492 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=21.8916 mle=1.9425 pcon=5.0366 forget=7.3305 favg=7.5820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=18.9276 mle=1.8401 pcon=5.0342 forget=6.9400 favg=5.1133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=12.7196 mle=1.5560 pcon=5.0321 forget=6.6955 favg=-0.5640 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 40 total=4.5030 mle=2.1968 pcon=5.0309 forget=6.9316 favg=-9.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=20.6353 mle=2.0558 pcon=5.0301 forget=6.8658 favg=6.6836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=17.5792 mle=1.8932 pcon=5.0293 forget=6.7348 favg=3.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=15.9547 mle=1.6522 pcon=5.0275 forget=6.7261 favg=2.5488 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=11.9108 mle=1.8117 pcon=5.0252 forget=6.8063 favg=-1.7324 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=11.0129 mle=2.0774 pcon=5.0232 forget=6.7756 favg=-2.8633 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=18.5289 mle=1.7164 pcon=5.0219 forget=7.1227 favg=4.6680 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=15.0640 mle=1.7654 pcon=5.0203 forget=6.8525 favg=1.4258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=13.7286 mle=1.7141 pcon=5.0181 forget=6.6638 favg=0.3325 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=12.1891 mle=1.9216 pcon=5.0161 forget=6.7817 favg=-1.5303 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=14.9165 mle=2.0260 pcon=5.0141 forget=6.8285 favg=1.0479 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=20.0454 mle=1.9030 pcon=5.0116 forget=6.8457 favg=6.2852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=14.7502 mle=1.7187 pcon=5.0088 forget=6.7454 favg=1.2773 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=12.1441 mle=1.6965 pcon=5.0061 forget=6.6748 favg=-1.2334 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=10.5089 mle=1.7495 pcon=5.0037 forget=6.6424 favg=-2.8867 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=8.9481 mle=1.7367 pcon=5.0018 forget=6.5729 favg=-4.3633 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=14.2213 mle=1.8280 pcon=5.0002 forget=6.6298 favg=0.7632 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=15.6045 mle=1.8083 pcon=4.9985 forget=6.7489 favg=2.0488 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=16.2440 mle=1.7543 pcon=4.9958 forget=6.8162 favg=2.6777 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=17.6404 mle=1.7672 pcon=4.9927 forget=6.7867 favg=4.0938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=18.2929 mle=1.9251 pcon=4.9897 forget=6.7883 favg=4.5898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=17.3609 mle=2.0907 pcon=4.9868 forget=6.9181 favg=3.3652 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=11.2417 mle=1.7366 pcon=4.9847 forget=6.8621 favg=-2.3418 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=8.4657 mle=1.7072 pcon=4.9824 forget=6.8229 favg=-5.0469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=8.2141 mle=1.8291 pcon=4.9799 forget=6.7918 favg=-5.3867 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=12.0054 mle=1.7747 pcon=4.9772 forget=6.8658 favg=-1.6123 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=17.9181 mle=1.8681 pcon=4.9744 forget=6.9428 favg=4.1328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=19.0780 mle=1.7032 pcon=4.9712 forget=7.0715 favg=5.3320 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=18.4878 mle=1.6926 pcon=4.9685 forget=7.1431 favg=4.6836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=16.8239 mle=1.6074 pcon=4.9654 forget=7.1710 favg=3.0801 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=13.7055 mle=1.8318 pcon=4.9626 forget=7.0372 favg=-0.1261 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=8.9920 mle=1.6453 pcon=4.9603 forget=6.7966 favg=-4.4102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=7.5108 mle=1.6132 pcon=4.9581 forget=6.7598 favg=-5.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=7.2729 mle=1.6452 pcon=4.9556 forget=6.9182 favg=-6.2461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=7.4500 mle=1.7547 pcon=4.9529 forget=7.0548 favg=-6.3125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=7.4073 mle=1.6855 pcon=4.9497 forget=7.1276 favg=-6.3555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.4025 mle=1.5909 pcon=4.9461 forget=7.1545 favg=-6.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=10.1925 mle=1.7284 pcon=4.9425 forget=7.2384 favg=-3.7168 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=13.4101 mle=1.7172 pcon=4.9392 forget=7.3489 favg=-0.5952 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=15.1353 mle=1.8921 pcon=4.9359 forget=7.4088 favg=0.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=14.4066 mle=1.8034 pcon=4.9334 forget=7.3508 favg=0.3191 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=11.3087 mle=1.6820 pcon=4.9310 forget=7.2133 favg=-2.5176 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=8.8726 mle=1.8468 pcon=4.9284 forget=7.2615 favg=-5.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=9.9636 mle=1.6569 pcon=4.9258 forget=7.5332 favg=-4.1523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=10.5759 mle=1.6738 pcon=4.9225 forget=7.6397 favg=-3.6602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=10.0475 mle=1.7583 pcon=4.9190 forget=7.6162 favg=-4.2461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=9.1676 mle=1.7783 pcon=4.9155 forget=7.5285 favg=-5.0547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=8.9699 mle=1.7478 pcon=4.9119 forget=7.5368 favg=-5.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=9.1319 mle=1.6914 pcon=4.9085 forget=7.6140 favg=-5.0820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=9.2088 mle=1.8334 pcon=4.9053 forget=7.7200 favg=-5.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=8.2593 mle=1.6872 pcon=4.9023 forget=7.8183 favg=-6.1484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.1045 mle=1.9020 pcon=4.8993 forget=7.9595 favg=-7.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=7.1311 mle=1.6352 pcon=4.8964 forget=8.2323 favg=-7.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=8.6777 mle=1.7168 pcon=4.8933 forget=8.5324 favg=-6.4648 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=8.9557 mle=1.6167 pcon=4.8900 forget=8.7186 favg=-6.2695 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=8.1068 mle=1.5933 pcon=4.8865 forget=8.7637 favg=-7.1367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=6.4514 mle=1.6877 pcon=4.8833 forget=8.7007 favg=-8.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=5.0218 mle=1.5639 pcon=4.8797 forget=8.5547 favg=-9.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=4.8508 mle=1.6645 pcon=4.8763 forget=8.5287 favg=-10.2188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=5.9629 mle=1.9451 pcon=4.8729 forget=8.6136 favg=-9.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=6.6322 mle=1.9869 pcon=4.8697 forget=8.8147 favg=-9.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=6.4458 mle=1.7073 pcon=4.8664 forget=8.9738 favg=-9.1016 nr=64 nf=64 protos=540 fproto_sim=NA
 34%|███▍      | 17/50 [14:51<27:40, 50.31s/it] 36%|███▌      | 18/50 [15:41<26:42, 50.08s/it] 38%|███▊      | 19/50 [16:32<26:01, 50.38s/it] 40%|████      | 20/50 [17:19<24:43, 49.44s/it] 42%|████▏     | 21/50 [18:10<24:09, 49.97s/it] 44%|████▍     | 22/50 [18:59<23:08, 49.60s/it] 46%|████▌     | 23/50 [19:48<22:15, 49.45s/it] 48%|████▊     | 24/50 [20:38<21:27, 49.51s/it] 50%|█████     | 25/50 [21:25<20:19, 48.79s/it][peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 17 it 20 total=6.0984 mle=1.8756 pcon=4.8629 forget=9.1491 favg=-9.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=5.5123 mle=1.9034 pcon=4.8598 forget=9.2960 favg=-10.5469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=4.9675 mle=1.6126 pcon=4.8565 forget=9.3579 favg=-10.8594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=5.4954 mle=1.6864 pcon=4.8529 forget=9.5107 favg=-10.5547 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=5.7650 mle=1.6884 pcon=4.8496 forget=9.6645 favg=-10.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=5.5560 mle=1.5850 pcon=4.8468 forget=9.7649 favg=-10.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=5.3848 mle=1.8977 pcon=4.8436 forget=9.7842 favg=-11.1406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=4.7720 mle=1.8192 pcon=4.8402 forget=9.7533 favg=-11.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 18 it 30 total=4.3869 mle=1.6885 pcon=4.8374 forget=9.7516 favg=-11.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=4.6944 mle=1.7224 pcon=4.8344 forget=9.7782 favg=-11.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=5.3162 mle=1.7405 pcon=4.8315 forget=9.9082 favg=-11.1641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=5.6863 mle=1.6871 pcon=4.8287 forget=10.0846 favg=-10.9141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=5.9621 mle=1.7495 pcon=4.8257 forget=10.2229 favg=-10.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=5.8477 mle=1.7337 pcon=4.8229 forget=10.3145 favg=-11.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=5.5356 mle=1.7697 pcon=4.8202 forget=10.3755 favg=-11.4297 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=5.4507 mle=1.8193 pcon=4.8175 forget=10.4467 favg=-11.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 19 it 40 total=5.3935 mle=1.6554 pcon=4.8150 forget=10.5403 favg=-11.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=5.7219 mle=1.8037 pcon=4.8124 forget=10.5980 favg=-11.4922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=5.6667 mle=1.6794 pcon=4.8097 forget=10.6229 favg=-11.4453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=5.5025 mle=1.7276 pcon=4.8071 forget=10.6553 favg=-11.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=5.5592 mle=1.8949 pcon=4.8045 forget=10.6410 favg=-11.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=5.6897 mle=1.8886 pcon=4.8022 forget=10.6317 favg=-11.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=5.6265 mle=1.5860 pcon=4.7998 forget=10.7017 favg=-11.4609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=6.0312 mle=1.7667 pcon=4.7973 forget=10.8265 favg=-11.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=6.0614 mle=1.6986 pcon=4.7949 forget=10.8961 favg=-11.3281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=6.1178 mle=1.8746 pcon=4.7925 forget=10.9350 favg=-11.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=5.8879 mle=1.8668 pcon=4.7900 forget=11.0046 favg=-11.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=5.4456 mle=1.5735 pcon=4.7875 forget=11.0221 favg=-11.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=5.9570 mle=1.9898 pcon=4.7851 forget=11.0337 favg=-11.8516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=6.0534 mle=1.9913 pcon=4.7826 forget=11.0764 favg=-11.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=5.6831 mle=1.5729 pcon=4.7804 forget=11.0954 favg=-11.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=5.7431 mle=1.6403 pcon=4.7782 forget=11.0745 favg=-11.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=5.7225 mle=1.6641 pcon=4.7760 forget=11.0559 favg=-11.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=5.7168 mle=1.6497 pcon=4.7739 forget=11.0510 favg=-11.7578 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=5.9206 mle=1.8045 pcon=4.7719 forget=11.1099 favg=-11.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=6.0945 mle=1.8421 pcon=4.7698 forget=11.1076 favg=-11.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=6.0257 mle=1.7885 pcon=4.7678 forget=11.1726 favg=-11.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=5.8099 mle=1.6504 pcon=4.7656 forget=11.1907 favg=-11.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=6.0372 mle=1.6427 pcon=4.7636 forget=11.1231 favg=-11.4922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=5.9285 mle=1.7797 pcon=4.7615 forget=11.1684 favg=-11.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=6.0217 mle=1.8768 pcon=4.7595 forget=11.2058 favg=-11.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=6.1386 mle=1.7768 pcon=4.7574 forget=11.1122 favg=-11.5078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=5.8019 mle=1.6271 pcon=4.7555 forget=11.1458 favg=-11.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=5.7394 mle=1.6880 pcon=4.7536 forget=11.1259 favg=-11.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=5.7259 mle=1.5033 pcon=4.7517 forget=11.0334 favg=-11.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=6.0434 mle=1.7112 pcon=4.7500 forget=11.1134 favg=-11.5312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=6.5018 mle=2.0293 pcon=4.7481 forget=10.9744 favg=-11.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 30 total=5.9768 mle=1.5243 pcon=4.7465 forget=11.0653 favg=-11.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=6.1707 mle=1.7093 pcon=4.7448 forget=11.0526 favg=-11.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=6.3732 mle=1.6195 pcon=4.7430 forget=11.0966 favg=-11.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=6.8551 mle=1.8015 pcon=4.7413 forget=11.1249 favg=-10.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=6.8384 mle=1.6476 pcon=4.7397 forget=11.0371 favg=-10.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=6.7698 mle=1.7562 pcon=4.7379 forget=11.0882 favg=-10.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.3787 mle=1.6697 pcon=4.7363 forget=11.0899 favg=-10.1172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=6.9529 mle=1.6677 pcon=4.7347 forget=11.0270 favg=-10.4766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=6.0958 mle=1.6661 pcon=4.7333 forget=11.0559 favg=-11.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=6.0592 mle=1.7598 pcon=4.7318 forget=10.8958 favg=-11.3281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=6.3364 mle=1.7204 pcon=4.7303 forget=10.7763 favg=-10.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=6.4757 mle=1.7188 pcon=4.7289 forget=10.6686 favg=-10.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=6.6468 mle=1.5517 pcon=4.7275 forget=10.6097 favg=-10.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.9441 mle=1.7768 pcon=4.7260 forget=10.5663 favg=-9.1250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=6.9589 mle=1.6920 pcon=4.7247 forget=10.5188 favg=-9.9766 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▏    | 26/50 [22:06<18:34, 46.43s/it] 54%|█████▍    | 27/50 [22:46<17:02, 44.47s/it] 56%|█████▌    | 28/50 [23:24<15:34, 42.47s/it] 58%|█████▊    | 29/50 [24:02<14:28, 41.34s/it] 60%|██████    | 30/50 [24:45<13:57, 41.85s/it] 62%|██████▏   | 31/50 [25:27<13:11, 41.65s/it] 64%|██████▍   | 32/50 [26:06<12:18, 41.04s/it] 66%|██████▌   | 33/50 [26:44<11:21, 40.12s/it][loss] ep 25 it 0 total=7.2578 mle=1.6667 pcon=4.7232 forget=10.4304 favg=-9.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=9.3587 mle=1.8431 pcon=4.7220 forget=10.3718 favg=-7.5781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=11.6996 mle=1.6215 pcon=4.7206 forget=10.3379 favg=-4.9805 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=11.3674 mle=1.8554 pcon=4.7194 forget=10.4019 favg=-5.6094 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.2133 mle=1.9090 pcon=4.7181 forget=10.1253 favg=-9.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=11.1001 mle=1.7003 pcon=4.7168 forget=10.0424 favg=-5.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=21.1557 mle=1.7125 pcon=4.7156 forget=10.0284 favg=4.6992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=6.3864 mle=1.6211 pcon=4.7145 forget=9.8320 favg=-9.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=12.6047 mle=1.6689 pcon=4.7133 forget=9.7421 favg=-3.5195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=12.7483 mle=1.6886 pcon=4.7121 forget=9.4805 favg=-3.1328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=6.8587 mle=1.7246 pcon=4.7111 forget=9.3917 favg=-8.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=15.9951 mle=1.6149 pcon=4.7100 forget=9.6321 favg=0.0381 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=20.0506 mle=1.7872 pcon=4.7087 forget=9.5547 favg=4.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=10.6855 mle=1.6913 pcon=4.7076 forget=9.3023 favg=-5.0156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=8.9842 mle=1.8791 pcon=4.7064 forget=9.1878 favg=-6.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=16.7494 mle=1.5807 pcon=4.7052 forget=9.2877 favg=1.1758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=15.1581 mle=1.6880 pcon=4.7043 forget=9.3663 favg=-0.6006 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=8.0044 mle=1.7096 pcon=4.7033 forget=9.2673 favg=-7.6758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.1993 mle=1.6797 pcon=4.7022 forget=9.3642 favg=-8.5469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=19.8848 mle=1.5747 pcon=4.7012 forget=9.4136 favg=4.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=19.4729 mle=1.5694 pcon=4.7001 forget=9.3479 favg=3.8555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=12.0850 mle=1.6773 pcon=4.6991 forget=9.1716 favg=-3.4629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=6.8521 mle=1.7999 pcon=4.6981 forget=9.1509 favg=-8.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=15.1496 mle=1.8292 pcon=4.6972 forget=9.3693 favg=-0.7461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=19.2979 mle=1.7324 pcon=4.6964 forget=9.5741 favg=3.2949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=15.9471 mle=1.7494 pcon=4.6956 forget=9.5505 favg=-0.0485 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=9.7689 mle=1.7192 pcon=4.6949 forget=9.4994 favg=-6.1445 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=6.2220 mle=1.6877 pcon=4.6942 forget=9.5432 favg=-9.7031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=10.2386 mle=1.5512 pcon=4.6933 forget=9.7207 favg=-5.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=17.0369 mle=1.6483 pcon=4.6925 forget=9.8163 favg=0.8799 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=17.7674 mle=1.9687 pcon=4.6918 forget=9.8178 favg=1.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=13.9186 mle=1.8687 pcon=4.6911 forget=9.6303 favg=-2.2715 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=8.9439 mle=1.7542 pcon=4.6902 forget=9.6050 favg=-7.1055 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=12.7434 mle=1.6688 pcon=4.6893 forget=9.7819 favg=-3.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=18.3617 mle=1.7497 pcon=4.6886 forget=10.0220 favg=1.9014 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=17.1902 mle=1.6597 pcon=4.6879 forget=10.1673 favg=0.6753 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=13.3314 mle=1.6998 pcon=4.6874 forget=10.1180 favg=-3.1738 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=9.0599 mle=1.8120 pcon=4.6869 forget=10.0142 favg=-7.4531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.1723 mle=1.6724 pcon=4.6865 forget=10.2353 favg=-9.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=6.9713 mle=1.6916 pcon=4.6860 forget=10.4062 favg=-9.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=12.9953 mle=1.7443 pcon=4.6856 forget=10.5615 favg=-3.9961 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=17.9392 mle=1.7188 pcon=4.6852 forget=10.6524 favg=0.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=17.2615 mle=1.8516 pcon=4.6847 forget=10.5680 favg=0.1572 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=12.4475 mle=1.5520 pcon=4.6841 forget=10.3208 favg=-4.1094 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.6091 mle=1.8810 pcon=4.6835 forget=10.2243 favg=-9.1797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=10.2123 mle=1.5585 pcon=4.6829 forget=10.3694 favg=-6.3984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=15.7694 mle=1.7876 pcon=4.6825 forget=10.5942 favg=-1.2949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=16.1874 mle=1.6817 pcon=4.6821 forget=10.8124 favg=-0.9888 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=12.8402 mle=1.6423 pcon=4.6817 forget=10.8248 favg=-4.3086 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=9.8614 mle=1.8337 pcon=4.6814 forget=10.8737 favg=-7.5273 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.4903 mle=1.6350 pcon=4.6810 forget=10.9555 favg=-9.7812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=6.4480 mle=1.6331 pcon=4.6807 forget=11.1186 favg=-10.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=6.5694 mle=1.5504 pcon=4.6802 forget=11.1513 favg=-10.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=8.4432 mle=1.7733 pcon=4.6798 forget=11.1386 favg=-9.1484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=10.6066 mle=1.6465 pcon=4.6792 forget=11.1636 favg=-6.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=12.1039 mle=1.7490 pcon=4.6787 forget=11.1216 favg=-5.4453 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=10.9073 mle=1.6264 pcon=4.6781 forget=11.0130 favg=-6.4102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=9.0985 mle=1.7242 pcon=4.6776 forget=10.7983 favg=-8.1016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=10.0106 mle=1.6282 pcon=4.6771 forget=10.8812 favg=-7.1758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=13.0224 mle=1.6860 pcon=4.6766 forget=11.2418 favg=-4.5820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=14.2753 mle=1.6519 pcon=4.6762 forget=11.4316 favg=-3.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=13.4601 mle=1.5779 pcon=4.6758 forget=11.5306 favg=-4.3242 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=11.1429 mle=1.5671 pcon=4.6756 forget=11.5331 favg=-6.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=9.2873 mle=1.7689 pcon=4.6752 forget=11.5698 favg=-8.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=8.3213 mle=1.9960 pcon=4.6749 forget=11.6504 favg=-10.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.2482 mle=1.6226 pcon=4.6745 forget=11.6385 favg=-10.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.5550 mle=1.8067 pcon=4.6742 forget=11.6600 favg=-10.5859 nr=64 nf=64 protos=540 fproto_sim=NA
 68%|██████▊   | 34/50 [27:23<10:33, 39.59s/it] 70%|███████   | 35/50 [28:01<09:48, 39.24s/it] 72%|███████▏  | 36/50 [28:39<09:03, 38.83s/it] 74%|███████▍  | 37/50 [29:17<08:22, 38.68s/it] 76%|███████▌  | 38/50 [29:55<07:40, 38.40s/it] 78%|███████▊  | 39/50 [30:32<06:57, 37.96s/it] 80%|████████  | 40/50 [31:10<06:21, 38.10s/it] 82%|████████▏ | 41/50 [31:48<05:42, 38.02s/it] 84%|████████▍ | 42/50 [32:26<05:03, 37.97s/it][loss] ep 33 it 230 total=8.2156 mle=1.6728 pcon=4.6739 forget=11.6814 favg=-9.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=9.1258 mle=1.7077 pcon=4.6735 forget=11.7680 favg=-9.0234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=10.3090 mle=1.8189 pcon=4.6732 forget=11.6020 favg=-7.7852 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=10.4100 mle=1.6713 pcon=4.6728 forget=11.5190 favg=-7.4531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=10.0937 mle=1.7540 pcon=4.6724 forget=11.4994 favg=-7.8320 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=9.4951 mle=1.6018 pcon=4.6719 forget=11.5808 favg=-8.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=10.4319 mle=1.7204 pcon=4.6715 forget=11.7275 favg=-7.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=12.0139 mle=1.6738 pcon=4.6711 forget=11.8955 favg=-6.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=12.8527 mle=1.7619 pcon=4.6707 forget=11.9787 favg=-5.5586 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=11.7455 mle=1.7026 pcon=4.6703 forget=12.0093 favg=-6.6367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=10.2704 mle=1.7340 pcon=4.6700 forget=12.1165 favg=-8.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=9.0046 mle=1.7199 pcon=4.6696 forget=12.1386 favg=-9.5234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=7.9745 mle=1.6636 pcon=4.6694 forget=12.2040 favg=-10.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=7.7122 mle=1.8576 pcon=4.6690 forget=11.8965 favg=-10.7109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=7.2526 mle=1.6732 pcon=4.6688 forget=12.1527 favg=-11.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=7.4596 mle=1.6478 pcon=4.6687 forget=12.1274 favg=-10.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=8.0146 mle=1.7550 pcon=4.6683 forget=12.2240 favg=-10.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=8.6443 mle=1.6241 pcon=4.6681 forget=12.2506 favg=-9.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=9.8202 mle=1.8213 pcon=4.6678 forget=12.1358 favg=-8.8047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=10.7478 mle=1.8137 pcon=4.6676 forget=12.1924 favg=-7.9258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=10.6680 mle=1.6059 pcon=4.6674 forget=12.2854 favg=-7.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=10.4949 mle=1.5948 pcon=4.6670 forget=12.2409 favg=-8.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=10.6670 mle=1.6909 pcon=4.6667 forget=12.3719 favg=-8.0625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=10.9912 mle=1.5977 pcon=4.6665 forget=12.3833 favg=-7.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=11.1674 mle=1.6636 pcon=4.6663 forget=12.3766 favg=-7.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=11.1053 mle=1.7021 pcon=4.6660 forget=12.3934 favg=-7.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=9.9810 mle=1.6881 pcon=4.6657 forget=12.5256 favg=-8.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=9.3525 mle=1.6795 pcon=4.6653 forget=12.6249 favg=-9.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=8.9849 mle=1.7887 pcon=4.6651 forget=12.5076 favg=-9.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=8.4735 mle=1.6821 pcon=4.6648 forget=12.6110 favg=-10.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=8.1389 mle=1.7066 pcon=4.6646 forget=12.6818 favg=-10.9141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=8.0671 mle=1.8221 pcon=4.6642 forget=12.5184 favg=-10.9375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=7.8731 mle=1.6648 pcon=4.6639 forget=12.7397 favg=-11.1953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=8.1726 mle=1.7013 pcon=4.6636 forget=12.7217 favg=-10.9141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=8.7484 mle=1.7390 pcon=4.6635 forget=12.6427 favg=-10.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=9.0478 mle=1.7179 pcon=4.6633 forget=12.5338 favg=-9.8672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=9.0531 mle=1.5735 pcon=4.6632 forget=12.4883 favg=-9.6719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=9.5919 mle=1.7047 pcon=4.6630 forget=12.6305 favg=-9.4062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=10.4134 mle=1.7183 pcon=4.6627 forget=12.5949 favg=-8.5625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=11.2271 mle=1.6459 pcon=4.6625 forget=12.6648 favg=-7.7461 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=11.1608 mle=1.6736 pcon=4.6623 forget=12.6452 favg=-7.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=10.2100 mle=1.6315 pcon=4.6619 forget=12.8228 favg=-8.9062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=9.2575 mle=1.5626 pcon=4.6617 forget=12.8378 favg=-9.8047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=8.6590 mle=1.7336 pcon=4.6616 forget=12.8498 favg=-10.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=8.3187 mle=1.7109 pcon=4.6614 forget=12.6886 favg=-10.7422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=8.3810 mle=1.7608 pcon=4.6612 forget=12.6386 favg=-10.6797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=8.0134 mle=1.5366 pcon=4.6610 forget=12.7689 favg=-10.9531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=8.2688 mle=1.6627 pcon=4.6609 forget=12.7421 favg=-10.7969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=8.2593 mle=1.4987 pcon=4.6607 forget=12.7170 favg=-10.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=9.1324 mle=1.6542 pcon=4.6606 forget=12.7708 favg=-9.9531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=10.5671 mle=1.5837 pcon=4.6604 forget=12.7058 favg=-8.3828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=11.9860 mle=1.7498 pcon=4.6602 forget=12.7284 favg=-7.1523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=10.9289 mle=1.6785 pcon=4.6598 forget=12.7781 favg=-8.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=9.2782 mle=1.5409 pcon=4.6596 forget=12.8043 favg=-9.7266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=9.6496 mle=1.7980 pcon=4.6593 forget=12.5673 favg=-9.3750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=11.3107 mle=1.8981 pcon=4.6590 forget=12.6793 favg=-7.9258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=11.7469 mle=1.6488 pcon=4.6589 forget=12.7634 favg=-7.3242 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=10.6164 mle=1.4917 pcon=4.6588 forget=12.7394 favg=-8.2734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=9.1514 mle=1.5475 pcon=4.6586 forget=12.7734 favg=-9.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=9.1482 mle=1.9967 pcon=4.6586 forget=12.5710 favg=-10.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=9.0459 mle=1.6584 pcon=4.6584 forget=12.7291 favg=-10.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=9.9682 mle=1.6272 pcon=4.6583 forget=12.6828 favg=-9.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=10.5186 mle=1.7832 pcon=4.6582 forget=12.6709 favg=-8.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=9.6946 mle=1.5464 pcon=4.6582 forget=12.6775 favg=-9.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=8.8941 mle=1.6468 pcon=4.6582 forget=12.7453 favg=-10.1562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=8.7048 mle=1.7086 pcon=4.6582 forget=12.7208 favg=-10.3828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=9.6110 mle=1.7017 pcon=4.6581 forget=12.6106 favg=-9.3594 nr=64 nf=64 protos=540 fproto_sim=NA
 86%|████████▌ | 43/50 [33:05<04:27, 38.15s/it] 88%|████████▊ | 44/50 [33:43<03:50, 38.34s/it] 90%|█████████ | 45/50 [34:21<03:10, 38.20s/it] 92%|█████████▏| 46/50 [34:52<02:23, 35.96s/it] 94%|█████████▍| 47/50 [35:17<01:37, 32.61s/it] 96%|█████████▌| 48/50 [35:43<01:01, 30.58s/it] 98%|█████████▊| 49/50 [36:08<00:29, 29.12s/it]100%|██████████| 50/50 [36:34<00:00, 27.96s/it]100%|██████████| 50/50 [36:34<00:00, 43.88s/it]
[loss] ep 42 it 70 total=11.0533 mle=1.7350 pcon=4.6578 forget=12.6996 favg=-8.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=11.9673 mle=1.8820 pcon=4.6576 forget=12.6817 favg=-7.2539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=11.1884 mle=1.6236 pcon=4.6575 forget=12.5245 favg=-7.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=10.0530 mle=1.6637 pcon=4.6574 forget=12.5600 favg=-8.8281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.6456 mle=1.8128 pcon=4.6573 forget=12.6990 favg=-10.5234 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=8.5663 mle=1.7599 pcon=4.6573 forget=12.5632 favg=-10.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=9.2152 mle=1.6764 pcon=4.6573 forget=12.5222 favg=-9.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=9.7096 mle=1.6749 pcon=4.6572 forget=12.6041 favg=-9.2266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=10.1076 mle=1.6571 pcon=4.6570 forget=12.6450 favg=-8.8516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=10.2935 mle=1.6883 pcon=4.6570 forget=12.5654 favg=-8.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=10.0629 mle=1.6314 pcon=4.6569 forget=12.5793 favg=-8.8047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=9.8543 mle=1.5847 pcon=4.6567 forget=12.6754 favg=-9.0625 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=9.6094 mle=1.5807 pcon=4.6567 forget=12.6533 favg=-9.2812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=9.2775 mle=1.5695 pcon=4.6565 forget=12.6921 favg=-9.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=9.0038 mle=1.5614 pcon=4.6563 forget=12.6767 favg=-9.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=9.1883 mle=1.7424 pcon=4.6562 forget=12.6257 favg=-9.8359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=9.3865 mle=1.6712 pcon=4.6560 forget=12.7546 favg=-9.6953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=9.9209 mle=1.6721 pcon=4.6559 forget=12.6319 favg=-9.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=10.6766 mle=1.5630 pcon=4.6558 forget=12.7625 favg=-8.3047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=11.4362 mle=1.6273 pcon=4.6557 forget=12.5672 favg=-7.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=11.8579 mle=1.7998 pcon=4.6557 forget=12.5118 favg=-7.1094 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=11.7855 mle=1.8002 pcon=4.6556 forget=12.6422 favg=-7.3125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=11.0482 mle=1.6484 pcon=4.6555 forget=12.6116 favg=-7.8672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=10.2349 mle=1.5951 pcon=4.6554 forget=12.6563 favg=-8.6719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=9.6248 mle=1.6176 pcon=4.6553 forget=12.6487 favg=-9.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=9.3712 mle=1.5850 pcon=4.6552 forget=12.6700 favg=-9.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=9.5233 mle=1.6669 pcon=4.6552 forget=12.6700 favg=-9.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=9.8144 mle=1.6606 pcon=4.6552 forget=12.6783 favg=-9.1797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=9.8972 mle=1.6132 pcon=4.6550 forget=12.7071 favg=-9.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=10.1165 mle=1.5931 pcon=4.6550 forget=12.6184 favg=-8.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=10.1947 mle=1.5625 pcon=4.6550 forget=12.6413 favg=-8.6641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=10.2532 mle=1.5725 pcon=4.6549 forget=12.7758 favg=-8.7500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=10.6118 mle=1.8401 pcon=4.6548 forget=12.6325 favg=-8.5156 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=10.3320 mle=1.5090 pcon=4.6547 forget=12.7620 favg=-8.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=10.6083 mle=1.8366 pcon=4.6546 forget=12.6953 favg=-8.5781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=10.4572 mle=1.7442 pcon=4.6544 forget=12.7695 favg=-8.7109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=10.2981 mle=1.5712 pcon=4.6544 forget=12.7678 favg=-8.6953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=10.4083 mle=1.7271 pcon=4.6543 forget=12.6909 favg=-8.6641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=10.0151 mle=1.5937 pcon=4.6541 forget=12.6422 favg=-8.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=9.8356 mle=1.6080 pcon=4.6540 forget=12.7767 favg=-9.2031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=9.9423 mle=1.6962 pcon=4.6538 forget=12.6861 favg=-9.0938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=9.7445 mle=1.6484 pcon=4.6536 forget=12.7159 favg=-9.2734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=9.6045 mle=1.5154 pcon=4.6535 forget=12.7246 favg=-9.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=9.7115 mle=1.7059 pcon=4.6534 forget=12.5944 favg=-9.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=9.7493 mle=1.6666 pcon=4.6533 forget=12.7654 favg=-9.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=9.8394 mle=1.7359 pcon=4.6532 forget=12.7471 favg=-9.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=9.8645 mle=1.6364 pcon=4.6532 forget=12.7624 favg=-9.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=9.9311 mle=1.6351 pcon=4.6531 forget=12.7914 favg=-9.1484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=10.2256 mle=1.7689 pcon=4.6530 forget=12.7725 favg=-8.9688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=10.0575 mle=1.6981 pcon=4.6530 forget=12.6282 favg=-8.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=10.3417 mle=1.7859 pcon=4.6530 forget=12.8638 favg=-8.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=10.3837 mle=1.6507 pcon=4.6529 forget=12.7676 favg=-8.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=10.5094 mle=1.6074 pcon=4.6528 forget=12.8819 favg=-8.6328 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=10.6806 mle=1.6033 pcon=4.6526 forget=12.8308 favg=-8.4062 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=10.8737 mle=1.6489 pcon=4.6526 forget=12.8066 favg=-8.2344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=11.3202 mle=1.6825 pcon=4.6526 forget=12.8757 favg=-7.8906 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=11.6044 mle=1.6293 pcon=4.6525 forget=12.7444 favg=-7.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=12.0010 mle=1.7589 pcon=4.6524 forget=12.7342 favg=-7.1445 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=12.1356 mle=1.7499 pcon=4.6522 forget=12.8233 favg=-7.0898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=12.2393 mle=1.6761 pcon=4.6521 forget=12.8251 favg=-6.9141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=12.4861 mle=1.6245 pcon=4.6521 forget=12.7603 favg=-6.5508 nr=64 nf=64 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:17,  2.83it/s]  3%|▎         | 10/391 [00:00<00:13, 27.79it/s]  5%|▍         | 19/391 [00:00<00:08, 44.97it/s]  7%|▋         | 28/391 [00:00<00:06, 56.96it/s]  9%|▉         | 37/391 [00:00<00:05, 66.21it/s] 12%|█▏        | 46/391 [00:00<00:04, 72.12it/s] 14%|█▍        | 55/391 [00:00<00:04, 77.06it/s] 16%|█▋        | 64/391 [00:01<00:04, 80.36it/s] 19%|█▊        | 73/391 [00:01<00:03, 80.99it/s] 21%|██        | 82/391 [00:01<00:03, 81.31it/s] 23%|██▎       | 91/391 [00:01<00:03, 82.35it/s] 26%|██▌       | 100/391 [00:01<00:03, 83.89it/s] 28%|██▊       | 109/391 [00:01<00:03, 85.22it/s] 30%|███       | 118/391 [00:01<00:03, 85.24it/s] 32%|███▏      | 127/391 [00:01<00:03, 86.14it/s] 35%|███▍      | 136/391 [00:01<00:02, 85.45it/s] 37%|███▋      | 146/391 [00:02<00:02, 87.18it/s] 40%|███▉      | 156/391 [00:02<00:02, 89.64it/s] 42%|████▏     | 166/391 [00:02<00:02, 91.08it/s] 45%|████▌     | 176/391 [00:02<00:02, 90.94it/s] 48%|████▊     | 186/391 [00:02<00:02, 90.28it/s] 50%|█████     | 196/391 [00:02<00:02, 89.90it/s] 52%|█████▏    | 205/391 [00:02<00:02, 88.52it/s] 55%|█████▍    | 214/391 [00:02<00:01, 88.62it/s] 57%|█████▋    | 223/391 [00:02<00:01, 87.04it/s] 59%|█████▉    | 232/391 [00:02<00:01, 87.36it/s] 62%|██████▏   | 241/391 [00:03<00:01, 86.12it/s] 64%|██████▍   | 250/391 [00:03<00:01, 85.53it/s] 66%|██████▌   | 259/391 [00:03<00:01, 84.58it/s] 69%|██████▊   | 268/391 [00:03<00:01, 85.95it/s] 71%|███████   | 277/391 [00:03<00:01, 87.02it/s] 73%|███████▎  | 286/391 [00:03<00:01, 87.37it/s] 75%|███████▌  | 295/391 [00:03<00:01, 87.96it/s] 78%|███████▊  | 304/391 [00:03<00:00, 88.42it/s] 80%|████████  | 313/391 [00:03<00:00, 84.25it/s] 82%|████████▏ | 322/391 [00:04<00:00, 82.08it/s] 85%|████████▍ | 331/391 [00:04<00:00, 81.75it/s] 87%|████████▋ | 340/391 [00:04<00:00, 83.92it/s] 89%|████████▉ | 349/391 [00:04<00:00, 85.45it/s] 92%|█████████▏| 358/391 [00:04<00:00, 86.59it/s] 94%|█████████▍| 367/391 [00:04<00:00, 87.42it/s] 96%|█████████▌| 376/391 [00:04<00:00, 87.46it/s] 98%|█████████▊| 385/391 [00:04<00:00, 87.49it/s]100%|██████████| 391/391 [00:04<00:00, 80.58it/s]
50000 images processed, 4.950427293777466 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.41it/s] 13%|█▎        | 10/79 [00:00<00:02, 24.31it/s] 24%|██▍       | 19/79 [00:00<00:01, 41.47it/s] 35%|███▌      | 28/79 [00:00<00:00, 54.34it/s] 47%|████▋     | 37/79 [00:00<00:00, 63.36it/s] 58%|█████▊    | 46/79 [00:00<00:00, 70.57it/s] 70%|██████▉   | 55/79 [00:01<00:00, 75.45it/s] 81%|████████  | 64/79 [00:01<00:00, 75.72it/s] 92%|█████████▏| 73/79 [00:01<00:00, 79.71it/s]100%|██████████| 79/79 [00:01<00:00, 59.52it/s]
10000 images processed, 1.3478267192840576 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<00:57,  3.52it/s]  5%|▍         | 10/204 [00:00<00:06, 32.13it/s]  9%|▉         | 19/204 [00:00<00:03, 50.08it/s] 14%|█▎        | 28/204 [00:00<00:02, 60.35it/s] 18%|█▊        | 37/204 [00:00<00:02, 68.32it/s] 23%|██▎       | 46/204 [00:00<00:02, 73.54it/s] 27%|██▋       | 55/204 [00:00<00:01, 77.41it/s] 31%|███▏      | 64/204 [00:01<00:01, 80.24it/s] 36%|███▌      | 73/204 [00:01<00:01, 81.93it/s] 40%|████      | 82/204 [00:01<00:01, 83.08it/s] 45%|████▍     | 91/204 [00:01<00:01, 83.40it/s] 49%|████▉     | 100/204 [00:01<00:01, 84.73it/s] 53%|█████▎    | 109/204 [00:01<00:01, 85.22it/s] 58%|█████▊    | 118/204 [00:01<00:01, 85.72it/s] 62%|██████▏   | 127/204 [00:01<00:00, 85.93it/s] 67%|██████▋   | 136/204 [00:01<00:00, 86.10it/s] 71%|███████   | 145/204 [00:01<00:00, 85.90it/s] 75%|███████▌  | 154/204 [00:02<00:00, 86.52it/s] 80%|████████  | 164/204 [00:02<00:00, 88.69it/s] 85%|████████▍ | 173/204 [00:02<00:00, 87.00it/s] 89%|████████▉ | 182/204 [00:02<00:00, 86.86it/s] 94%|█████████▎| 191/204 [00:02<00:00, 86.80it/s] 98%|█████████▊| 200/204 [00:02<00:00, 87.33it/s]100%|██████████| 204/204 [00:02<00:00, 77.32it/s]
26032 images processed, 2.677551746368408 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.77it/s] 11%|█▏        | 9/79 [00:00<00:04, 16.77it/s] 22%|██▏       | 17/79 [00:00<00:02, 27.70it/s] 32%|███▏      | 25/79 [00:00<00:01, 35.49it/s] 42%|████▏     | 33/79 [00:01<00:01, 41.21it/s] 49%|████▉     | 39/79 [00:01<00:00, 44.62it/s] 57%|█████▋    | 45/79 [00:01<00:00, 43.09it/s] 65%|██████▍   | 51/79 [00:01<00:00, 42.55it/s] 73%|███████▎  | 58/79 [00:01<00:00, 45.92it/s] 81%|████████  | 64/79 [00:01<00:00, 48.54it/s] 89%|████████▊ | 70/79 [00:01<00:00, 46.47it/s] 97%|█████████▋| 77/79 [00:02<00:00, 48.00it/s]100%|██████████| 79/79 [00:02<00:00, 38.39it/s]
10000 images processed, 2.0892207622528076 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:34,  2.26it/s] 11%|█▏        | 9/79 [00:00<00:03, 21.21it/s] 23%|██▎       | 18/79 [00:00<00:01, 38.54it/s] 34%|███▍      | 27/79 [00:00<00:01, 51.70it/s] 46%|████▌     | 36/79 [00:00<00:00, 60.99it/s] 57%|█████▋    | 45/79 [00:00<00:00, 67.73it/s] 67%|██████▋   | 53/79 [00:01<00:00, 71.04it/s] 77%|███████▋  | 61/79 [00:01<00:00, 71.90it/s] 89%|████████▊ | 70/79 [00:01<00:00, 76.59it/s]100%|██████████| 79/79 [00:01<00:00, 57.62it/s]
10000 images processed, 1.393115520477295 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:28,  2.44it/s] 14%|█▍        | 10/70 [00:00<00:02, 24.89it/s] 27%|██▋       | 19/70 [00:00<00:01, 41.89it/s] 40%|████      | 28/70 [00:00<00:00, 54.45it/s] 53%|█████▎    | 37/70 [00:00<00:00, 63.57it/s] 64%|██████▍   | 45/70 [00:00<00:00, 67.49it/s] 76%|███████▌  | 53/70 [00:01<00:00, 69.73it/s] 89%|████████▊ | 62/70 [00:01<00:00, 75.25it/s]100%|██████████| 70/70 [00:01<00:00, 56.89it/s]
8925 images processed, 1.2602624893188477 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:40,  1.09it/s]  7%|▋         | 3/45 [00:01<00:11,  3.65it/s] 20%|██        | 9/45 [00:01<00:03,  9.69it/s] 24%|██▍       | 11/45 [00:01<00:03,  9.14it/s] 38%|███▊      | 17/45 [00:01<00:02, 12.85it/s] 42%|████▏     | 19/45 [00:02<00:02, 12.77it/s] 53%|█████▎    | 24/45 [00:02<00:01, 17.04it/s] 60%|██████    | 27/45 [00:02<00:01, 13.11it/s] 67%|██████▋   | 30/45 [00:02<00:00, 15.05it/s] 73%|███████▎  | 33/45 [00:03<00:01, 10.53it/s] 80%|████████  | 36/45 [00:03<00:00, 12.81it/s] 89%|████████▉ | 40/45 [00:03<00:00, 15.67it/s] 96%|█████████▌| 43/45 [00:03<00:00, 10.29it/s]100%|██████████| 45/45 [00:04<00:00, 11.18it/s]
5640 images processed, 4.046351671218872 seconds used

19.50508213043213
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           5.12  98.93
places365     75.30  79.16
LSUN          28.16  94.77
iSUN          80.96  78.43
dtd           45.20  89.92
AVG           46.95  88.24
Retain-Acc: 0.7326
Forget-as-OOD (retain known vs forget novel):
  FPR: 74.40 AUROC: 87.60 AUIN: 98.44
11.527413368225098
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
