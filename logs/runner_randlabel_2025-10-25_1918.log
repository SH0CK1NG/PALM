nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:503: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:591: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [01:08<04:35, 68.96s/it] 40%|████      | 2/5 [02:06<03:06, 62.16s/it] 60%|██████    | 3/5 [03:02<01:58, 59.44s/it] 80%|████████  | 4/5 [03:45<00:53, 53.09s/it]100%|██████████| 5/5 [04:23<00:00, 47.33s/it]100%|██████████| 5/5 [04:23<00:00, 52.61s/it]
[loss-randlabel] ep 0 it 0 total=9.8872 ce_r=0.2465 ce_f=9.6408
[loss-randlabel] ep 0 it 50 total=9.2470 ce_r=0.5324 ce_f=8.7146
[loss-randlabel] ep 0 it 100 total=8.0560 ce_r=1.3016 ce_f=6.7543
[loss-randlabel] ep 0 it 150 total=7.2953 ce_r=1.7217 ce_f=5.5736
[loss-randlabel] ep 0 it 200 total=6.9875 ce_r=1.3208 ce_f=5.6667
[loss-randlabel] ep 0 it 250 total=6.4282 ce_r=0.9481 ce_f=5.4800
[loss-randlabel] ep 0 it 300 total=6.4661 ce_r=0.8819 ce_f=5.5842
[loss-randlabel] ep 0 it 350 total=6.5648 ce_r=0.7764 ce_f=5.7885
[loss-randlabel] ep 1 it 10 total=6.3063 ce_r=0.9843 ce_f=5.3221
[loss-randlabel] ep 1 it 60 total=6.4294 ce_r=0.8142 ce_f=5.6152
[loss-randlabel] ep 1 it 110 total=6.3663 ce_r=0.8780 ce_f=5.4883
[loss-randlabel] ep 1 it 160 total=6.1872 ce_r=0.9267 ce_f=5.2605
[loss-randlabel] ep 1 it 210 total=6.2044 ce_r=0.8127 ce_f=5.3918
[loss-randlabel] ep 1 it 260 total=6.3596 ce_r=0.7330 ce_f=5.6266
[loss-randlabel] ep 1 it 310 total=6.1917 ce_r=0.7880 ce_f=5.4037
[loss-randlabel] ep 1 it 360 total=6.2658 ce_r=0.9809 ce_f=5.2850
[loss-randlabel] ep 2 it 20 total=6.1287 ce_r=0.9544 ce_f=5.1743
[loss-randlabel] ep 2 it 70 total=6.1788 ce_r=0.7315 ce_f=5.4472
[loss-randlabel] ep 2 it 120 total=6.0451 ce_r=0.9088 ce_f=5.1363
[loss-randlabel] ep 2 it 170 total=6.3345 ce_r=1.0298 ce_f=5.3047
[loss-randlabel] ep 2 it 220 total=6.0271 ce_r=0.9162 ce_f=5.1109
[loss-randlabel] ep 2 it 270 total=6.2794 ce_r=0.9244 ce_f=5.3549
[loss-randlabel] ep 2 it 320 total=6.3223 ce_r=1.0221 ce_f=5.3001
[loss-randlabel] ep 2 it 370 total=6.0313 ce_r=0.8620 ce_f=5.1693
[loss-randlabel] ep 3 it 30 total=6.2432 ce_r=0.9049 ce_f=5.3383
[loss-randlabel] ep 3 it 80 total=6.1264 ce_r=0.7048 ce_f=5.4217
[loss-randlabel] ep 3 it 130 total=6.1533 ce_r=0.6194 ce_f=5.5339
[loss-randlabel] ep 3 it 180 total=6.0526 ce_r=0.6977 ce_f=5.3549
[loss-randlabel] ep 3 it 230 total=6.0757 ce_r=0.7793 ce_f=5.2964
[loss-randlabel] ep 3 it 280 total=6.0009 ce_r=0.7008 ce_f=5.3002
[loss-randlabel] ep 3 it 330 total=6.1421 ce_r=0.9140 ce_f=5.2281
[loss-randlabel] ep 3 it 380 total=6.0375 ce_r=0.8405 ce_f=5.1969
[loss-randlabel] ep 4 it 40 total=6.1453 ce_r=0.7635 ce_f=5.3819
[loss-randlabel] ep 4 it 90 total=6.1314 ce_r=0.9857 ce_f=5.1457
[loss-randlabel] ep 4 it 140 total=6.0368 ce_r=0.8539 ce_f=5.1829
[loss-randlabel] ep 4 it 190 total=5.9821 ce_r=0.7637 ce_f=5.2184
[loss-randlabel] ep 4 it 240 total=6.1139 ce_r=0.8866 ce_f=5.2273
[loss-randlabel] ep 4 it 290 total=5.9322 ce_r=0.7378 ce_f=5.1944
[loss-randlabel] ep 4 it 340 total=6.1098 ce_r=0.8777 ce_f=5.2321
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<04:48,  1.35it/s]  2%|▏         | 7/391 [00:00<00:35, 10.68it/s]  4%|▎         | 14/391 [00:00<00:17, 21.31it/s]  6%|▌         | 22/391 [00:01<00:11, 33.41it/s]  8%|▊         | 31/391 [00:01<00:07, 45.81it/s] 10%|▉         | 38/391 [00:01<00:06, 51.61it/s] 12%|█▏        | 45/391 [00:01<00:06, 49.96it/s] 13%|█▎        | 52/391 [00:01<00:06, 52.49it/s] 15%|█▌        | 60/391 [00:01<00:05, 58.58it/s] 18%|█▊        | 69/391 [00:01<00:04, 66.44it/s] 20%|██        | 79/391 [00:01<00:04, 73.52it/s] 23%|██▎       | 88/391 [00:01<00:03, 77.95it/s] 25%|██▍       | 97/391 [00:02<00:03, 73.84it/s] 27%|██▋       | 105/391 [00:02<00:04, 65.25it/s] 29%|██▊       | 112/391 [00:02<00:04, 62.60it/s] 31%|███       | 121/391 [00:02<00:03, 68.25it/s] 33%|███▎      | 129/391 [00:02<00:03, 71.24it/s] 35%|███▌      | 137/391 [00:02<00:03, 68.13it/s] 37%|███▋      | 144/391 [00:02<00:03, 61.86it/s] 39%|███▊      | 151/391 [00:02<00:03, 60.34it/s] 41%|████      | 160/391 [00:03<00:03, 66.89it/s] 43%|████▎     | 169/391 [00:03<00:03, 72.21it/s] 45%|████▌     | 177/391 [00:03<00:03, 67.33it/s] 47%|████▋     | 184/391 [00:03<00:03, 61.50it/s] 49%|████▉     | 191/391 [00:03<00:03, 59.95it/s] 51%|█████     | 200/391 [00:03<00:02, 67.21it/s] 54%|█████▎    | 210/391 [00:03<00:02, 74.34it/s] 56%|█████▌    | 219/391 [00:03<00:02, 77.73it/s] 58%|█████▊    | 227/391 [00:04<00:02, 73.87it/s] 60%|██████    | 235/391 [00:04<00:02, 64.94it/s] 62%|██████▏   | 242/391 [00:04<00:02, 62.80it/s] 64%|██████▍   | 252/391 [00:04<00:01, 70.44it/s] 67%|██████▋   | 261/391 [00:04<00:01, 73.96it/s] 69%|██████▉   | 270/391 [00:04<00:01, 76.78it/s] 71%|███████   | 278/391 [00:04<00:01, 65.65it/s] 73%|███████▎  | 285/391 [00:04<00:01, 64.49it/s] 75%|███████▍  | 292/391 [00:05<00:01, 63.03it/s] 77%|███████▋  | 301/391 [00:05<00:01, 69.11it/s] 79%|███████▉  | 310/391 [00:05<00:01, 73.03it/s] 81%|████████▏ | 318/391 [00:05<00:01, 70.40it/s] 83%|████████▎ | 326/391 [00:05<00:01, 63.90it/s] 85%|████████▌ | 333/391 [00:05<00:00, 61.91it/s] 88%|████████▊ | 343/391 [00:05<00:00, 69.68it/s] 90%|█████████ | 353/391 [00:05<00:00, 75.61it/s] 92%|█████████▏| 361/391 [00:05<00:00, 76.72it/s] 94%|█████████▍| 369/391 [00:06<00:00, 65.48it/s] 96%|█████████▌| 376/391 [00:06<00:00, 64.06it/s] 98%|█████████▊| 383/391 [00:06<00:00, 64.66it/s]100%|██████████| 391/391 [00:06<00:00, 60.69it/s]
50000 images processed, 6.529880046844482 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:56,  1.38it/s]  8%|▊         | 6/79 [00:00<00:07,  9.30it/s] 15%|█▌        | 12/79 [00:00<00:03, 18.53it/s] 23%|██▎       | 18/79 [00:01<00:02, 26.62it/s] 34%|███▍      | 27/79 [00:01<00:01, 40.73it/s] 46%|████▌     | 36/79 [00:01<00:00, 51.85it/s] 54%|█████▍    | 43/79 [00:01<00:00, 53.64it/s] 63%|██████▎   | 50/79 [00:01<00:00, 51.64it/s] 71%|███████   | 56/79 [00:01<00:00, 52.56it/s] 82%|████████▏ | 65/79 [00:01<00:00, 61.71it/s] 95%|█████████▍| 75/79 [00:01<00:00, 70.34it/s]100%|██████████| 79/79 [00:01<00:00, 41.63it/s]
10000 images processed, 1.9260787963867188 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:06,  1.61it/s]  3%|▎         | 6/204 [00:00<00:18, 10.50it/s]  7%|▋         | 15/204 [00:00<00:07, 26.73it/s] 12%|█▏        | 24/204 [00:00<00:04, 40.58it/s] 17%|█▋        | 34/204 [00:01<00:03, 53.76it/s] 21%|██        | 42/204 [00:01<00:03, 49.85it/s] 24%|██▍       | 49/204 [00:01<00:03, 51.59it/s] 28%|██▊       | 57/204 [00:01<00:02, 57.08it/s] 32%|███▏      | 66/204 [00:01<00:02, 63.05it/s] 36%|███▋      | 74/204 [00:01<00:02, 64.87it/s] 40%|███▉      | 81/204 [00:01<00:02, 57.33it/s] 44%|████▍     | 90/204 [00:01<00:01, 64.63it/s] 48%|████▊     | 97/204 [00:02<00:01, 61.45it/s] 52%|█████▏    | 107/204 [00:02<00:01, 69.49it/s] 57%|█████▋    | 116/204 [00:02<00:01, 73.92it/s] 61%|██████▏   | 125/204 [00:02<00:01, 78.06it/s] 66%|██████▌   | 134/204 [00:02<00:01, 64.02it/s] 69%|██████▉   | 141/204 [00:02<00:01, 60.29it/s] 74%|███████▎  | 150/204 [00:02<00:00, 66.05it/s] 78%|███████▊  | 159/204 [00:02<00:00, 71.20it/s] 82%|████████▏ | 167/204 [00:03<00:00, 69.71it/s] 86%|████████▌ | 175/204 [00:03<00:00, 60.87it/s] 89%|████████▉ | 182/204 [00:03<00:00, 59.58it/s] 94%|█████████▍| 192/204 [00:03<00:00, 68.02it/s] 99%|█████████▉| 202/204 [00:03<00:00, 74.37it/s]100%|██████████| 204/204 [00:03<00:00, 56.49it/s]
26032 images processed, 3.673027753829956 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:58,  1.33it/s] 14%|█▍        | 11/79 [00:00<00:03, 17.04it/s] 27%|██▋       | 21/79 [00:00<00:01, 32.28it/s] 37%|███▋      | 29/79 [00:01<00:01, 38.85it/s] 47%|████▋     | 37/79 [00:01<00:00, 47.16it/s] 58%|█████▊    | 46/79 [00:01<00:00, 55.99it/s] 71%|███████   | 56/79 [00:01<00:00, 65.25it/s] 82%|████████▏ | 65/79 [00:01<00:00, 71.47it/s] 95%|█████████▍| 75/79 [00:01<00:00, 77.55it/s]100%|██████████| 79/79 [00:01<00:00, 47.42it/s]
10000 images processed, 1.690570592880249 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:00,  1.28it/s]  8%|▊         | 6/79 [00:00<00:08,  8.61it/s] 15%|█▌        | 12/79 [00:01<00:03, 17.55it/s] 25%|██▌       | 20/79 [00:01<00:01, 29.51it/s] 37%|███▋      | 29/79 [00:01<00:01, 41.87it/s] 49%|████▉     | 39/79 [00:01<00:00, 54.24it/s] 59%|█████▉    | 47/79 [00:01<00:00, 56.96it/s] 68%|██████▊   | 54/79 [00:01<00:00, 53.96it/s] 77%|███████▋  | 61/79 [00:01<00:00, 54.58it/s] 89%|████████▊ | 70/79 [00:01<00:00, 63.24it/s]100%|██████████| 79/79 [00:01<00:00, 41.16it/s]
10000 images processed, 1.939152479171753 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:49,  1.39it/s]  9%|▊         | 6/70 [00:00<00:06,  9.41it/s] 17%|█▋        | 12/70 [00:00<00:03, 18.45it/s] 30%|███       | 21/70 [00:01<00:01, 32.88it/s] 41%|████▏     | 29/70 [00:01<00:00, 43.49it/s] 54%|█████▍    | 38/70 [00:01<00:00, 52.93it/s] 64%|██████▍   | 45/70 [00:01<00:00, 49.18it/s] 74%|███████▍  | 52/70 [00:01<00:00, 50.71it/s] 89%|████████▊ | 62/70 [00:01<00:00, 61.01it/s]100%|██████████| 70/70 [00:01<00:00, 39.80it/s]
8925 images processed, 1.8101909160614014 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:49,  1.13s/it]  4%|▍         | 2/45 [00:01<00:23,  1.82it/s] 16%|█▌        | 7/45 [00:01<00:04,  8.19it/s] 38%|███▊      | 17/45 [00:01<00:01, 16.87it/s] 44%|████▍     | 20/45 [00:01<00:01, 18.68it/s] 51%|█████     | 23/45 [00:01<00:01, 19.90it/s] 64%|██████▍   | 29/45 [00:02<00:00, 27.16it/s] 73%|███████▎  | 33/45 [00:02<00:00, 18.14it/s] 80%|████████  | 36/45 [00:02<00:00, 19.04it/s] 93%|█████████▎| 42/45 [00:02<00:00, 25.98it/s]100%|██████████| 45/45 [00:02<00:00, 16.45it/s]
5640 images processed, 2.758185863494873 seconds used

22.04109477996826
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.32  99.14
places365     71.52  79.20
LSUN          24.38  94.82
iSUN          70.22  83.81
dtd           46.42  88.13
AVG           43.17  89.02
Retain-Acc: 0.7384
Forget-as-OOD (retain known vs forget novel):
  FPR: 46.40 AUROC: 90.82 AUIN: 98.83
29.171358823776245
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl1_rf.png
