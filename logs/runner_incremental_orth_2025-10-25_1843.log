nohup: ignoring input
==== Stage 1: forget_inc={0,8,11,40,51}; forget_seen={}; all={0,8,11,40,51,66,67,88,94,57} ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1', adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [01:40<1:22:19, 100.82s/it]  4%|▍         | 2/50 [02:05<44:48, 56.01s/it]     6%|▌         | 3/50 [02:30<32:57, 42.07s/it]  8%|▊         | 4/50 [03:05<30:01, 39.16s/it] 10%|█         | 5/50 [03:38<27:32, 36.71s/it] 12%|█▏        | 6/50 [04:09<25:32, 34.82s/it][loss] ep 0 it 0 total=8.3808 mle=1.5977 pcon=5.2951 forget=1.4880 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 0 it 50 total=8.7598 mle=1.9975 pcon=5.2911 forget=1.4712 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 100 total=8.8938 mle=2.1490 pcon=5.2870 forget=1.4579 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 150 total=9.2588 mle=2.5110 pcon=5.2832 forget=1.4646 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 0 it 200 total=9.2767 mle=2.5478 pcon=5.2791 forget=1.4498 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 250 total=8.6589 mle=1.9173 pcon=5.2752 forget=1.4664 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 0 it 300 total=8.5035 mle=1.7859 pcon=5.2713 forget=1.4463 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 350 total=9.0417 mle=2.3249 pcon=5.2675 forget=1.4493 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 1 it 10 total=8.3754 mle=1.6422 pcon=5.2637 forget=1.4696 orth=0.0000 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 1 it 60 total=8.3649 mle=1.6559 pcon=5.2599 forget=1.4491 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 1 it 110 total=8.3748 mle=1.6667 pcon=5.2563 forget=1.4519 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 1 it 160 total=8.5363 mle=1.7870 pcon=5.2527 forget=1.4967 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 1 it 210 total=8.2692 mle=1.5534 pcon=5.2490 forget=1.4668 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 1 it 260 total=8.7188 mle=2.0005 pcon=5.2453 forget=1.4730 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 1 it 310 total=8.9538 mle=2.2414 pcon=5.2419 forget=1.4704 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 1 it 360 total=8.5471 mle=1.8661 pcon=5.2383 forget=1.4427 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 2 it 20 total=8.0544 mle=1.3650 pcon=5.2348 forget=1.4546 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 2 it 70 total=8.4469 mle=1.8040 pcon=5.2316 forget=1.4112 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 2 it 120 total=8.3461 mle=1.6640 pcon=5.2282 forget=1.4539 orth=0.0000 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 2 it 170 total=8.7061 mle=2.0456 pcon=5.2248 forget=1.4357 orth=0.0000 favg=0.0000 nr=24 nf=24 protos=570 fproto_sim=NA
[loss] ep 2 it 220 total=9.0419 mle=2.3929 pcon=5.2216 forget=1.4274 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 2 it 270 total=8.4752 mle=1.8097 pcon=5.2184 forget=1.4471 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 2 it 320 total=8.2584 mle=1.5979 pcon=5.2153 forget=1.4453 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 2 it 370 total=8.6890 mle=2.0396 pcon=5.2123 forget=1.4371 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 3 it 30 total=8.2848 mle=1.6322 pcon=5.2091 forget=1.4436 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 3 it 80 total=8.7029 mle=1.9744 pcon=5.2058 forget=1.5227 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 3 it 130 total=8.5243 mle=1.9436 pcon=5.2030 forget=1.3776 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 3 it 180 total=8.7427 mle=2.1014 pcon=5.1997 forget=1.4416 orth=0.0000 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 3 it 230 total=8.4348 mle=1.8276 pcon=5.1967 forget=1.4104 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 3 it 280 total=8.4478 mle=1.8484 pcon=5.1939 forget=1.4056 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 3 it 330 total=8.7780 mle=2.1114 pcon=5.1911 forget=1.4755 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 3 it 380 total=8.3114 mle=1.6330 pcon=5.1881 forget=1.4903 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 4 it 40 total=8.5259 mle=1.8575 pcon=5.1854 forget=1.4830 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 4 it 90 total=8.2827 mle=1.7164 pcon=5.1825 forget=1.3839 orth=0.0000 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 4 it 140 total=8.9954 mle=2.3381 pcon=5.1797 forget=1.4776 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 4 it 190 total=8.5000 mle=1.8534 pcon=5.1767 forget=1.4698 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 4 it 240 total=8.5114 mle=1.8304 pcon=5.1738 forget=1.5072 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 4 it 290 total=8.3026 mle=1.7318 pcon=5.1710 forget=1.3997 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 4 it 340 total=8.6435 mle=2.0392 pcon=5.1682 forget=1.4360 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 5 it 0 total=8.5837 mle=2.0073 pcon=5.1659 forget=1.4106 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 5 it 50 total=8.8950 mle=2.3047 pcon=5.1631 forget=1.4272 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 5 it 100 total=8.8497 mle=2.2130 pcon=5.1606 forget=1.4761 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 5 it 150 total=8.4470 mle=1.8725 pcon=5.1582 forget=1.4163 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 5 it 200 total=9.0861 mle=2.5113 pcon=5.1555 forget=1.4193 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 5 it 250 total=8.4102 mle=1.7715 pcon=5.1530 forget=1.4857 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 5 it 300 total=8.8081 mle=2.2598 pcon=5.1506 forget=1.3977 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 5 it 350 total=8.8151 mle=2.2501 pcon=5.1481 forget=1.4169 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 6 it 10 total=8.1806 mle=1.6298 pcon=5.1457 forget=1.4051 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 6 it 60 total=8.5165 mle=1.9549 pcon=5.1432 forget=1.4184 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 6 it 110 total=8.3508 mle=1.8258 pcon=5.1406 forget=1.3844 orth=0.0000 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 6 it 160 total=8.5975 mle=2.0632 pcon=5.1380 forget=1.3962 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 6 it 210 total=8.4434 mle=1.8875 pcon=5.1351 forget=1.4208 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 6 it 260 total=8.5021 mle=1.9469 pcon=5.1324 forget=1.4227 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 6 it 310 total=8.5701 mle=1.9905 pcon=5.1299 forget=1.4497 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 6 it 360 total=8.5307 mle=1.9282 pcon=5.1279 forget=1.4747 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
 14%|█▍        | 7/50 [04:46<25:26, 35.49s/it] 16%|█▌        | 8/50 [05:17<23:56, 34.20s/it] 18%|█▊        | 9/50 [05:42<21:21, 31.26s/it] 20%|██        | 10/50 [06:07<19:37, 29.44s/it] 22%|██▏       | 11/50 [06:27<17:14, 26.53s/it] 24%|██▍       | 12/50 [06:53<16:45, 26.46s/it] 26%|██▌       | 13/50 [07:14<15:19, 24.84s/it][peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 7 it 20 total=8.2175 mle=1.6810 pcon=5.1254 forget=1.4112 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 7 it 70 total=8.1948 mle=1.6954 pcon=5.1228 forget=1.3765 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 7 it 120 total=8.6716 mle=2.1666 pcon=5.1206 forget=1.3844 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 7 it 170 total=8.2800 mle=1.6950 pcon=5.1185 forget=1.4665 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 7 it 220 total=8.1182 mle=1.5957 pcon=5.1160 forget=1.4064 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 7 it 270 total=9.3598 mle=2.8930 pcon=5.1136 forget=1.3532 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 7 it 320 total=8.4414 mle=1.9307 pcon=5.1110 forget=1.3996 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 7 it 370 total=8.3827 mle=1.8768 pcon=5.1086 forget=1.3974 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 8 it 30 total=8.5728 mle=2.0734 pcon=5.1064 forget=1.3930 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 8 it 80 total=8.1592 mle=1.6395 pcon=5.1039 forget=1.4159 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 8 it 130 total=8.5330 mle=2.0174 pcon=5.1015 forget=1.4141 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 8 it 180 total=8.4801 mle=1.9961 pcon=5.0993 forget=1.3848 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 8 it 230 total=8.1885 mle=1.6796 pcon=5.0969 forget=1.4121 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 8 it 280 total=7.8743 mle=1.4293 pcon=5.0944 forget=1.3505 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 8 it 330 total=8.9582 mle=2.4564 pcon=5.0917 forget=1.4101 orth=0.0000 favg=0.0000 nr=23 nf=23 protos=570 fproto_sim=NA
[loss] ep 8 it 380 total=8.2679 mle=1.7687 pcon=5.0893 forget=1.4098 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 9 it 40 total=8.3619 mle=1.9168 pcon=5.0868 forget=1.3583 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 9 it 90 total=8.3442 mle=1.8469 pcon=5.0845 forget=1.4128 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 9 it 140 total=8.1409 mle=1.6977 pcon=5.0823 forget=1.3609 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 9 it 190 total=8.0790 mle=1.6081 pcon=5.0803 forget=1.3906 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 9 it 240 total=8.5636 mle=2.1188 pcon=5.0781 forget=1.3667 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 9 it 290 total=8.1594 mle=1.6847 pcon=5.0759 forget=1.3988 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 9 it 340 total=8.0211 mle=1.5839 pcon=5.0738 forget=1.3634 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 10 it 0 total=8.0472 mle=1.5716 pcon=5.0713 forget=1.4043 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 10 it 50 total=8.1632 mle=1.7203 pcon=5.0692 forget=1.3736 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 10 it 100 total=7.9427 mle=1.4922 pcon=5.0667 forget=1.3838 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 10 it 150 total=8.2347 mle=1.7916 pcon=5.0644 forget=1.3787 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 10 it 200 total=8.3927 mle=1.9452 pcon=5.0625 forget=1.3850 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 10 it 250 total=8.9040 mle=2.4614 pcon=5.0603 forget=1.3823 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 10 it 300 total=8.2693 mle=1.8174 pcon=5.0580 forget=1.3939 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 10 it 350 total=8.1888 mle=1.7408 pcon=5.0561 forget=1.3920 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 11 it 10 total=8.1571 mle=1.7212 pcon=5.0540 forget=1.3819 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 11 it 60 total=8.0226 mle=1.5825 pcon=5.0519 forget=1.3882 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 11 it 110 total=7.8272 mle=1.3871 pcon=5.0499 forget=1.3901 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 11 it 160 total=8.2251 mle=1.7830 pcon=5.0479 forget=1.3942 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 11 it 210 total=8.0993 mle=1.6566 pcon=5.0457 forget=1.3969 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 11 it 260 total=7.9204 mle=1.4670 pcon=5.0434 forget=1.4099 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 11 it 310 total=8.4018 mle=1.9616 pcon=5.0412 forget=1.3990 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 11 it 360 total=8.2641 mle=1.8156 pcon=5.0389 forget=1.4096 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 12 it 20 total=7.9472 mle=1.4964 pcon=5.0366 forget=1.4141 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 70 total=8.2131 mle=1.7486 pcon=5.0342 forget=1.4303 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 12 it 120 total=8.1306 mle=1.6558 pcon=5.0319 forget=1.4429 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 12 it 170 total=8.4063 mle=1.9417 pcon=5.0295 forget=1.4351 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 220 total=8.1091 mle=1.6344 pcon=5.0269 forget=1.4477 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 12 it 270 total=8.0896 mle=1.6158 pcon=5.0244 forget=1.4494 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 320 total=8.2799 mle=1.8122 pcon=5.0220 forget=1.4457 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 12 it 370 total=8.4956 mle=2.0209 pcon=5.0195 forget=1.4552 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 13 it 30 total=8.4131 mle=1.9597 pcon=5.0171 forget=1.4363 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 13 it 80 total=8.2429 mle=1.7539 pcon=5.0148 forget=1.4743 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 13 it 130 total=8.3096 mle=1.8208 pcon=5.0124 forget=1.4764 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 13 it 180 total=8.0940 mle=1.6185 pcon=5.0098 forget=1.4657 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 13 it 230 total=8.0444 mle=1.5667 pcon=5.0073 forget=1.4704 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 13 it 280 total=8.0211 mle=1.5677 pcon=5.0049 forget=1.4485 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
 28%|██▊       | 14/50 [07:35<14:09, 23.60s/it] 30%|███       | 15/50 [07:56<13:13, 22.67s/it] 32%|███▏      | 16/50 [08:19<12:55, 22.80s/it] 34%|███▍      | 17/50 [08:40<12:12, 22.20s/it] 36%|███▌      | 18/50 [09:00<11:29, 21.54s/it] 38%|███▊      | 19/50 [09:20<10:57, 21.21s/it] 40%|████      | 20/50 [09:45<11:07, 22.24s/it][loss] ep 13 it 330 total=8.1725 mle=1.6862 pcon=5.0024 forget=1.4838 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 13 it 380 total=8.1579 mle=1.6904 pcon=5.0001 forget=1.4673 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 14 it 40 total=8.0008 mle=1.5262 pcon=4.9978 forget=1.4767 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 90 total=8.2946 mle=1.7926 pcon=4.9957 forget=1.5063 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 140 total=8.1004 mle=1.6170 pcon=4.9934 forget=1.4900 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 14 it 190 total=7.9959 mle=1.5321 pcon=4.9910 forget=1.4728 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 240 total=8.0419 mle=1.5891 pcon=4.9887 forget=1.4641 orth=0.0000 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 14 it 290 total=7.9247 mle=1.4737 pcon=4.9863 forget=1.4647 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 14 it 340 total=8.0245 mle=1.5942 pcon=4.9842 forget=1.4460 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 15 it 0 total=7.9508 mle=1.5340 pcon=4.9818 forget=1.4351 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 15 it 50 total=8.0167 mle=1.5833 pcon=4.9795 forget=1.4539 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 15 it 100 total=8.0374 mle=1.6001 pcon=4.9775 forget=1.4598 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 150 total=8.3824 mle=1.9686 pcon=4.9752 forget=1.4386 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 200 total=7.9601 mle=1.5975 pcon=4.9731 forget=1.3896 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 15 it 250 total=8.0827 mle=1.7229 pcon=4.9711 forget=1.3887 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 15 it 300 total=8.0232 mle=1.7330 pcon=4.9688 forget=1.3213 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 350 total=7.7519 mle=1.5200 pcon=4.9667 forget=1.2652 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 16 it 10 total=7.8049 mle=1.4666 pcon=4.9645 forget=1.3738 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 16 it 60 total=7.7958 mle=1.5413 pcon=4.9624 forget=1.2921 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 16 it 110 total=7.9291 mle=1.6924 pcon=4.9605 forget=1.2762 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 16 it 160 total=7.8296 mle=1.5761 pcon=4.9585 forget=1.2950 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 16 it 210 total=8.0455 mle=1.8110 pcon=4.9564 forget=1.2781 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 16 it 260 total=7.8938 mle=1.7071 pcon=4.9543 forget=1.2324 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 16 it 310 total=7.8667 mle=1.6729 pcon=4.9523 forget=1.2415 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 16 it 360 total=7.8764 mle=1.7056 pcon=4.9502 forget=1.2206 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 17 it 20 total=8.1069 mle=1.9713 pcon=4.9483 forget=1.1872 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 70 total=7.8590 mle=1.6493 pcon=4.9464 forget=1.2632 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 120 total=7.9112 mle=1.8258 pcon=4.9444 forget=1.1410 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 170 total=7.9044 mle=1.8231 pcon=4.9424 forget=1.1389 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 17 it 220 total=7.9488 mle=1.8749 pcon=4.9401 forget=1.1338 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 17 it 270 total=7.6933 mle=1.6373 pcon=4.9379 forget=1.1180 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 17 it 320 total=7.6428 mle=1.6552 pcon=4.9355 forget=1.0520 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 17 it 370 total=7.6453 mle=1.6810 pcon=4.9331 forget=1.0313 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 18 it 30 total=7.5451 mle=1.5654 pcon=4.9307 forget=1.0490 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 18 it 80 total=7.7051 mle=1.7552 pcon=4.9282 forget=1.0217 orth=0.0000 favg=0.0000 nr=23 nf=23 protos=570 fproto_sim=NA
[loss] ep 18 it 130 total=7.4894 mle=1.5353 pcon=4.9257 forget=1.0284 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 18 it 180 total=7.6876 mle=1.7496 pcon=4.9229 forget=1.0151 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 18 it 230 total=7.5699 mle=1.6877 pcon=4.9204 forget=0.9619 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 18 it 280 total=7.5511 mle=1.6594 pcon=4.9176 forget=0.9741 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 18 it 330 total=7.8633 mle=1.9322 pcon=4.9147 forget=1.0165 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 18 it 380 total=7.3346 mle=1.4299 pcon=4.9121 forget=0.9925 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 19 it 40 total=7.6325 mle=1.7354 pcon=4.9096 forget=0.9875 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 19 it 90 total=7.4766 mle=1.5732 pcon=4.9068 forget=0.9966 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 19 it 140 total=7.5577 mle=1.6593 pcon=4.9040 forget=0.9945 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 19 it 190 total=7.4786 mle=1.5704 pcon=4.9012 forget=1.0071 orth=0.0000 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 19 it 240 total=7.5191 mle=1.6204 pcon=4.8984 forget=1.0004 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 19 it 290 total=7.5248 mle=1.6655 pcon=4.8959 forget=0.9633 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 19 it 340 total=7.3278 mle=1.4405 pcon=4.8932 forget=0.9941 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 20 it 0 total=7.3904 mle=1.5051 pcon=4.8907 forget=0.9947 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 20 it 50 total=7.5508 mle=1.6746 pcon=4.8881 forget=0.9882 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 20 it 100 total=7.4941 mle=1.5967 pcon=4.8854 forget=1.0120 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 20 it 150 total=7.7373 mle=1.8570 pcon=4.8827 forget=0.9976 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 20 it 200 total=7.5903 mle=1.6968 pcon=4.8803 forget=1.0132 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
 42%|████▏     | 21/50 [10:05<10:29, 21.69s/it] 44%|████▍     | 22/50 [10:28<10:14, 21.94s/it] 46%|████▌     | 23/50 [10:54<10:32, 23.42s/it] 48%|████▊     | 24/50 [11:19<10:13, 23.60s/it] 50%|█████     | 25/50 [11:39<09:26, 22.67s/it] 52%|█████▏    | 26/50 [12:04<09:18, 23.28s/it] 54%|█████▍    | 27/50 [12:25<08:40, 22.62s/it] 56%|█████▌    | 28/50 [12:45<08:00, 21.86s/it][loss] ep 20 it 250 total=7.6579 mle=1.7810 pcon=4.8777 forget=0.9993 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 20 it 300 total=7.4325 mle=1.5487 pcon=4.8752 forget=1.0086 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 20 it 350 total=7.5332 mle=1.6404 pcon=4.8728 forget=1.0199 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[loss] ep 21 it 10 total=7.3767 mle=1.5062 pcon=4.8703 forget=1.0002 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 21 it 60 total=7.4608 mle=1.5702 pcon=4.8677 forget=1.0228 orth=0.0000 favg=0.0000 nr=24 nf=24 protos=570 fproto_sim=NA
[loss] ep 21 it 110 total=7.3865 mle=1.4972 pcon=4.8654 forget=1.0240 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 21 it 160 total=7.4371 mle=1.5566 pcon=4.8629 forget=1.0175 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 21 it 210 total=7.3856 mle=1.4879 pcon=4.8604 forget=1.0372 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 21 it 260 total=7.7182 mle=1.8134 pcon=4.8583 forget=1.0465 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 21 it 310 total=7.5107 mle=1.6183 pcon=4.8560 forget=1.0363 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 21 it 360 total=7.5831 mle=1.6762 pcon=4.8540 forget=1.0529 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 22 it 20 total=7.5406 mle=1.6332 pcon=4.8518 forget=1.0555 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 22 it 70 total=7.8183 mle=1.9179 pcon=4.8495 forget=1.0508 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 22 it 120 total=7.7709 mle=1.8475 pcon=4.8473 forget=1.0761 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 22 it 170 total=7.4899 mle=1.5865 pcon=4.8452 forget=1.0581 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 22 it 220 total=7.6609 mle=1.7483 pcon=4.8431 forget=1.0695 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 22 it 270 total=7.5290 mle=1.6024 pcon=4.8411 forget=1.0855 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 22 it 320 total=7.5506 mle=1.6281 pcon=4.8391 forget=1.0834 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 22 it 370 total=7.7169 mle=1.7851 pcon=4.8372 forget=1.0946 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 23 it 30 total=7.6748 mle=1.7621 pcon=4.8352 forget=1.0775 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 23 it 80 total=7.5765 mle=1.6489 pcon=4.8331 forget=1.0944 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 23 it 130 total=7.6282 mle=1.7038 pcon=4.8309 forget=1.0935 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 23 it 180 total=7.5548 mle=1.6258 pcon=4.8289 forget=1.1001 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 23 it 230 total=7.4014 mle=1.4709 pcon=4.8269 forget=1.1036 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 23 it 280 total=7.6734 mle=1.7329 pcon=4.8251 forget=1.1153 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 23 it 330 total=7.6785 mle=1.7426 pcon=4.8232 forget=1.1127 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 23 it 380 total=7.6335 mle=1.6937 pcon=4.8213 forget=1.1185 orth=0.0000 favg=0.0000 nr=21 nf=21 protos=570 fproto_sim=NA
[loss] ep 24 it 40 total=7.4865 mle=1.5492 pcon=4.8194 forget=1.1179 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 24 it 90 total=7.6144 mle=1.6242 pcon=4.8175 forget=1.1726 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 24 it 140 total=7.4308 mle=1.4773 pcon=4.8158 forget=1.1377 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 24 it 190 total=7.6278 mle=1.6747 pcon=4.8140 forget=1.1391 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 24 it 240 total=7.5622 mle=1.5997 pcon=4.8124 forget=1.1501 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 24 it 290 total=7.9014 mle=1.9424 pcon=4.8104 forget=1.1486 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 24 it 340 total=7.6716 mle=1.6962 pcon=4.8088 forget=1.1667 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 25 it 0 total=7.5087 mle=1.5243 pcon=4.8072 forget=1.1772 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 25 it 50 total=7.6009 mle=1.6217 pcon=4.8057 forget=1.1735 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 25 it 100 total=7.7535 mle=1.7894 pcon=4.8041 forget=1.1600 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 25 it 150 total=7.6408 mle=1.6606 pcon=4.8025 forget=1.1777 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 25 it 200 total=7.7815 mle=1.7844 pcon=4.8009 forget=1.1963 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 25 it 250 total=7.5087 mle=1.5311 pcon=4.7993 forget=1.1783 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 25 it 300 total=7.6891 mle=1.6889 pcon=4.7978 forget=1.2024 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 25 it 350 total=7.6994 mle=1.7137 pcon=4.7963 forget=1.1894 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 26 it 10 total=7.7460 mle=1.7591 pcon=4.7948 forget=1.1921 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 26 it 60 total=7.7444 mle=1.7532 pcon=4.7934 forget=1.1978 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 26 it 110 total=7.6186 mle=1.6190 pcon=4.7920 forget=1.2076 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 26 it 160 total=7.5615 mle=1.5697 pcon=4.7906 forget=1.2011 orth=0.0000 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 26 it 210 total=7.7596 mle=1.7573 pcon=4.7893 forget=1.2131 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 26 it 260 total=7.6285 mle=1.6357 pcon=4.7879 forget=1.2049 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 26 it 310 total=7.6518 mle=1.6363 pcon=4.7864 forget=1.2291 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 26 it 360 total=7.6894 mle=1.6717 pcon=4.7850 forget=1.2326 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 27 it 20 total=7.6447 mle=1.6372 pcon=4.7835 forget=1.2240 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 27 it 70 total=7.5074 mle=1.4891 pcon=4.7821 forget=1.2363 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 27 it 120 total=7.8775 mle=1.8716 pcon=4.7807 forget=1.2251 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 27 it 170 total=7.6630 mle=1.6469 pcon=4.7794 forget=1.2367 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 27 it 220 total=7.5180 mle=1.4980 pcon=4.7781 forget=1.2419 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 27 it 270 total=7.5264 mle=1.4981 pcon=4.7767 forget=1.2516 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 27 it 320 total=7.6070 mle=1.5845 pcon=4.7753 forget=1.2472 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 27 it 370 total=7.5537 mle=1.5151 pcon=4.7740 forget=1.2646 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 28 it 30 total=7.9221 mle=1.9035 pcon=4.7727 forget=1.2459 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 28 it 80 total=7.7852 mle=1.7565 pcon=4.7714 forget=1.2572 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 28 it 130 total=7.5931 mle=1.5583 pcon=4.7703 forget=1.2645 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
 58%|█████▊    | 29/50 [13:04<07:24, 21.16s/it] 60%|██████    | 30/50 [13:26<07:06, 21.35s/it] 62%|██████▏   | 31/50 [13:47<06:39, 21.03s/it] 64%|██████▍   | 32/50 [14:08<06:20, 21.13s/it] 66%|██████▌   | 33/50 [14:29<05:58, 21.07s/it] 68%|██████▊   | 34/50 [14:50<05:36, 21.04s/it] 70%|███████   | 35/50 [15:11<05:17, 21.18s/it] 72%|███████▏  | 36/50 [15:32<04:55, 21.13s/it][loss] ep 28 it 180 total=7.5628 mle=1.5324 pcon=4.7690 forget=1.2613 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 28 it 230 total=7.7037 mle=1.6678 pcon=4.7680 forget=1.2679 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 28 it 280 total=7.6281 mle=1.5988 pcon=4.7668 forget=1.2626 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 28 it 330 total=7.6136 mle=1.5687 pcon=4.7656 forget=1.2793 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 28 it 380 total=7.6355 mle=1.5974 pcon=4.7643 forget=1.2738 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 29 it 40 total=7.6892 mle=1.6323 pcon=4.7630 forget=1.2939 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 29 it 90 total=7.7672 mle=1.7227 pcon=4.7620 forget=1.2825 orth=0.0000 favg=0.0000 nr=24 nf=24 protos=570 fproto_sim=NA
[loss] ep 29 it 140 total=7.7016 mle=1.6549 pcon=4.7608 forget=1.2859 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 29 it 190 total=7.7991 mle=1.7325 pcon=4.7597 forget=1.3069 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 29 it 240 total=7.8164 mle=1.7588 pcon=4.7587 forget=1.2990 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 29 it 290 total=7.7018 mle=1.6434 pcon=4.7575 forget=1.3009 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 29 it 340 total=7.7514 mle=1.6930 pcon=4.7565 forget=1.3019 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 30 it 0 total=7.7980 mle=1.7355 pcon=4.7554 forget=1.3072 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 30 it 50 total=7.7598 mle=1.7026 pcon=4.7543 forget=1.3029 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 30 it 100 total=7.6789 mle=1.6184 pcon=4.7535 forget=1.3071 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 30 it 150 total=7.8058 mle=1.7422 pcon=4.7525 forget=1.3112 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 30 it 200 total=7.7926 mle=1.7249 pcon=4.7516 forget=1.3162 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 30 it 250 total=7.5621 mle=1.4869 pcon=4.7506 forget=1.3247 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 30 it 300 total=7.7840 mle=1.7062 pcon=4.7496 forget=1.3282 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 30 it 350 total=7.6865 mle=1.6232 pcon=4.7486 forget=1.3147 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 31 it 10 total=7.6548 mle=1.5893 pcon=4.7477 forget=1.3178 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 31 it 60 total=7.7987 mle=1.7153 pcon=4.7468 forget=1.3367 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 31 it 110 total=7.5309 mle=1.4513 pcon=4.7459 forget=1.3336 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 31 it 160 total=7.6096 mle=1.5179 pcon=4.7450 forget=1.3466 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 31 it 210 total=7.8257 mle=1.7580 pcon=4.7441 forget=1.3235 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 31 it 260 total=7.6837 mle=1.5991 pcon=4.7433 forget=1.3412 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 31 it 310 total=7.5807 mle=1.5026 pcon=4.7424 forget=1.3357 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 31 it 360 total=7.6756 mle=1.5928 pcon=4.7417 forget=1.3411 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 32 it 20 total=7.5996 mle=1.5161 pcon=4.7410 forget=1.3425 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 32 it 70 total=7.6031 mle=1.5189 pcon=4.7401 forget=1.3441 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 32 it 120 total=7.6792 mle=1.5773 pcon=4.7392 forget=1.3626 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 32 it 170 total=7.7986 mle=1.7019 pcon=4.7384 forget=1.3583 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 32 it 220 total=7.8208 mle=1.7205 pcon=4.7376 forget=1.3627 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 32 it 270 total=7.6878 mle=1.5960 pcon=4.7366 forget=1.3551 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 32 it 320 total=7.7925 mle=1.7039 pcon=4.7357 forget=1.3529 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 32 it 370 total=7.5695 mle=1.4753 pcon=4.7350 forget=1.3591 orth=0.0000 favg=0.0000 nr=23 nf=23 protos=570 fproto_sim=NA
[loss] ep 33 it 30 total=7.9698 mle=1.8748 pcon=4.7343 forget=1.3607 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 33 it 80 total=7.6376 mle=1.5486 pcon=4.7335 forget=1.3555 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 33 it 130 total=7.6850 mle=1.5823 pcon=4.7327 forget=1.3700 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 33 it 180 total=7.7666 mle=1.6724 pcon=4.7320 forget=1.3622 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 33 it 230 total=7.8596 mle=1.7595 pcon=4.7313 forget=1.3688 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 33 it 280 total=8.2035 mle=2.0843 pcon=4.7305 forget=1.3887 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 33 it 330 total=7.6078 mle=1.5129 pcon=4.7297 forget=1.3651 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 33 it 380 total=7.7022 mle=1.5954 pcon=4.7292 forget=1.3776 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 34 it 40 total=7.7883 mle=1.6836 pcon=4.7286 forget=1.3761 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 34 it 90 total=7.7739 mle=1.6651 pcon=4.7279 forget=1.3810 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 34 it 140 total=7.8524 mle=1.7464 pcon=4.7272 forget=1.3788 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 34 it 190 total=7.7579 mle=1.6307 pcon=4.7265 forget=1.4007 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 34 it 240 total=7.7411 mle=1.6360 pcon=4.7259 forget=1.3792 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 34 it 290 total=7.6178 mle=1.5024 pcon=4.7253 forget=1.3901 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 34 it 340 total=7.6497 mle=1.5342 pcon=4.7246 forget=1.3908 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 35 it 0 total=7.6973 mle=1.5821 pcon=4.7240 forget=1.3912 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 35 it 50 total=7.9931 mle=1.8748 pcon=4.7234 forget=1.3950 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 35 it 100 total=7.7304 mle=1.6117 pcon=4.7229 forget=1.3958 orth=0.0000 favg=0.0000 nr=43 nf=43 protos=570 fproto_sim=NA
[loss] ep 35 it 150 total=7.7392 mle=1.6233 pcon=4.7223 forget=1.3936 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 35 it 200 total=7.6112 mle=1.4879 pcon=4.7218 forget=1.4015 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 35 it 250 total=7.8590 mle=1.7386 pcon=4.7212 forget=1.3993 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 35 it 300 total=7.7448 mle=1.6223 pcon=4.7206 forget=1.4019 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 35 it 350 total=7.6546 mle=1.5328 pcon=4.7200 forget=1.4017 orth=0.0000 favg=0.0000 nr=21 nf=21 protos=570 fproto_sim=NA
[loss] ep 36 it 10 total=7.7329 mle=1.6122 pcon=4.7194 forget=1.4013 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 36 it 60 total=7.6419 mle=1.5182 pcon=4.7189 forget=1.4048 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 36 it 110 total=7.8513 mle=1.7135 pcon=4.7183 forget=1.4196 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
 74%|███████▍  | 37/50 [15:53<04:32, 20.97s/it] 76%|███████▌  | 38/50 [16:15<04:14, 21.19s/it] 78%|███████▊  | 39/50 [16:36<03:54, 21.34s/it] 80%|████████  | 40/50 [16:57<03:31, 21.14s/it] 82%|████████▏ | 41/50 [17:18<03:11, 21.24s/it] 84%|████████▍ | 42/50 [17:40<02:50, 21.37s/it] 86%|████████▌ | 43/50 [18:01<02:28, 21.17s/it] 88%|████████▊ | 44/50 [18:23<02:08, 21.39s/it][loss] ep 36 it 160 total=7.5528 mle=1.4118 pcon=4.7178 forget=1.4232 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 36 it 210 total=7.8759 mle=1.7157 pcon=4.7173 forget=1.4429 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 36 it 260 total=7.7971 mle=1.6527 pcon=4.7169 forget=1.4275 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 36 it 310 total=7.6969 mle=1.5617 pcon=4.7164 forget=1.4188 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 36 it 360 total=7.6999 mle=1.5557 pcon=4.7161 forget=1.4281 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 37 it 20 total=7.6310 mle=1.4876 pcon=4.7158 forget=1.4276 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 37 it 70 total=7.9943 mle=1.8552 pcon=4.7152 forget=1.4239 orth=0.0000 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 37 it 120 total=7.6356 mle=1.4861 pcon=4.7147 forget=1.4349 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 37 it 170 total=7.5926 mle=1.4434 pcon=4.7142 forget=1.4349 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 37 it 220 total=7.9363 mle=1.7860 pcon=4.7137 forget=1.4365 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 37 it 270 total=7.8050 mle=1.6596 pcon=4.7133 forget=1.4321 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 37 it 320 total=7.6857 mle=1.5393 pcon=4.7129 forget=1.4335 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 37 it 370 total=7.7738 mle=1.6156 pcon=4.7125 forget=1.4456 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 38 it 30 total=7.8967 mle=1.7368 pcon=4.7121 forget=1.4478 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 38 it 80 total=7.7689 mle=1.6098 pcon=4.7117 forget=1.4474 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 38 it 130 total=7.7540 mle=1.5881 pcon=4.7114 forget=1.4545 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 38 it 180 total=7.6005 mle=1.4302 pcon=4.7110 forget=1.4593 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 38 it 230 total=7.6250 mle=1.4420 pcon=4.7107 forget=1.4722 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 38 it 280 total=8.1910 mle=2.0222 pcon=4.7102 forget=1.4586 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 38 it 330 total=7.7774 mle=1.6024 pcon=4.7099 forget=1.4651 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 38 it 380 total=7.7850 mle=1.6126 pcon=4.7094 forget=1.4630 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 39 it 40 total=7.7615 mle=1.5829 pcon=4.7091 forget=1.4694 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 39 it 90 total=7.7787 mle=1.5793 pcon=4.7087 forget=1.4907 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 39 it 140 total=8.0286 mle=1.8566 pcon=4.7084 forget=1.4635 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 39 it 190 total=7.9323 mle=1.7318 pcon=4.7081 forget=1.4924 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 39 it 240 total=7.9417 mle=1.7645 pcon=4.7079 forget=1.4693 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 39 it 290 total=8.0490 mle=1.8532 pcon=4.7076 forget=1.4882 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 39 it 340 total=7.8463 mle=1.6634 pcon=4.7073 forget=1.4755 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 40 it 0 total=7.6351 mle=1.4378 pcon=4.7069 forget=1.4905 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 40 it 50 total=7.6788 mle=1.4879 pcon=4.7065 forget=1.4843 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 40 it 100 total=8.0310 mle=1.8340 pcon=4.7062 forget=1.4908 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 40 it 150 total=7.7789 mle=1.5796 pcon=4.7058 forget=1.4934 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 40 it 200 total=7.9023 mle=1.6960 pcon=4.7055 forget=1.5008 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 40 it 250 total=7.9197 mle=1.7205 pcon=4.7051 forget=1.4941 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 40 it 300 total=7.9278 mle=1.7020 pcon=4.7048 forget=1.5209 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 40 it 350 total=7.6868 mle=1.4846 pcon=4.7045 forget=1.4976 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 41 it 10 total=7.8197 mle=1.6043 pcon=4.7043 forget=1.5111 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 41 it 60 total=7.8521 mle=1.6442 pcon=4.7041 forget=1.5038 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 41 it 110 total=7.9761 mle=1.7441 pcon=4.7038 forget=1.5281 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 41 it 160 total=7.6456 mle=1.4231 pcon=4.7035 forget=1.5190 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 41 it 210 total=8.0858 mle=1.8559 pcon=4.7031 forget=1.5267 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 41 it 260 total=7.9958 mle=1.7730 pcon=4.7029 forget=1.5200 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 41 it 310 total=7.7301 mle=1.5091 pcon=4.7026 forget=1.5183 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 41 it 360 total=7.8796 mle=1.6568 pcon=4.7024 forget=1.5205 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 42 it 20 total=7.8381 mle=1.6037 pcon=4.7023 forget=1.5321 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 42 it 70 total=7.9305 mle=1.6923 pcon=4.7020 forget=1.5362 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 42 it 120 total=8.1584 mle=1.9214 pcon=4.7018 forget=1.5352 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 42 it 170 total=8.0459 mle=1.8063 pcon=4.7016 forget=1.5380 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 42 it 220 total=7.7713 mle=1.5314 pcon=4.7013 forget=1.5386 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 42 it 270 total=7.9180 mle=1.6685 pcon=4.7011 forget=1.5483 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 42 it 320 total=8.0538 mle=1.8133 pcon=4.7009 forget=1.5396 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 42 it 370 total=7.8094 mle=1.5566 pcon=4.7006 forget=1.5522 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 43 it 30 total=8.2581 mle=2.0082 pcon=4.7004 forget=1.5495 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 43 it 80 total=8.1882 mle=1.9278 pcon=4.7001 forget=1.5603 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 43 it 130 total=8.2527 mle=1.9903 pcon=4.6999 forget=1.5625 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 43 it 180 total=7.8719 mle=1.6085 pcon=4.6996 forget=1.5638 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 43 it 230 total=7.7728 mle=1.5151 pcon=4.6996 forget=1.5582 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 43 it 280 total=7.7014 mle=1.4459 pcon=4.6995 forget=1.5560 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 43 it 330 total=7.9601 mle=1.6931 pcon=4.6993 forget=1.5677 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 43 it 380 total=8.0752 mle=1.8158 pcon=4.6992 forget=1.5601 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 44 it 40 total=8.4168 mle=2.1397 pcon=4.6990 forget=1.5781 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 44 it 90 total=7.7467 mle=1.4675 pcon=4.6988 forget=1.5805 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
 90%|█████████ | 45/50 [18:46<01:49, 21.95s/it] 92%|█████████▏| 46/50 [19:14<01:34, 23.64s/it] 94%|█████████▍| 47/50 [19:42<01:15, 25.20s/it] 96%|█████████▌| 48/50 [20:15<00:54, 27.50s/it] 98%|█████████▊| 49/50 [20:48<00:29, 29.15s/it]100%|██████████| 50/50 [21:22<00:00, 30.50s/it]100%|██████████| 50/50 [21:22<00:00, 25.65s/it]
[loss] ep 44 it 140 total=7.9579 mle=1.6838 pcon=4.6985 forget=1.5756 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 44 it 190 total=7.9900 mle=1.7025 pcon=4.6984 forget=1.5891 orth=0.0000 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 44 it 240 total=8.0069 mle=1.7220 pcon=4.6982 forget=1.5867 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 44 it 290 total=8.2552 mle=1.9774 pcon=4.6981 forget=1.5796 orth=0.0000 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 44 it 340 total=7.8314 mle=1.5588 pcon=4.6981 forget=1.5745 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 45 it 0 total=7.6980 mle=1.4182 pcon=4.6978 forget=1.5820 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 45 it 50 total=7.9152 mle=1.6227 pcon=4.6976 forget=1.5949 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 45 it 100 total=8.0051 mle=1.7103 pcon=4.6975 forget=1.5974 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 45 it 150 total=7.9503 mle=1.6467 pcon=4.6974 forget=1.6062 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 45 it 200 total=7.8973 mle=1.6055 pcon=4.6971 forget=1.5947 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 45 it 250 total=7.9153 mle=1.6061 pcon=4.6969 forget=1.6122 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 45 it 300 total=7.7663 mle=1.4646 pcon=4.6968 forget=1.6049 orth=0.0000 favg=0.0000 nr=24 nf=24 protos=570 fproto_sim=NA
[loss] ep 45 it 350 total=8.1635 mle=1.8660 pcon=4.6967 forget=1.6009 orth=0.0000 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 46 it 10 total=7.9338 mle=1.6263 pcon=4.6965 forget=1.6110 orth=0.0000 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 46 it 60 total=7.8373 mle=1.5227 pcon=4.6964 forget=1.6181 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 46 it 110 total=7.8104 mle=1.5000 pcon=4.6963 forget=1.6142 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 46 it 160 total=8.1874 mle=1.8811 pcon=4.6963 forget=1.6101 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 46 it 210 total=8.0989 mle=1.7943 pcon=4.6960 forget=1.6086 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 46 it 260 total=8.1134 mle=1.7765 pcon=4.6958 forget=1.6411 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 46 it 310 total=8.0051 mle=1.6661 pcon=4.6956 forget=1.6434 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 46 it 360 total=8.0714 mle=1.7629 pcon=4.6956 forget=1.6128 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 47 it 20 total=8.3666 mle=2.0245 pcon=4.6955 forget=1.6466 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 47 it 70 total=7.8039 mle=1.4766 pcon=4.6953 forget=1.6320 orth=0.0000 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 47 it 120 total=7.9408 mle=1.6148 pcon=4.6952 forget=1.6308 orth=0.0000 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 47 it 170 total=8.0144 mle=1.6910 pcon=4.6951 forget=1.6283 orth=0.0000 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 47 it 220 total=7.9660 mle=1.6438 pcon=4.6950 forget=1.6272 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 47 it 270 total=8.0516 mle=1.7122 pcon=4.6948 forget=1.6446 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 47 it 320 total=7.8886 mle=1.5541 pcon=4.6947 forget=1.6397 orth=0.0000 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 47 it 370 total=7.9165 mle=1.5645 pcon=4.6946 forget=1.6575 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 48 it 30 total=8.1051 mle=1.7693 pcon=4.6945 forget=1.6414 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 48 it 80 total=8.0612 mle=1.7080 pcon=4.6944 forget=1.6588 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 48 it 130 total=7.9510 mle=1.6074 pcon=4.6943 forget=1.6493 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 48 it 180 total=8.1481 mle=1.7998 pcon=4.6943 forget=1.6540 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 48 it 230 total=8.2042 mle=1.8431 pcon=4.6942 forget=1.6669 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 48 it 280 total=8.0220 mle=1.6727 pcon=4.6942 forget=1.6551 orth=0.0000 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 48 it 330 total=7.8160 mle=1.4552 pcon=4.6942 forget=1.6666 orth=0.0000 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 48 it 380 total=8.0845 mle=1.7108 pcon=4.6942 forget=1.6796 orth=0.0000 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 49 it 40 total=7.8580 mle=1.4984 pcon=4.6940 forget=1.6656 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 49 it 90 total=8.0376 mle=1.6746 pcon=4.6940 forget=1.6690 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 49 it 140 total=7.8260 mle=1.4652 pcon=4.6939 forget=1.6670 orth=0.0000 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 49 it 190 total=7.9820 mle=1.6147 pcon=4.6938 forget=1.6734 orth=0.0000 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 49 it 240 total=8.1521 mle=1.7808 pcon=4.6938 forget=1.6776 orth=0.0000 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 49 it 290 total=7.9513 mle=1.5922 pcon=4.6938 forget=1.6653 orth=0.0000 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 49 it 340 total=8.0052 mle=1.6313 pcon=4.6937 forget=1.6801 orth=0.0000 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-inc1: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<04:17,  1.51it/s]  3%|▎         | 10/391 [00:00<00:22, 16.94it/s]  5%|▌         | 20/391 [00:00<00:11, 32.97it/s]  8%|▊         | 30/391 [00:00<00:07, 46.55it/s] 10%|█         | 40/391 [00:01<00:06, 57.73it/s] 13%|█▎        | 50/391 [00:01<00:05, 67.21it/s] 15%|█▌        | 59/391 [00:01<00:04, 72.75it/s] 17%|█▋        | 68/391 [00:01<00:04, 76.69it/s] 20%|█▉        | 77/391 [00:01<00:04, 69.71it/s] 22%|██▏       | 86/391 [00:01<00:04, 74.83it/s] 24%|██▍       | 95/391 [00:01<00:03, 78.32it/s] 27%|██▋       | 104/391 [00:01<00:03, 79.61it/s] 29%|██▉       | 113/391 [00:01<00:03, 82.44it/s] 31%|███       | 122/391 [00:02<00:03, 83.44it/s] 34%|███▎      | 131/391 [00:02<00:03, 74.79it/s] 36%|███▌      | 139/391 [00:02<00:03, 68.23it/s] 38%|███▊      | 147/391 [00:02<00:03, 64.20it/s] 40%|███▉      | 156/391 [00:02<00:03, 69.21it/s] 42%|████▏     | 165/391 [00:02<00:03, 73.64it/s] 45%|████▍     | 174/391 [00:02<00:02, 77.21it/s] 47%|████▋     | 183/391 [00:02<00:02, 79.84it/s] 49%|████▉     | 192/391 [00:03<00:02, 70.02it/s] 51%|█████     | 200/391 [00:03<00:02, 65.84it/s] 53%|█████▎    | 207/391 [00:03<00:02, 63.30it/s] 55%|█████▌    | 216/391 [00:03<00:02, 68.29it/s] 58%|█████▊    | 225/391 [00:03<00:02, 72.15it/s] 60%|█████▉    | 234/391 [00:03<00:02, 74.47it/s] 62%|██████▏   | 242/391 [00:03<00:02, 69.14it/s] 64%|██████▍   | 250/391 [00:03<00:02, 61.92it/s] 66%|██████▌   | 257/391 [00:04<00:02, 60.12it/s] 68%|██████▊   | 266/391 [00:04<00:01, 66.54it/s] 70%|███████   | 275/391 [00:04<00:01, 71.68it/s] 73%|███████▎  | 284/391 [00:04<00:01, 75.58it/s] 75%|███████▍  | 293/391 [00:04<00:01, 77.81it/s] 77%|███████▋  | 301/391 [00:04<00:01, 68.41it/s] 79%|███████▉  | 309/391 [00:04<00:01, 61.90it/s] 81%|████████  | 316/391 [00:04<00:01, 63.23it/s] 83%|████████▎ | 325/391 [00:05<00:00, 69.12it/s] 85%|████████▌ | 334/391 [00:05<00:00, 73.50it/s] 88%|████████▊ | 343/391 [00:05<00:00, 75.86it/s] 90%|████████▉ | 351/391 [00:05<00:00, 70.57it/s] 92%|█████████▏| 359/391 [00:05<00:00, 64.16it/s] 94%|█████████▎| 366/391 [00:05<00:00, 61.43it/s] 96%|█████████▌| 376/391 [00:05<00:00, 69.22it/s] 99%|█████████▊| 386/391 [00:05<00:00, 75.16it/s]100%|██████████| 391/391 [00:05<00:00, 65.31it/s]
50000 images processed, 6.087037086486816 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:48,  1.60it/s]  9%|▉         | 7/79 [00:00<00:05, 12.38it/s] 20%|██        | 16/79 [00:00<00:02, 28.00it/s] 32%|███▏      | 25/79 [00:00<00:01, 40.86it/s] 42%|████▏     | 33/79 [00:01<00:00, 49.75it/s] 51%|█████     | 40/79 [00:01<00:00, 47.83it/s] 59%|█████▉    | 47/79 [00:01<00:00, 49.25it/s] 70%|██████▉   | 55/79 [00:01<00:00, 56.02it/s] 81%|████████  | 64/79 [00:01<00:00, 64.32it/s] 92%|█████████▏| 73/79 [00:01<00:00, 70.66it/s]100%|██████████| 79/79 [00:01<00:00, 45.63it/s]
10000 images processed, 1.7605273723602295 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-inc1/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:39,  1.28it/s]  2%|▏         | 5/204 [00:00<00:27,  7.11it/s]  6%|▋         | 13/204 [00:01<00:09, 19.68it/s] 10%|█         | 21/204 [00:01<00:05, 31.40it/s] 15%|█▍        | 30/204 [00:01<00:04, 43.45it/s] 18%|█▊        | 37/204 [00:01<00:03, 43.23it/s] 22%|██▏       | 44/204 [00:01<00:03, 47.23it/s] 25%|██▍       | 50/204 [00:01<00:03, 50.04it/s] 28%|██▊       | 58/204 [00:01<00:02, 57.46it/s] 33%|███▎      | 67/204 [00:01<00:02, 65.53it/s] 37%|███▋      | 75/204 [00:01<00:01, 69.32it/s] 41%|████      | 83/204 [00:02<00:02, 58.19it/s] 44%|████▍     | 90/204 [00:02<00:02, 56.00it/s] 48%|████▊     | 98/204 [00:02<00:01, 61.14it/s] 51%|█████▏    | 105/204 [00:02<00:01, 63.08it/s] 55%|█████▍    | 112/204 [00:02<00:01, 64.48it/s] 58%|█████▊    | 119/204 [00:02<00:01, 55.46it/s] 61%|██████▏   | 125/204 [00:02<00:01, 54.17it/s] 65%|██████▌   | 133/204 [00:02<00:01, 60.64it/s] 69%|██████▉   | 141/204 [00:03<00:00, 65.30it/s] 74%|███████▎  | 150/204 [00:03<00:00, 71.45it/s] 77%|███████▋  | 158/204 [00:03<00:00, 62.01it/s] 81%|████████  | 165/204 [00:03<00:00, 61.53it/s] 84%|████████▍ | 172/204 [00:03<00:00, 59.40it/s] 89%|████████▊ | 181/204 [00:03<00:00, 67.06it/s] 93%|█████████▎| 190/204 [00:03<00:00, 73.13it/s] 98%|█████████▊| 199/204 [00:03<00:00, 77.58it/s]100%|██████████| 204/204 [00:03<00:00, 52.15it/s]
26032 images processed, 3.9567854404449463 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:08,  1.14it/s]  9%|▉         | 7/79 [00:00<00:07,  9.36it/s] 20%|██        | 16/79 [00:01<00:02, 22.67it/s] 32%|███▏      | 25/79 [00:01<00:01, 34.88it/s] 43%|████▎     | 34/79 [00:01<00:00, 45.72it/s] 53%|█████▎    | 42/79 [00:01<00:00, 48.25it/s] 62%|██████▏   | 49/79 [00:01<00:00, 49.65it/s] 71%|███████   | 56/79 [00:01<00:00, 50.93it/s] 82%|████████▏ | 65/79 [00:01<00:00, 60.01it/s] 94%|█████████▎| 74/79 [00:01<00:00, 66.94it/s]100%|██████████| 79/79 [00:01<00:00, 40.25it/s]
10000 images processed, 2.0070745944976807 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:53,  1.45it/s] 11%|█▏        | 9/79 [00:00<00:04, 14.73it/s] 22%|██▏       | 17/79 [00:00<00:02, 27.12it/s] 33%|███▎      | 26/79 [00:01<00:01, 40.17it/s] 42%|████▏     | 33/79 [00:01<00:01, 41.91it/s] 51%|█████     | 40/79 [00:01<00:00, 44.38it/s] 59%|█████▉    | 47/79 [00:01<00:00, 49.30it/s] 71%|███████   | 56/79 [00:01<00:00, 58.89it/s] 82%|████████▏ | 65/79 [00:01<00:00, 66.80it/s] 94%|█████████▎| 74/79 [00:01<00:00, 72.77it/s]100%|██████████| 79/79 [00:01<00:00, 44.80it/s]
10000 images processed, 1.7838413715362549 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:47,  1.46it/s]  9%|▊         | 6/70 [00:00<00:06,  9.77it/s] 16%|█▌        | 11/70 [00:00<00:03, 17.53it/s] 27%|██▋       | 19/70 [00:00<00:01, 31.06it/s] 40%|████      | 28/70 [00:01<00:00, 44.36it/s] 51%|█████▏    | 36/70 [00:01<00:00, 52.98it/s] 61%|██████▏   | 43/70 [00:01<00:00, 49.22it/s] 71%|███████▏  | 50/70 [00:01<00:00, 49.33it/s] 83%|████████▎ | 58/70 [00:01<00:00, 56.60it/s] 96%|█████████▌| 67/70 [00:01<00:00, 64.78it/s]100%|██████████| 70/70 [00:01<00:00, 40.00it/s]
8925 images processed, 1.7893681526184082 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:52,  1.19s/it]  4%|▍         | 2/45 [00:01<00:24,  1.77it/s] 24%|██▍       | 11/45 [00:01<00:02, 13.07it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.72it/s] 47%|████▋     | 21/45 [00:01<00:01, 16.10it/s] 60%|██████    | 27/45 [00:02<00:00, 22.29it/s] 73%|███████▎  | 33/45 [00:02<00:00, 19.89it/s] 82%|████████▏ | 37/45 [00:02<00:00, 17.99it/s]100%|██████████| 45/45 [00:02<00:00, 16.11it/s]
5640 images processed, 2.8152670860290527 seconds used

21.943180084228516
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.55  99.36
places365     68.45  80.52
LSUN          22.01  94.99
iSUN          72.53  81.45
dtd           38.40  91.28
AVG           40.79  89.52
Retain-Acc: 0.7485
Forget-as-OOD (retain known vs forget novel):
  FPR: 55.20 AUROC: 88.46 AUIN: 99.25
36.06576132774353
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-inc1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-inc1_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-seen: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<04:53,  1.33it/s]  2%|▏         | 7/391 [00:00<00:36, 10.51it/s]  3%|▎         | 12/391 [00:00<00:21, 17.58it/s]  4%|▍         | 17/391 [00:01<00:16, 23.12it/s]  6%|▌         | 23/391 [00:01<00:11, 30.70it/s]  7%|▋         | 29/391 [00:01<00:09, 36.31it/s]  9%|▉         | 36/391 [00:01<00:08, 43.96it/s] 11%|█         | 42/391 [00:01<00:07, 44.98it/s] 12%|█▏        | 48/391 [00:01<00:07, 46.54it/s] 14%|█▍        | 55/391 [00:01<00:06, 50.29it/s] 16%|█▌        | 63/391 [00:01<00:05, 56.15it/s] 18%|█▊        | 70/391 [00:02<00:05, 56.93it/s] 19%|█▉        | 76/391 [00:02<00:05, 52.72it/s] 21%|██        | 83/391 [00:02<00:05, 55.78it/s] 23%|██▎       | 89/391 [00:02<00:05, 53.93it/s] 25%|██▍       | 97/391 [00:02<00:04, 60.33it/s] 27%|██▋       | 106/391 [00:02<00:04, 66.14it/s] 29%|██▉       | 113/391 [00:02<00:04, 64.62it/s] 31%|███       | 120/391 [00:02<00:04, 57.82it/s] 32%|███▏      | 126/391 [00:02<00:04, 56.65it/s] 35%|███▍      | 135/391 [00:03<00:04, 63.55it/s] 37%|███▋      | 144/391 [00:03<00:03, 69.82it/s] 39%|███▉      | 152/391 [00:03<00:03, 72.19it/s] 41%|████      | 160/391 [00:03<00:03, 69.24it/s] 43%|████▎     | 168/391 [00:03<00:03, 62.08it/s] 45%|████▍     | 175/391 [00:03<00:03, 61.96it/s] 47%|████▋     | 182/391 [00:04<00:05, 40.57it/s] 49%|████▊     | 190/391 [00:04<00:04, 47.88it/s] 51%|█████     | 198/391 [00:04<00:03, 54.41it/s] 53%|█████▎    | 206/391 [00:04<00:03, 58.04it/s] 54%|█████▍    | 213/391 [00:04<00:03, 54.05it/s] 56%|█████▋    | 220/391 [00:04<00:03, 55.00it/s] 58%|█████▊    | 227/391 [00:04<00:02, 58.52it/s] 60%|██████    | 236/391 [00:04<00:02, 64.93it/s] 63%|██████▎   | 245/391 [00:04<00:02, 70.48it/s] 65%|██████▍   | 254/391 [00:05<00:01, 72.17it/s] 67%|██████▋   | 262/391 [00:05<00:02, 62.19it/s] 69%|██████▉   | 270/391 [00:05<00:01, 63.40it/s] 71%|███████   | 277/391 [00:05<00:01, 62.87it/s] 73%|███████▎  | 285/391 [00:05<00:01, 66.71it/s] 75%|███████▍  | 293/391 [00:05<00:01, 69.81it/s] 77%|███████▋  | 301/391 [00:05<00:01, 63.52it/s] 79%|███████▉  | 308/391 [00:05<00:01, 59.92it/s] 81%|████████  | 315/391 [00:06<00:01, 57.08it/s] 83%|████████▎ | 323/391 [00:06<00:01, 61.88it/s] 85%|████████▍ | 331/391 [00:06<00:00, 63.92it/s] 86%|████████▋ | 338/391 [00:06<00:00, 56.20it/s] 88%|████████▊ | 344/391 [00:06<00:00, 56.58it/s] 90%|████████▉ | 350/391 [00:06<00:00, 55.99it/s] 92%|█████████▏| 359/391 [00:06<00:00, 62.75it/s] 94%|█████████▍| 368/391 [00:06<00:00, 69.68it/s] 96%|█████████▋| 377/391 [00:06<00:00, 75.18it/s] 98%|█████████▊| 385/391 [00:07<00:00, 63.55it/s]100%|██████████| 391/391 [00:07<00:00, 53.68it/s]
50000 images processed, 7.3909077644348145 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:06,  1.17it/s]  8%|▊         | 6/79 [00:00<00:09,  8.10it/s] 18%|█▊        | 14/79 [00:01<00:03, 19.65it/s] 28%|██▊       | 22/79 [00:01<00:01, 30.51it/s] 35%|███▌      | 28/79 [00:01<00:01, 33.84it/s] 43%|████▎     | 34/79 [00:01<00:01, 38.55it/s] 51%|█████     | 40/79 [00:01<00:00, 41.54it/s] 59%|█████▉    | 47/79 [00:01<00:00, 47.93it/s] 70%|██████▉   | 55/79 [00:01<00:00, 55.59it/s] 78%|███████▊  | 62/79 [00:01<00:00, 52.37it/s] 87%|████████▋ | 69/79 [00:02<00:00, 54.88it/s] 95%|█████████▍| 75/79 [00:02<00:00, 55.56it/s]100%|██████████| 79/79 [00:02<00:00, 36.09it/s]
10000 images processed, 2.2123610973358154 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-seen/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<03:02,  1.11it/s]  3%|▎         | 6/204 [00:01<00:25,  7.80it/s]  6%|▌         | 12/204 [00:01<00:11, 16.19it/s] 10%|▉         | 20/204 [00:01<00:06, 27.92it/s] 14%|█▎        | 28/204 [00:01<00:04, 38.41it/s] 17%|█▋        | 35/204 [00:01<00:04, 39.27it/s] 20%|██        | 41/204 [00:01<00:03, 41.76it/s] 24%|██▍       | 49/204 [00:01<00:03, 49.99it/s] 28%|██▊       | 57/204 [00:01<00:02, 57.24it/s] 32%|███▏      | 66/204 [00:01<00:02, 62.21it/s] 36%|███▌      | 73/204 [00:02<00:02, 54.21it/s] 39%|███▉      | 80/204 [00:02<00:02, 53.84it/s] 44%|████▎     | 89/204 [00:02<00:01, 60.94it/s] 48%|████▊     | 97/204 [00:02<00:01, 64.89it/s] 51%|█████▏    | 105/204 [00:02<00:01, 65.27it/s] 55%|█████▍    | 112/204 [00:02<00:01, 57.28it/s] 58%|█████▊    | 119/204 [00:02<00:01, 56.33it/s] 62%|██████▏   | 127/204 [00:02<00:01, 61.70it/s] 66%|██████▌   | 135/204 [00:03<00:01, 65.42it/s] 71%|███████   | 144/204 [00:03<00:00, 70.42it/s] 75%|███████▍  | 152/204 [00:03<00:00, 60.38it/s] 78%|███████▊  | 159/204 [00:03<00:00, 56.53it/s] 82%|████████▏ | 168/204 [00:03<00:00, 63.27it/s] 87%|████████▋ | 177/204 [00:03<00:00, 69.52it/s] 91%|█████████ | 186/204 [00:03<00:00, 74.71it/s] 96%|█████████▌| 195/204 [00:03<00:00, 78.50it/s]100%|██████████| 204/204 [00:04<00:00, 80.47it/s]100%|██████████| 204/204 [00:04<00:00, 50.65it/s]
26032 images processed, 4.068756341934204 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:01<01:23,  1.08s/it] 10%|█         | 8/79 [00:01<00:07,  8.95it/s] 22%|██▏       | 17/79 [00:01<00:03, 20.10it/s] 29%|██▉       | 23/79 [00:01<00:02, 24.65it/s] 37%|███▋      | 29/79 [00:01<00:01, 29.69it/s] 47%|████▋     | 37/79 [00:01<00:01, 38.99it/s] 57%|█████▋    | 45/79 [00:01<00:00, 47.60it/s] 68%|██████▊   | 54/79 [00:01<00:00, 56.29it/s] 77%|███████▋  | 61/79 [00:01<00:00, 59.59it/s] 86%|████████▌ | 68/79 [00:02<00:00, 53.49it/s] 95%|█████████▍| 75/79 [00:02<00:00, 54.65it/s]100%|██████████| 79/79 [00:02<00:00, 33.94it/s]
10000 images processed, 2.3684372901916504 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:03,  1.23it/s] 11%|█▏        | 9/79 [00:00<00:05, 12.84it/s] 22%|██▏       | 17/79 [00:01<00:02, 24.06it/s] 32%|███▏      | 25/79 [00:01<00:01, 34.25it/s] 41%|████      | 32/79 [00:01<00:01, 36.64it/s] 48%|████▊     | 38/79 [00:01<00:00, 41.52it/s] 57%|█████▋    | 45/79 [00:01<00:00, 47.47it/s] 67%|██████▋   | 53/79 [00:01<00:00, 55.01it/s] 78%|███████▊  | 62/79 [00:01<00:00, 63.80it/s] 90%|████████▉ | 71/79 [00:01<00:00, 69.63it/s]100%|██████████| 79/79 [00:01<00:00, 60.92it/s]100%|██████████| 79/79 [00:01<00:00, 39.52it/s]
10000 images processed, 2.0306289196014404 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<01:05,  1.05it/s] 13%|█▎        | 9/70 [00:01<00:05, 11.37it/s] 23%|██▎       | 16/70 [00:01<00:02, 19.93it/s] 31%|███▏      | 22/70 [00:01<00:01, 25.06it/s] 40%|████      | 28/70 [00:01<00:01, 30.63it/s] 53%|█████▎    | 37/70 [00:01<00:00, 42.05it/s] 66%|██████▌   | 46/70 [00:01<00:00, 51.84it/s] 79%|███████▊  | 55/70 [00:01<00:00, 60.85it/s] 91%|█████████▏| 64/70 [00:01<00:00, 67.78it/s]100%|██████████| 70/70 [00:01<00:00, 35.68it/s]
8925 images processed, 1.9944970607757568 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:02,  1.43s/it]  4%|▍         | 2/45 [00:01<00:29,  1.44it/s] 13%|█▎        | 6/45 [00:01<00:07,  5.57it/s] 27%|██▋       | 12/45 [00:01<00:02, 12.58it/s] 38%|███▊      | 17/45 [00:02<00:01, 15.00it/s] 44%|████▍     | 20/45 [00:02<00:01, 15.69it/s] 64%|██████▍   | 29/45 [00:02<00:00, 27.75it/s] 76%|███████▌  | 34/45 [00:02<00:00, 16.13it/s] 87%|████████▋ | 39/45 [00:03<00:00, 19.71it/s]100%|██████████| 45/45 [00:03<00:00, 24.97it/s]100%|██████████| 45/45 [00:03<00:00, 14.06it/s]
5640 images processed, 3.2236671447753906 seconds used

25.238560914993286
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.55  99.36
places365     68.45  80.52
LSUN          22.01  94.99
iSUN          72.53  81.45
dtd           38.40  91.28
AVG           40.79  89.52
Retain-Acc: 0.7485
Forget-as-OOD (retain known vs forget novel):
  FPR: 55.20 AUROC: 88.46 AUIN: 99.25
30.923444747924805
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-seen_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage1-seen_rf.png
==== Stage 2: forget_inc={66,67,88,94,57}; forget_seen={0,8,11,40,51}; all={0,8,11,40,51,66,67,88,94,57} ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2', adapter_load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1', adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1', forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:227: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
  2%|▏         | 1/50 [02:13<1:48:47, 133.22s/it]  4%|▍         | 2/50 [03:04<1:08:07, 85.15s/it]   6%|▌         | 3/50 [03:51<53:03, 67.74s/it]    8%|▊         | 4/50 [04:36<45:03, 58.76s/it] 10%|█         | 5/50 [05:09<36:58, 49.30s/it] 12%|█▏        | 6/50 [05:37<30:53, 42.13s/it][loss] ep 0 it 0 total=9.9468 mle=2.0780 pcon=5.2950 forget=1.3342 orth=1.2397 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=9.9089 mle=2.0135 pcon=5.2855 forget=1.3704 orth=1.2394 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=10.1300 mle=2.2630 pcon=5.2766 forget=1.3513 orth=1.2390 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=10.0203 mle=2.1114 pcon=5.2676 forget=1.4029 orth=1.2384 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=10.0304 mle=2.1610 pcon=5.2586 forget=1.3733 orth=1.2374 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=9.9093 mle=2.0848 pcon=5.2499 forget=1.3384 orth=1.2363 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=9.9154 mle=2.0840 pcon=5.2411 forget=1.3553 orth=1.2349 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=9.8070 mle=1.9902 pcon=5.2327 forget=1.3509 orth=1.2332 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 1 it 10 total=9.9624 mle=2.1326 pcon=5.2245 forget=1.3740 orth=1.2313 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=9.8810 mle=2.0751 pcon=5.2161 forget=1.3607 orth=1.2291 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=9.9133 mle=2.1232 pcon=5.2079 forget=1.3556 orth=1.2266 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=9.7260 mle=1.9619 pcon=5.2001 forget=1.3402 orth=1.2238 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=9.6733 mle=1.9098 pcon=5.1923 forget=1.3503 orth=1.2208 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=9.6756 mle=1.9257 pcon=5.1846 forget=1.3478 orth=1.2175 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=9.7959 mle=2.0278 pcon=5.1768 forget=1.3770 orth=1.2142 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=9.7968 mle=2.0479 pcon=5.1693 forget=1.3691 orth=1.2105 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 2 it 20 total=9.5483 mle=1.8184 pcon=5.1619 forget=1.3613 orth=1.2067 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=9.4585 mle=1.7552 pcon=5.1546 forget=1.3461 orth=1.2026 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=9.6777 mle=1.9690 pcon=5.1475 forget=1.3628 orth=1.1984 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=9.4290 mle=1.7487 pcon=5.1407 forget=1.3455 orth=1.1941 favg=0.0000 nr=40 nf=40 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=9.6411 mle=1.9693 pcon=5.1338 forget=1.3481 orth=1.1898 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=9.7194 mle=2.0601 pcon=5.1272 forget=1.3468 orth=1.1853 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=9.2821 mle=1.6585 pcon=5.1204 forget=1.3225 orth=1.1807 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=9.4294 mle=1.7976 pcon=5.1141 forget=1.3419 orth=1.1757 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 3 it 30 total=9.3521 mle=1.7523 pcon=5.1078 forget=1.3211 orth=1.1709 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=9.7095 mle=2.0945 pcon=5.1016 forget=1.3475 orth=1.1658 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=9.2110 mle=1.6164 pcon=5.0955 forget=1.3387 orth=1.1605 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=9.6376 mle=2.0451 pcon=5.0895 forget=1.3479 orth=1.1551 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=9.4314 mle=1.8731 pcon=5.0837 forget=1.3250 orth=1.1496 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=9.4901 mle=1.9589 pcon=5.0779 forget=1.3090 orth=1.1442 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=9.4426 mle=1.9117 pcon=5.0721 forget=1.3204 orth=1.1384 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=9.2869 mle=1.7931 pcon=5.0666 forget=1.2945 orth=1.1327 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 4 it 40 total=9.2332 mle=1.7141 pcon=5.0609 forget=1.3315 orth=1.1267 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=9.3040 mle=1.8145 pcon=5.0556 forget=1.3128 orth=1.1210 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=9.1912 mle=1.6993 pcon=5.0504 forget=1.3263 orth=1.1151 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.9660 mle=1.5020 pcon=5.0453 forget=1.3095 orth=1.1092 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=9.5390 mle=2.0847 pcon=5.0403 forget=1.3109 orth=1.1032 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=9.1178 mle=1.7191 pcon=5.0353 forget=1.2661 orth=1.0972 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=9.3735 mle=1.9359 pcon=5.0304 forget=1.3162 orth=1.0909 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 5 it 0 total=9.0613 mle=1.6925 pcon=5.0256 forget=1.2587 orth=1.0846 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=9.2063 mle=1.8719 pcon=5.0211 forget=1.2348 orth=1.0785 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=9.3625 mle=2.0231 pcon=5.0165 forget=1.2505 orth=1.0724 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=9.3520 mle=2.0312 pcon=5.0121 forget=1.2429 orth=1.0658 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=9.0183 mle=1.7154 pcon=5.0077 forget=1.2360 orth=1.0593 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=9.0187 mle=1.7685 pcon=5.0034 forget=1.1937 orth=1.0531 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.8830 mle=1.6050 pcon=4.9992 forget=1.2321 orth=1.0467 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=9.1171 mle=1.8728 pcon=4.9951 forget=1.2088 orth=1.0404 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 6 it 10 total=8.9501 mle=1.7359 pcon=4.9914 forget=1.1891 orth=1.0336 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=9.0673 mle=1.8594 pcon=4.9878 forget=1.1929 orth=1.0272 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=9.1998 mle=2.0100 pcon=4.9842 forget=1.1845 orth=1.0212 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=8.8057 mle=1.6432 pcon=4.9807 forget=1.1668 orth=1.0151 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.8732 mle=1.7432 pcon=4.9772 forget=1.1440 orth=1.0089 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=9.2387 mle=2.1171 pcon=4.9738 forget=1.1449 orth=1.0029 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=8.7849 mle=1.6622 pcon=4.9706 forget=1.1555 orth=0.9966 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=9.0992 mle=2.0132 pcon=4.9674 forget=1.1281 orth=0.9905 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
 14%|█▍        | 7/50 [06:03<26:21, 36.78s/it] 16%|█▌        | 8/50 [06:27<22:52, 32.68s/it] 18%|█▊        | 9/50 [06:52<20:40, 30.25s/it] 20%|██        | 10/50 [07:15<18:49, 28.23s/it] 22%|██▏       | 11/50 [07:40<17:36, 27.10s/it] 24%|██▍       | 12/50 [08:07<17:10, 27.13s/it] 26%|██▌       | 13/50 [08:33<16:28, 26.73s/it][peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 7 it 20 total=8.7584 mle=1.6854 pcon=4.9643 forget=1.1244 orth=0.9843 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=8.8642 mle=1.7829 pcon=4.9613 forget=1.1416 orth=0.9784 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.8227 mle=1.7840 pcon=4.9583 forget=1.1080 orth=0.9724 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.7312 mle=1.7121 pcon=4.9554 forget=1.0969 orth=0.9668 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.6751 mle=1.6779 pcon=4.9525 forget=1.0835 orth=0.9611 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.8942 mle=1.8837 pcon=4.9500 forget=1.1050 orth=0.9554 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=8.7950 mle=1.8110 pcon=4.9474 forget=1.0869 orth=0.9497 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.7747 mle=1.8303 pcon=4.9446 forget=1.0559 orth=0.9439 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 8 it 30 total=8.6495 mle=1.6872 pcon=4.9421 forget=1.0818 orth=0.9384 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=8.6745 mle=1.7469 pcon=4.9396 forget=1.0554 orth=0.9327 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.6461 mle=1.7050 pcon=4.9372 forget=1.0765 orth=0.9275 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.7482 mle=1.8676 pcon=4.9349 forget=1.0241 orth=0.9217 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=8.5418 mle=1.6373 pcon=4.9327 forget=1.0562 orth=0.9156 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=8.4682 mle=1.6057 pcon=4.9306 forget=1.0214 orth=0.9105 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.5356 mle=1.6560 pcon=4.9284 forget=1.0461 orth=0.9051 favg=0.0000 nr=41 nf=41 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.9689 mle=2.0968 pcon=4.9264 forget=1.0462 orth=0.8995 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 9 it 40 total=8.7696 mle=1.9204 pcon=4.9243 forget=1.0306 orth=0.8943 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.5522 mle=1.7325 pcon=4.9223 forget=1.0087 orth=0.8888 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.5105 mle=1.6973 pcon=4.9203 forget=1.0097 orth=0.8832 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=8.2780 mle=1.4692 pcon=4.9185 forget=1.0129 orth=0.8774 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.5301 mle=1.7157 pcon=4.9165 forget=1.0257 orth=0.8722 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.3402 mle=1.5447 pcon=4.9146 forget=1.0143 orth=0.8665 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=8.5013 mle=1.7292 pcon=4.9129 forget=0.9987 orth=0.8605 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 10 it 0 total=8.3484 mle=1.6020 pcon=4.9109 forget=0.9804 orth=0.8550 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=8.2695 mle=1.5255 pcon=4.9091 forget=0.9852 orth=0.8497 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.6081 mle=1.8508 pcon=4.9072 forget=1.0061 orth=0.8440 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.4148 mle=1.6884 pcon=4.9055 forget=0.9827 orth=0.8382 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.5340 mle=1.7908 pcon=4.9038 forget=1.0069 orth=0.8326 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.3792 mle=1.6411 pcon=4.9021 forget=1.0092 orth=0.8268 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.5513 mle=1.8465 pcon=4.9003 forget=0.9833 orth=0.8212 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=8.4446 mle=1.7631 pcon=4.8987 forget=0.9674 orth=0.8153 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 11 it 10 total=8.2857 mle=1.6156 pcon=4.8971 forget=0.9636 orth=0.8095 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.2594 mle=1.5862 pcon=4.8953 forget=0.9742 orth=0.8037 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=8.4084 mle=1.7431 pcon=4.8937 forget=0.9740 orth=0.7975 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=8.3455 mle=1.6860 pcon=4.8921 forget=0.9759 orth=0.7915 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=8.2853 mle=1.6508 pcon=4.8907 forget=0.9586 orth=0.7852 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=8.2549 mle=1.6177 pcon=4.8890 forget=0.9693 orth=0.7789 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.3065 mle=1.6808 pcon=4.8876 forget=0.9656 orth=0.7725 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=8.3843 mle=1.7748 pcon=4.8861 forget=0.9574 orth=0.7661 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 12 it 20 total=8.2409 mle=1.6406 pcon=4.8845 forget=0.9564 orth=0.7595 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=8.1696 mle=1.5699 pcon=4.8829 forget=0.9644 orth=0.7525 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.4411 mle=1.8318 pcon=4.8813 forget=0.9826 orth=0.7454 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.2334 mle=1.6443 pcon=4.8797 forget=0.9709 orth=0.7384 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=8.0893 mle=1.5307 pcon=4.8781 forget=0.9492 orth=0.7313 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=8.2037 mle=1.6206 pcon=4.8766 forget=0.9830 orth=0.7235 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.3163 mle=1.7609 pcon=4.8751 forget=0.9644 orth=0.7158 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.3594 mle=1.8253 pcon=4.8737 forget=0.9524 orth=0.7080 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 13 it 30 total=8.2417 mle=1.7116 pcon=4.8724 forget=0.9574 orth=0.7002 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.4731 mle=1.9309 pcon=4.8710 forget=0.9794 orth=0.6918 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0777 mle=1.5479 pcon=4.8695 forget=0.9771 orth=0.6833 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.4134 mle=1.9156 pcon=4.8681 forget=0.9550 orth=0.6747 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=8.2346 mle=1.7547 pcon=4.8666 forget=0.9473 orth=0.6661 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=8.0118 mle=1.5431 pcon=4.8651 forget=0.9465 orth=0.6571 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
 28%|██▊       | 14/50 [09:03<16:43, 27.87s/it] 30%|███       | 15/50 [09:36<17:01, 29.19s/it] 32%|███▏      | 16/50 [10:07<16:50, 29.73s/it] 34%|███▍      | 17/50 [10:43<17:23, 31.63s/it] 36%|███▌      | 18/50 [11:12<16:28, 30.89s/it] 38%|███▊      | 19/50 [11:37<15:07, 29.29s/it] 40%|████      | 20/50 [12:01<13:46, 27.55s/it][loss] ep 13 it 330 total=8.1933 mle=1.7190 pcon=4.8635 forget=0.9628 orth=0.6479 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=8.0086 mle=1.5562 pcon=4.8622 forget=0.9516 orth=0.6387 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 14 it 40 total=8.1295 mle=1.6809 pcon=4.8608 forget=0.9587 orth=0.6292 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=8.2984 mle=1.8710 pcon=4.8593 forget=0.9485 orth=0.6195 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9795 mle=1.5373 pcon=4.8579 forget=0.9745 orth=0.6098 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=8.1535 mle=1.7561 pcon=4.8565 forget=0.9410 orth=0.5999 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=8.2994 mle=1.9007 pcon=4.8550 forget=0.9539 orth=0.5898 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=8.0152 mle=1.6269 pcon=4.8536 forget=0.9552 orth=0.5796 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=8.0856 mle=1.6905 pcon=4.8523 forget=0.9736 orth=0.5692 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 15 it 0 total=8.1290 mle=1.7319 pcon=4.8508 forget=0.9875 orth=0.5588 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9783 mle=1.6323 pcon=4.8495 forget=0.9480 orth=0.5485 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=8.1398 mle=1.7953 pcon=4.8483 forget=0.9583 orth=0.5379 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0397 mle=1.6920 pcon=4.8469 forget=0.9737 orth=0.5271 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=8.0968 mle=1.7692 pcon=4.8456 forget=0.9657 orth=0.5163 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8437 mle=1.5399 pcon=4.8443 forget=0.9540 orth=0.5055 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.1194 mle=1.8025 pcon=4.8430 forget=0.9793 orth=0.4945 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=8.3020 mle=2.0078 pcon=4.8419 forget=0.9687 orth=0.4836 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 16 it 10 total=8.1005 mle=1.8252 pcon=4.8405 forget=0.9623 orth=0.4726 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=8.0406 mle=1.7679 pcon=4.8391 forget=0.9719 orth=0.4616 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.8136 mle=1.5664 pcon=4.8377 forget=0.9587 orth=0.4508 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.7288 mle=1.4960 pcon=4.8364 forget=0.9566 orth=0.4399 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.9703 mle=1.7379 pcon=4.8351 forget=0.9681 orth=0.4292 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.0359 mle=1.8014 pcon=4.8336 forget=0.9824 orth=0.4186 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.0428 mle=1.8280 pcon=4.8322 forget=0.9747 orth=0.4079 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.7996 mle=1.5788 pcon=4.8311 forget=0.9926 orth=0.3973 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 17 it 20 total=8.1152 mle=1.8908 pcon=4.8299 forget=1.0077 orth=0.3868 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0518 mle=1.8682 pcon=4.8288 forget=0.9784 orth=0.3765 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.8701 mle=1.7082 pcon=4.8276 forget=0.9681 orth=0.3662 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9176 mle=1.7697 pcon=4.8263 forget=0.9654 orth=0.3561 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=7.9040 mle=1.7600 pcon=4.8250 forget=0.9729 orth=0.3461 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=7.7446 mle=1.6188 pcon=4.8238 forget=0.9659 orth=0.3362 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8519 mle=1.7386 pcon=4.8225 forget=0.9643 orth=0.3265 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9276 mle=1.7986 pcon=4.8212 forget=0.9906 orth=0.3171 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 18 it 30 total=7.6101 mle=1.5001 pcon=4.8201 forget=0.9821 orth=0.3079 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0471 mle=1.9401 pcon=4.8187 forget=0.9895 orth=0.2987 favg=0.0000 nr=41 nf=41 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0347 mle=1.9371 pcon=4.8177 forget=0.9902 orth=0.2897 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9560 mle=1.8429 pcon=4.8165 forget=1.0156 orth=0.2810 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.7354 mle=1.6215 pcon=4.8153 forget=1.0261 orth=0.2725 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=8.0354 mle=1.9613 pcon=4.8142 forget=0.9957 orth=0.2641 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.7279 mle=1.6636 pcon=4.8129 forget=0.9955 orth=0.2559 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.7680 mle=1.7159 pcon=4.8118 forget=0.9925 orth=0.2479 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 19 it 40 total=7.8316 mle=1.7935 pcon=4.8106 forget=0.9873 orth=0.2402 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.6867 mle=1.6491 pcon=4.8094 forget=0.9955 orth=0.2327 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7204 mle=1.6807 pcon=4.8082 forget=1.0062 orth=0.2254 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.6305 mle=1.6105 pcon=4.8070 forget=0.9948 orth=0.2183 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8812 mle=1.8535 pcon=4.8057 forget=1.0106 orth=0.2114 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.5988 mle=1.5699 pcon=4.8047 forget=1.0196 orth=0.2047 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.6938 mle=1.6931 pcon=4.8036 forget=0.9989 orth=0.1982 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 20 it 0 total=7.5683 mle=1.5555 pcon=4.8023 forget=1.0185 orth=0.1920 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.7164 mle=1.7181 pcon=4.8012 forget=1.0112 orth=0.1859 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.6991 mle=1.6797 pcon=4.8000 forget=1.0394 orth=0.1800 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=7.5511 mle=1.5614 pcon=4.7989 forget=1.0164 orth=0.1744 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.6653 mle=1.6735 pcon=4.7978 forget=1.0251 orth=0.1689 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
 42%|████▏     | 21/50 [12:25<12:51, 26.61s/it] 44%|████▍     | 22/50 [12:53<12:31, 26.85s/it] 46%|████▌     | 23/50 [13:17<11:46, 26.17s/it] 48%|████▊     | 24/50 [13:42<11:07, 25.66s/it] 50%|█████     | 25/50 [14:07<10:37, 25.49s/it] 52%|█████▏    | 26/50 [14:36<10:39, 26.63s/it] 54%|█████▍    | 27/50 [15:08<10:46, 28.12s/it][loss] ep 20 it 250 total=7.7360 mle=1.7491 pcon=4.7967 forget=1.0266 orth=0.1636 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.6777 mle=1.6972 pcon=4.7956 forget=1.0264 orth=0.1585 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.7112 mle=1.7311 pcon=4.7943 forget=1.0322 orth=0.1536 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 21 it 10 total=7.5050 mle=1.5180 pcon=4.7931 forget=1.0450 orth=0.1489 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.6444 mle=1.6710 pcon=4.7920 forget=1.0370 orth=0.1443 favg=0.0000 nr=40 nf=40 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7575 mle=1.7478 pcon=4.7908 forget=1.0789 orth=0.1399 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.4448 mle=1.4840 pcon=4.7897 forget=1.0355 orth=0.1356 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.6199 mle=1.6606 pcon=4.7886 forget=1.0390 orth=0.1317 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=7.9118 mle=1.9407 pcon=4.7874 forget=1.0558 orth=0.1279 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.7450 mle=1.7909 pcon=4.7862 forget=1.0437 orth=0.1241 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.7323 mle=1.7842 pcon=4.7850 forget=1.0425 orth=0.1206 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 22 it 20 total=7.5827 mle=1.6332 pcon=4.7837 forget=1.0487 orth=0.1172 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.7599 mle=1.8134 pcon=4.7825 forget=1.0500 orth=0.1140 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.6320 mle=1.6778 pcon=4.7813 forget=1.0620 orth=0.1109 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.7399 mle=1.7649 pcon=4.7802 forget=1.0868 orth=0.1079 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.6821 mle=1.7249 pcon=4.7792 forget=1.0730 orth=0.1050 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.5515 mle=1.5989 pcon=4.7781 forget=1.0723 orth=0.1022 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.4934 mle=1.5443 pcon=4.7769 forget=1.0726 orth=0.0995 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.5220 mle=1.5466 pcon=4.7756 forget=1.1028 orth=0.0970 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 23 it 30 total=7.8994 mle=1.9462 pcon=4.7745 forget=1.0842 orth=0.0946 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.5790 mle=1.6367 pcon=4.7733 forget=1.0768 orth=0.0922 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.8831 mle=1.8950 pcon=4.7721 forget=1.1259 orth=0.0900 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.6904 mle=1.7271 pcon=4.7709 forget=1.1045 orth=0.0879 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.5635 mle=1.6083 pcon=4.7698 forget=1.0997 orth=0.0859 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.6343 mle=1.6804 pcon=4.7685 forget=1.1015 orth=0.0839 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.7351 mle=1.7810 pcon=4.7672 forget=1.1048 orth=0.0820 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.5410 mle=1.5915 pcon=4.7661 forget=1.1032 orth=0.0802 favg=0.0000 nr=43 nf=43 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stack/stage2
[loss] ep 24 it 40 total=7.9285 mle=1.9654 pcon=4.7650 forget=1.1197 orth=0.0785 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.8144 mle=1.8572 pcon=4.7639 forget=1.1164 orth=0.0768 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.6630 mle=1.7104 pcon=4.7629 forget=1.1145 orth=0.0753 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.7483 mle=1.7788 pcon=4.7618 forget=1.1339 orth=0.0738 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.6454 mle=1.6899 pcon=4.7608 forget=1.1225 orth=0.0723 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.6848 mle=1.7189 pcon=4.7596 forget=1.1355 orth=0.0709 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.6729 mle=1.7152 pcon=4.7586 forget=1.1296 orth=0.0695 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 25 it 0 total=7.7255 mle=1.7637 pcon=4.7576 forget=1.1359 orth=0.0683 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.7053 mle=1.7304 pcon=4.7565 forget=1.1513 orth=0.0671 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.6013 mle=1.6273 pcon=4.7554 forget=1.1527 orth=0.0659 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.8311 mle=1.8644 pcon=4.7543 forget=1.1477 orth=0.0647 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.8569 mle=1.8851 pcon=4.7532 forget=1.1549 orth=0.0637 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.7464 mle=1.7679 pcon=4.7522 forget=1.1636 orth=0.0626 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.6532 mle=1.6804 pcon=4.7512 forget=1.1601 orth=0.0616 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.7456 mle=1.7761 pcon=4.7502 forget=1.1586 orth=0.0606 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.7533 mle=1.7804 pcon=4.7493 forget=1.1639 orth=0.0597 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.8149 mle=1.8317 pcon=4.7482 forget=1.1763 orth=0.0588 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.7716 mle=1.7868 pcon=4.7472 forget=1.1797 orth=0.0579 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.5817 mle=1.5955 pcon=4.7463 forget=1.1829 orth=0.0570 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.8727 mle=1.8824 pcon=4.7454 forget=1.1887 orth=0.0562 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.8206 mle=1.8108 pcon=4.7447 forget=1.2097 orth=0.0555 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.9600 mle=1.9489 pcon=4.7437 forget=1.2127 orth=0.0547 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.8197 mle=1.8244 pcon=4.7428 forget=1.1985 orth=0.0540 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=7.6211 mle=1.6324 pcon=4.7420 forget=1.1935 orth=0.0533 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.6300 mle=1.6262 pcon=4.7410 forget=1.2102 orth=0.0526 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.7189 mle=1.7169 pcon=4.7402 forget=1.2098 orth=0.0520 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.6837 mle=1.6858 pcon=4.7393 forget=1.2073 orth=0.0513 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.7311 mle=1.7224 pcon=4.7384 forget=1.2196 orth=0.0507 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.6944 mle=1.6623 pcon=4.7375 forget=1.2444 orth=0.0501 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.7024 mle=1.6927 pcon=4.7367 forget=1.2235 orth=0.0496 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
 56%|█████▌    | 28/50 [15:36<10:17, 28.05s/it] 58%|█████▊    | 29/50 [16:01<09:35, 27.41s/it] 60%|██████    | 30/50 [16:26<08:49, 26.48s/it] 62%|██████▏   | 31/50 [16:46<07:44, 24.47s/it] 64%|██████▍   | 32/50 [17:03<06:40, 22.27s/it] 66%|██████▌   | 33/50 [17:22<06:00, 21.23s/it] 68%|██████▊   | 34/50 [17:51<06:20, 23.80s/it] 70%|███████   | 35/50 [18:35<07:24, 29.65s/it][loss] ep 27 it 370 total=7.7615 mle=1.7526 pcon=4.7359 forget=1.2240 orth=0.0490 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.5719 mle=1.5648 pcon=4.7350 forget=1.2236 orth=0.0485 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.9465 mle=1.9221 pcon=4.7343 forget=1.2421 orth=0.0480 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.5818 mle=1.5487 pcon=4.7335 forget=1.2521 orth=0.0474 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.5650 mle=1.5425 pcon=4.7326 forget=1.2429 orth=0.0470 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.8290 mle=1.8080 pcon=4.7318 forget=1.2428 orth=0.0465 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7766 mle=1.7404 pcon=4.7310 forget=1.2591 orth=0.0461 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.8714 mle=1.8406 pcon=4.7301 forget=1.2552 orth=0.0456 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7378 mle=1.7068 pcon=4.7292 forget=1.2566 orth=0.0452 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=7.6988 mle=1.6455 pcon=4.7284 forget=1.2801 orth=0.0448 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6449 mle=1.6129 pcon=4.7276 forget=1.2601 orth=0.0444 favg=0.0000 nr=40 nf=40 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.5965 mle=1.5553 pcon=4.7268 forget=1.2703 orth=0.0440 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=8.0360 mle=1.9975 pcon=4.7259 forget=1.2689 orth=0.0436 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.8028 mle=1.7583 pcon=4.7252 forget=1.2760 orth=0.0432 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.7833 mle=1.7354 pcon=4.7244 forget=1.2807 orth=0.0429 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7828 mle=1.7384 pcon=4.7236 forget=1.2782 orth=0.0425 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.7152 mle=1.6609 pcon=4.7229 forget=1.2892 orth=0.0422 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.6859 mle=1.6301 pcon=4.7220 forget=1.2918 orth=0.0419 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.8243 mle=1.7560 pcon=4.7213 forget=1.3055 orth=0.0416 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.7297 mle=1.6579 pcon=4.7207 forget=1.3099 orth=0.0412 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.9308 mle=1.8597 pcon=4.7199 forget=1.3103 orth=0.0410 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.9514 mle=1.8884 pcon=4.7192 forget=1.3031 orth=0.0407 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=8.0479 mle=1.9753 pcon=4.7185 forget=1.3137 orth=0.0404 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.8836 mle=1.8124 pcon=4.7178 forget=1.3133 orth=0.0401 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.8393 mle=1.7492 pcon=4.7171 forget=1.3332 orth=0.0398 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.7454 mle=1.6626 pcon=4.7163 forget=1.3268 orth=0.0396 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=7.9989 mle=1.8997 pcon=4.7157 forget=1.3442 orth=0.0393 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.9119 mle=1.8280 pcon=4.7150 forget=1.3299 orth=0.0391 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.9954 mle=1.8883 pcon=4.7144 forget=1.3539 orth=0.0388 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.7711 mle=1.6843 pcon=4.7136 forget=1.3347 orth=0.0386 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=7.7666 mle=1.6795 pcon=4.7128 forget=1.3360 orth=0.0383 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=7.7819 mle=1.6829 pcon=4.7123 forget=1.3486 orth=0.0381 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.6822 mle=1.5900 pcon=4.7117 forget=1.3427 orth=0.0379 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.7118 mle=1.5964 pcon=4.7111 forget=1.3667 orth=0.0377 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=7.6877 mle=1.5849 pcon=4.7105 forget=1.3549 orth=0.0375 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.7670 mle=1.6661 pcon=4.7098 forget=1.3538 orth=0.0373 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.6499 mle=1.5404 pcon=4.7092 forget=1.3632 orth=0.0371 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=7.6222 mle=1.5140 pcon=4.7085 forget=1.3627 orth=0.0369 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=7.6950 mle=1.5735 pcon=4.7079 forget=1.3769 orth=0.0367 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.7380 mle=1.6315 pcon=4.7074 forget=1.3626 orth=0.0365 favg=0.0000 nr=41 nf=41 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.8135 mle=1.6987 pcon=4.7068 forget=1.3717 orth=0.0363 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=8.0062 mle=1.8921 pcon=4.7062 forget=1.3718 orth=0.0361 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.8193 mle=1.7034 pcon=4.7056 forget=1.3744 orth=0.0360 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.7899 mle=1.6579 pcon=4.7050 forget=1.3912 orth=0.0358 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=8.1294 mle=1.9987 pcon=4.7046 forget=1.3905 orth=0.0356 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=7.6530 mle=1.5317 pcon=4.7040 forget=1.3818 orth=0.0355 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=8.0423 mle=1.9188 pcon=4.7034 forget=1.3848 orth=0.0353 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=7.6438 mle=1.5156 pcon=4.7028 forget=1.3902 orth=0.0352 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=7.9011 mle=1.7684 pcon=4.7022 forget=1.3955 orth=0.0350 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=7.8351 mle=1.7001 pcon=4.7017 forget=1.3985 orth=0.0349 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=7.7576 mle=1.6220 pcon=4.7012 forget=1.3997 orth=0.0347 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.8743 mle=1.7409 pcon=4.7007 forget=1.3981 orth=0.0346 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=7.8761 mle=1.7379 pcon=4.7002 forget=1.4036 orth=0.0345 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=7.8178 mle=1.6802 pcon=4.6997 forget=1.4036 orth=0.0343 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=7.7892 mle=1.6456 pcon=4.6992 forget=1.4101 orth=0.0342 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=7.6801 mle=1.5388 pcon=4.6987 forget=1.4084 orth=0.0341 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=7.8717 mle=1.7118 pcon=4.6982 forget=1.4277 orth=0.0339 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=8.1540 mle=2.0069 pcon=4.6978 forget=1.4154 orth=0.0338 favg=0.0000 nr=21 nf=21 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=7.7368 mle=1.5853 pcon=4.6972 forget=1.4206 orth=0.0337 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=7.7400 mle=1.5842 pcon=4.6969 forget=1.4253 orth=0.0336 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=8.0115 mle=1.8632 pcon=4.6965 forget=1.4184 orth=0.0335 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=7.9369 mle=1.7853 pcon=4.6960 forget=1.4222 orth=0.0334 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
 72%|███████▏  | 36/50 [19:20<08:03, 34.50s/it] 74%|███████▍  | 37/50 [20:04<08:04, 37.28s/it] 76%|███████▌  | 38/50 [20:35<07:02, 35.23s/it] 78%|███████▊  | 39/50 [21:00<05:54, 32.25s/it] 80%|████████  | 40/50 [21:33<05:25, 32.57s/it] 82%|████████▏ | 41/50 [22:08<04:59, 33.26s/it] 84%|████████▍ | 42/50 [22:45<04:34, 34.30s/it] 86%|████████▌ | 43/50 [23:26<04:13, 36.24s/it][loss] ep 35 it 350 total=7.9127 mle=1.7441 pcon=4.6956 forget=1.4398 orth=0.0333 favg=0.0000 nr=43 nf=43 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=7.8236 mle=1.6612 pcon=4.6951 forget=1.4342 orth=0.0332 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.8410 mle=1.6780 pcon=4.6946 forget=1.4353 orth=0.0331 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=8.0198 mle=1.8630 pcon=4.6942 forget=1.4297 orth=0.0330 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.8439 mle=1.6867 pcon=4.6937 forget=1.4306 orth=0.0329 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=8.0821 mle=1.9190 pcon=4.6933 forget=1.4370 orth=0.0328 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=8.2022 mle=2.0404 pcon=4.6929 forget=1.4362 orth=0.0327 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=7.7799 mle=1.6137 pcon=4.6925 forget=1.4411 orth=0.0326 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=7.8347 mle=1.6616 pcon=4.6922 forget=1.4485 orth=0.0325 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=7.9952 mle=1.8314 pcon=4.6918 forget=1.4395 orth=0.0324 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=8.1533 mle=1.9775 pcon=4.6914 forget=1.4521 orth=0.0324 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=7.8184 mle=1.6467 pcon=4.6909 forget=1.4485 orth=0.0323 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=7.7165 mle=1.5375 pcon=4.6905 forget=1.4564 orth=0.0322 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=7.7829 mle=1.5975 pcon=4.6901 forget=1.4632 orth=0.0321 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=7.9398 mle=1.7557 pcon=4.6897 forget=1.4624 orth=0.0320 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.9583 mle=1.7874 pcon=4.6894 forget=1.4495 orth=0.0320 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.9251 mle=1.7328 pcon=4.6890 forget=1.4713 orth=0.0319 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=7.9705 mle=1.7953 pcon=4.6886 forget=1.4548 orth=0.0318 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=7.8559 mle=1.6784 pcon=4.6883 forget=1.4575 orth=0.0317 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=7.7644 mle=1.5822 pcon=4.6879 forget=1.4627 orth=0.0317 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=7.8151 mle=1.6157 pcon=4.6874 forget=1.4804 orth=0.0316 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=7.7751 mle=1.5889 pcon=4.6871 forget=1.4676 orth=0.0315 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=8.2808 mle=2.0902 pcon=4.6867 forget=1.4724 orth=0.0315 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=8.0294 mle=1.8422 pcon=4.6864 forget=1.4694 orth=0.0314 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=7.9996 mle=1.8024 pcon=4.6860 forget=1.4799 orth=0.0314 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=7.8560 mle=1.6590 pcon=4.6856 forget=1.4800 orth=0.0313 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=8.0126 mle=1.8238 pcon=4.6853 forget=1.4723 orth=0.0312 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=8.0173 mle=1.8261 pcon=4.6849 forget=1.4750 orth=0.0312 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=7.7936 mle=1.6096 pcon=4.6846 forget=1.4683 orth=0.0311 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=7.8370 mle=1.6467 pcon=4.6843 forget=1.4749 orth=0.0311 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=7.7929 mle=1.6006 pcon=4.6839 forget=1.4773 orth=0.0310 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=8.1340 mle=1.9410 pcon=4.6837 forget=1.4783 orth=0.0310 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=7.8684 mle=1.6745 pcon=4.6834 forget=1.4797 orth=0.0309 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=8.0705 mle=1.8664 pcon=4.6830 forget=1.4902 orth=0.0309 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=8.0085 mle=1.8170 pcon=4.6827 forget=1.4780 orth=0.0308 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=7.8737 mle=1.6769 pcon=4.6824 forget=1.4836 orth=0.0308 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=8.0096 mle=1.8145 pcon=4.6821 forget=1.4822 orth=0.0307 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=7.8639 mle=1.6637 pcon=4.6818 forget=1.4877 orth=0.0307 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=8.1324 mle=1.9320 pcon=4.6815 forget=1.4881 orth=0.0307 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=7.9057 mle=1.7101 pcon=4.6812 forget=1.4837 orth=0.0306 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=7.9053 mle=1.7066 pcon=4.6809 forget=1.4872 orth=0.0306 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=7.9766 mle=1.7739 pcon=4.6806 forget=1.4916 orth=0.0306 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=7.9681 mle=1.7646 pcon=4.6803 forget=1.4927 orth=0.0305 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=7.7817 mle=1.5764 pcon=4.6801 forget=1.4948 orth=0.0305 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=7.9757 mle=1.7712 pcon=4.6798 forget=1.4943 orth=0.0304 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=7.8736 mle=1.6652 pcon=4.6796 forget=1.4984 orth=0.0304 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=7.8177 mle=1.6130 pcon=4.6794 forget=1.4948 orth=0.0304 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=8.0247 mle=1.8151 pcon=4.6793 forget=1.5000 orth=0.0304 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=7.8269 mle=1.6217 pcon=4.6790 forget=1.4959 orth=0.0303 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=8.0990 mle=1.8928 pcon=4.6787 forget=1.4972 orth=0.0303 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=7.8281 mle=1.6152 pcon=4.6784 forget=1.5042 orth=0.0303 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=8.2327 mle=2.0240 pcon=4.6781 forget=1.5003 orth=0.0302 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=7.8105 mle=1.6012 pcon=4.6778 forget=1.5012 orth=0.0302 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.0377 mle=1.8230 pcon=4.6775 forget=1.5070 orth=0.0302 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=8.1856 mle=1.9678 pcon=4.6773 forget=1.5104 orth=0.0302 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=7.8680 mle=1.6533 pcon=4.6770 forget=1.5076 orth=0.0301 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=8.0846 mle=1.8605 pcon=4.6768 forget=1.5172 orth=0.0301 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=8.3308 mle=2.1125 pcon=4.6765 forget=1.5117 orth=0.0301 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=8.1610 mle=1.9321 pcon=4.6762 forget=1.5226 orth=0.0301 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=7.9181 mle=1.6895 pcon=4.6760 forget=1.5226 orth=0.0301 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=7.8422 mle=1.6189 pcon=4.6758 forget=1.5174 orth=0.0300 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=7.8618 mle=1.6428 pcon=4.6756 forget=1.5134 orth=0.0300 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
 88%|████████▊ | 44/50 [24:02<03:37, 36.22s/it] 90%|█████████ | 45/50 [24:30<02:49, 33.96s/it] 92%|█████████▏| 46/50 [25:05<02:16, 34.06s/it] 94%|█████████▍| 47/50 [25:38<01:41, 33.92s/it] 96%|█████████▌| 48/50 [26:15<01:09, 34.61s/it] 98%|█████████▊| 49/50 [26:50<00:34, 34.80s/it]100%|██████████| 50/50 [27:28<00:00, 35.80s/it]100%|██████████| 50/50 [27:28<00:00, 32.97s/it]
[loss] ep 43 it 330 total=8.3185 mle=2.0743 pcon=4.6753 forget=1.5389 orth=0.0300 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=8.0616 mle=1.8396 pcon=4.6751 forget=1.5169 orth=0.0300 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=8.0002 mle=1.7757 pcon=4.6749 forget=1.5197 orth=0.0300 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=7.8749 mle=1.6460 pcon=4.6746 forget=1.5243 orth=0.0300 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=7.9562 mle=1.7231 pcon=4.6745 forget=1.5286 orth=0.0299 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=8.0392 mle=1.8159 pcon=4.6743 forget=1.5192 orth=0.0299 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=7.9591 mle=1.7119 pcon=4.6740 forget=1.5433 orth=0.0299 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=8.1398 mle=1.9132 pcon=4.6738 forget=1.5229 orth=0.0299 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=8.0373 mle=1.7915 pcon=4.6736 forget=1.5423 orth=0.0299 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=7.7856 mle=1.5512 pcon=4.6734 forget=1.5311 orth=0.0299 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=7.8750 mle=1.6439 pcon=4.6732 forget=1.5281 orth=0.0299 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=8.0802 mle=1.8474 pcon=4.6731 forget=1.5299 orth=0.0298 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=8.1623 mle=1.9200 pcon=4.6729 forget=1.5396 orth=0.0298 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=8.1843 mle=1.9464 pcon=4.6727 forget=1.5354 orth=0.0298 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=7.8656 mle=1.6162 pcon=4.6724 forget=1.5471 orth=0.0298 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=7.7341 mle=1.4885 pcon=4.6722 forget=1.5436 orth=0.0298 favg=0.0000 nr=40 nf=40 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=7.8755 mle=1.6291 pcon=4.6721 forget=1.5446 orth=0.0298 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=7.8053 mle=1.5718 pcon=4.6720 forget=1.5317 orth=0.0298 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=8.0157 mle=1.7825 pcon=4.6718 forget=1.5316 orth=0.0298 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=8.0201 mle=1.7807 pcon=4.6717 forget=1.5379 orth=0.0298 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=8.0774 mle=1.8364 pcon=4.6715 forget=1.5397 orth=0.0298 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=7.9836 mle=1.7381 pcon=4.6713 forget=1.5444 orth=0.0298 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=8.0488 mle=1.8011 pcon=4.6711 forget=1.5468 orth=0.0298 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=8.0496 mle=1.8043 pcon=4.6709 forget=1.5446 orth=0.0298 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=8.1033 mle=1.8621 pcon=4.6708 forget=1.5406 orth=0.0298 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=7.9181 mle=1.6782 pcon=4.6707 forget=1.5394 orth=0.0297 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=8.0402 mle=1.7846 pcon=4.6705 forget=1.5554 orth=0.0297 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=7.8367 mle=1.5920 pcon=4.6703 forget=1.5447 orth=0.0297 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=8.3139 mle=2.0544 pcon=4.6702 forget=1.5596 orth=0.0297 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=7.7746 mle=1.5143 pcon=4.6700 forget=1.5605 orth=0.0297 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=8.1052 mle=1.8381 pcon=4.6700 forget=1.5674 orth=0.0297 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=8.0043 mle=1.7550 pcon=4.6698 forget=1.5498 orth=0.0297 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=7.9811 mle=1.7312 pcon=4.6696 forget=1.5506 orth=0.0297 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=8.0200 mle=1.7532 pcon=4.6695 forget=1.5675 orth=0.0297 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=8.1080 mle=1.8592 pcon=4.6694 forget=1.5497 orth=0.0297 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=8.0307 mle=1.7736 pcon=4.6693 forget=1.5581 orth=0.0297 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=7.9307 mle=1.6729 pcon=4.6692 forget=1.5589 orth=0.0297 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=7.9160 mle=1.6597 pcon=4.6690 forget=1.5577 orth=0.0297 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=7.9192 mle=1.6676 pcon=4.6689 forget=1.5530 orth=0.0297 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=7.8424 mle=1.5777 pcon=4.6688 forget=1.5661 orth=0.0297 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=7.8314 mle=1.5613 pcon=4.6687 forget=1.5716 orth=0.0297 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=7.8368 mle=1.5770 pcon=4.6686 forget=1.5615 orth=0.0297 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=7.9979 mle=1.7295 pcon=4.6684 forget=1.5703 orth=0.0297 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=7.9836 mle=1.7178 pcon=4.6682 forget=1.5679 orth=0.0297 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=7.8893 mle=1.6364 pcon=4.6681 forget=1.5552 orth=0.0297 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=8.1540 mle=1.8893 pcon=4.6679 forget=1.5670 orth=0.0297 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=8.2551 mle=1.9845 pcon=4.6679 forget=1.5730 orth=0.0297 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=8.0408 mle=1.7649 pcon=4.6678 forget=1.5784 orth=0.0297 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc1: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<04:46,  1.36it/s]  2%|▏         | 8/391 [00:00<00:30, 12.50it/s]  4%|▍         | 17/391 [00:00<00:13, 26.95it/s]  7%|▋         | 26/391 [00:01<00:09, 39.22it/s]  9%|▉         | 35/391 [00:01<00:07, 50.46it/s] 11%|█         | 43/391 [00:01<00:06, 57.00it/s] 13%|█▎        | 52/391 [00:01<00:05, 65.17it/s] 16%|█▌        | 61/391 [00:01<00:04, 69.67it/s] 18%|█▊        | 70/391 [00:01<00:04, 72.93it/s] 20%|██        | 79/391 [00:01<00:04, 75.43it/s] 23%|██▎       | 88/391 [00:01<00:03, 77.53it/s] 25%|██▍       | 97/391 [00:01<00:03, 78.99it/s] 27%|██▋       | 106/391 [00:02<00:03, 79.79it/s] 29%|██▉       | 115/391 [00:02<00:03, 81.45it/s] 32%|███▏      | 124/391 [00:02<00:03, 82.06it/s] 34%|███▍      | 133/391 [00:02<00:03, 81.12it/s] 36%|███▋      | 142/391 [00:02<00:03, 79.92it/s] 39%|███▊      | 151/391 [00:02<00:02, 80.82it/s] 41%|████      | 160/391 [00:02<00:02, 79.89it/s] 43%|████▎     | 169/391 [00:02<00:02, 80.03it/s] 46%|████▌     | 178/391 [00:02<00:02, 81.82it/s] 48%|████▊     | 187/391 [00:03<00:02, 83.44it/s] 50%|█████     | 196/391 [00:03<00:02, 82.85it/s] 52%|█████▏    | 205/391 [00:03<00:02, 82.22it/s] 55%|█████▍    | 214/391 [00:03<00:02, 82.57it/s] 57%|█████▋    | 223/391 [00:03<00:02, 82.05it/s] 59%|█████▉    | 232/391 [00:03<00:01, 82.87it/s] 62%|██████▏   | 241/391 [00:03<00:01, 84.15it/s] 64%|██████▍   | 250/391 [00:03<00:01, 82.19it/s] 66%|██████▌   | 259/391 [00:03<00:01, 77.11it/s] 69%|██████▊   | 268/391 [00:04<00:01, 78.89it/s] 71%|███████   | 277/391 [00:04<00:01, 80.16it/s] 73%|███████▎  | 286/391 [00:04<00:01, 81.65it/s] 75%|███████▌  | 295/391 [00:04<00:01, 82.99it/s] 78%|███████▊  | 304/391 [00:04<00:01, 81.85it/s] 80%|████████  | 313/391 [00:04<00:00, 80.04it/s] 82%|████████▏ | 322/391 [00:04<00:00, 78.81it/s] 84%|████████▍ | 330/391 [00:04<00:00, 78.27it/s] 86%|████████▋ | 338/391 [00:04<00:00, 76.79it/s] 88%|████████▊ | 346/391 [00:05<00:00, 74.27it/s] 91%|█████████ | 354/391 [00:05<00:00, 71.29it/s] 93%|█████████▎| 362/391 [00:05<00:00, 72.60it/s] 95%|█████████▍| 371/391 [00:05<00:00, 77.21it/s] 97%|█████████▋| 381/391 [00:05<00:00, 81.17it/s]100%|█████████▉| 390/391 [00:05<00:00, 83.46it/s]100%|██████████| 391/391 [00:05<00:00, 70.09it/s]
50000 images processed, 5.7081074714660645 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:57,  1.36it/s]  9%|▉         | 7/79 [00:00<00:06, 10.80it/s] 19%|█▉        | 15/79 [00:00<00:02, 23.67it/s] 29%|██▉       | 23/79 [00:01<00:01, 35.32it/s] 41%|████      | 32/79 [00:01<00:01, 46.57it/s] 52%|█████▏    | 41/79 [00:01<00:00, 56.52it/s] 63%|██████▎   | 50/79 [00:01<00:00, 64.48it/s] 75%|███████▍  | 59/79 [00:01<00:00, 70.88it/s] 86%|████████▌ | 68/79 [00:01<00:00, 74.96it/s] 97%|█████████▋| 77/79 [00:01<00:00, 78.66it/s]100%|██████████| 79/79 [00:02<00:00, 28.36it/s]
10000 images processed, 2.811457395553589 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc1/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:46,  1.22it/s]  3%|▎         | 6/204 [00:00<00:23,  8.42it/s]  7%|▋         | 15/204 [00:01<00:08, 22.24it/s] 11%|█▏        | 23/204 [00:01<00:05, 33.08it/s] 15%|█▌        | 31/204 [00:01<00:04, 42.62it/s] 19%|█▉        | 39/204 [00:01<00:03, 50.90it/s] 24%|██▎       | 48/204 [00:01<00:02, 59.37it/s] 28%|██▊       | 57/204 [00:01<00:02, 66.62it/s] 32%|███▏      | 66/204 [00:01<00:01, 70.51it/s] 36%|███▋      | 74/204 [00:01<00:01, 72.74it/s] 40%|████      | 82/204 [00:01<00:01, 73.69it/s] 45%|████▍     | 91/204 [00:01<00:01, 76.58it/s] 49%|████▉     | 100/204 [00:02<00:01, 79.14it/s] 53%|█████▎    | 109/204 [00:02<00:01, 80.96it/s] 58%|█████▊    | 118/204 [00:02<00:01, 80.12it/s] 62%|██████▏   | 127/204 [00:02<00:00, 81.44it/s] 67%|██████▋   | 136/204 [00:02<00:00, 79.39it/s] 71%|███████   | 145/204 [00:02<00:00, 77.00it/s] 75%|███████▌  | 154/204 [00:02<00:00, 78.29it/s] 80%|███████▉  | 163/204 [00:02<00:00, 79.26it/s] 84%|████████▍ | 172/204 [00:02<00:00, 80.37it/s] 89%|████████▊ | 181/204 [00:03<00:00, 82.03it/s] 93%|█████████▎| 190/204 [00:03<00:00, 83.92it/s] 98%|█████████▊| 199/204 [00:03<00:00, 85.01it/s]100%|██████████| 204/204 [00:03<00:00, 60.60it/s]
26032 images processed, 3.4266676902770996 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:11,  1.09it/s] 10%|█         | 8/79 [00:01<00:06, 10.27it/s] 20%|██        | 16/79 [00:01<00:02, 21.10it/s] 32%|███▏      | 25/79 [00:01<00:01, 33.14it/s] 43%|████▎     | 34/79 [00:01<00:01, 43.72it/s] 53%|█████▎    | 42/79 [00:01<00:00, 46.44it/s] 65%|██████▍   | 51/79 [00:01<00:00, 54.68it/s] 76%|███████▌  | 60/79 [00:01<00:00, 61.13it/s] 87%|████████▋ | 69/79 [00:01<00:00, 66.94it/s] 99%|█████████▊| 78/79 [00:01<00:00, 70.87it/s]100%|██████████| 79/79 [00:01<00:00, 40.37it/s]
10000 images processed, 1.9969570636749268 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:04,  1.21it/s]  6%|▋         | 5/79 [00:00<00:10,  6.80it/s] 18%|█▊        | 14/79 [00:01<00:03, 20.94it/s] 28%|██▊       | 22/79 [00:01<00:01, 31.98it/s] 39%|███▉      | 31/79 [00:01<00:01, 43.51it/s] 49%|████▉     | 39/79 [00:01<00:00, 51.17it/s] 59%|█████▉    | 47/79 [00:01<00:00, 57.98it/s] 71%|███████   | 56/79 [00:01<00:00, 64.60it/s] 82%|████████▏ | 65/79 [00:01<00:00, 69.63it/s] 94%|█████████▎| 74/79 [00:01<00:00, 74.75it/s]100%|██████████| 79/79 [00:01<00:00, 42.89it/s]
10000 images processed, 1.871680498123169 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:50,  1.36it/s] 11%|█▏        | 8/70 [00:00<00:05, 12.39it/s] 24%|██▍       | 17/70 [00:00<00:02, 26.48it/s] 37%|███▋      | 26/70 [00:01<00:01, 38.84it/s] 49%|████▊     | 34/70 [00:01<00:00, 46.82it/s] 61%|██████▏   | 43/70 [00:01<00:00, 55.72it/s] 74%|███████▍  | 52/70 [00:01<00:00, 63.98it/s] 87%|████████▋ | 61/70 [00:01<00:00, 69.98it/s]100%|██████████| 70/70 [00:01<00:00, 74.26it/s]100%|██████████| 70/70 [00:01<00:00, 43.86it/s]
8925 images processed, 1.6255483627319336 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:05,  1.50s/it] 13%|█▎        | 6/45 [00:01<00:07,  4.94it/s] 33%|███▎      | 15/45 [00:01<00:02, 14.27it/s] 47%|████▋     | 21/45 [00:02<00:01, 12.96it/s] 58%|█████▊    | 26/45 [00:02<00:01, 16.97it/s] 73%|███████▎  | 33/45 [00:02<00:00, 15.16it/s] 84%|████████▍ | 38/45 [00:02<00:00, 18.83it/s]100%|██████████| 45/45 [00:03<00:00, 14.69it/s]
5640 images processed, 3.092437267303467 seconds used

22.4354829788208
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.74  99.29
places365     74.73  79.11
LSUN          20.51  95.38
iSUN          78.34  79.48
dtd           43.60  90.14
AVG           43.98  88.68
Retain-Acc: 0.7087
Forget-as-OOD (retain known vs forget novel):
  FPR: 77.80 AUROC: 84.40 AUIN: 99.01
30.67442488670349
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc1_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc2: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:52,  2.26it/s]  3%|▎         | 10/391 [00:00<00:16, 23.67it/s]  5%|▍         | 19/391 [00:00<00:09, 39.99it/s]  7%|▋         | 27/391 [00:00<00:07, 50.36it/s]  9%|▉         | 36/391 [00:00<00:05, 59.80it/s] 12%|█▏        | 45/391 [00:00<00:05, 67.86it/s] 14%|█▍        | 54/391 [00:01<00:04, 73.76it/s] 16%|█▌        | 63/391 [00:01<00:04, 78.28it/s] 18%|█▊        | 72/391 [00:01<00:03, 81.18it/s] 21%|██        | 81/391 [00:01<00:03, 83.20it/s] 23%|██▎       | 90/391 [00:01<00:03, 84.59it/s] 25%|██▌       | 99/391 [00:01<00:03, 84.42it/s] 28%|██▊       | 108/391 [00:01<00:03, 85.76it/s] 30%|██▉       | 117/391 [00:01<00:03, 86.82it/s] 32%|███▏      | 126/391 [00:01<00:03, 87.51it/s] 35%|███▍      | 135/391 [00:01<00:02, 87.74it/s] 37%|███▋      | 144/391 [00:02<00:02, 88.09it/s] 39%|███▉      | 153/391 [00:02<00:02, 88.32it/s] 41%|████▏     | 162/391 [00:02<00:02, 88.61it/s] 44%|████▎     | 171/391 [00:02<00:02, 88.52it/s] 46%|████▌     | 180/391 [00:02<00:02, 88.60it/s] 48%|████▊     | 189/391 [00:02<00:02, 88.74it/s] 51%|█████     | 198/391 [00:02<00:02, 88.60it/s] 53%|█████▎    | 207/391 [00:02<00:02, 88.73it/s] 55%|█████▌    | 216/391 [00:02<00:01, 88.50it/s] 58%|█████▊    | 225/391 [00:02<00:01, 88.64it/s] 60%|█████▉    | 234/391 [00:03<00:01, 88.39it/s] 62%|██████▏   | 243/391 [00:03<00:01, 88.49it/s] 64%|██████▍   | 252/391 [00:03<00:01, 88.45it/s] 67%|██████▋   | 261/391 [00:03<00:01, 87.23it/s] 69%|██████▉   | 270/391 [00:03<00:01, 87.67it/s] 71%|███████▏  | 279/391 [00:03<00:01, 88.02it/s] 74%|███████▎  | 288/391 [00:03<00:01, 87.89it/s] 76%|███████▌  | 297/391 [00:03<00:01, 87.82it/s] 78%|███████▊  | 306/391 [00:03<00:00, 87.83it/s] 81%|████████  | 315/391 [00:04<00:00, 88.12it/s] 83%|████████▎ | 324/391 [00:04<00:00, 88.11it/s] 85%|████████▌ | 333/391 [00:04<00:00, 88.26it/s] 87%|████████▋ | 342/391 [00:04<00:00, 88.44it/s] 90%|████████▉ | 351/391 [00:04<00:00, 88.56it/s] 92%|█████████▏| 360/391 [00:04<00:00, 87.02it/s] 95%|█████████▍| 370/391 [00:04<00:00, 88.04it/s] 97%|█████████▋| 380/391 [00:04<00:00, 88.75it/s]100%|█████████▉| 390/391 [00:04<00:00, 89.25it/s]100%|██████████| 391/391 [00:04<00:00, 79.96it/s]
50000 images processed, 4.9810144901275635 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:39,  1.96it/s] 13%|█▎        | 10/79 [00:00<00:03, 21.08it/s] 24%|██▍       | 19/79 [00:00<00:01, 36.85it/s] 35%|███▌      | 28/79 [00:00<00:01, 49.64it/s] 47%|████▋     | 37/79 [00:00<00:00, 58.44it/s] 58%|█████▊    | 46/79 [00:01<00:00, 65.07it/s] 70%|██████▉   | 55/79 [00:01<00:00, 71.44it/s] 81%|████████  | 64/79 [00:01<00:00, 76.31it/s] 92%|█████████▏| 73/79 [00:01<00:00, 79.93it/s]100%|██████████| 79/79 [00:02<00:00, 36.51it/s]
10000 images processed, 2.1880359649658203 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc2/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:01,  1.68it/s]  5%|▍         | 10/204 [00:00<00:10, 18.60it/s]  9%|▉         | 19/204 [00:00<00:05, 33.60it/s] 14%|█▎        | 28/204 [00:00<00:03, 46.40it/s] 18%|█▊        | 37/204 [00:01<00:02, 55.82it/s] 23%|██▎       | 46/204 [00:01<00:02, 63.88it/s] 27%|██▋       | 55/204 [00:01<00:02, 69.76it/s] 31%|███▏      | 64/204 [00:01<00:01, 74.25it/s] 36%|███▌      | 73/204 [00:01<00:01, 76.76it/s] 40%|████      | 82/204 [00:01<00:01, 79.43it/s] 45%|████▍     | 91/204 [00:01<00:01, 77.52it/s] 49%|████▉     | 100/204 [00:01<00:01, 79.26it/s] 53%|█████▎    | 109/204 [00:01<00:01, 78.98it/s] 58%|█████▊    | 118/204 [00:01<00:01, 81.11it/s] 62%|██████▏   | 127/204 [00:02<00:00, 82.71it/s] 67%|██████▋   | 136/204 [00:02<00:00, 83.59it/s] 71%|███████   | 145/204 [00:02<00:00, 83.89it/s] 75%|███████▌  | 154/204 [00:02<00:00, 84.19it/s] 80%|███████▉  | 163/204 [00:02<00:00, 85.10it/s] 84%|████████▍ | 172/204 [00:02<00:00, 84.79it/s] 89%|████████▊ | 181/204 [00:02<00:00, 85.77it/s] 93%|█████████▎| 190/204 [00:02<00:00, 86.40it/s] 98%|█████████▊| 199/204 [00:02<00:00, 86.98it/s]100%|██████████| 204/204 [00:02<00:00, 68.07it/s]
26032 images processed, 3.041761636734009 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:50,  1.54it/s]  9%|▉         | 7/79 [00:00<00:05, 12.04it/s] 20%|██        | 16/79 [00:00<00:02, 27.76it/s] 32%|███▏      | 25/79 [00:00<00:01, 41.23it/s] 43%|████▎     | 34/79 [00:01<00:00, 52.00it/s] 54%|█████▍    | 43/79 [00:01<00:00, 60.75it/s] 65%|██████▍   | 51/79 [00:01<00:00, 65.20it/s] 76%|███████▌  | 60/79 [00:01<00:00, 71.37it/s] 87%|████████▋ | 69/79 [00:01<00:00, 76.24it/s] 99%|█████████▊| 78/79 [00:01<00:00, 79.93it/s]100%|██████████| 79/79 [00:01<00:00, 49.83it/s]
10000 images processed, 1.6211576461791992 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:41,  1.88it/s] 10%|█         | 8/79 [00:00<00:04, 16.28it/s] 22%|██▏       | 17/79 [00:00<00:01, 33.16it/s] 33%|███▎      | 26/79 [00:00<00:01, 46.97it/s] 44%|████▍     | 35/79 [00:00<00:00, 57.80it/s] 56%|█████▌    | 44/79 [00:01<00:00, 66.00it/s] 67%|██████▋   | 53/79 [00:01<00:00, 72.14it/s] 78%|███████▊  | 62/79 [00:01<00:00, 76.89it/s] 90%|████████▉ | 71/79 [00:01<00:00, 80.43it/s]100%|██████████| 79/79 [00:01<00:00, 55.26it/s]
10000 images processed, 1.4470646381378174 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:33,  2.04it/s] 14%|█▍        | 10/70 [00:00<00:02, 21.49it/s] 27%|██▋       | 19/70 [00:00<00:01, 37.70it/s] 40%|████      | 28/70 [00:00<00:00, 50.26it/s] 53%|█████▎    | 37/70 [00:00<00:00, 60.15it/s] 66%|██████▌   | 46/70 [00:01<00:00, 67.86it/s] 79%|███████▊  | 55/70 [00:01<00:00, 73.61it/s] 91%|█████████▏| 64/70 [00:01<00:00, 78.02it/s]100%|██████████| 70/70 [00:01<00:00, 54.40it/s]
8925 images processed, 1.3189280033111572 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:46,  1.05s/it]  4%|▍         | 2/45 [00:01<00:22,  1.95it/s] 24%|██▍       | 11/45 [00:01<00:02, 14.26it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.71it/s] 51%|█████     | 23/45 [00:01<00:01, 20.89it/s] 71%|███████   | 32/45 [00:01<00:00, 32.08it/s] 84%|████████▍ | 38/45 [00:02<00:00, 19.55it/s]100%|██████████| 45/45 [00:02<00:00, 25.38it/s]100%|██████████| 45/45 [00:02<00:00, 17.54it/s]
5640 images processed, 2.5910539627075195 seconds used

18.99066185951233
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.64  99.31
places365     73.15  79.36
LSUN          19.62  95.60
iSUN          77.04  79.75
dtd           42.39  90.36
AVG           42.97  88.88
Retain-Acc: 0.7087
Forget-as-OOD (retain known vs forget novel):
  FPR: 69.20 AUROC: 87.58 AUIN: 99.28
10.348008871078491
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-inc2_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-seen: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:29,  1.86it/s]  3%|▎         | 10/391 [00:00<00:18, 20.14it/s]  5%|▍         | 19/391 [00:00<00:10, 35.94it/s]  7%|▋         | 28/391 [00:00<00:07, 49.06it/s]  9%|▉         | 37/391 [00:00<00:05, 59.34it/s] 12%|█▏        | 46/391 [00:01<00:05, 67.15it/s] 14%|█▍        | 55/391 [00:01<00:04, 72.59it/s] 16%|█▋        | 64/391 [00:01<00:04, 77.03it/s] 19%|█▊        | 73/391 [00:01<00:03, 80.56it/s] 21%|██        | 82/391 [00:01<00:03, 82.98it/s] 23%|██▎       | 91/391 [00:01<00:03, 83.40it/s] 26%|██▌       | 100/391 [00:01<00:03, 84.90it/s] 28%|██▊       | 109/391 [00:01<00:03, 85.98it/s] 30%|███       | 118/391 [00:01<00:03, 86.79it/s] 32%|███▏      | 127/391 [00:01<00:03, 87.44it/s] 35%|███▍      | 136/391 [00:02<00:02, 86.73it/s] 37%|███▋      | 145/391 [00:02<00:02, 87.48it/s] 39%|███▉      | 154/391 [00:02<00:02, 88.02it/s] 42%|████▏     | 163/391 [00:02<00:02, 88.34it/s] 44%|████▍     | 172/391 [00:02<00:02, 87.88it/s] 46%|████▋     | 181/391 [00:02<00:02, 88.10it/s] 49%|████▊     | 190/391 [00:02<00:02, 87.97it/s] 51%|█████     | 199/391 [00:02<00:02, 88.21it/s] 53%|█████▎    | 208/391 [00:02<00:02, 86.49it/s] 55%|█████▌    | 217/391 [00:03<00:02, 84.90it/s] 58%|█████▊    | 226/391 [00:03<00:01, 85.99it/s] 60%|██████    | 235/391 [00:03<00:01, 85.90it/s] 62%|██████▏   | 244/391 [00:03<00:01, 86.63it/s] 65%|██████▍   | 253/391 [00:03<00:01, 87.09it/s] 67%|██████▋   | 262/391 [00:03<00:01, 87.57it/s] 69%|██████▉   | 271/391 [00:03<00:01, 87.70it/s] 72%|███████▏  | 280/391 [00:03<00:01, 86.14it/s] 74%|███████▍  | 289/391 [00:03<00:01, 86.86it/s] 76%|███████▌  | 298/391 [00:03<00:01, 87.36it/s] 79%|███████▊  | 307/391 [00:04<00:00, 87.54it/s] 81%|████████  | 316/391 [00:04<00:00, 87.09it/s] 83%|████████▎ | 325/391 [00:04<00:00, 87.30it/s] 85%|████████▌ | 334/391 [00:04<00:00, 86.84it/s] 88%|████████▊ | 343/391 [00:04<00:00, 86.61it/s] 90%|█████████ | 352/391 [00:04<00:00, 87.08it/s] 92%|█████████▏| 361/391 [00:04<00:00, 87.38it/s] 95%|█████████▍| 370/391 [00:04<00:00, 88.04it/s] 97%|█████████▋| 380/391 [00:04<00:00, 88.80it/s]100%|█████████▉| 390/391 [00:04<00:00, 89.31it/s]100%|██████████| 391/391 [00:04<00:00, 78.22it/s]
50000 images processed, 5.095525026321411 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:35,  2.22it/s] 10%|█         | 8/79 [00:00<00:03, 18.07it/s] 22%|██▏       | 17/79 [00:00<00:01, 35.40it/s] 33%|███▎      | 26/79 [00:00<00:01, 49.28it/s] 44%|████▍     | 35/79 [00:00<00:00, 59.69it/s] 56%|█████▌    | 44/79 [00:00<00:00, 67.45it/s] 67%|██████▋   | 53/79 [00:01<00:00, 73.28it/s] 78%|███████▊  | 62/79 [00:01<00:00, 77.78it/s] 90%|████████▉ | 71/79 [00:01<00:00, 80.98it/s]100%|██████████| 79/79 [00:01<00:00, 52.07it/s]
10000 images processed, 1.5498383045196533 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-seen/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:33,  2.17it/s]  5%|▍         | 10/204 [00:00<00:08, 22.53it/s]  9%|▉         | 19/204 [00:00<00:04, 38.56it/s] 14%|█▎        | 28/204 [00:00<00:03, 51.40it/s] 18%|█▊        | 37/204 [00:00<00:02, 61.03it/s] 23%|██▎       | 46/204 [00:00<00:02, 68.35it/s] 27%|██▋       | 55/204 [00:01<00:02, 73.84it/s] 31%|███▏      | 64/204 [00:01<00:01, 77.94it/s] 36%|███▌      | 73/204 [00:01<00:01, 80.59it/s] 40%|████      | 82/204 [00:01<00:01, 81.91it/s] 45%|████▍     | 91/204 [00:01<00:01, 82.58it/s] 49%|████▉     | 100/204 [00:01<00:01, 83.51it/s] 53%|█████▎    | 109/204 [00:01<00:01, 84.35it/s] 58%|█████▊    | 118/204 [00:01<00:01, 84.96it/s] 62%|██████▏   | 127/204 [00:01<00:00, 85.67it/s] 67%|██████▋   | 136/204 [00:02<00:00, 86.02it/s] 71%|███████   | 145/204 [00:02<00:00, 86.55it/s] 75%|███████▌  | 154/204 [00:02<00:00, 86.48it/s] 80%|███████▉  | 163/204 [00:02<00:00, 86.70it/s] 84%|████████▍ | 172/204 [00:02<00:00, 86.80it/s] 89%|████████▊ | 181/204 [00:02<00:00, 87.34it/s] 93%|█████████▎| 190/204 [00:02<00:00, 87.78it/s] 98%|█████████▊| 199/204 [00:02<00:00, 88.14it/s]100%|██████████| 204/204 [00:02<00:00, 72.71it/s]
26032 images processed, 2.847043514251709 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:55,  1.42it/s]  8%|▊         | 6/79 [00:00<00:07,  9.53it/s] 19%|█▉        | 15/79 [00:00<00:02, 24.92it/s] 30%|███       | 24/79 [00:01<00:01, 38.68it/s] 42%|████▏     | 33/79 [00:01<00:00, 49.94it/s] 53%|█████▎    | 42/79 [00:01<00:00, 58.57it/s] 63%|██████▎   | 50/79 [00:01<00:00, 63.71it/s] 75%|███████▍  | 59/79 [00:01<00:00, 70.38it/s] 86%|████████▌ | 68/79 [00:01<00:00, 75.51it/s] 97%|█████████▋| 77/79 [00:01<00:00, 79.36it/s]100%|██████████| 79/79 [00:01<00:00, 47.81it/s]
10000 images processed, 1.6703009605407715 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.77it/s] 13%|█▎        | 10/79 [00:00<00:03, 19.23it/s] 24%|██▍       | 19/79 [00:00<00:01, 34.70it/s] 35%|███▌      | 28/79 [00:00<00:01, 47.51it/s] 47%|████▋     | 37/79 [00:00<00:00, 57.83it/s] 58%|█████▊    | 46/79 [00:01<00:00, 65.80it/s] 70%|██████▉   | 55/79 [00:01<00:00, 72.13it/s] 81%|████████  | 64/79 [00:01<00:00, 76.83it/s] 92%|█████████▏| 73/79 [00:01<00:00, 80.18it/s]100%|██████████| 79/79 [00:01<00:00, 54.50it/s]
10000 images processed, 1.4690101146697998 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:36,  1.89it/s] 14%|█▍        | 10/70 [00:00<00:02, 20.36it/s] 27%|██▋       | 19/70 [00:00<00:01, 36.10it/s] 40%|████      | 28/70 [00:00<00:00, 48.92it/s] 53%|█████▎    | 37/70 [00:00<00:00, 59.01it/s] 66%|██████▌   | 46/70 [00:01<00:00, 66.79it/s] 79%|███████▊  | 55/70 [00:01<00:00, 72.97it/s] 91%|█████████▏| 64/70 [00:01<00:00, 77.35it/s]100%|██████████| 70/70 [00:01<00:00, 52.77it/s]
8925 images processed, 1.3611376285552979 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:43,  1.02it/s]  4%|▍         | 2/45 [00:01<00:22,  1.94it/s] 24%|██▍       | 11/45 [00:01<00:02, 14.19it/s] 38%|███▊      | 17/45 [00:01<00:01, 19.10it/s] 47%|████▋     | 21/45 [00:01<00:01, 16.11it/s] 62%|██████▏   | 28/45 [00:01<00:00, 23.84it/s] 73%|███████▎  | 33/45 [00:02<00:00, 23.12it/s] 82%|████████▏ | 37/45 [00:02<00:00, 17.61it/s]100%|██████████| 45/45 [00:02<00:00, 17.24it/s]
5640 images processed, 2.630805492401123 seconds used

18.251463651657104
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.57  99.36
places365     68.08  81.18
LSUN          17.82  96.07
iSUN          72.36  81.80
dtd           38.48  91.38
AVG           39.86  89.96
Retain-Acc: 0.7481
Forget-as-OOD (retain known vs forget novel):
  FPR: 54.60 AUROC: 89.30 AUIN: 98.64
8.878535985946655
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-seen_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-ol1-stage2-seen_rf.png
