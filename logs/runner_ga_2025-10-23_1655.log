nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=10, batch_size=128, lr=0.0005, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_ga_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='ga', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/10 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:472: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:560: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 10%|█         | 1/10 [00:36<05:28, 36.54s/it] 20%|██        | 2/10 [01:00<03:52, 29.07s/it] 30%|███       | 3/10 [01:34<03:40, 31.51s/it] 40%|████      | 4/10 [02:08<03:14, 32.49s/it] 50%|█████     | 5/10 [02:42<02:43, 32.79s/it] 60%|██████    | 6/10 [03:15<02:12, 33.03s/it] 70%|███████   | 7/10 [03:49<01:39, 33.15s/it] 80%|████████  | 8/10 [04:23<01:06, 33.45s/it] 90%|█████████ | 9/10 [04:57<00:33, 33.61s/it]100%|██████████| 10/10 [05:30<00:00, 33.43s/it]100%|██████████| 10/10 [05:30<00:00, 33.01s/it]
[loss-ga] ep 0 it 0 total=0.1796 ce_r=0.2465 ce_f=0.3342
[loss-ga] ep 0 it 50 total=0.1432 ce_r=0.1892 ce_f=0.2297
[loss-ga] ep 0 it 100 total=0.2028 ce_r=0.2684 ce_f=0.3279
[loss-ga] ep 0 it 150 total=0.0912 ce_r=0.1213 ce_f=0.1504
[loss-ga] ep 0 it 200 total=0.1398 ce_r=0.1851 ce_f=0.2267
[loss-ga] ep 0 it 250 total=0.0571 ce_r=0.0672 ce_f=0.0505
[loss-ga] ep 0 it 300 total=0.1228 ce_r=0.1668 ce_f=0.2201
[loss-ga] ep 0 it 350 total=0.0370 ce_r=0.0500 ce_f=0.0650
[loss-ga] ep 1 it 10 total=0.0403 ce_r=0.0531 ce_f=0.0638
[loss-ga] ep 1 it 60 total=0.0301 ce_r=0.0396 ce_f=0.0475
[loss-ga] ep 1 it 110 total=0.0213 ce_r=0.0272 ce_f=0.0297
[loss-ga] ep 1 it 160 total=0.0362 ce_r=0.0472 ce_f=0.0549
[loss-ga] ep 1 it 210 total=0.0521 ce_r=0.0668 ce_f=0.0735
[loss-ga] ep 1 it 260 total=0.0168 ce_r=0.0223 ce_f=0.0272
[loss-ga] ep 1 it 310 total=0.0495 ce_r=0.0662 ce_f=0.0835
[loss-ga] ep 1 it 360 total=0.0412 ce_r=0.0539 ce_f=0.0634
[loss-ga] ep 2 it 20 total=0.0317 ce_r=0.0426 ce_f=0.0545
[loss-ga] ep 2 it 70 total=0.0443 ce_r=0.0567 ce_f=0.0624
[loss-ga] ep 2 it 120 total=0.0123 ce_r=0.0152 ce_f=0.0142
[loss-ga] ep 2 it 170 total=0.0570 ce_r=0.0728 ce_f=0.0790
[loss-ga] ep 2 it 220 total=0.0250 ce_r=0.0307 ce_f=0.0284
[loss-ga] ep 2 it 270 total=0.0415 ce_r=0.0517 ce_f=0.0512
[loss-ga] ep 2 it 320 total=0.0697 ce_r=0.0915 ce_f=0.1092
[loss-ga] ep 2 it 370 total=0.0207 ce_r=0.0249 ce_f=0.0209
[loss-ga] ep 3 it 30 total=0.0152 ce_r=0.0197 ce_f=0.0224
[loss-ga] ep 3 it 80 total=0.0138 ce_r=0.0178 ce_f=0.0202
[loss-ga] ep 3 it 130 total=0.0357 ce_r=0.0399 ce_f=0.0210
[loss-ga] ep 3 it 180 total=0.0617 ce_r=0.0785 ce_f=0.0841
[loss-ga] ep 3 it 230 total=0.0188 ce_r=0.0234 ce_f=0.0229
[loss-ga] ep 3 it 280 total=0.0502 ce_r=0.0674 ce_f=0.0858
[loss-ga] ep 3 it 330 total=0.0515 ce_r=0.0557 ce_f=0.0211
[loss-ga] ep 3 it 380 total=0.0089 ce_r=0.0117 ce_f=0.0140
[loss-ga] ep 4 it 40 total=0.1054 ce_r=0.1395 ce_f=0.1706
[loss-ga] ep 4 it 90 total=0.1052 ce_r=0.1348 ce_f=0.1482
[loss-ga] ep 4 it 140 total=0.0470 ce_r=0.0608 ce_f=0.0689
[loss-ga] ep 4 it 190 total=0.0183 ce_r=0.0243 ce_f=0.0304
[loss-ga] ep 4 it 240 total=0.0354 ce_r=0.0411 ce_f=0.0285
[loss-ga] ep 4 it 290 total=0.0133 ce_r=0.0172 ce_f=0.0198
[loss-ga] ep 4 it 340 total=0.0236 ce_r=0.0308 ce_f=0.0360
[loss-ga] ep 5 it 0 total=0.0331 ce_r=0.0420 ce_f=0.0442
[loss-ga] ep 5 it 50 total=0.0171 ce_r=0.0186 ce_f=0.0074
[loss-ga] ep 5 it 100 total=0.0698 ce_r=0.0923 ce_f=0.1126
[loss-ga] ep 5 it 150 total=0.0243 ce_r=0.0311 ce_f=0.0340
[loss-ga] ep 5 it 200 total=0.0131 ce_r=0.0139 ce_f=0.0045
[loss-ga] ep 5 it 250 total=0.0165 ce_r=0.0193 ce_f=0.0143
[loss-ga] ep 5 it 300 total=0.0218 ce_r=0.0268 ce_f=0.0251
[loss-ga] ep 5 it 350 total=0.0114 ce_r=0.0133 ce_f=0.0092
[loss-ga] ep 6 it 10 total=0.0200 ce_r=0.0214 ce_f=0.0066
[loss-ga] ep 6 it 60 total=0.0158 ce_r=0.0191 ce_f=0.0168
[loss-ga] ep 6 it 110 total=0.0351 ce_r=0.0424 ce_f=0.0367
[loss-ga] ep 6 it 160 total=0.0138 ce_r=0.0151 ce_f=0.0064
[loss-ga] ep 6 it 210 total=0.0107 ce_r=0.0128 ce_f=0.0106
[loss-ga] ep 6 it 260 total=0.0256 ce_r=0.0341 ce_f=0.0424
[loss-ga] ep 6 it 310 total=0.0439 ce_r=0.0561 ce_f=0.0610
[loss-ga] ep 6 it 360 total=0.0233 ce_r=0.0249 ce_f=0.0076
[loss-ga] ep 7 it 20 total=0.0282 ce_r=0.0373 ce_f=0.0458
[loss-ga] ep 7 it 70 total=0.0520 ce_r=0.0687 ce_f=0.0835
[loss-ga] ep 7 it 120 total=0.0196 ce_r=0.0245 ce_f=0.0244
[loss-ga] ep 7 it 170 total=0.0094 ce_r=0.0118 ce_f=0.0122
[loss-ga] ep 7 it 220 total=0.0418 ce_r=0.0505 ce_f=0.0433
[loss-ga] ep 7 it 270 total=0.0073 ce_r=0.0093 ce_f=0.0102
[loss-ga] ep 7 it 320 total=0.0341 ce_r=0.0411 ce_f=0.0352
[loss-ga] ep 7 it 370 total=0.0049 ce_r=0.0057 ce_f=0.0043
[loss-ga] ep 8 it 30 total=0.0531 ce_r=0.0594 ce_f=0.0315
[loss-ga] ep 8 it 80 total=0.0080 ce_r=0.0089 ce_f=0.0043
[loss-ga] ep 8 it 130 total=0.0220 ce_r=0.0257 ce_f=0.0183
[loss-ga] ep 8 it 180 total=0.0087 ce_r=0.0115 ce_f=0.0139
[loss-ga] ep 8 it 230 total=0.0326 ce_r=0.0421 ce_f=0.0479
[loss-ga] ep 8 it 280 total=0.0622 ce_r=0.0748 ce_f=0.0631
[loss-ga] ep 8 it 330 total=0.0164 ce_r=0.0203 ce_f=0.0195
[loss-ga] ep 8 it 380 total=0.0257 ce_r=0.0328 ce_f=0.0356
[loss-ga] ep 9 it 40 total=0.0041 ce_r=0.0051 ce_f=0.0054
[loss-ga] ep 9 it 90 total=0.0472 ce_r=0.0618 ce_f=0.0732
[loss-ga] ep 9 it 140 total=0.0108 ce_r=0.0127 ce_f=0.0094
[loss-ga] ep 9 it 190 total=0.0279 ce_r=0.0358 ce_f=0.0395
[loss-ga] ep 9 it 240 total=0.0086 ce_r=0.0105 ce_f=0.0099
[loss-ga] ep 9 it 290 total=0.0828 ce_r=0.1048 ce_f=0.1102
[loss-ga] ep 9 it 340 total=0.0086 ce_r=0.0112 ce_f=0.0132
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_ga_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e10-lr0.0005-wd1e-4-fl0.2: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:20,  2.77it/s]  2%|▏         | 7/391 [00:00<00:20, 18.90it/s]  3%|▎         | 13/391 [00:00<00:12, 30.62it/s]  5%|▌         | 20/391 [00:00<00:09, 39.77it/s]  7%|▋         | 26/391 [00:00<00:08, 44.50it/s]  8%|▊         | 33/391 [00:00<00:07, 49.61it/s] 10%|█         | 40/391 [00:01<00:06, 53.17it/s] 12%|█▏        | 47/391 [00:01<00:06, 56.43it/s] 14%|█▎        | 53/391 [00:01<00:06, 55.61it/s] 15%|█▌        | 59/391 [00:01<00:05, 56.66it/s] 17%|█▋        | 66/391 [00:01<00:05, 59.37it/s] 19%|█▊        | 73/391 [00:01<00:05, 58.06it/s] 20%|██        | 79/391 [00:01<00:05, 58.56it/s] 22%|██▏       | 85/391 [00:01<00:05, 57.47it/s] 23%|██▎       | 91/391 [00:01<00:05, 56.62it/s] 25%|██▌       | 98/391 [00:01<00:04, 60.37it/s] 27%|██▋       | 105/391 [00:02<00:04, 61.25it/s] 29%|██▊       | 112/391 [00:02<00:04, 61.41it/s] 30%|███       | 119/391 [00:02<00:04, 62.23it/s] 32%|███▏      | 126/391 [00:02<00:04, 62.32it/s] 34%|███▍      | 133/391 [00:02<00:04, 61.44it/s] 36%|███▌      | 140/391 [00:02<00:04, 60.95it/s] 38%|███▊      | 147/391 [00:02<00:03, 62.30it/s] 39%|███▉      | 154/391 [00:02<00:03, 60.78it/s] 41%|████      | 161/391 [00:03<00:03, 60.79it/s] 43%|████▎     | 168/391 [00:03<00:03, 58.07it/s] 45%|████▍     | 175/391 [00:03<00:03, 60.09it/s] 47%|████▋     | 182/391 [00:03<00:03, 60.52it/s] 48%|████▊     | 189/391 [00:03<00:03, 60.83it/s] 50%|█████     | 196/391 [00:03<00:03, 60.92it/s] 52%|█████▏    | 203/391 [00:03<00:03, 61.18it/s] 54%|█████▎    | 210/391 [00:03<00:02, 60.54it/s] 55%|█████▌    | 217/391 [00:03<00:02, 60.29it/s] 57%|█████▋    | 224/391 [00:04<00:02, 61.74it/s] 59%|█████▉    | 231/391 [00:04<00:02, 62.90it/s] 61%|██████    | 238/391 [00:04<00:02, 61.39it/s] 63%|██████▎   | 245/391 [00:04<00:02, 61.67it/s] 64%|██████▍   | 252/391 [00:04<00:02, 61.09it/s] 66%|██████▌   | 259/391 [00:04<00:02, 60.71it/s] 68%|██████▊   | 266/391 [00:04<00:02, 61.99it/s] 70%|██████▉   | 273/391 [00:04<00:01, 62.83it/s] 72%|███████▏  | 280/391 [00:04<00:01, 63.20it/s] 73%|███████▎  | 287/391 [00:05<00:01, 63.84it/s] 75%|███████▌  | 294/391 [00:05<00:01, 62.04it/s] 77%|███████▋  | 301/391 [00:05<00:01, 62.97it/s] 79%|███████▉  | 308/391 [00:05<00:01, 63.68it/s] 81%|████████  | 315/391 [00:05<00:01, 62.05it/s] 82%|████████▏ | 322/391 [00:05<00:01, 61.63it/s] 84%|████████▍ | 329/391 [00:05<00:01, 60.77it/s] 86%|████████▌ | 336/391 [00:05<00:00, 61.86it/s] 88%|████████▊ | 343/391 [00:05<00:00, 62.86it/s] 90%|████████▉ | 350/391 [00:06<00:00, 63.66it/s] 91%|█████████▏| 357/391 [00:06<00:00, 63.40it/s] 93%|█████████▎| 364/391 [00:06<00:00, 61.29it/s] 95%|█████████▍| 371/391 [00:06<00:00, 58.07it/s] 96%|█████████▋| 377/391 [00:06<00:00, 57.91it/s] 98%|█████████▊| 384/391 [00:06<00:00, 60.18it/s]100%|██████████| 391/391 [00:06<00:00, 61.93it/s]100%|██████████| 391/391 [00:06<00:00, 57.86it/s]
50000 images processed, 6.834973096847534 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:26,  2.91it/s]  9%|▉         | 7/79 [00:00<00:03, 19.36it/s] 16%|█▋        | 13/79 [00:00<00:02, 30.93it/s] 25%|██▌       | 20/79 [00:00<00:01, 40.89it/s] 34%|███▍      | 27/79 [00:00<00:01, 47.60it/s] 43%|████▎     | 34/79 [00:00<00:00, 51.36it/s] 51%|█████     | 40/79 [00:00<00:00, 53.68it/s] 58%|█████▊    | 46/79 [00:01<00:00, 53.79it/s] 67%|██████▋   | 53/79 [00:01<00:00, 56.55it/s] 76%|███████▌  | 60/79 [00:01<00:00, 57.67it/s] 85%|████████▍ | 67/79 [00:01<00:00, 59.76it/s] 94%|█████████▎| 74/79 [00:01<00:00, 60.57it/s]100%|██████████| 79/79 [00:02<00:00, 33.22it/s]
10000 images processed, 2.4014670848846436 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:23,  2.43it/s]  3%|▎         | 7/204 [00:00<00:11, 17.06it/s]  6%|▋         | 13/204 [00:00<00:06, 28.45it/s]  9%|▉         | 19/204 [00:00<00:05, 35.84it/s] 12%|█▏        | 25/204 [00:00<00:04, 42.07it/s] 15%|█▌        | 31/204 [00:00<00:03, 47.06it/s] 19%|█▊        | 38/204 [00:01<00:03, 51.11it/s] 22%|██▏       | 44/204 [00:01<00:03, 51.83it/s] 25%|██▍       | 50/204 [00:01<00:02, 53.64it/s] 27%|██▋       | 56/204 [00:01<00:02, 54.47it/s] 31%|███       | 63/204 [00:01<00:02, 57.38it/s] 34%|███▍      | 70/204 [00:01<00:02, 60.26it/s] 39%|███▉      | 80/204 [00:01<00:01, 71.63it/s] 44%|████▍     | 90/204 [00:01<00:01, 79.23it/s] 49%|████▉     | 100/204 [00:01<00:01, 85.28it/s] 54%|█████▍    | 110/204 [00:01<00:01, 88.61it/s] 59%|█████▉    | 120/204 [00:02<00:00, 90.01it/s] 64%|██████▎   | 130/204 [00:02<00:00, 77.61it/s] 68%|██████▊   | 139/204 [00:02<00:00, 74.45it/s] 72%|███████▏  | 147/204 [00:02<00:00, 69.72it/s] 76%|███████▌  | 155/204 [00:02<00:00, 66.07it/s] 79%|███████▉  | 162/204 [00:02<00:00, 62.18it/s] 83%|████████▎ | 170/204 [00:02<00:00, 63.34it/s] 87%|████████▋ | 177/204 [00:03<00:00, 62.89it/s] 90%|█████████ | 184/204 [00:03<00:00, 63.60it/s] 94%|█████████▎| 191/204 [00:03<00:00, 62.50it/s] 97%|█████████▋| 198/204 [00:03<00:00, 60.81it/s]100%|██████████| 204/204 [00:03<00:00, 58.66it/s]
26032 images processed, 3.5201504230499268 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:42,  1.85it/s] 10%|█         | 8/79 [00:00<00:04, 15.88it/s] 15%|█▌        | 12/79 [00:00<00:03, 20.77it/s] 23%|██▎       | 18/79 [00:00<00:02, 28.19it/s] 30%|███       | 24/79 [00:00<00:01, 35.82it/s] 37%|███▋      | 29/79 [00:01<00:01, 36.26it/s] 44%|████▍     | 35/79 [00:01<00:01, 41.73it/s] 53%|█████▎    | 42/79 [00:01<00:00, 43.31it/s] 61%|██████    | 48/79 [00:01<00:00, 47.32it/s] 68%|██████▊   | 54/79 [00:01<00:00, 49.99it/s] 76%|███████▌  | 60/79 [00:01<00:00, 49.18it/s] 84%|████████▎ | 66/79 [00:01<00:00, 48.27it/s] 92%|█████████▏| 73/79 [00:01<00:00, 49.48it/s]100%|██████████| 79/79 [00:02<00:00, 38.29it/s]
10000 images processed, 2.0966880321502686 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:29,  2.63it/s]  8%|▊         | 6/79 [00:00<00:04, 14.92it/s] 15%|█▌        | 12/79 [00:00<00:02, 27.04it/s] 23%|██▎       | 18/79 [00:00<00:01, 35.68it/s] 30%|███       | 24/79 [00:00<00:01, 42.40it/s] 38%|███▊      | 30/79 [00:00<00:01, 46.81it/s] 46%|████▌     | 36/79 [00:01<00:00, 49.52it/s] 54%|█████▍    | 43/79 [00:01<00:00, 54.36it/s] 62%|██████▏   | 49/79 [00:01<00:00, 55.24it/s] 70%|██████▉   | 55/79 [00:01<00:00, 56.41it/s] 78%|███████▊  | 62/79 [00:01<00:00, 57.87it/s] 86%|████████▌ | 68/79 [00:01<00:00, 56.94it/s] 95%|█████████▍| 75/79 [00:01<00:00, 59.55it/s]100%|██████████| 79/79 [00:01<00:00, 46.24it/s]
10000 images processed, 1.729478359222412 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:26,  2.60it/s] 11%|█▏        | 8/70 [00:00<00:03, 19.98it/s] 20%|██        | 14/70 [00:00<00:01, 29.98it/s] 29%|██▊       | 20/70 [00:00<00:01, 37.01it/s] 37%|███▋      | 26/70 [00:00<00:01, 43.08it/s] 47%|████▋     | 33/70 [00:00<00:00, 48.30it/s] 57%|█████▋    | 40/70 [00:01<00:00, 53.05it/s] 67%|██████▋   | 47/70 [00:01<00:00, 55.06it/s] 76%|███████▌  | 53/70 [00:01<00:00, 55.56it/s] 86%|████████▌ | 60/70 [00:01<00:00, 56.46it/s] 94%|█████████▍| 66/70 [00:01<00:00, 56.85it/s]100%|██████████| 70/70 [00:01<00:00, 44.87it/s]
8925 images processed, 1.593635082244873 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:38,  1.15it/s]  4%|▍         | 2/45 [00:01<00:21,  2.01it/s] 18%|█▊        | 8/45 [00:01<00:03, 10.40it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.54it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.50it/s] 44%|████▍     | 20/45 [00:02<00:02, 12.05it/s] 56%|█████▌    | 25/45 [00:02<00:01, 15.89it/s] 62%|██████▏   | 28/45 [00:02<00:01, 12.69it/s] 69%|██████▉   | 31/45 [00:02<00:00, 14.72it/s] 76%|███████▌  | 34/45 [00:03<00:01, 10.17it/s] 89%|████████▉ | 40/45 [00:03<00:00, 15.97it/s] 96%|█████████▌| 43/45 [00:04<00:00, 10.14it/s]100%|██████████| 45/45 [00:04<00:00, 10.90it/s]
5640 images processed, 4.148157119750977 seconds used

24.011143445968628
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.02  99.18
places365     70.49  79.69
LSUN          23.15  94.99
iSUN          68.89  83.81
dtd           42.46  88.96
AVG           41.60  89.33
Retain-Acc: 0.7367
Forget-as-OOD (retain known vs forget novel):
  FPR: 45.50 AUROC: 90.27 AUIN: 98.74
8.895511150360107
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e10-lr0.0005-wd1e-4-fl0.2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e10-lr0.0005-wd1e-4-fl0.2_rf.png
