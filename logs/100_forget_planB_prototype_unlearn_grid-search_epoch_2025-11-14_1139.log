nohup: ignoring input
[Full Grid] Searching over: lambdas(0.2) × lrs(0.001) × epochs(5 10 15 20 25 30 35 40 45 50) × lora_r(8)
[Run] lambda=0.2 lr=0.001 epochs=5 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
 20%|██        | 1/5 [00:14<00:56, 14.19s/it] 40%|████      | 2/5 [00:22<00:32, 10.89s/it] 60%|██████    | 3/5 [00:32<00:20, 10.23s/it] 80%|████████  | 4/5 [00:43<00:10, 10.58s/it]100%|██████████| 5/5 [00:51<00:00,  9.80s/it]100%|██████████| 5/5 [00:51<00:00, 10.35s/it]
[loss] ep 0 it 0 total=8.2324 mle=1.5619 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3186 mle=1.6306 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4640 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4347 mle=1.7482 pcon=5.2750 forget=1.4115 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5258 mle=1.8430 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3321 mle=1.6798 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2594 mle=1.6256 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4395 mle=1.8019 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0947 mle=1.4465 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2488 mle=1.6387 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5267 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2073 mle=1.6063 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2560 mle=1.6695 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1514 mle=1.5594 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2312 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3118 mle=1.7253 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3768 mle=1.8354 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2556 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3574 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3045 mle=1.7525 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9740 mle=1.4275 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1376 mle=1.6127 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1875 mle=1.6634 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0958 mle=1.5680 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3408 mle=1.8282 pcon=5.1498 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2085 mle=1.7051 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7593 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3265 mle=1.8248 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1233 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0826 mle=1.5752 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2291 mle=1.7061 pcon=5.1245 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1645 mle=1.6602 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2964 mle=1.8092 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9095 mle=1.4522 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1731 mle=1.6864 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[Run] lambda=0.2 lr=0.001 epochs=10 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=10, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/10 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
 10%|█         | 1/10 [00:14<02:12, 14.67s/it] 20%|██        | 2/10 [00:23<01:28, 11.05s/it] 30%|███       | 3/10 [00:31<01:09, 10.00s/it] 40%|████      | 4/10 [00:40<00:57,  9.53s/it] 50%|█████     | 5/10 [00:53<00:53, 10.62s/it] 60%|██████    | 6/10 [01:05<00:45, 11.30s/it][loss] ep 0 it 0 total=8.2324 mle=1.5619 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3186 mle=1.6306 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4640 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4347 mle=1.7482 pcon=5.2750 forget=1.4115 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5258 mle=1.8430 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3321 mle=1.6798 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2594 mle=1.6256 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4395 mle=1.8019 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0947 mle=1.4465 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2488 mle=1.6387 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1406 mle=1.5266 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2073 mle=1.6063 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2560 mle=1.6695 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1515 mle=1.5595 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2311 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3116 mle=1.7251 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3769 mle=1.8356 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2557 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3574 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3045 mle=1.7525 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9740 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1377 mle=1.6128 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1874 mle=1.6633 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0959 mle=1.5680 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3406 mle=1.8280 pcon=5.1498 forget=1.3628 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7050 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7594 pcon=5.1425 forget=1.3617 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3264 mle=1.8246 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1234 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0827 mle=1.5753 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0056 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1646 mle=1.6603 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2965 mle=1.8094 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1730 mle=1.6863 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0602 mle=1.6086 pcon=5.1084 forget=1.3432 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1415 mle=1.6927 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2606 mle=1.7996 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4410 mle=1.9765 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2330 mle=1.7906 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1483 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2211 mle=1.7675 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1620 mle=1.7197 pcon=5.0875 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9842 mle=1.5559 pcon=5.0848 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1434 mle=1.7058 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1253 mle=1.7005 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5105 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1204 mle=1.6772 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1850 mle=1.7630 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9238 mle=1.4888 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 70%|███████   | 7/10 [01:15<00:31, 10.64s/it] 80%|████████  | 8/10 [01:24<00:20, 10.20s/it] 90%|█████████ | 9/10 [01:32<00:09,  9.66s/it]100%|██████████| 10/10 [01:41<00:00,  9.23s/it]100%|██████████| 10/10 [01:41<00:00, 10.12s/it]
[loss] ep 6 it 360 total=8.1560 mle=1.7146 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9112 mle=1.5085 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9676 mle=1.5725 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1361 mle=1.7402 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1776 mle=1.7623 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0641 mle=1.6550 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2669 mle=1.8785 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9422 mle=1.5476 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1816 mle=1.7907 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1851 mle=1.7914 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9136 mle=1.5224 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1379 mle=1.7441 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6501 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9673 mle=1.5664 pcon=5.0399 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8275 mle=1.4570 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1990 mle=1.7912 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6503 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1602 mle=1.7996 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1265 mle=1.7461 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0380 mle=1.6805 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1456 mle=1.7623 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0239 mle=1.6658 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8728 mle=1.5100 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e10-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[Run] lambda=0.2 lr=0.001 epochs=15 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=15, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/15 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  7%|▋         | 1/15 [00:11<02:46, 11.92s/it] 13%|█▎        | 2/15 [00:19<02:04,  9.59s/it] 20%|██        | 3/15 [00:28<01:47,  8.99s/it] 27%|██▋       | 4/15 [00:36<01:34,  8.62s/it] 33%|███▎      | 5/15 [00:44<01:24,  8.44s/it] 40%|████      | 6/15 [00:52<01:14,  8.30s/it][loss] ep 0 it 0 total=8.2324 mle=1.5619 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3186 mle=1.6306 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4639 mle=1.7912 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4348 mle=1.7482 pcon=5.2750 forget=1.4116 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5258 mle=1.8430 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3322 mle=1.6799 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2594 mle=1.6257 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4392 mle=1.8017 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0947 mle=1.4465 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2487 mle=1.6387 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5267 pcon=5.2323 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2073 mle=1.6063 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2561 mle=1.6695 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1514 mle=1.5594 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2312 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3119 mle=1.7253 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0014 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3770 mle=1.8356 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2556 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3575 mle=1.8061 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3045 mle=1.7524 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9739 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1376 mle=1.6127 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1876 mle=1.6635 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0960 mle=1.5682 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3407 mle=1.8280 pcon=5.1498 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7049 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2635 mle=1.7592 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3264 mle=1.8246 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1235 mle=1.6195 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0826 mle=1.5752 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1645 mle=1.6602 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2964 mle=1.8093 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1731 mle=1.6864 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0600 mle=1.6085 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1417 mle=1.6929 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2608 mle=1.7997 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4409 mle=1.9763 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2329 mle=1.7906 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1483 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2213 mle=1.7677 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1619 mle=1.7197 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9843 mle=1.5560 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1435 mle=1.7058 pcon=5.0822 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1252 mle=1.7004 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5106 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1205 mle=1.6773 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1851 mle=1.7631 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9237 mle=1.4888 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 47%|████▋     | 7/15 [01:00<01:05,  8.25s/it] 53%|█████▎    | 8/15 [01:08<00:58,  8.31s/it] 60%|██████    | 9/15 [01:17<00:49,  8.26s/it] 67%|██████▋   | 10/15 [01:24<00:40,  8.12s/it] 73%|███████▎  | 11/15 [01:32<00:32,  8.11s/it] 80%|████████  | 12/15 [01:40<00:24,  8.06s/it] 87%|████████▋ | 13/15 [01:49<00:16,  8.09s/it][loss] ep 6 it 360 total=8.1562 mle=1.7148 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9110 mle=1.5083 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9677 mle=1.5725 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1364 mle=1.7405 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1778 mle=1.7624 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0642 mle=1.6551 pcon=5.0562 forget=1.3530 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2672 mle=1.8788 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9421 mle=1.5476 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1816 mle=1.7908 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1849 mle=1.7911 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9136 mle=1.5225 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1381 mle=1.7443 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6500 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9672 mle=1.5663 pcon=5.0400 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8273 mle=1.4568 pcon=5.0380 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1988 mle=1.7910 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0389 mle=1.6501 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1601 mle=1.7994 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1263 mle=1.7460 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0380 mle=1.6805 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8338 mle=1.4881 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1455 mle=1.7623 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0237 mle=1.6656 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8727 mle=1.5099 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8219 mle=1.4855 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8198 mle=1.4735 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0396 mle=1.7010 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0423 mle=1.7017 pcon=5.0158 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1250 mle=1.7806 pcon=5.0143 forget=1.3302 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1884 mle=1.8495 pcon=5.0127 forget=1.3262 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1224 mle=1.7761 pcon=5.0110 forget=1.3353 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8596 mle=1.5341 pcon=5.0097 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1318 mle=1.7941 pcon=5.0079 forget=1.3297 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0274 mle=1.7039 pcon=5.0065 forget=1.3170 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9241 mle=1.5912 pcon=5.0050 forget=1.3279 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8769 mle=1.5654 pcon=5.0032 forget=1.3083 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8422 mle=1.5272 pcon=5.0016 forget=1.3134 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8612 mle=1.5294 pcon=4.9998 forget=1.3321 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0734 mle=1.7510 pcon=4.9982 forget=1.3242 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9556 mle=1.6476 pcon=4.9968 forget=1.3112 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9199 mle=1.5969 pcon=4.9948 forget=1.3282 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8154 mle=1.4999 pcon=4.9931 forget=1.3224 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0458 mle=1.7188 pcon=4.9913 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0471 mle=1.7219 pcon=4.9896 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8259 mle=1.5205 pcon=4.9883 forget=1.3171 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9140 mle=1.5848 pcon=4.9870 forget=1.3423 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0214 mle=1.7175 pcon=4.9856 forget=1.3183 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0324 mle=1.7103 pcon=4.9842 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=8.0026 mle=1.7058 pcon=4.9830 forget=1.3138 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1861 mle=1.8427 pcon=4.9816 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0214 mle=1.6965 pcon=4.9800 forget=1.3450 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0548 mle=1.7539 pcon=4.9782 forget=1.3227 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 93%|█████████▎| 14/15 [01:57<00:08,  8.14s/it]100%|██████████| 15/15 [02:05<00:00,  8.21s/it]100%|██████████| 15/15 [02:05<00:00,  8.38s/it]
[loss] ep 13 it 230 total=8.0039 mle=1.6957 pcon=4.9769 forget=1.3313 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7645 mle=1.4674 pcon=4.9755 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0956 mle=1.7838 pcon=4.9744 forget=1.3374 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9595 mle=1.6567 pcon=4.9733 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e15-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0320 mle=1.7183 pcon=4.9720 forget=1.3417 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8907 mle=1.5587 pcon=4.9710 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9614 mle=1.6679 pcon=4.9698 forget=1.3236 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9341 mle=1.6260 pcon=4.9688 forget=1.3393 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9483 mle=1.6470 pcon=4.9673 forget=1.3340 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8785 mle=1.5676 pcon=4.9663 forget=1.3446 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8829 mle=1.5583 pcon=4.9653 forget=1.3593 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[Run] lambda=0.2 lr=0.001 epochs=20 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=20, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/20 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  5%|▌         | 1/20 [00:16<05:07, 16.17s/it] 10%|█         | 2/20 [00:25<03:40, 12.25s/it] 15%|█▌        | 3/20 [00:33<02:57, 10.46s/it] 20%|██        | 4/20 [00:42<02:36,  9.81s/it] 25%|██▌       | 5/20 [00:51<02:21,  9.41s/it] 30%|███       | 6/20 [01:01<02:12,  9.47s/it][loss] ep 0 it 0 total=8.2323 mle=1.5618 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4639 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4349 mle=1.7483 pcon=5.2750 forget=1.4116 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5257 mle=1.8429 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3324 mle=1.6800 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2595 mle=1.6257 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4394 mle=1.8018 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0948 mle=1.4467 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2489 mle=1.6388 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5267 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2072 mle=1.6062 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2559 mle=1.6693 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1514 mle=1.5594 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2312 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3117 mle=1.7252 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3749 mle=1.8335 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2556 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2145 mle=1.6701 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3574 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3046 mle=1.7525 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9739 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1376 mle=1.6127 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1876 mle=1.6635 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0960 mle=1.5681 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3340 mle=1.8214 pcon=5.1498 forget=1.3628 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2083 mle=1.7049 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7593 pcon=5.1425 forget=1.3617 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3266 mle=1.8249 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1234 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0825 mle=1.5751 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5309 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1644 mle=1.6601 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2962 mle=1.8091 pcon=5.1176 forget=1.3696 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9094 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1732 mle=1.6865 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0601 mle=1.6086 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1418 mle=1.6930 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2608 mle=1.7997 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4410 mle=1.9765 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2332 mle=1.7908 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1484 mle=1.7135 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2211 mle=1.7675 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1620 mle=1.7198 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9842 mle=1.5559 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1435 mle=1.7059 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1253 mle=1.7005 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5105 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1205 mle=1.6774 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1851 mle=1.7631 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9238 mle=1.4889 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 35%|███▌      | 7/20 [01:10<02:02,  9.45s/it] 40%|████      | 8/20 [01:19<01:53,  9.43s/it] 45%|████▌     | 9/20 [01:28<01:41,  9.18s/it] 50%|█████     | 10/20 [01:37<01:31,  9.17s/it] 55%|█████▌    | 11/20 [01:45<01:18,  8.75s/it] 60%|██████    | 12/20 [01:53<01:09,  8.65s/it] 65%|██████▌   | 13/20 [02:02<01:00,  8.66s/it][loss] ep 6 it 360 total=8.1560 mle=1.7146 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9110 mle=1.5083 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9677 mle=1.5726 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1364 mle=1.7405 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1778 mle=1.7625 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0641 mle=1.6550 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2671 mle=1.8787 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9422 mle=1.5476 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1817 mle=1.7909 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1850 mle=1.7912 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9136 mle=1.5224 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1378 mle=1.7440 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6500 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9672 mle=1.5663 pcon=5.0399 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8275 mle=1.4570 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1990 mle=1.7912 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0389 mle=1.6501 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1599 mle=1.7993 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1263 mle=1.7460 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1454 mle=1.7622 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0240 mle=1.6659 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8727 mle=1.5099 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8221 mle=1.4857 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8197 mle=1.4735 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0396 mle=1.7010 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0423 mle=1.7017 pcon=5.0158 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1322 mle=1.7878 pcon=5.0142 forget=1.3302 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1884 mle=1.8495 pcon=5.0127 forget=1.3262 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1224 mle=1.7762 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8591 mle=1.5338 pcon=5.0097 forget=1.3156 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1315 mle=1.7940 pcon=5.0079 forget=1.3296 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0271 mle=1.7039 pcon=5.0064 forget=1.3168 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5909 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8765 mle=1.5653 pcon=5.0032 forget=1.3081 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8409 mle=1.5265 pcon=5.0015 forget=1.3130 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8603 mle=1.5289 pcon=4.9997 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0723 mle=1.7507 pcon=4.9981 forget=1.3236 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9551 mle=1.6478 pcon=4.9967 forget=1.3107 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9101 mle=1.5879 pcon=4.9946 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8128 mle=1.4981 pcon=4.9928 forget=1.3219 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0416 mle=1.7152 pcon=4.9909 forget=1.3355 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0464 mle=1.7225 pcon=4.9891 forget=1.3348 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8248 mle=1.5207 pcon=4.9877 forget=1.3165 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9137 mle=1.5853 pcon=4.9863 forget=1.3421 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0176 mle=1.7143 pcon=4.9848 forget=1.3186 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0283 mle=1.7073 pcon=4.9832 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9995 mle=1.7036 pcon=4.9819 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1762 mle=1.8334 pcon=4.9803 forget=1.3625 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0166 mle=1.6925 pcon=4.9785 forget=1.3456 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0470 mle=1.7466 pcon=4.9765 forget=1.3239 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 70%|███████   | 14/20 [02:11<00:52,  8.78s/it] 75%|███████▌  | 15/20 [02:19<00:42,  8.57s/it] 80%|████████  | 16/20 [02:28<00:34,  8.63s/it] 85%|████████▌ | 17/20 [02:36<00:25,  8.51s/it] 90%|█████████ | 18/20 [02:45<00:17,  8.51s/it] 95%|█████████▌| 19/20 [02:54<00:08,  8.89s/it]100%|██████████| 20/20 [03:04<00:00,  9.19s/it]100%|██████████| 20/20 [03:04<00:00,  9.24s/it]
[loss] ep 13 it 230 total=7.9945 mle=1.6887 pcon=4.9749 forget=1.3310 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7621 mle=1.4646 pcon=4.9733 forget=1.3242 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0909 mle=1.7790 pcon=4.9718 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9549 mle=1.6508 pcon=4.9703 forget=1.3339 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0300 mle=1.7155 pcon=4.9687 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8924 mle=1.5600 pcon=4.9672 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9567 mle=1.6609 pcon=4.9657 forget=1.3302 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9226 mle=1.6130 pcon=4.9642 forget=1.3454 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9544 mle=1.6504 pcon=4.9622 forget=1.3418 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8685 mle=1.5543 pcon=4.9607 forget=1.3535 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8792 mle=1.5519 pcon=4.9591 forget=1.3681 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9679 mle=1.6493 pcon=4.9573 forget=1.3612 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9008 mle=1.5869 pcon=4.9558 forget=1.3580 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=8.0132 mle=1.6831 pcon=4.9544 forget=1.3757 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0610 mle=1.7397 pcon=4.9529 forget=1.3684 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8317 mle=1.5154 pcon=4.9514 forget=1.3649 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8510 mle=1.5363 pcon=4.9496 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.2133 mle=1.8824 pcon=4.9478 forget=1.3831 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.9052 mle=1.5922 pcon=4.9463 forget=1.3667 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=7.8265 mle=1.5136 pcon=4.9445 forget=1.3684 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8338 mle=1.5088 pcon=4.9430 forget=1.3819 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6867 mle=1.3825 pcon=4.9412 forget=1.3630 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8058 mle=1.4978 pcon=4.9398 forget=1.3682 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.9107 mle=1.6061 pcon=4.9382 forget=1.3664 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.2499 mle=1.9487 pcon=4.9363 forget=1.3649 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2745 mle=1.9524 pcon=4.9344 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8425 mle=1.5184 pcon=4.9328 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 20 total=8.0932 mle=1.7685 pcon=4.9314 forget=1.3933 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0852 mle=1.7767 pcon=4.9301 forget=1.3784 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.8244 mle=1.5024 pcon=4.9282 forget=1.3938 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=8.0544 mle=1.7479 pcon=4.9266 forget=1.3800 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1876 mle=1.8782 pcon=4.9249 forget=1.3845 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.1301 mle=1.8261 pcon=4.9233 forget=1.3806 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.9428 mle=1.6313 pcon=4.9219 forget=1.3897 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9372 mle=1.6182 pcon=4.9202 forget=1.3988 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 30 total=7.7618 mle=1.4649 pcon=4.9187 forget=1.3782 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0740 mle=1.7447 pcon=4.9173 forget=1.4120 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0905 mle=1.7694 pcon=4.9159 forget=1.4051 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9388 mle=1.6299 pcon=4.9146 forget=1.3942 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.9226 mle=1.6130 pcon=4.9131 forget=1.3965 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.9916 mle=1.6886 pcon=4.9117 forget=1.3914 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=8.0361 mle=1.7270 pcon=4.9103 forget=1.3988 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8835 mle=1.5708 pcon=4.9092 forget=1.4035 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.9515 mle=1.6451 pcon=4.9080 forget=1.3984 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.9584 mle=1.6493 pcon=4.9066 forget=1.4025 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.8611 mle=1.5504 pcon=4.9054 forget=1.4054 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.8245 mle=1.5191 pcon=4.9040 forget=1.4014 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.9854 mle=1.6806 pcon=4.9028 forget=1.4021 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.9232 mle=1.6100 pcon=4.9020 forget=1.4112 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.9157 mle=1.6110 pcon=4.9014 forget=1.4033 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[Run] lambda=0.2 lr=0.001 epochs=25 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=25, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/25 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  4%|▍         | 1/25 [00:14<05:41, 14.23s/it]  8%|▊         | 2/25 [00:22<04:07, 10.76s/it] 12%|█▏        | 3/25 [00:30<03:28,  9.47s/it] 16%|█▌        | 4/25 [00:38<03:07,  8.92s/it] 20%|██        | 5/25 [00:46<02:53,  8.70s/it] 24%|██▍       | 6/25 [00:55<02:45,  8.70s/it][loss] ep 0 it 0 total=8.2323 mle=1.5618 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4639 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4349 mle=1.7483 pcon=5.2750 forget=1.4116 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5257 mle=1.8429 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3324 mle=1.6800 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2595 mle=1.6257 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4394 mle=1.8018 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0948 mle=1.4467 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2489 mle=1.6388 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5267 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2072 mle=1.6062 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2559 mle=1.6693 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1514 mle=1.5594 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2312 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3117 mle=1.7252 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3748 mle=1.8334 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2557 mle=1.6844 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3575 mle=1.8061 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3046 mle=1.7526 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9739 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1376 mle=1.6127 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1875 mle=1.6634 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0958 mle=1.5679 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3342 mle=1.8215 pcon=5.1498 forget=1.3628 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7049 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7594 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3264 mle=1.8246 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1235 mle=1.6196 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0828 mle=1.5754 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1644 mle=1.6601 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2964 mle=1.8093 pcon=5.1176 forget=1.3696 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4520 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1729 mle=1.6863 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0600 mle=1.6085 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1418 mle=1.6930 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2608 mle=1.7998 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4409 mle=1.9764 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2330 mle=1.7906 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1484 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2211 mle=1.7675 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1621 mle=1.7199 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9844 mle=1.5560 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1433 mle=1.7057 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1251 mle=1.7003 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5105 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1206 mle=1.6774 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1853 mle=1.7632 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9237 mle=1.4888 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 28%|██▊       | 7/25 [01:04<02:37,  8.75s/it] 32%|███▏      | 8/25 [01:12<02:27,  8.67s/it] 36%|███▌      | 9/25 [01:21<02:18,  8.65s/it] 40%|████      | 10/25 [01:32<02:21,  9.42s/it] 44%|████▍     | 11/25 [01:46<02:28, 10.63s/it] 48%|████▊     | 12/25 [01:55<02:14, 10.36s/it] 52%|█████▏    | 13/25 [02:04<01:58,  9.85s/it][loss] ep 6 it 360 total=8.1561 mle=1.7148 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9110 mle=1.5083 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9675 mle=1.5724 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1365 mle=1.7406 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1778 mle=1.7624 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0640 mle=1.6549 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2671 mle=1.8787 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9422 mle=1.5477 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1816 mle=1.7907 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1850 mle=1.7912 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9136 mle=1.5224 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1378 mle=1.7440 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6501 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9672 mle=1.5663 pcon=5.0400 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8272 mle=1.4567 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1990 mle=1.7911 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6502 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1602 mle=1.7996 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1264 mle=1.7461 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1455 mle=1.7623 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0237 mle=1.6656 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8725 mle=1.5098 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8219 mle=1.4855 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8196 mle=1.4733 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0395 mle=1.7010 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0422 mle=1.7016 pcon=5.0157 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1247 mle=1.7803 pcon=5.0142 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1885 mle=1.8497 pcon=5.0126 forget=1.3262 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1221 mle=1.7759 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8591 mle=1.5339 pcon=5.0097 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1317 mle=1.7942 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0271 mle=1.7039 pcon=5.0064 forget=1.3168 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5910 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8765 mle=1.5653 pcon=5.0032 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8408 mle=1.5265 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8601 mle=1.5288 pcon=4.9997 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0720 mle=1.7505 pcon=4.9981 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9551 mle=1.6479 pcon=4.9966 forget=1.3106 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9098 mle=1.5878 pcon=4.9945 forget=1.3275 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8124 mle=1.4980 pcon=4.9927 forget=1.3218 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0406 mle=1.7143 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0465 mle=1.7228 pcon=4.9890 forget=1.3346 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8248 mle=1.5209 pcon=4.9875 forget=1.3164 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9134 mle=1.5853 pcon=4.9861 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0164 mle=1.7132 pcon=4.9846 forget=1.3186 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0275 mle=1.7068 pcon=4.9830 forget=1.3377 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9985 mle=1.7028 pcon=4.9816 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1729 mle=1.8303 pcon=4.9800 forget=1.3626 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0158 mle=1.6919 pcon=4.9781 forget=1.3458 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0451 mle=1.7448 pcon=4.9761 forget=1.3243 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 56%|█████▌    | 14/25 [02:12<01:43,  9.37s/it] 60%|██████    | 15/25 [02:21<01:31,  9.11s/it] 64%|██████▍   | 16/25 [02:29<01:18,  8.76s/it] 68%|██████▊   | 17/25 [02:37<01:08,  8.55s/it] 72%|███████▏  | 18/25 [02:45<00:58,  8.40s/it] 76%|███████▌  | 19/25 [02:53<00:49,  8.27s/it] 80%|████████  | 20/25 [03:01<00:40,  8.20s/it][loss] ep 13 it 230 total=7.9914 mle=1.6861 pcon=4.9744 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7611 mle=1.4634 pcon=4.9727 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0897 mle=1.7778 pcon=4.9711 forget=1.3408 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9537 mle=1.6491 pcon=4.9695 forget=1.3350 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0279 mle=1.7132 pcon=4.9677 forget=1.3470 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8936 mle=1.5611 pcon=4.9661 forget=1.3664 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9556 mle=1.6590 pcon=4.9644 forget=1.3323 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9243 mle=1.6144 pcon=4.9626 forget=1.3472 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9491 mle=1.6441 pcon=4.9604 forget=1.3445 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8667 mle=1.5516 pcon=4.9586 forget=1.3564 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8791 mle=1.5515 pcon=4.9568 forget=1.3708 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9613 mle=1.6427 pcon=4.9546 forget=1.3640 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.8950 mle=1.5812 pcon=4.9527 forget=1.3612 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9996 mle=1.6704 pcon=4.9508 forget=1.3784 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0497 mle=1.7293 pcon=4.9488 forget=1.3715 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8319 mle=1.5152 pcon=4.9468 forget=1.3698 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8574 mle=1.5435 pcon=4.9445 forget=1.3694 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.2040 mle=1.8744 pcon=4.9422 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8889 mle=1.5781 pcon=4.9400 forget=1.3708 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=7.8426 mle=1.5306 pcon=4.9375 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8260 mle=1.5032 pcon=4.9352 forget=1.3875 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6773 mle=1.3753 pcon=4.9327 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8191 mle=1.5137 pcon=4.9304 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8908 mle=1.5906 pcon=4.9279 forget=1.3724 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.2270 mle=1.9309 pcon=4.9251 forget=1.3710 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2753 mle=1.9600 pcon=4.9222 forget=1.3931 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8477 mle=1.5321 pcon=4.9195 forget=1.3961 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.1031 mle=1.7877 pcon=4.9170 forget=1.3983 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0638 mle=1.7637 pcon=4.9146 forget=1.3854 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.8068 mle=1.4953 pcon=4.9116 forget=1.3999 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9895 mle=1.6976 pcon=4.9089 forget=1.3830 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1329 mle=1.8366 pcon=4.9059 forget=1.3904 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.1006 mle=1.8124 pcon=4.9031 forget=1.3851 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.9218 mle=1.6273 pcon=4.9003 forget=1.3942 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9174 mle=1.6166 pcon=4.8973 forget=1.4035 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7451 mle=1.4694 pcon=4.8946 forget=1.3811 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0434 mle=1.7390 pcon=4.8919 forget=1.4125 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0756 mle=1.7817 pcon=4.8891 forget=1.4048 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9359 mle=1.6508 pcon=4.8865 forget=1.3986 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8565 mle=1.5757 pcon=4.8838 forget=1.3970 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.9131 mle=1.6398 pcon=4.8811 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.9618 mle=1.6870 pcon=4.8783 forget=1.3965 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8710 mle=1.5952 pcon=4.8759 forget=1.3998 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.9346 mle=1.6637 pcon=4.8734 forget=1.3975 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.9325 mle=1.6605 pcon=4.8707 forget=1.4014 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.8075 mle=1.5390 pcon=4.8682 forget=1.4003 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7829 mle=1.5208 pcon=4.8655 forget=1.3966 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.9284 mle=1.6684 pcon=4.8630 forget=1.3970 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.9193 mle=1.6522 pcon=4.8609 forget=1.4063 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.8434 mle=1.5909 pcon=4.8587 forget=1.3938 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6772 mle=1.4315 pcon=4.8565 forget=1.3892 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.9135 mle=1.6772 pcon=4.8542 forget=1.3821 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.8230 mle=1.5622 pcon=4.8519 forget=1.4089 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=7.8509 mle=1.6094 pcon=4.8497 forget=1.3918 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.8478 mle=1.6046 pcon=4.8475 forget=1.3957 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 84%|████████▍ | 21/25 [03:09<00:33,  8.27s/it] 88%|████████▊ | 22/25 [03:17<00:24,  8.21s/it] 92%|█████████▏| 23/25 [03:25<00:16,  8.10s/it] 96%|█████████▌| 24/25 [03:33<00:08,  8.03s/it]100%|██████████| 25/25 [03:41<00:00,  8.15s/it]100%|██████████| 25/25 [03:41<00:00,  8.88s/it]
[loss] ep 20 it 250 total=7.9838 mle=1.7384 pcon=4.8453 forget=1.4001 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=8.0061 mle=1.7650 pcon=4.8434 forget=1.3977 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.9452 mle=1.7160 pcon=4.8412 forget=1.3879 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5769 mle=1.3471 pcon=4.8389 forget=1.3908 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.8547 mle=1.6379 pcon=4.8368 forget=1.3800 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.8298 mle=1.5917 pcon=4.8348 forget=1.4033 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.9099 mle=1.6802 pcon=4.8328 forget=1.3968 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.7875 mle=1.5765 pcon=4.8307 forget=1.3804 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.1582 mle=1.9197 pcon=4.8289 forget=1.4096 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.9419 mle=1.7201 pcon=4.8269 forget=1.3950 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.9494 mle=1.7373 pcon=4.8250 forget=1.3872 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.8526 mle=1.6323 pcon=4.8232 forget=1.3971 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.8665 mle=1.6574 pcon=4.8214 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.9208 mle=1.7081 pcon=4.8196 forget=1.3931 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.8262 mle=1.6100 pcon=4.8178 forget=1.3984 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.9518 mle=1.7362 pcon=4.8162 forget=1.3995 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.7751 mle=1.5688 pcon=4.8147 forget=1.3916 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.7363 mle=1.5146 pcon=4.8133 forget=1.4084 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.9520 mle=1.7354 pcon=4.8116 forget=1.4050 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.8139 mle=1.6189 pcon=4.8102 forget=1.3848 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.7986 mle=1.6122 pcon=4.8086 forget=1.3778 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.9910 mle=1.7762 pcon=4.8071 forget=1.4078 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.7711 mle=1.5713 pcon=4.8056 forget=1.3942 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.7615 mle=1.5759 pcon=4.8043 forget=1.3813 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.9043 mle=1.7187 pcon=4.8029 forget=1.3827 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.9601 mle=1.7696 pcon=4.8014 forget=1.3892 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.7030 mle=1.5285 pcon=4.8001 forget=1.3744 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.7998 mle=1.6231 pcon=4.7990 forget=1.3776 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.9616 mle=1.7751 pcon=4.7977 forget=1.3888 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.7853 mle=1.5901 pcon=4.7964 forget=1.3988 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.8058 mle=1.6179 pcon=4.7953 forget=1.3926 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.8112 mle=1.6214 pcon=4.7943 forget=1.3956 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.8791 mle=1.6986 pcon=4.7929 forget=1.3876 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.7687 mle=1.5889 pcon=4.7917 forget=1.3881 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e25-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[Run] lambda=0.2 lr=0.001 epochs=30 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=30, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/30 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  3%|▎         | 1/30 [00:14<06:48, 14.08s/it]  7%|▋         | 2/30 [00:22<05:08, 11.01s/it] 10%|█         | 3/30 [00:31<04:27,  9.91s/it] 13%|█▎        | 4/30 [00:40<04:05,  9.45s/it] 17%|█▋        | 5/30 [00:48<03:49,  9.17s/it] 20%|██        | 6/30 [00:57<03:36,  9.03s/it][loss] ep 0 it 0 total=8.2326 mle=1.5621 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4637 mle=1.7910 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4348 mle=1.7483 pcon=5.2750 forget=1.4115 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5253 mle=1.8425 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3321 mle=1.6798 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2594 mle=1.6256 pcon=5.2557 forget=1.3781 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4393 mle=1.8017 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0947 mle=1.4466 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2486 mle=1.6386 pcon=5.2377 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5268 pcon=5.2322 forget=1.3817 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2073 mle=1.6064 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2557 mle=1.6691 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1516 mle=1.5596 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2311 mle=1.6334 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3117 mle=1.7252 pcon=5.2049 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3823 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3771 mle=1.8357 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2556 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2143 mle=1.6699 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3573 mle=1.8058 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3046 mle=1.7527 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9742 mle=1.4276 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1373 mle=1.6124 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1875 mle=1.6634 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0958 mle=1.5680 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0676 mle=1.5598 pcon=5.1539 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3406 mle=1.8280 pcon=5.1498 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2085 mle=1.7051 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2635 mle=1.7593 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3266 mle=1.8248 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1234 mle=1.6195 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0828 mle=1.5754 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0056 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2289 mle=1.7059 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1643 mle=1.6600 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2963 mle=1.8092 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1730 mle=1.6863 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0605 mle=1.6089 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1416 mle=1.6927 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2605 mle=1.7995 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4410 mle=1.9765 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2326 mle=1.7902 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1483 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2210 mle=1.7675 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1615 mle=1.7193 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9846 mle=1.5563 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1433 mle=1.7056 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1250 mle=1.7002 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9364 mle=1.5105 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1206 mle=1.6774 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1852 mle=1.7632 pcon=5.0721 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9236 mle=1.4887 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 23%|██▎       | 7/30 [01:06<03:23,  8.83s/it] 27%|██▋       | 8/30 [01:14<03:11,  8.70s/it] 30%|███       | 9/30 [01:22<03:00,  8.60s/it] 33%|███▎      | 10/30 [01:31<02:53,  8.68s/it] 37%|███▋      | 11/30 [01:41<02:49,  8.93s/it] 40%|████      | 12/30 [01:49<02:38,  8.80s/it] 43%|████▎     | 13/30 [01:58<02:29,  8.80s/it][loss] ep 6 it 360 total=8.1565 mle=1.7151 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9111 mle=1.5085 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9675 mle=1.5724 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1365 mle=1.7406 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1777 mle=1.7623 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0639 mle=1.6548 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2671 mle=1.8787 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9423 mle=1.5478 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1795 mle=1.7886 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1849 mle=1.7911 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9139 mle=1.5228 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1378 mle=1.7440 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0298 mle=1.6502 pcon=5.0418 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9672 mle=1.5664 pcon=5.0399 forget=1.3609 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8274 mle=1.4569 pcon=5.0380 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1988 mle=1.7910 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6502 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1597 mle=1.7991 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1261 mle=1.7457 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0293 forget=1.3282 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1453 mle=1.7621 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0238 mle=1.6657 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8726 mle=1.5099 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8245 mle=1.4881 pcon=5.0205 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8197 mle=1.4734 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0397 mle=1.7011 pcon=5.0174 forget=1.3211 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0422 mle=1.7016 pcon=5.0157 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1320 mle=1.7876 pcon=5.0142 forget=1.3302 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1883 mle=1.8496 pcon=5.0127 forget=1.3261 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1226 mle=1.7764 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8593 mle=1.5341 pcon=5.0096 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1316 mle=1.7942 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0272 mle=1.7040 pcon=5.0064 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5910 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8764 mle=1.5653 pcon=5.0032 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8410 mle=1.5267 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8601 mle=1.5287 pcon=4.9996 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0721 mle=1.7506 pcon=4.9980 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9548 mle=1.6476 pcon=4.9966 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9097 mle=1.5877 pcon=4.9945 forget=1.3275 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8122 mle=1.4979 pcon=4.9927 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0403 mle=1.7141 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0460 mle=1.7225 pcon=4.9890 forget=1.3346 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8247 mle=1.5209 pcon=4.9875 forget=1.3163 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9135 mle=1.5854 pcon=4.9861 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0234 mle=1.7202 pcon=4.9846 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0271 mle=1.7064 pcon=4.9829 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9981 mle=1.7025 pcon=4.9815 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1717 mle=1.8291 pcon=4.9799 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0152 mle=1.6913 pcon=4.9780 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0445 mle=1.7443 pcon=4.9759 forget=1.3244 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 47%|████▋     | 14/30 [02:07<02:20,  8.76s/it] 50%|█████     | 15/30 [02:15<02:09,  8.66s/it] 53%|█████▎    | 16/30 [02:24<02:02,  8.74s/it] 57%|█████▋    | 17/30 [02:33<01:54,  8.83s/it] 60%|██████    | 18/30 [02:42<01:46,  8.89s/it] 63%|██████▎   | 19/30 [02:51<01:38,  8.97s/it] 67%|██████▋   | 20/30 [03:00<01:29,  8.93s/it][loss] ep 13 it 230 total=7.9905 mle=1.6855 pcon=4.9742 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7603 mle=1.4626 pcon=4.9724 forget=1.3252 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0890 mle=1.7772 pcon=4.9708 forget=1.3411 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9525 mle=1.6479 pcon=4.9692 forget=1.3355 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0270 mle=1.7123 pcon=4.9673 forget=1.3474 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8938 mle=1.5612 pcon=4.9656 forget=1.3669 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9547 mle=1.6577 pcon=4.9638 forget=1.3331 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9225 mle=1.6126 pcon=4.9620 forget=1.3480 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9464 mle=1.6410 pcon=4.9597 forget=1.3457 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8653 mle=1.5500 pcon=4.9577 forget=1.3576 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8860 mle=1.5584 pcon=4.9557 forget=1.3719 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9557 mle=1.6372 pcon=4.9534 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9025 mle=1.5888 pcon=4.9513 forget=1.3625 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9934 mle=1.6646 pcon=4.9493 forget=1.3795 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0486 mle=1.7288 pcon=4.9470 forget=1.3727 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8248 mle=1.5083 pcon=4.9448 forget=1.3717 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8593 mle=1.5459 pcon=4.9422 forget=1.3712 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.2012 mle=1.8725 pcon=4.9396 forget=1.3891 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8813 mle=1.5717 pcon=4.9371 forget=1.3725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=7.8512 mle=1.5400 pcon=4.9343 forget=1.3768 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8195 mle=1.4982 pcon=4.9317 forget=1.3896 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6748 mle=1.3745 pcon=4.9288 forget=1.3715 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8307 mle=1.5267 pcon=4.9262 forget=1.3778 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8746 mle=1.5768 pcon=4.9232 forget=1.3746 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.2097 mle=1.9165 pcon=4.9200 forget=1.3732 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2624 mle=1.9503 pcon=4.9168 forget=1.3952 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8485 mle=1.5374 pcon=4.9138 forget=1.3974 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.0970 mle=1.7862 pcon=4.9109 forget=1.3999 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0567 mle=1.7612 pcon=4.9081 forget=1.3873 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.7984 mle=1.4922 pcon=4.9048 forget=1.4014 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9633 mle=1.6791 pcon=4.9016 forget=1.3826 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1097 mle=1.8198 pcon=4.8982 forget=1.3918 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.1006 mle=1.8201 pcon=4.8951 forget=1.3854 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.9064 mle=1.6201 pcon=4.8919 forget=1.3944 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9052 mle=1.6137 pcon=4.8886 forget=1.4029 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7380 mle=1.4716 pcon=4.8855 forget=1.3809 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0403 mle=1.7477 pcon=4.8825 forget=1.4101 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0781 mle=1.7964 pcon=4.8794 forget=1.4023 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9248 mle=1.6512 pcon=4.8766 forget=1.3971 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8304 mle=1.5630 pcon=4.8736 forget=1.3938 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.8891 mle=1.6295 pcon=4.8705 forget=1.3891 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.9270 mle=1.6678 pcon=4.8675 forget=1.3917 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8507 mle=1.5919 pcon=4.8648 forget=1.3939 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.9307 mle=1.6754 pcon=4.8621 forget=1.3932 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.9055 mle=1.6504 pcon=4.8591 forget=1.3960 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7847 mle=1.5352 pcon=4.8564 forget=1.3931 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7736 mle=1.5304 pcon=4.8535 forget=1.3896 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8930 mle=1.6532 pcon=4.8507 forget=1.3891 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.8910 mle=1.6467 pcon=4.8484 forget=1.3959 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.8119 mle=1.5831 pcon=4.8461 forget=1.3828 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6608 mle=1.4396 pcon=4.8436 forget=1.3776 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.8707 mle=1.6586 pcon=4.8411 forget=1.3711 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.8036 mle=1.5688 pcon=4.8386 forget=1.3961 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=7.8080 mle=1.5936 pcon=4.8361 forget=1.3782 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.8124 mle=1.5968 pcon=4.8337 forget=1.3819 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 70%|███████   | 21/30 [03:10<01:22,  9.18s/it] 73%|███████▎  | 22/30 [03:21<01:18,  9.77s/it] 77%|███████▋  | 23/30 [03:30<01:07,  9.59s/it] 80%|████████  | 24/30 [03:39<00:56,  9.42s/it] 83%|████████▎ | 25/30 [03:49<00:46,  9.36s/it] 87%|████████▋ | 26/30 [03:58<00:37,  9.29s/it] 90%|█████████ | 27/30 [04:07<00:27,  9.23s/it][loss] ep 20 it 250 total=7.9630 mle=1.7456 pcon=4.8314 forget=1.3860 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.9720 mle=1.7620 pcon=4.8292 forget=1.3808 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.8850 mle=1.6880 pcon=4.8269 forget=1.3701 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5589 mle=1.3626 pcon=4.8244 forget=1.3719 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.8233 mle=1.6416 pcon=4.8221 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7991 mle=1.5942 pcon=4.8199 forget=1.3849 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.8591 mle=1.6643 pcon=4.8178 forget=1.3771 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.7292 mle=1.5548 pcon=4.8155 forget=1.3589 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.1103 mle=1.9082 pcon=4.8135 forget=1.3886 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8886 mle=1.7062 pcon=4.8113 forget=1.3711 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.8916 mle=1.7212 pcon=4.8093 forget=1.3612 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.8136 mle=1.6327 pcon=4.8073 forget=1.3736 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.8353 mle=1.6666 pcon=4.8053 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.8796 mle=1.7101 pcon=4.8033 forget=1.3661 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.7426 mle=1.5725 pcon=4.8013 forget=1.3688 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.8990 mle=1.7277 pcon=4.7995 forget=1.3717 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.7251 mle=1.5656 pcon=4.7979 forget=1.3616 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.6847 mle=1.5116 pcon=4.7963 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.8883 mle=1.7168 pcon=4.7944 forget=1.3772 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.7849 mle=1.6381 pcon=4.7928 forget=1.3541 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.7567 mle=1.6186 pcon=4.7909 forget=1.3472 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.9828 mle=1.8148 pcon=4.7892 forget=1.3788 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.7158 mle=1.5696 pcon=4.7875 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.7051 mle=1.5724 pcon=4.7860 forget=1.3466 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.8538 mle=1.7210 pcon=4.7845 forget=1.3484 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.8691 mle=1.7349 pcon=4.7827 forget=1.3515 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.6330 mle=1.5134 pcon=4.7812 forget=1.3383 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.7572 mle=1.6367 pcon=4.7799 forget=1.3407 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.9018 mle=1.7696 pcon=4.7783 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.7438 mle=1.6022 pcon=4.7768 forget=1.3647 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.7563 mle=1.6276 pcon=4.7755 forget=1.3532 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.7563 mle=1.6256 pcon=4.7743 forget=1.3564 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.8084 mle=1.6916 pcon=4.7727 forget=1.3440 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.7206 mle=1.6012 pcon=4.7713 forget=1.3481 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 25 it 0 total=7.8320 mle=1.7152 pcon=4.7700 forget=1.3468 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.7825 mle=1.6482 pcon=4.7687 forget=1.3656 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.8654 mle=1.7608 pcon=4.7673 forget=1.3372 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.8005 mle=1.6903 pcon=4.7662 forget=1.3440 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.9122 mle=1.8034 pcon=4.7649 forget=1.3439 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.7005 mle=1.5962 pcon=4.7638 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.7384 mle=1.6344 pcon=4.7626 forget=1.3414 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.8751 mle=1.7720 pcon=4.7615 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 26 it 10 total=7.8191 mle=1.7262 pcon=4.7605 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.8480 mle=1.7304 pcon=4.7592 forget=1.3584 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.8293 mle=1.7126 pcon=4.7581 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.6961 mle=1.5984 pcon=4.7569 forget=1.3408 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.8275 mle=1.7296 pcon=4.7560 forget=1.3419 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.7433 mle=1.6426 pcon=4.7553 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.9491 mle=1.8110 pcon=4.7541 forget=1.3840 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.9642 mle=1.8519 pcon=4.7532 forget=1.3591 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 27 it 20 total=7.6294 mle=1.5429 pcon=4.7524 forget=1.3341 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.7270 mle=1.6272 pcon=4.7513 forget=1.3485 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 93%|█████████▎| 28/30 [04:16<00:18,  9.27s/it] 97%|█████████▋| 29/30 [04:26<00:09,  9.37s/it]100%|██████████| 30/30 [04:35<00:00,  9.31s/it]100%|██████████| 30/30 [04:35<00:00,  9.18s/it]
[loss] ep 27 it 120 total=7.7823 mle=1.7091 pcon=4.7506 forget=1.3227 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.6234 mle=1.5433 pcon=4.7497 forget=1.3304 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.7687 mle=1.6656 pcon=4.7491 forget=1.3541 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.6858 mle=1.5817 pcon=4.7482 forget=1.3558 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.7461 mle=1.6479 pcon=4.7476 forget=1.3505 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.6629 mle=1.5707 pcon=4.7469 forget=1.3454 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 28 it 30 total=7.7316 mle=1.6537 pcon=4.7463 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.8240 mle=1.7420 pcon=4.7454 forget=1.3366 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.5326 mle=1.4390 pcon=4.7448 forget=1.3487 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.5858 mle=1.4969 pcon=4.7440 forget=1.3448 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.6990 mle=1.6115 pcon=4.7433 forget=1.3442 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7752 mle=1.6855 pcon=4.7428 forget=1.3470 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.6062 mle=1.5152 pcon=4.7420 forget=1.3490 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7776 mle=1.6983 pcon=4.7412 forget=1.3381 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 29 it 40 total=7.7187 mle=1.6177 pcon=4.7405 forget=1.3605 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6460 mle=1.5776 pcon=4.7399 forget=1.3285 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.6167 mle=1.5462 pcon=4.7393 forget=1.3312 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.9952 mle=1.8933 pcon=4.7385 forget=1.3634 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.7631 mle=1.6715 pcon=4.7381 forget=1.3535 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.7252 mle=1.6418 pcon=4.7373 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7499 mle=1.6809 pcon=4.7369 forget=1.3322 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e30-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[Run] lambda=0.2 lr=0.001 epochs=35 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=35, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/35 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  3%|▎         | 1/35 [00:12<07:00, 12.36s/it]  6%|▌         | 2/35 [00:21<05:45, 10.48s/it]  9%|▊         | 3/35 [00:29<04:59,  9.37s/it] 11%|█▏        | 4/35 [00:37<04:35,  8.88s/it] 14%|█▍        | 5/35 [00:45<04:16,  8.57s/it] 17%|█▋        | 6/35 [00:53<03:59,  8.27s/it][loss] ep 0 it 0 total=8.2324 mle=1.5619 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3186 mle=1.6306 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4640 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4347 mle=1.7482 pcon=5.2750 forget=1.4115 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5258 mle=1.8430 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3321 mle=1.6798 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2594 mle=1.6256 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4395 mle=1.8019 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0947 mle=1.4465 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2488 mle=1.6387 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1406 mle=1.5266 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2073 mle=1.6063 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2560 mle=1.6695 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1515 mle=1.5595 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2311 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3116 mle=1.7251 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3769 mle=1.8356 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2557 mle=1.6843 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3574 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3045 mle=1.7525 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9740 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1377 mle=1.6128 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1874 mle=1.6633 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0959 mle=1.5680 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3406 mle=1.8280 pcon=5.1498 forget=1.3628 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7050 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7594 pcon=5.1425 forget=1.3617 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3264 mle=1.8246 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1234 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0827 mle=1.5752 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1647 mle=1.6604 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2963 mle=1.8091 pcon=5.1176 forget=1.3696 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9094 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1730 mle=1.6863 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0602 mle=1.6086 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1416 mle=1.6928 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2608 mle=1.7998 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4409 mle=1.9764 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2332 mle=1.7908 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1483 mle=1.7133 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2212 mle=1.7676 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1621 mle=1.7199 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9844 mle=1.5560 pcon=5.0848 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1434 mle=1.7058 pcon=5.0822 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1253 mle=1.7005 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9366 mle=1.5106 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1205 mle=1.6773 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1851 mle=1.7630 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9239 mle=1.4890 pcon=5.0699 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 20%|██        | 7/35 [01:01<03:49,  8.19s/it] 23%|██▎       | 8/35 [01:09<03:37,  8.06s/it] 26%|██▌       | 9/35 [01:17<03:27,  7.98s/it] 29%|██▊       | 10/35 [01:24<03:18,  7.95s/it] 31%|███▏      | 11/35 [01:32<03:09,  7.91s/it] 34%|███▍      | 12/35 [01:40<03:03,  7.97s/it] 37%|███▋      | 13/35 [01:48<02:54,  7.93s/it][loss] ep 6 it 360 total=8.1561 mle=1.7147 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9110 mle=1.5084 pcon=5.0651 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9676 mle=1.5725 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1364 mle=1.7405 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1779 mle=1.7626 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0641 mle=1.6550 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2670 mle=1.8786 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9423 mle=1.5477 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1816 mle=1.7907 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1850 mle=1.7912 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9134 mle=1.5223 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1379 mle=1.7441 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0299 mle=1.6502 pcon=5.0418 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9673 mle=1.5664 pcon=5.0400 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8273 mle=1.4568 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1989 mle=1.7910 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6502 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1601 mle=1.7995 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1264 mle=1.7461 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8339 mle=1.4882 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1456 mle=1.7623 pcon=5.0262 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0240 mle=1.6659 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8727 mle=1.5099 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8220 mle=1.4856 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8196 mle=1.4733 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0395 mle=1.7009 pcon=5.0174 forget=1.3211 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0423 mle=1.7016 pcon=5.0158 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1247 mle=1.7803 pcon=5.0143 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1884 mle=1.8495 pcon=5.0127 forget=1.3261 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1222 mle=1.7760 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8592 mle=1.5340 pcon=5.0097 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1315 mle=1.7940 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0271 mle=1.7040 pcon=5.0065 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5910 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8764 mle=1.5652 pcon=5.0032 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8408 mle=1.5265 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8601 mle=1.5288 pcon=4.9997 forget=1.3316 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0723 mle=1.7509 pcon=4.9981 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9550 mle=1.6478 pcon=4.9966 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9097 mle=1.5877 pcon=4.9945 forget=1.3275 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8121 mle=1.4977 pcon=4.9927 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0399 mle=1.7137 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0463 mle=1.7228 pcon=4.9890 forget=1.3345 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8247 mle=1.5209 pcon=4.9875 forget=1.3163 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9135 mle=1.5855 pcon=4.9861 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0235 mle=1.7203 pcon=4.9845 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0269 mle=1.7062 pcon=4.9829 forget=1.3377 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9981 mle=1.7025 pcon=4.9815 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1712 mle=1.8286 pcon=4.9799 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0152 mle=1.6913 pcon=4.9779 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0441 mle=1.7438 pcon=4.9758 forget=1.3244 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 40%|████      | 14/35 [01:57<02:49,  8.05s/it] 43%|████▎     | 15/35 [02:04<02:39,  7.99s/it] 46%|████▌     | 16/35 [02:12<02:31,  7.99s/it] 49%|████▊     | 17/35 [02:21<02:25,  8.08s/it] 51%|█████▏    | 18/35 [02:29<02:18,  8.13s/it] 54%|█████▍    | 19/35 [02:37<02:09,  8.11s/it] 57%|█████▋    | 20/35 [02:45<02:03,  8.21s/it][loss] ep 13 it 230 total=7.9901 mle=1.6851 pcon=4.9741 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7602 mle=1.4625 pcon=4.9723 forget=1.3254 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0890 mle=1.7771 pcon=4.9707 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9529 mle=1.6481 pcon=4.9690 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0271 mle=1.7123 pcon=4.9672 forget=1.3476 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8940 mle=1.5615 pcon=4.9654 forget=1.3671 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9546 mle=1.6575 pcon=4.9636 forget=1.3335 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9218 mle=1.6118 pcon=4.9617 forget=1.3483 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9453 mle=1.6396 pcon=4.9593 forget=1.3463 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8733 mle=1.5579 pcon=4.9573 forget=1.3582 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8856 mle=1.5581 pcon=4.9552 forget=1.3724 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9542 mle=1.6357 pcon=4.9528 forget=1.3657 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9018 mle=1.5881 pcon=4.9507 forget=1.3631 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9898 mle=1.6612 pcon=4.9485 forget=1.3800 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0412 mle=1.7217 pcon=4.9461 forget=1.3734 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8310 mle=1.5145 pcon=4.9438 forget=1.3726 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8655 mle=1.5524 pcon=4.9411 forget=1.3720 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.1987 mle=1.8706 pcon=4.9383 forget=1.3898 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8801 mle=1.5709 pcon=4.9357 forget=1.3734 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 16 it 10 total=7.8550 mle=1.5443 pcon=4.9327 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8178 mle=1.4973 pcon=4.9299 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6740 mle=1.3746 pcon=4.9269 forget=1.3725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8349 mle=1.5316 pcon=4.9241 forget=1.3792 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8734 mle=1.5768 pcon=4.9210 forget=1.3757 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.2031 mle=1.9111 pcon=4.9176 forget=1.3743 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2526 mle=1.9422 pcon=4.9142 forget=1.3962 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8475 mle=1.5386 pcon=4.9110 forget=1.3979 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.0920 mle=1.7834 pcon=4.9081 forget=1.4006 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0526 mle=1.7593 pcon=4.9051 forget=1.3881 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.7965 mle=1.4929 pcon=4.9017 forget=1.4019 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9532 mle=1.6726 pcon=4.8984 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1061 mle=1.8190 pcon=4.8949 forget=1.3922 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.1002 mle=1.8234 pcon=4.8916 forget=1.3853 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8997 mle=1.6174 pcon=4.8883 forget=1.3940 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9008 mle=1.6140 pcon=4.8848 forget=1.4019 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7376 mle=1.4760 pcon=4.8817 forget=1.3799 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0276 mle=1.7405 pcon=4.8786 forget=1.4084 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0806 mle=1.8045 pcon=4.8754 forget=1.4007 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9222 mle=1.6544 pcon=4.8725 forget=1.3954 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8191 mle=1.5583 pcon=4.8694 forget=1.3914 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.8803 mle=1.6275 pcon=4.8663 forget=1.3864 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.9069 mle=1.6553 pcon=4.8632 forget=1.3884 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8412 mle=1.5908 pcon=4.8605 forget=1.3899 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.9168 mle=1.6691 pcon=4.8577 forget=1.3900 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.8880 mle=1.6418 pcon=4.8547 forget=1.3915 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7740 mle=1.5340 pcon=4.8519 forget=1.3881 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7644 mle=1.5304 pcon=4.8490 forget=1.3850 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8761 mle=1.6464 pcon=4.8461 forget=1.3835 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.8754 mle=1.6435 pcon=4.8437 forget=1.3882 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.7964 mle=1.5801 pcon=4.8413 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6509 mle=1.4424 pcon=4.8388 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.8540 mle=1.6546 pcon=4.8363 forget=1.3631 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.7994 mle=1.5785 pcon=4.8338 forget=1.3871 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 60%|██████    | 21/35 [02:54<01:55,  8.23s/it] 63%|██████▎   | 22/35 [03:02<01:45,  8.15s/it] 66%|██████▌   | 23/35 [03:10<01:38,  8.21s/it] 69%|██████▊   | 24/35 [03:19<01:31,  8.34s/it] 71%|███████▏  | 25/35 [03:27<01:22,  8.28s/it] 74%|███████▍  | 26/35 [03:35<01:14,  8.28s/it] 77%|███████▋  | 27/35 [03:43<01:06,  8.27s/it][loss] ep 20 it 150 total=7.7890 mle=1.5894 pcon=4.8313 forget=1.3684 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.7967 mle=1.5960 pcon=4.8288 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=7.9468 mle=1.7452 pcon=4.8264 forget=1.3752 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.9643 mle=1.7717 pcon=4.8242 forget=1.3683 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.8605 mle=1.6817 pcon=4.8219 forget=1.3569 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5440 mle=1.3665 pcon=4.8194 forget=1.3582 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.8135 mle=1.6525 pcon=4.8171 forget=1.3439 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7806 mle=1.5954 pcon=4.8149 forget=1.3704 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.8288 mle=1.6550 pcon=4.8127 forget=1.3611 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.7043 mle=1.5523 pcon=4.8104 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.0821 mle=1.9032 pcon=4.8084 forget=1.3705 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8600 mle=1.7025 pcon=4.8062 forget=1.3513 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.8567 mle=1.7138 pcon=4.8041 forget=1.3388 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.7866 mle=1.6331 pcon=4.8021 forget=1.3513 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.8088 mle=1.6681 pcon=4.8001 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.8455 mle=1.7078 pcon=4.7981 forget=1.3396 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.6922 mle=1.5557 pcon=4.7961 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.8640 mle=1.7258 pcon=4.7943 forget=1.3439 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.6896 mle=1.5663 pcon=4.7926 forget=1.3308 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.6464 mle=1.5131 pcon=4.7909 forget=1.3423 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.8441 mle=1.7082 pcon=4.7890 forget=1.3470 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.7553 mle=1.6482 pcon=4.7873 forget=1.3198 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.7214 mle=1.6249 pcon=4.7854 forget=1.3110 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.9400 mle=1.8120 pcon=4.7836 forget=1.3444 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.6764 mle=1.5778 pcon=4.7819 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.6518 mle=1.5679 pcon=4.7803 forget=1.3036 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.8090 mle=1.7250 pcon=4.7786 forget=1.3055 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.8017 mle=1.7220 pcon=4.7768 forget=1.3029 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.5765 mle=1.5097 pcon=4.7752 forget=1.2916 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.7022 mle=1.6393 pcon=4.7737 forget=1.2892 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.8458 mle=1.7677 pcon=4.7720 forget=1.3060 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.6989 mle=1.6101 pcon=4.7704 forget=1.3184 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.6932 mle=1.6280 pcon=4.7689 forget=1.2962 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.6922 mle=1.6242 pcon=4.7676 forget=1.3004 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.7426 mle=1.6926 pcon=4.7659 forget=1.2841 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.6604 mle=1.6023 pcon=4.7643 forget=1.2938 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 25 it 0 total=7.7523 mle=1.7035 pcon=4.7629 forget=1.2859 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.7006 mle=1.6406 pcon=4.7615 forget=1.2985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.7726 mle=1.7356 pcon=4.7599 forget=1.2771 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.7355 mle=1.6964 pcon=4.7586 forget=1.2804 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.8314 mle=1.7933 pcon=4.7572 forget=1.2808 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.6215 mle=1.5867 pcon=4.7559 forget=1.2789 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.6825 mle=1.6475 pcon=4.7546 forget=1.2805 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.8050 mle=1.7730 pcon=4.7533 forget=1.2787 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 26 it 10 total=7.7429 mle=1.7183 pcon=4.7521 forget=1.2725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.7810 mle=1.7344 pcon=4.7507 forget=1.2959 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.7577 mle=1.7159 pcon=4.7494 forget=1.2924 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.6178 mle=1.5896 pcon=4.7481 forget=1.2800 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.7259 mle=1.6976 pcon=4.7469 forget=1.2813 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.6681 mle=1.6356 pcon=4.7461 forget=1.2865 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.8807 mle=1.8159 pcon=4.7448 forget=1.3200 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.9007 mle=1.8522 pcon=4.7437 forget=1.3047 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e35-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
 80%|████████  | 28/35 [03:51<00:57,  8.20s/it] 83%|████████▎ | 29/35 [04:00<00:49,  8.21s/it] 86%|████████▌ | 30/35 [04:07<00:40,  8.07s/it] 89%|████████▊ | 31/35 [04:16<00:33,  8.26s/it] 91%|█████████▏| 32/35 [04:24<00:24,  8.16s/it] 94%|█████████▍| 33/35 [04:32<00:16,  8.23s/it] 97%|█████████▋| 34/35 [04:40<00:08,  8.17s/it]100%|██████████| 35/35 [04:48<00:00,  8.12s/it]100%|██████████| 35/35 [04:48<00:00,  8.25s/it]
[loss] ep 27 it 20 total=7.5829 mle=1.5561 pcon=4.7427 forget=1.2841 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.6680 mle=1.6314 pcon=4.7415 forget=1.2951 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.7255 mle=1.7055 pcon=4.7406 forget=1.2794 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.5710 mle=1.5442 pcon=4.7396 forget=1.2872 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.7030 mle=1.6601 pcon=4.7388 forget=1.3041 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.6405 mle=1.5917 pcon=4.7378 forget=1.3110 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.6883 mle=1.6431 pcon=4.7370 forget=1.3082 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.6228 mle=1.5807 pcon=4.7361 forget=1.3060 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.6927 mle=1.6606 pcon=4.7354 forget=1.2966 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.7634 mle=1.7292 pcon=4.7344 forget=1.2998 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.4909 mle=1.4462 pcon=4.7337 forget=1.3110 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.5446 mle=1.4981 pcon=4.7327 forget=1.3138 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.6568 mle=1.6142 pcon=4.7320 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7108 mle=1.6629 pcon=4.7313 forget=1.3166 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.5692 mle=1.5126 pcon=4.7304 forget=1.3262 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7310 mle=1.6822 pcon=4.7295 forget=1.3194 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=7.6830 mle=1.6217 pcon=4.7287 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6205 mle=1.5766 pcon=4.7281 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.5953 mle=1.5493 pcon=4.7274 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.9278 mle=1.8562 pcon=4.7266 forget=1.3450 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.7228 mle=1.6572 pcon=4.7261 forget=1.3396 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.6922 mle=1.6311 pcon=4.7252 forget=1.3359 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7405 mle=1.6872 pcon=4.7247 forget=1.3286 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.7387 mle=1.6734 pcon=4.7239 forget=1.3414 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.7021 mle=1.6289 pcon=4.7230 forget=1.3502 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.7131 mle=1.6390 pcon=4.7226 forget=1.3515 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.6218 mle=1.5435 pcon=4.7220 forget=1.3562 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.7136 mle=1.6327 pcon=4.7215 forget=1.3594 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.7051 mle=1.6211 pcon=4.7212 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=7.8105 mle=1.7271 pcon=4.7205 forget=1.3630 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.7449 mle=1.6686 pcon=4.7199 forget=1.3564 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.8580 mle=1.7779 pcon=4.7194 forget=1.3608 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.6553 mle=1.5662 pcon=4.7189 forget=1.3701 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=7.7613 mle=1.6754 pcon=4.7186 forget=1.3673 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.6439 mle=1.5624 pcon=4.7180 forget=1.3634 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.8395 mle=1.7573 pcon=4.7177 forget=1.3645 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.7470 mle=1.6665 pcon=4.7172 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=7.6254 mle=1.5369 pcon=4.7167 forget=1.3717 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=7.6754 mle=1.5806 pcon=4.7164 forget=1.3784 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.6050 mle=1.5261 pcon=4.7163 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.5920 mle=1.5005 pcon=4.7161 forget=1.3754 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=7.6221 mle=1.5253 pcon=4.7157 forget=1.3811 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.6278 mle=1.5160 pcon=4.7153 forget=1.3965 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.7006 mle=1.5955 pcon=4.7149 forget=1.3903 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=7.6709 mle=1.5724 pcon=4.7145 forget=1.3840 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=7.6117 mle=1.5182 pcon=4.7140 forget=1.3795 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.5735 mle=1.4755 pcon=4.7138 forget=1.3842 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.8406 mle=1.7500 pcon=4.7135 forget=1.3772 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=7.9193 mle=1.8291 pcon=4.7131 forget=1.3771 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.7900 mle=1.6784 pcon=4.7130 forget=1.3987 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.6468 mle=1.5340 pcon=4.7127 forget=1.4001 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=7.8584 mle=1.7535 pcon=4.7126 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=7.7162 mle=1.6071 pcon=4.7122 forget=1.3970 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=7.8756 mle=1.7776 pcon=4.7119 forget=1.3862 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=7.6853 mle=1.5576 pcon=4.7117 forget=1.4161 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=7.7951 mle=1.6837 pcon=4.7113 forget=1.4002 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=7.7591 mle=1.6302 pcon=4.7111 forget=1.4178 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=7.7032 mle=1.6016 pcon=4.7107 forget=1.3909 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.7200 mle=1.5927 pcon=4.7104 forget=1.4168 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=7.7683 mle=1.6549 pcon=4.7101 forget=1.4033 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=7.6698 mle=1.5508 pcon=4.7100 forget=1.4090 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=7.6490 mle=1.5216 pcon=4.7097 forget=1.4177 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[Run] lambda=0.2 lr=0.001 epochs=40 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=40, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/40 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▎         | 1/40 [00:13<08:41, 13.36s/it]  5%|▌         | 2/40 [00:22<06:43, 10.62s/it]  8%|▊         | 3/40 [00:30<05:55,  9.62s/it] 10%|█         | 4/40 [00:38<05:27,  9.09s/it] 12%|█▎        | 5/40 [00:47<05:10,  8.86s/it] 15%|█▌        | 6/40 [00:56<05:01,  8.87s/it][loss] ep 0 it 0 total=8.2325 mle=1.5620 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4637 mle=1.7910 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4349 mle=1.7483 pcon=5.2750 forget=1.4116 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5253 mle=1.8425 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3322 mle=1.6798 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2595 mle=1.6257 pcon=5.2557 forget=1.3781 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4395 mle=1.8020 pcon=5.2498 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0948 mle=1.4466 pcon=5.2437 forget=1.4045 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2488 mle=1.6388 pcon=5.2377 forget=1.3722 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1409 mle=1.5269 pcon=5.2322 forget=1.3817 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2072 mle=1.6063 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2557 mle=1.6692 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1515 mle=1.5596 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2313 mle=1.6336 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3116 mle=1.7252 pcon=5.2049 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0014 mle=1.4194 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3770 mle=1.8356 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2554 mle=1.6841 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2144 mle=1.6700 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3574 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3048 mle=1.7528 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9740 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1374 mle=1.6125 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1875 mle=1.6634 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0959 mle=1.5681 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0675 mle=1.5597 pcon=5.1539 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3407 mle=1.8281 pcon=5.1498 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7050 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2635 mle=1.7593 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3262 mle=1.8245 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1233 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0827 mle=1.5753 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0056 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2289 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1643 mle=1.6600 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2962 mle=1.8091 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4521 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1728 mle=1.6862 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0604 mle=1.6088 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1418 mle=1.6930 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2604 mle=1.7994 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4411 mle=1.9766 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2328 mle=1.7904 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1483 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2208 mle=1.7672 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1619 mle=1.7197 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9843 mle=1.5560 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1435 mle=1.7058 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1252 mle=1.7004 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9363 mle=1.5104 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1205 mle=1.6773 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1853 mle=1.7633 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9238 mle=1.4890 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 18%|█▊        | 7/40 [01:05<04:58,  9.03s/it] 20%|██        | 8/40 [01:14<04:53,  9.18s/it] 22%|██▎       | 9/40 [01:23<04:38,  8.99s/it] 25%|██▌       | 10/40 [01:32<04:27,  8.93s/it] 28%|██▊       | 11/40 [01:40<04:15,  8.80s/it] 30%|███       | 12/40 [01:49<04:03,  8.69s/it] 32%|███▎      | 13/40 [01:57<03:49,  8.52s/it][loss] ep 6 it 360 total=8.1562 mle=1.7148 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9113 mle=1.5086 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9674 mle=1.5723 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1363 mle=1.7404 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1778 mle=1.7625 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0640 mle=1.6549 pcon=5.0561 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2669 mle=1.8785 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9420 mle=1.5475 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1817 mle=1.7908 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1849 mle=1.7911 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9138 mle=1.5226 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1377 mle=1.7439 pcon=5.0438 forget=1.3501 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6500 pcon=5.0418 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9674 mle=1.5665 pcon=5.0399 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8274 mle=1.4569 pcon=5.0380 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1989 mle=1.7911 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0389 mle=1.6501 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1597 mle=1.7991 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1260 mle=1.7457 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0292 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8339 mle=1.4882 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1453 mle=1.7621 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0236 mle=1.6656 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8726 mle=1.5098 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8218 mle=1.4854 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8193 mle=1.4731 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0397 mle=1.7011 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0422 mle=1.7015 pcon=5.0157 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1245 mle=1.7801 pcon=5.0142 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1886 mle=1.8499 pcon=5.0126 forget=1.3261 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1225 mle=1.7763 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8592 mle=1.5341 pcon=5.0096 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1315 mle=1.7941 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0269 mle=1.7037 pcon=5.0064 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5910 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8762 mle=1.5651 pcon=5.0031 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8409 mle=1.5266 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8600 mle=1.5287 pcon=4.9996 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0722 mle=1.7508 pcon=4.9980 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9548 mle=1.6477 pcon=4.9966 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9176 mle=1.5957 pcon=4.9945 forget=1.3275 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8120 mle=1.4976 pcon=4.9926 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0399 mle=1.7138 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0460 mle=1.7225 pcon=4.9889 forget=1.3345 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8249 mle=1.5211 pcon=4.9875 forget=1.3163 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9134 mle=1.5853 pcon=4.9860 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0233 mle=1.7202 pcon=4.9845 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0272 mle=1.7066 pcon=4.9828 forget=1.3377 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9977 mle=1.7021 pcon=4.9814 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1718 mle=1.8293 pcon=4.9798 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0147 mle=1.6909 pcon=4.9779 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0438 mle=1.7437 pcon=4.9757 forget=1.3245 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 35%|███▌      | 14/40 [02:05<03:41,  8.53s/it] 38%|███▊      | 15/40 [02:14<03:35,  8.63s/it] 40%|████      | 16/40 [02:23<03:28,  8.69s/it] 42%|████▎     | 17/40 [02:32<03:17,  8.59s/it] 45%|████▌     | 18/40 [02:40<03:08,  8.58s/it] 48%|████▊     | 19/40 [02:50<03:06,  8.89s/it] 50%|█████     | 20/40 [02:58<02:53,  8.68s/it][loss] ep 13 it 230 total=7.9898 mle=1.6848 pcon=4.9740 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7601 mle=1.4624 pcon=4.9723 forget=1.3254 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0885 mle=1.7767 pcon=4.9706 forget=1.3413 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9524 mle=1.6477 pcon=4.9689 forget=1.3358 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0264 mle=1.7116 pcon=4.9670 forget=1.3477 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8943 mle=1.5618 pcon=4.9653 forget=1.3672 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9547 mle=1.6576 pcon=4.9634 forget=1.3337 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9213 mle=1.6113 pcon=4.9615 forget=1.3485 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9443 mle=1.6385 pcon=4.9591 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8729 mle=1.5574 pcon=4.9570 forget=1.3585 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8860 mle=1.5584 pcon=4.9549 forget=1.3727 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9535 mle=1.6351 pcon=4.9525 forget=1.3660 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9015 mle=1.5878 pcon=4.9503 forget=1.3634 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9874 mle=1.6590 pcon=4.9481 forget=1.3803 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0409 mle=1.7216 pcon=4.9456 forget=1.3737 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8319 mle=1.5156 pcon=4.9432 forget=1.3731 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8666 mle=1.5537 pcon=4.9404 forget=1.3725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.1933 mle=1.8656 pcon=4.9375 forget=1.3902 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8786 mle=1.5698 pcon=4.9348 forget=1.3739 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 16 it 10 total=7.8578 mle=1.5473 pcon=4.9318 forget=1.3787 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8152 mle=1.4952 pcon=4.9289 forget=1.3911 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6736 mle=1.3747 pcon=4.9258 forget=1.3731 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8369 mle=1.5341 pcon=4.9229 forget=1.3799 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8715 mle=1.5756 pcon=4.9197 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.1990 mle=1.9078 pcon=4.9163 forget=1.3748 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2508 mle=1.9413 pcon=4.9128 forget=1.3967 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8442 mle=1.5366 pcon=4.9096 forget=1.3981 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.0888 mle=1.7815 pcon=4.9065 forget=1.4009 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0485 mle=1.7565 pcon=4.9035 forget=1.3885 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.7958 mle=1.4938 pcon=4.8999 forget=1.4020 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9483 mle=1.6697 pcon=4.8966 forget=1.3819 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1063 mle=1.8210 pcon=4.8931 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.0999 mle=1.8252 pcon=4.8897 forget=1.3850 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8960 mle=1.6161 pcon=4.8864 forget=1.3936 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.8955 mle=1.6115 pcon=4.8829 forget=1.4012 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7366 mle=1.4777 pcon=4.8797 forget=1.3791 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0262 mle=1.7425 pcon=4.8766 forget=1.4072 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0816 mle=1.8086 pcon=4.8734 forget=1.3996 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9169 mle=1.6523 pcon=4.8704 forget=1.3942 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8105 mle=1.5535 pcon=4.8673 forget=1.3897 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.8785 mle=1.6298 pcon=4.8642 forget=1.3845 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.8963 mle=1.6492 pcon=4.8611 forget=1.3861 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8399 mle=1.5943 pcon=4.8583 forget=1.3873 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.9041 mle=1.6609 pcon=4.8554 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.8822 mle=1.6413 pcon=4.8524 forget=1.3885 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7670 mle=1.5326 pcon=4.8496 forget=1.3848 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7575 mle=1.5291 pcon=4.8467 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8666 mle=1.6432 pcon=4.8438 forget=1.3796 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.8665 mle=1.6422 pcon=4.8414 forget=1.3830 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.7911 mle=1.5825 pcon=4.8389 forget=1.3696 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6444 mle=1.4437 pcon=4.8364 forget=1.3642 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.8430 mle=1.6518 pcon=4.8338 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.7917 mle=1.5797 pcon=4.8313 forget=1.3807 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▎    | 21/40 [03:07<02:45,  8.73s/it] 55%|█████▌    | 22/40 [03:16<02:38,  8.82s/it] 57%|█████▊    | 23/40 [03:24<02:28,  8.75s/it] 60%|██████    | 24/40 [03:33<02:18,  8.68s/it] 62%|██████▎   | 25/40 [03:42<02:12,  8.87s/it] 65%|██████▌   | 26/40 [03:50<02:00,  8.62s/it] 68%|██████▊   | 27/40 [03:59<01:52,  8.67s/it][loss] ep 20 it 150 total=7.7775 mle=1.5877 pcon=4.8288 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.7887 mle=1.5980 pcon=4.8263 forget=1.3643 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=7.9345 mle=1.7437 pcon=4.8239 forget=1.3669 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.9507 mle=1.7706 pcon=4.8217 forget=1.3584 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.8509 mle=1.6849 pcon=4.8194 forget=1.3466 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5335 mle=1.3697 pcon=4.8168 forget=1.3470 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.7972 mle=1.6518 pcon=4.8145 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7648 mle=1.5946 pcon=4.8123 forget=1.3579 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.8058 mle=1.6488 pcon=4.8101 forget=1.3468 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.6865 mle=1.5527 pcon=4.8078 forget=1.3260 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.0617 mle=1.9030 pcon=4.8058 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8352 mle=1.6989 pcon=4.8036 forget=1.3327 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.8339 mle=1.7154 pcon=4.8015 forget=1.3171 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.7632 mle=1.6352 pcon=4.7995 forget=1.3286 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.7840 mle=1.6691 pcon=4.7974 forget=1.3175 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.8138 mle=1.7058 pcon=4.7954 forget=1.3126 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.6529 mle=1.5485 pcon=4.7933 forget=1.3110 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.8308 mle=1.7263 pcon=4.7915 forget=1.3130 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.6535 mle=1.5671 pcon=4.7897 forget=1.2967 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.6113 mle=1.5202 pcon=4.7880 forget=1.3031 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.8015 mle=1.7026 pcon=4.7859 forget=1.3130 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.7128 mle=1.6471 pcon=4.7841 forget=1.2816 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.6838 mle=1.6300 pcon=4.7821 forget=1.2716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.8912 mle=1.8071 pcon=4.7802 forget=1.3039 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.6309 mle=1.5773 pcon=4.7783 forget=1.2752 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.6091 mle=1.5718 pcon=4.7765 forget=1.2607 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.7621 mle=1.7241 pcon=4.7747 forget=1.2633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.7476 mle=1.7151 pcon=4.7727 forget=1.2599 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.5311 mle=1.5098 pcon=4.7709 forget=1.2505 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.6657 mle=1.6470 pcon=4.7692 forget=1.2495 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.8067 mle=1.7745 pcon=4.7673 forget=1.2648 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.6627 mle=1.6175 pcon=4.7655 forget=1.2797 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.6579 mle=1.6355 pcon=4.7638 forget=1.2586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.6592 mle=1.6321 pcon=4.7622 forget=1.2649 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.7042 mle=1.6910 pcon=4.7603 forget=1.2529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.6330 mle=1.6059 pcon=4.7586 forget=1.2686 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e40-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 25 it 0 total=7.7081 mle=1.6888 pcon=4.7569 forget=1.2624 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.6608 mle=1.6345 pcon=4.7553 forget=1.2710 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.7427 mle=1.7259 pcon=4.7535 forget=1.2633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.7206 mle=1.7021 pcon=4.7521 forget=1.2665 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.8103 mle=1.7853 pcon=4.7505 forget=1.2745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.6032 mle=1.5806 pcon=4.7490 forget=1.2736 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.6798 mle=1.6548 pcon=4.7475 forget=1.2775 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.7991 mle=1.7720 pcon=4.7461 forget=1.2810 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.7334 mle=1.7051 pcon=4.7447 forget=1.2836 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.7798 mle=1.7319 pcon=4.7432 forget=1.3046 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.7659 mle=1.7197 pcon=4.7419 forget=1.3044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.6179 mle=1.5752 pcon=4.7404 forget=1.3023 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.7309 mle=1.6873 pcon=4.7392 forget=1.3043 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.6890 mle=1.6383 pcon=4.7382 forget=1.3124 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.8881 mle=1.8111 pcon=4.7369 forget=1.3400 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.9185 mle=1.8511 pcon=4.7358 forget=1.3316 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=7.6241 mle=1.5636 pcon=4.7348 forget=1.3257 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.7119 mle=1.6433 pcon=4.7336 forget=1.3350 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.7548 mle=1.6936 pcon=4.7326 forget=1.3285 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 70%|███████   | 28/40 [04:07<01:43,  8.59s/it] 72%|███████▎  | 29/40 [04:16<01:35,  8.65s/it] 75%|███████▌  | 30/40 [04:25<01:25,  8.59s/it] 78%|███████▊  | 31/40 [04:33<01:17,  8.64s/it] 80%|████████  | 32/40 [04:42<01:08,  8.55s/it] 82%|████████▎ | 33/40 [04:50<00:59,  8.49s/it] 85%|████████▌ | 34/40 [04:59<00:51,  8.56s/it] 88%|████████▊ | 35/40 [05:07<00:43,  8.61s/it][loss] ep 27 it 170 total=7.6132 mle=1.5440 pcon=4.7317 forget=1.3375 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.7316 mle=1.6534 pcon=4.7309 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.6841 mle=1.5965 pcon=4.7299 forget=1.3577 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.7400 mle=1.6541 pcon=4.7291 forget=1.3568 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.6627 mle=1.5793 pcon=4.7283 forget=1.3551 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.7369 mle=1.6646 pcon=4.7277 forget=1.3446 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.8115 mle=1.7263 pcon=4.7268 forget=1.3584 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.5475 mle=1.4503 pcon=4.7261 forget=1.3711 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.5938 mle=1.5012 pcon=4.7252 forget=1.3675 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.7108 mle=1.6165 pcon=4.7245 forget=1.3698 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7469 mle=1.6515 pcon=4.7239 forget=1.3715 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.6341 mle=1.5277 pcon=4.7230 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7762 mle=1.6735 pcon=4.7222 forget=1.3805 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=7.7295 mle=1.6234 pcon=4.7215 forget=1.3846 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6685 mle=1.5722 pcon=4.7209 forget=1.3754 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.6442 mle=1.5460 pcon=4.7203 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.9646 mle=1.8502 pcon=4.7195 forget=1.3950 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.7733 mle=1.6625 pcon=4.7190 forget=1.3918 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.7383 mle=1.6279 pcon=4.7182 forget=1.3922 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7869 mle=1.6884 pcon=4.7177 forget=1.3808 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.7841 mle=1.6810 pcon=4.7170 forget=1.3861 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.7433 mle=1.6276 pcon=4.7161 forget=1.3996 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.7507 mle=1.6402 pcon=4.7157 forget=1.3948 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.6534 mle=1.5386 pcon=4.7151 forget=1.3996 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.7477 mle=1.6346 pcon=4.7146 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.7385 mle=1.6224 pcon=4.7143 forget=1.4018 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=7.8351 mle=1.7187 pcon=4.7136 forget=1.4027 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.7630 mle=1.6597 pcon=4.7130 forget=1.3902 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.8780 mle=1.7726 pcon=4.7125 forget=1.3929 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.6811 mle=1.5661 pcon=4.7120 forget=1.4029 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=7.7798 mle=1.6720 pcon=4.7116 forget=1.3962 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.6530 mle=1.5569 pcon=4.7111 forget=1.3851 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.8574 mle=1.7591 pcon=4.7107 forget=1.3876 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.7663 mle=1.6684 pcon=4.7102 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=7.6414 mle=1.5399 pcon=4.7096 forget=1.3919 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=7.6896 mle=1.5896 pcon=4.7093 forget=1.3907 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.6131 mle=1.5315 pcon=4.7091 forget=1.3725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.6008 mle=1.5052 pcon=4.7089 forget=1.3868 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=7.6254 mle=1.5289 pcon=4.7084 forget=1.3881 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.6386 mle=1.5275 pcon=4.7081 forget=1.4031 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.7028 mle=1.6037 pcon=4.7075 forget=1.3916 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=7.6653 mle=1.5716 pcon=4.7071 forget=1.3867 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=7.6010 mle=1.5146 pcon=4.7065 forget=1.3799 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.5669 mle=1.4786 pcon=4.7063 forget=1.3820 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.8161 mle=1.7393 pcon=4.7059 forget=1.3709 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=7.9138 mle=1.8410 pcon=4.7055 forget=1.3674 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.7772 mle=1.6827 pcon=4.7052 forget=1.3893 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.6346 mle=1.5472 pcon=4.7050 forget=1.3825 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=7.8511 mle=1.7692 pcon=4.7047 forget=1.3771 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=7.7149 mle=1.6285 pcon=4.7042 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=7.8456 mle=1.7786 pcon=4.7038 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=7.6581 mle=1.5623 pcon=4.7036 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=7.7538 mle=1.6740 pcon=4.7031 forget=1.3767 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=7.7355 mle=1.6405 pcon=4.7028 forget=1.3921 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=7.6651 mle=1.6015 pcon=4.7024 forget=1.3611 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.6700 mle=1.5853 pcon=4.7020 forget=1.3827 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=7.7346 mle=1.6618 pcon=4.7016 forget=1.3712 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=7.6330 mle=1.5584 pcon=4.7014 forget=1.3732 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=7.6126 mle=1.5307 pcon=4.7010 forget=1.3809 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=7.6301 mle=1.5520 pcon=4.7008 forget=1.3773 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=7.8153 mle=1.7365 pcon=4.7006 forget=1.3782 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=7.6355 mle=1.5536 pcon=4.7005 forget=1.3814 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 90%|█████████ | 36/40 [05:16<00:33,  8.48s/it] 92%|█████████▎| 37/40 [05:24<00:25,  8.39s/it] 95%|█████████▌| 38/40 [05:32<00:16,  8.36s/it] 98%|█████████▊| 39/40 [05:40<00:08,  8.32s/it]100%|██████████| 40/40 [05:50<00:00,  8.59s/it]100%|██████████| 40/40 [05:50<00:00,  8.75s/it]
[loss] ep 35 it 150 total=7.5729 mle=1.5104 pcon=4.7000 forget=1.3625 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=7.7634 mle=1.6852 pcon=4.6998 forget=1.3784 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=7.7283 mle=1.6728 pcon=4.6996 forget=1.3559 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=7.7080 mle=1.6419 pcon=4.6993 forget=1.3669 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=7.7307 mle=1.6579 pcon=4.6991 forget=1.3737 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=7.7846 mle=1.7189 pcon=4.6988 forget=1.3669 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.8375 mle=1.7735 pcon=4.6984 forget=1.3656 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=7.8877 mle=1.8185 pcon=4.6983 forget=1.3709 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.8104 mle=1.7196 pcon=4.6980 forget=1.3928 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=7.8536 mle=1.7908 pcon=4.6976 forget=1.3653 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=7.9161 mle=1.8322 pcon=4.6973 forget=1.3866 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=7.6308 mle=1.5891 pcon=4.6972 forget=1.3445 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=7.6520 mle=1.5740 pcon=4.6973 forget=1.3807 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=7.8314 mle=1.7671 pcon=4.6971 forget=1.3672 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=7.8573 mle=1.7880 pcon=4.6969 forget=1.3724 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=7.6502 mle=1.5881 pcon=4.6965 forget=1.3656 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=7.6040 mle=1.5575 pcon=4.6965 forget=1.3501 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=7.6322 mle=1.5635 pcon=4.6962 forget=1.3725 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=7.5958 mle=1.5256 pcon=4.6961 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.7368 mle=1.6782 pcon=4.6960 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.6599 mle=1.5678 pcon=4.6959 forget=1.3963 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=7.6916 mle=1.6333 pcon=4.6957 forget=1.3626 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=7.7171 mle=1.6593 pcon=4.6955 forget=1.3623 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=7.6350 mle=1.5672 pcon=4.6953 forget=1.3726 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=7.5656 mle=1.4988 pcon=4.6951 forget=1.3717 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=7.6528 mle=1.5901 pcon=4.6950 forget=1.3677 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=7.8931 mle=1.8265 pcon=4.6948 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=7.9273 mle=1.8508 pcon=4.6945 forget=1.3819 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=7.7639 mle=1.7027 pcon=4.6943 forget=1.3670 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=7.6996 mle=1.6440 pcon=4.6941 forget=1.3615 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=7.7199 mle=1.6410 pcon=4.6940 forget=1.3849 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=7.7512 mle=1.7101 pcon=4.6940 forget=1.3471 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=7.6840 mle=1.6225 pcon=4.6939 forget=1.3676 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=7.7058 mle=1.6433 pcon=4.6939 forget=1.3686 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=7.6778 mle=1.6230 pcon=4.6936 forget=1.3612 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=7.7906 mle=1.7250 pcon=4.6937 forget=1.3719 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[Run] lambda=0.2 lr=0.001 epochs=45 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=45, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/45 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/45 [00:13<09:57, 13.57s/it]  4%|▍         | 2/45 [00:22<07:37, 10.64s/it]  7%|▋         | 3/45 [00:30<06:51,  9.79s/it]  9%|▉         | 4/45 [00:39<06:29,  9.50s/it] 11%|█         | 5/45 [00:48<06:05,  9.14s/it] 13%|█▎        | 6/45 [00:58<06:01,  9.27s/it][loss] ep 0 it 0 total=8.2324 mle=1.5619 pcon=5.2951 forget=1.3754 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4638 mle=1.7911 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4348 mle=1.7482 pcon=5.2750 forget=1.4115 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5257 mle=1.8429 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3323 mle=1.6800 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2593 mle=1.6255 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4395 mle=1.8019 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0948 mle=1.4466 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2487 mle=1.6386 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1408 mle=1.5267 pcon=5.2323 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2075 mle=1.6065 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2560 mle=1.6694 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1516 mle=1.5596 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2311 mle=1.6334 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3118 mle=1.7253 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0014 mle=1.4194 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3748 mle=1.8334 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2558 mle=1.6844 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6701 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3575 mle=1.8060 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3045 mle=1.7525 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9740 mle=1.4275 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1377 mle=1.6128 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1876 mle=1.6635 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0957 mle=1.5679 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0678 mle=1.5600 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3342 mle=1.8215 pcon=5.1498 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2061 mle=1.7027 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2637 mle=1.7594 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3265 mle=1.8247 pcon=5.1384 forget=1.3634 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1233 mle=1.6194 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0827 mle=1.5752 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0055 mle=1.5307 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2291 mle=1.7062 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1645 mle=1.6602 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2965 mle=1.8094 pcon=5.1176 forget=1.3695 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9094 mle=1.4522 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1731 mle=1.6864 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0602 mle=1.6086 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1414 mle=1.6926 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2606 mle=1.7996 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4409 mle=1.9763 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2329 mle=1.7905 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1482 mle=1.7133 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2210 mle=1.7674 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1620 mle=1.7198 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9844 mle=1.5560 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1432 mle=1.7055 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1252 mle=1.7004 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5106 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1206 mle=1.6774 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1851 mle=1.7631 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9238 mle=1.4888 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 16%|█▌        | 7/45 [01:06<05:43,  9.05s/it] 18%|█▊        | 8/45 [01:15<05:27,  8.86s/it] 20%|██        | 9/45 [01:24<05:25,  9.03s/it] 22%|██▏       | 10/45 [01:33<05:14,  8.98s/it] 24%|██▍       | 11/45 [01:42<05:02,  8.90s/it] 27%|██▋       | 12/45 [01:51<05:02,  9.17s/it] 29%|██▉       | 13/45 [02:00<04:51,  9.10s/it][loss] ep 6 it 360 total=8.1562 mle=1.7149 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9109 mle=1.5082 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9677 mle=1.5726 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1364 mle=1.7405 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1779 mle=1.7625 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0641 mle=1.6550 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2671 mle=1.8787 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9422 mle=1.5477 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1815 mle=1.7906 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1850 mle=1.7912 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9137 mle=1.5226 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1380 mle=1.7442 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0298 mle=1.6501 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9673 mle=1.5664 pcon=5.0399 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8275 mle=1.4570 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1989 mle=1.7910 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6502 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1601 mle=1.7995 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1265 mle=1.7461 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0381 mle=1.6806 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1455 mle=1.7622 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0239 mle=1.6658 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8728 mle=1.5099 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8247 mle=1.4883 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8198 mle=1.4735 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0397 mle=1.7011 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0423 mle=1.7016 pcon=5.0158 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1247 mle=1.7803 pcon=5.0143 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1885 mle=1.8497 pcon=5.0127 forget=1.3262 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1224 mle=1.7762 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8593 mle=1.5341 pcon=5.0097 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1316 mle=1.7941 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0271 mle=1.7039 pcon=5.0065 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9234 mle=1.5909 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8764 mle=1.5652 pcon=5.0032 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8409 mle=1.5266 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8601 mle=1.5288 pcon=4.9997 forget=1.3316 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0721 mle=1.7507 pcon=4.9980 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9551 mle=1.6480 pcon=4.9966 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9176 mle=1.5957 pcon=4.9945 forget=1.3275 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8119 mle=1.4976 pcon=4.9927 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0399 mle=1.7137 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0461 mle=1.7226 pcon=4.9889 forget=1.3345 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8246 mle=1.5209 pcon=4.9875 forget=1.3163 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9135 mle=1.5855 pcon=4.9860 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0233 mle=1.7201 pcon=4.9845 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0266 mle=1.7060 pcon=4.9829 forget=1.3377 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9977 mle=1.7022 pcon=4.9814 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1707 mle=1.8282 pcon=4.9798 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0150 mle=1.6912 pcon=4.9779 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0436 mle=1.7434 pcon=4.9757 forget=1.3245 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 31%|███       | 14/45 [02:09<04:39,  9.01s/it] 33%|███▎      | 15/45 [02:18<04:28,  8.96s/it] 36%|███▌      | 16/45 [02:26<04:15,  8.81s/it] 38%|███▊      | 17/45 [02:35<04:05,  8.79s/it] 40%|████      | 18/45 [02:44<03:54,  8.69s/it] 42%|████▏     | 19/45 [02:52<03:44,  8.62s/it] 44%|████▍     | 20/45 [03:00<03:33,  8.53s/it][loss] ep 13 it 230 total=7.9900 mle=1.6850 pcon=4.9740 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7600 mle=1.4622 pcon=4.9723 forget=1.3255 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0886 mle=1.7767 pcon=4.9705 forget=1.3413 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9524 mle=1.6476 pcon=4.9689 forget=1.3359 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0263 mle=1.7115 pcon=4.9670 forget=1.3478 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8944 mle=1.5619 pcon=4.9652 forget=1.3673 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9545 mle=1.6573 pcon=4.9633 forget=1.3339 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9207 mle=1.6107 pcon=4.9614 forget=1.3486 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9439 mle=1.6380 pcon=4.9590 forget=1.3469 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8729 mle=1.5573 pcon=4.9569 forget=1.3587 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8857 mle=1.5581 pcon=4.9548 forget=1.3728 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9529 mle=1.6345 pcon=4.9523 forget=1.3662 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9013 mle=1.5876 pcon=4.9500 forget=1.3636 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9866 mle=1.6583 pcon=4.9478 forget=1.3805 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0403 mle=1.7210 pcon=4.9453 forget=1.3739 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8316 mle=1.5153 pcon=4.9429 forget=1.3734 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8674 mle=1.5546 pcon=4.9400 forget=1.3728 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.1923 mle=1.8648 pcon=4.9371 forget=1.3904 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8778 mle=1.5691 pcon=4.9344 forget=1.3742 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 16 it 10 total=7.8589 mle=1.5485 pcon=4.9313 forget=1.3791 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8139 mle=1.4941 pcon=4.9284 forget=1.3914 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6729 mle=1.3743 pcon=4.9252 forget=1.3734 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8379 mle=1.5353 pcon=4.9222 forget=1.3803 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8708 mle=1.5753 pcon=4.9190 forget=1.3765 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.1964 mle=1.9057 pcon=4.9156 forget=1.3752 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2496 mle=1.9406 pcon=4.9121 forget=1.3970 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8429 mle=1.5360 pcon=4.9088 forget=1.3982 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.0863 mle=1.7796 pcon=4.9057 forget=1.4010 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0458 mle=1.7544 pcon=4.9026 forget=1.3887 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.7973 mle=1.4961 pcon=4.8990 forget=1.4021 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9454 mle=1.6680 pcon=4.8957 forget=1.3817 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.1024 mle=1.8181 pcon=4.8921 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.0994 mle=1.8258 pcon=4.8887 forget=1.3849 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8934 mle=1.6148 pcon=4.8853 forget=1.3932 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.8937 mle=1.6112 pcon=4.8818 forget=1.4007 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7371 mle=1.4799 pcon=4.8787 forget=1.3786 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0253 mle=1.7434 pcon=4.8755 forget=1.4064 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0820 mle=1.8109 pcon=4.8723 forget=1.3988 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9154 mle=1.6528 pcon=4.8693 forget=1.3933 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8057 mle=1.5509 pcon=4.8662 forget=1.3886 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.8714 mle=1.6251 pcon=4.8630 forget=1.3833 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.8900 mle=1.6455 pcon=4.8599 forget=1.3846 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8363 mle=1.5935 pcon=4.8571 forget=1.3857 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.8950 mle=1.6546 pcon=4.8542 forget=1.3862 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.8752 mle=1.6376 pcon=4.8512 forget=1.3863 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7627 mle=1.5317 pcon=4.8484 forget=1.3825 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7525 mle=1.5276 pcon=4.8454 forget=1.3795 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8610 mle=1.6415 pcon=4.8425 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.8578 mle=1.6383 pcon=4.8401 forget=1.3793 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.7854 mle=1.5819 pcon=4.8377 forget=1.3658 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6402 mle=1.4448 pcon=4.8351 forget=1.3603 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.8384 mle=1.6527 pcon=4.8325 forget=1.3531 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.7883 mle=1.5823 pcon=4.8300 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 47%|████▋     | 21/45 [03:08<03:21,  8.40s/it] 49%|████▉     | 22/45 [03:17<03:12,  8.36s/it] 51%|█████     | 23/45 [03:25<03:01,  8.24s/it] 53%|█████▎    | 24/45 [03:33<02:53,  8.28s/it] 56%|█████▌    | 25/45 [03:42<02:48,  8.44s/it] 58%|█████▊    | 26/45 [03:50<02:40,  8.45s/it] 60%|██████    | 27/45 [03:59<02:32,  8.46s/it][loss] ep 20 it 150 total=7.7711 mle=1.5881 pcon=4.8275 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.7815 mle=1.5979 pcon=4.8250 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=7.9270 mle=1.7440 pcon=4.8226 forget=1.3604 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.9405 mle=1.7696 pcon=4.8204 forget=1.3506 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.8423 mle=1.6859 pcon=4.8180 forget=1.3384 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5252 mle=1.3716 pcon=4.8155 forget=1.3381 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.7889 mle=1.6554 pcon=4.8132 forget=1.3203 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7536 mle=1.5954 pcon=4.8110 forget=1.3472 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.7883 mle=1.6449 pcon=4.8088 forget=1.3346 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.6714 mle=1.5524 pcon=4.8064 forget=1.3125 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.0424 mle=1.9009 pcon=4.8044 forget=1.3371 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8232 mle=1.7044 pcon=4.8022 forget=1.3165 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.8139 mle=1.7158 pcon=4.8000 forget=1.2981 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.7422 mle=1.6357 pcon=4.7980 forget=1.3085 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.7532 mle=1.6598 pcon=4.7959 forget=1.2975 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.7882 mle=1.7047 pcon=4.7938 forget=1.2897 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.6187 mle=1.5409 pcon=4.7916 forget=1.2862 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.8029 mle=1.7259 pcon=4.7897 forget=1.2873 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.6216 mle=1.5645 pcon=4.7879 forget=1.2692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.5855 mle=1.5262 pcon=4.7861 forget=1.2732 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.7689 mle=1.6976 pcon=4.7839 forget=1.2874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.6898 mle=1.6526 pcon=4.7820 forget=1.2552 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.6608 mle=1.6344 pcon=4.7798 forget=1.2466 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.8604 mle=1.8049 pcon=4.7777 forget=1.2778 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.6091 mle=1.5798 pcon=4.7757 forget=1.2536 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.5983 mle=1.5840 pcon=4.7738 forget=1.2405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.7379 mle=1.7213 pcon=4.7718 forget=1.2448 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.7286 mle=1.7145 pcon=4.7696 forget=1.2445 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.5158 mle=1.5095 pcon=4.7676 forget=1.2387 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.6541 mle=1.6468 pcon=4.7657 forget=1.2416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.7996 mle=1.7799 pcon=4.7637 forget=1.2560 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.6542 mle=1.6204 pcon=4.7617 forget=1.2720 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.6511 mle=1.6337 pcon=4.7599 forget=1.2575 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.6630 mle=1.6379 pcon=4.7582 forget=1.2669 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.7069 mle=1.6912 pcon=4.7563 forget=1.2595 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.6471 mle=1.6157 pcon=4.7544 forget=1.2771 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e45-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 25 it 0 total=7.7045 mle=1.6765 pcon=4.7527 forget=1.2752 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.6698 mle=1.6344 pcon=4.7510 forget=1.2844 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.7559 mle=1.7238 pcon=4.7492 forget=1.2828 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.7385 mle=1.7037 pcon=4.7477 forget=1.2871 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.8271 mle=1.7826 pcon=4.7461 forget=1.2984 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.6231 mle=1.5802 pcon=4.7446 forget=1.2983 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.7071 mle=1.6600 pcon=4.7432 forget=1.3038 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.8247 mle=1.7731 pcon=4.7418 forget=1.3099 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.7567 mle=1.7009 pcon=4.7405 forget=1.3154 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.8044 mle=1.7315 pcon=4.7390 forget=1.3339 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.7952 mle=1.7218 pcon=4.7377 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.6451 mle=1.5711 pcon=4.7364 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.7633 mle=1.6891 pcon=4.7352 forget=1.3390 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.7198 mle=1.6385 pcon=4.7344 forget=1.3469 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.9178 mle=1.8145 pcon=4.7331 forget=1.3701 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.9462 mle=1.8508 pcon=4.7321 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=7.6559 mle=1.5638 pcon=4.7312 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.7483 mle=1.6499 pcon=4.7300 forget=1.3684 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.7843 mle=1.6932 pcon=4.7292 forget=1.3619 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 62%|██████▏   | 28/45 [04:07<02:22,  8.38s/it] 64%|██████▍   | 29/45 [04:15<02:12,  8.29s/it] 67%|██████▋   | 30/45 [04:26<02:14,  8.94s/it] 69%|██████▉   | 31/45 [04:34<02:01,  8.71s/it] 71%|███████   | 32/45 [04:42<01:50,  8.53s/it] 73%|███████▎  | 33/45 [04:50<01:39,  8.31s/it] 76%|███████▌  | 34/45 [04:58<01:31,  8.32s/it] 78%|███████▊  | 35/45 [05:06<01:23,  8.33s/it][loss] ep 27 it 170 total=7.6398 mle=1.5415 pcon=4.7283 forget=1.3700 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.7549 mle=1.6509 pcon=4.7276 forget=1.3763 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.7095 mle=1.5970 pcon=4.7267 forget=1.3858 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.7698 mle=1.6605 pcon=4.7260 forget=1.3833 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.6839 mle=1.5787 pcon=4.7253 forget=1.3799 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.7617 mle=1.6703 pcon=4.7247 forget=1.3667 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.8306 mle=1.7254 pcon=4.7238 forget=1.3814 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.5643 mle=1.4484 pcon=4.7233 forget=1.3926 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.6063 mle=1.4998 pcon=4.7224 forget=1.3841 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.7268 mle=1.6188 pcon=4.7217 forget=1.3863 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7546 mle=1.6482 pcon=4.7212 forget=1.3853 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.6505 mle=1.5370 pcon=4.7203 forget=1.3933 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7784 mle=1.6691 pcon=4.7195 forget=1.3897 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=7.7421 mle=1.6314 pcon=4.7188 forget=1.3919 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6694 mle=1.5712 pcon=4.7182 forget=1.3800 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.6389 mle=1.5409 pcon=4.7175 forget=1.3804 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.9657 mle=1.8554 pcon=4.7167 forget=1.3936 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.7617 mle=1.6549 pcon=4.7162 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.7336 mle=1.6294 pcon=4.7154 forget=1.3889 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7752 mle=1.6863 pcon=4.7148 forget=1.3740 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.7757 mle=1.6849 pcon=4.7140 forget=1.3768 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.7304 mle=1.6288 pcon=4.7131 forget=1.3884 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.7375 mle=1.6435 pcon=4.7127 forget=1.3814 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.6332 mle=1.5375 pcon=4.7121 forget=1.3837 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.7313 mle=1.6387 pcon=4.7115 forget=1.3811 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.7155 mle=1.6217 pcon=4.7111 forget=1.3827 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=7.8053 mle=1.7135 pcon=4.7103 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.7507 mle=1.6733 pcon=4.7097 forget=1.3678 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.8426 mle=1.7647 pcon=4.7090 forget=1.3688 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.6541 mle=1.5678 pcon=4.7085 forget=1.3778 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=7.7460 mle=1.6673 pcon=4.7080 forget=1.3708 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.6204 mle=1.5543 pcon=4.7074 forget=1.3587 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.8331 mle=1.7648 pcon=4.7069 forget=1.3614 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.7326 mle=1.6664 pcon=4.7063 forget=1.3599 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=7.6089 mle=1.5427 pcon=4.7057 forget=1.3605 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=7.6632 mle=1.5986 pcon=4.7053 forget=1.3593 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.5823 mle=1.5363 pcon=4.7050 forget=1.3410 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.5670 mle=1.5086 pcon=4.7047 forget=1.3538 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=7.5999 mle=1.5416 pcon=4.7041 forget=1.3542 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.6038 mle=1.5327 pcon=4.7036 forget=1.3675 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.6644 mle=1.6075 pcon=4.7030 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=7.6264 mle=1.5728 pcon=4.7025 forget=1.3511 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=7.5618 mle=1.5127 pcon=4.7018 forget=1.3472 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.5262 mle=1.4841 pcon=4.7015 forget=1.3406 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.7629 mle=1.7302 pcon=4.7010 forget=1.3317 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=7.8782 mle=1.8483 pcon=4.7005 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.7356 mle=1.6874 pcon=4.7001 forget=1.3481 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.5929 mle=1.5523 pcon=4.6998 forget=1.3408 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=7.8102 mle=1.7722 pcon=4.6994 forget=1.3386 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=7.6787 mle=1.6373 pcon=4.6989 forget=1.3426 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=7.8017 mle=1.7786 pcon=4.6984 forget=1.3247 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=7.6098 mle=1.5663 pcon=4.6980 forget=1.3454 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=7.7052 mle=1.6733 pcon=4.6974 forget=1.3345 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=7.6902 mle=1.6432 pcon=4.6970 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=7.6253 mle=1.6073 pcon=4.6965 forget=1.3214 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.6206 mle=1.5889 pcon=4.6960 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=7.6963 mle=1.6739 pcon=4.6955 forget=1.3269 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=7.5820 mle=1.5580 pcon=4.6952 forget=1.3288 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=7.5643 mle=1.5370 pcon=4.6947 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=7.5707 mle=1.5453 pcon=4.6944 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=7.7655 mle=1.7403 pcon=4.6941 forget=1.3311 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=7.5964 mle=1.5697 pcon=4.6939 forget=1.3329 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 80%|████████  | 36/45 [05:15<01:15,  8.43s/it] 82%|████████▏ | 37/45 [05:26<01:13,  9.23s/it] 84%|████████▍ | 38/45 [05:35<01:04,  9.14s/it] 87%|████████▋ | 39/45 [05:44<00:54,  9.05s/it] 89%|████████▉ | 40/45 [05:53<00:45,  9.06s/it] 91%|█████████ | 41/45 [06:01<00:35,  8.85s/it] 93%|█████████▎| 42/45 [06:10<00:26,  8.76s/it] 96%|█████████▌| 43/45 [06:19<00:17,  8.86s/it][loss] ep 35 it 150 total=7.5344 mle=1.5199 pcon=4.6933 forget=1.3213 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=7.7132 mle=1.6865 pcon=4.6929 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=7.6802 mle=1.6728 pcon=4.6926 forget=1.3147 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=7.6530 mle=1.6405 pcon=4.6922 forget=1.3203 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=7.6905 mle=1.6663 pcon=4.6920 forget=1.3322 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=7.7318 mle=1.7187 pcon=4.6916 forget=1.3215 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.7865 mle=1.7747 pcon=4.6910 forget=1.3208 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=7.8412 mle=1.8258 pcon=4.6908 forget=1.3246 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.7587 mle=1.7216 pcon=4.6904 forget=1.3468 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=7.8177 mle=1.8107 pcon=4.6899 forget=1.3171 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=7.8591 mle=1.8262 pcon=4.6896 forget=1.3434 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=7.5919 mle=1.5974 pcon=4.6893 forget=1.3052 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=7.6045 mle=1.5831 pcon=4.6892 forget=1.3322 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=7.7844 mle=1.7777 pcon=4.6890 forget=1.3176 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=7.8105 mle=1.7998 pcon=4.6887 forget=1.3220 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=7.5968 mle=1.5882 pcon=4.6882 forget=1.3204 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=7.5561 mle=1.5582 pcon=4.6880 forget=1.3099 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=7.5794 mle=1.5623 pcon=4.6876 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=7.5426 mle=1.5288 pcon=4.6874 forget=1.3263 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.6886 mle=1.6856 pcon=4.6872 forget=1.3159 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.5995 mle=1.5665 pcon=4.6870 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=7.6364 mle=1.6354 pcon=4.6867 forget=1.3143 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=7.6645 mle=1.6590 pcon=4.6864 forget=1.3190 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=7.5761 mle=1.5632 pcon=4.6861 forget=1.3269 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=7.5178 mle=1.5040 pcon=4.6858 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=7.5941 mle=1.5853 pcon=4.6856 forget=1.3233 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=7.8436 mle=1.8329 pcon=4.6853 forget=1.3254 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=7.8664 mle=1.8458 pcon=4.6849 forget=1.3356 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=7.7119 mle=1.7057 pcon=4.6845 forget=1.3216 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=7.6524 mle=1.6464 pcon=4.6843 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=7.6538 mle=1.6364 pcon=4.6841 forget=1.3333 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=7.7060 mle=1.7143 pcon=4.6840 forget=1.3077 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=7.6355 mle=1.6248 pcon=4.6837 forget=1.3269 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=7.6483 mle=1.6471 pcon=4.6836 forget=1.3176 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=7.6198 mle=1.6208 pcon=4.6833 forget=1.3157 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=7.7380 mle=1.7350 pcon=4.6832 forget=1.3198 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=7.6489 mle=1.6435 pcon=4.6830 forget=1.3224 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=7.6180 mle=1.6071 pcon=4.6828 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=7.6919 mle=1.6905 pcon=4.6827 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=7.7214 mle=1.7300 pcon=4.6824 forget=1.3089 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=7.6340 mle=1.6380 pcon=4.6822 forget=1.3138 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=7.6324 mle=1.6194 pcon=4.6820 forget=1.3310 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=7.7032 mle=1.6899 pcon=4.6818 forget=1.3315 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=7.6100 mle=1.6108 pcon=4.6816 forget=1.3177 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=7.6977 mle=1.6997 pcon=4.6813 forget=1.3166 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=7.6718 mle=1.6692 pcon=4.6814 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=7.6859 mle=1.6620 pcon=4.6812 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=7.5352 mle=1.5285 pcon=4.6810 forget=1.3257 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=7.7086 mle=1.6898 pcon=4.6808 forget=1.3380 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=7.6387 mle=1.6397 pcon=4.6807 forget=1.3183 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=7.5865 mle=1.5877 pcon=4.6806 forget=1.3183 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=7.6778 mle=1.6717 pcon=4.6805 forget=1.3257 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=7.6776 mle=1.6645 pcon=4.6804 forget=1.3327 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=7.5974 mle=1.5922 pcon=4.6802 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=7.7198 mle=1.7069 pcon=4.6800 forget=1.3329 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=7.7838 mle=1.7750 pcon=4.6798 forget=1.3290 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=7.5505 mle=1.5531 pcon=4.6797 forget=1.3177 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=7.7047 mle=1.6985 pcon=4.6795 forget=1.3266 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=7.8837 mle=1.8765 pcon=4.6793 forget=1.3279 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=7.6669 mle=1.6456 pcon=4.6791 forget=1.3422 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=7.7863 mle=1.7598 pcon=4.6790 forget=1.3474 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=7.8538 mle=1.8453 pcon=4.6788 forget=1.3297 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 98%|█████████▊| 44/45 [06:28<00:08,  8.82s/it]100%|██████████| 45/45 [06:37<00:00,  8.85s/it]100%|██████████| 45/45 [06:37<00:00,  8.82s/it]
[loss] ep 43 it 130 total=7.8585 mle=1.8353 pcon=4.6787 forget=1.3446 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=7.5237 mle=1.5157 pcon=4.6785 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=7.4960 mle=1.5036 pcon=4.6784 forget=1.3140 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=7.5578 mle=1.5592 pcon=4.6783 forget=1.3204 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=7.7294 mle=1.7133 pcon=4.6782 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=7.7502 mle=1.7579 pcon=4.6781 forget=1.3142 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=7.7715 mle=1.7678 pcon=4.6780 forget=1.3257 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=7.6114 mle=1.6105 pcon=4.6778 forget=1.3230 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=7.7271 mle=1.7135 pcon=4.6777 forget=1.3359 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=7.7657 mle=1.7369 pcon=4.6775 forget=1.3513 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=7.6687 mle=1.6548 pcon=4.6774 forget=1.3365 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=7.8588 mle=1.8557 pcon=4.6773 forget=1.3258 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=7.6604 mle=1.6446 pcon=4.6772 forget=1.3386 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[Run] lambda=0.2 lr=0.001 epochs=50 lora_r=8
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes=None, forget_list_path=None, forget_classes_inc='0,8,11,40,51,66,67,88,94,57', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:14<12:06, 14.82s/it]  4%|▍         | 2/50 [00:23<09:00, 11.25s/it]  6%|▌         | 3/50 [00:32<07:50, 10.02s/it]  8%|▊         | 4/50 [00:40<07:15,  9.46s/it] 10%|█         | 5/50 [00:49<06:47,  9.05s/it] 12%|█▏        | 6/50 [00:57<06:29,  8.86s/it][loss] ep 0 it 0 total=8.2323 mle=1.5618 pcon=5.2951 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.3187 mle=1.6307 pcon=5.2880 forget=1.4000 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.4639 mle=1.7913 pcon=5.2813 forget=1.3913 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.4349 mle=1.7483 pcon=5.2750 forget=1.4116 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.5257 mle=1.8429 pcon=5.2683 forget=1.4145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.3324 mle=1.6800 pcon=5.2618 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.2595 mle=1.6257 pcon=5.2557 forget=1.3780 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.4394 mle=1.8018 pcon=5.2498 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 1 it 10 total=8.0948 mle=1.4467 pcon=5.2437 forget=1.4044 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.2489 mle=1.6388 pcon=5.2378 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.1407 mle=1.5267 pcon=5.2322 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.2072 mle=1.6062 pcon=5.2265 forget=1.3745 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.2559 mle=1.6693 pcon=5.2211 forget=1.3654 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.1514 mle=1.5594 pcon=5.2158 forget=1.3762 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.2312 mle=1.6335 pcon=5.2102 forget=1.3874 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.3117 mle=1.7252 pcon=5.2050 forget=1.3815 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 2 it 20 total=8.0013 mle=1.4193 pcon=5.1998 forget=1.3822 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.3748 mle=1.8334 pcon=5.1947 forget=1.3467 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.2557 mle=1.6844 pcon=5.1895 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2146 mle=1.6702 pcon=5.1848 forget=1.3596 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.3575 mle=1.8061 pcon=5.1798 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.3046 mle=1.7526 pcon=5.1751 forget=1.3769 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.9739 mle=1.4274 pcon=5.1706 forget=1.3759 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1376 mle=1.6127 pcon=5.1666 forget=1.3583 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 3 it 30 total=8.1875 mle=1.6634 pcon=5.1623 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.0958 mle=1.5679 pcon=5.1581 forget=1.3697 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.0677 mle=1.5599 pcon=5.1540 forget=1.3539 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.3342 mle=1.8215 pcon=5.1498 forget=1.3628 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.2084 mle=1.7049 pcon=5.1462 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.2636 mle=1.7594 pcon=5.1425 forget=1.3618 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.3264 mle=1.8246 pcon=5.1384 forget=1.3633 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.1235 mle=1.6196 pcon=5.1347 forget=1.3692 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 4 it 40 total=8.0828 mle=1.5754 pcon=5.1310 forget=1.3764 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.0057 mle=1.5308 pcon=5.1275 forget=1.3473 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.2290 mle=1.7060 pcon=5.1244 forget=1.3985 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.1644 mle=1.6601 pcon=5.1209 forget=1.3834 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.2964 mle=1.8093 pcon=5.1176 forget=1.3696 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=7.9093 mle=1.4520 pcon=5.1145 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.1729 mle=1.6863 pcon=5.1117 forget=1.3750 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 5 it 0 total=8.0600 mle=1.6085 pcon=5.1084 forget=1.3431 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1418 mle=1.6930 pcon=5.1055 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.2608 mle=1.7998 pcon=5.1024 forget=1.3586 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.4409 mle=1.9764 pcon=5.0993 forget=1.3652 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2330 mle=1.7906 pcon=5.0964 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.1484 mle=1.7134 pcon=5.0933 forget=1.3416 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2211 mle=1.7675 pcon=5.0904 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.1621 mle=1.7199 pcon=5.0874 forget=1.3548 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 6 it 10 total=7.9844 mle=1.5560 pcon=5.0847 forget=1.3436 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.1433 mle=1.7057 pcon=5.0821 forget=1.3555 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1251 mle=1.7003 pcon=5.0797 forget=1.3451 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9365 mle=1.5105 pcon=5.0772 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.1206 mle=1.6774 pcon=5.0745 forget=1.3687 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.1853 mle=1.7632 pcon=5.0721 forget=1.3499 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.9237 mle=1.4888 pcon=5.0698 forget=1.3651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 14%|█▍        | 7/50 [01:05<06:15,  8.73s/it] 16%|█▌        | 8/50 [01:19<07:17, 10.41s/it] 18%|█▊        | 9/50 [01:31<07:14, 10.61s/it] 20%|██        | 10/50 [01:39<06:38,  9.95s/it] 22%|██▏       | 11/50 [01:48<06:21,  9.77s/it] 24%|██▍       | 12/50 [01:57<05:57,  9.40s/it] 26%|██▌       | 13/50 [02:06<05:42,  9.26s/it][loss] ep 6 it 360 total=8.1561 mle=1.7148 pcon=5.0673 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 7 it 20 total=7.9110 mle=1.5083 pcon=5.0650 forget=1.3376 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.9675 mle=1.5724 pcon=5.0625 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.1365 mle=1.7406 pcon=5.0602 forget=1.3357 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.1778 mle=1.7624 pcon=5.0580 forget=1.3574 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.0640 mle=1.6549 pcon=5.0562 forget=1.3529 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2671 mle=1.8787 pcon=5.0542 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=7.9422 mle=1.5477 pcon=5.0518 forget=1.3427 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1816 mle=1.7907 pcon=5.0496 forget=1.3412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 8 it 30 total=8.1850 mle=1.7912 pcon=5.0477 forget=1.3461 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=7.9136 mle=1.5224 pcon=5.0457 forget=1.3455 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1378 mle=1.7440 pcon=5.0438 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.0297 mle=1.6501 pcon=5.0418 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.9672 mle=1.5663 pcon=5.0400 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.8272 mle=1.4567 pcon=5.0380 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.1990 mle=1.7911 pcon=5.0360 forget=1.3718 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.0390 mle=1.6502 pcon=5.0343 forget=1.3545 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 9 it 40 total=8.1602 mle=1.7996 pcon=5.0325 forget=1.3281 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.1264 mle=1.7461 pcon=5.0306 forget=1.3497 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.0379 mle=1.6804 pcon=5.0293 forget=1.3283 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.8340 mle=1.4883 pcon=5.0276 forget=1.3181 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.1455 mle=1.7623 pcon=5.0261 forget=1.3571 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0237 mle=1.6656 pcon=5.0243 forget=1.3338 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.8725 mle=1.5098 pcon=5.0227 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 10 it 0 total=7.8219 mle=1.4855 pcon=5.0206 forget=1.3158 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=7.8196 mle=1.4734 pcon=5.0192 forget=1.3271 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.0393 mle=1.7008 pcon=5.0174 forget=1.3212 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.0423 mle=1.7017 pcon=5.0157 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1247 mle=1.7803 pcon=5.0142 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.1884 mle=1.8496 pcon=5.0127 forget=1.3261 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1222 mle=1.7761 pcon=5.0110 forget=1.3352 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.8592 mle=1.5341 pcon=5.0096 forget=1.3155 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 11 it 10 total=8.1315 mle=1.7941 pcon=5.0079 forget=1.3295 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.0270 mle=1.7038 pcon=5.0064 forget=1.3167 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9235 mle=1.5910 pcon=5.0049 forget=1.3276 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.8764 mle=1.5653 pcon=5.0032 forget=1.3080 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.8409 mle=1.5266 pcon=5.0014 forget=1.3129 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.8598 mle=1.5286 pcon=4.9996 forget=1.3316 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.0722 mle=1.7508 pcon=4.9980 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.9549 mle=1.6478 pcon=4.9966 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 12 it 20 total=7.9096 mle=1.5877 pcon=4.9945 forget=1.3274 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.8120 mle=1.4977 pcon=4.9927 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.0400 mle=1.7138 pcon=4.9908 forget=1.3354 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.0461 mle=1.7226 pcon=4.9889 forget=1.3345 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=7.8245 mle=1.5208 pcon=4.9875 forget=1.3163 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=7.9134 mle=1.5854 pcon=4.9860 forget=1.3420 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.0233 mle=1.7201 pcon=4.9845 forget=1.3187 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.0234 mle=1.7029 pcon=4.9829 forget=1.3377 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 13 it 30 total=7.9977 mle=1.7021 pcon=4.9814 forget=1.3141 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.1718 mle=1.8293 pcon=4.9798 forget=1.3627 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.0151 mle=1.6913 pcon=4.9778 forget=1.3459 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.0436 mle=1.7434 pcon=4.9757 forget=1.3245 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 28%|██▊       | 14/50 [02:14<05:17,  8.81s/it] 30%|███       | 15/50 [02:22<05:05,  8.74s/it] 32%|███▏      | 16/50 [02:31<04:55,  8.69s/it] 34%|███▍      | 17/50 [02:39<04:41,  8.52s/it] 36%|███▌      | 18/50 [02:47<04:25,  8.31s/it] 38%|███▊      | 19/50 [02:55<04:16,  8.27s/it] 40%|████      | 20/50 [03:04<04:18,  8.61s/it][loss] ep 13 it 230 total=7.9897 mle=1.6848 pcon=4.9740 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7597 mle=1.4619 pcon=4.9722 forget=1.3255 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.0886 mle=1.7767 pcon=4.9705 forget=1.3413 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9520 mle=1.6472 pcon=4.9689 forget=1.3359 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 14 it 40 total=8.0263 mle=1.7115 pcon=4.9669 forget=1.3479 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8943 mle=1.5618 pcon=4.9652 forget=1.3674 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=7.9545 mle=1.6573 pcon=4.9633 forget=1.3340 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=7.9204 mle=1.6104 pcon=4.9613 forget=1.3487 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=7.9438 mle=1.6378 pcon=4.9590 forget=1.3470 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=7.8729 mle=1.5572 pcon=4.9568 forget=1.3588 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.8794 mle=1.5518 pcon=4.9546 forget=1.3729 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.9527 mle=1.6342 pcon=4.9522 forget=1.3663 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=7.9012 mle=1.5875 pcon=4.9499 forget=1.3638 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.9855 mle=1.6573 pcon=4.9476 forget=1.3806 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.0399 mle=1.7207 pcon=4.9451 forget=1.3740 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.8256 mle=1.5093 pcon=4.9426 forget=1.3736 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.8680 mle=1.5553 pcon=4.9398 forget=1.3730 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.1916 mle=1.8642 pcon=4.9368 forget=1.3906 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8771 mle=1.5686 pcon=4.9340 forget=1.3744 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 16 it 10 total=7.8596 mle=1.5494 pcon=4.9309 forget=1.3793 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.8113 mle=1.4917 pcon=4.9280 forget=1.3916 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.6728 mle=1.3744 pcon=4.9248 forget=1.3736 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8385 mle=1.5361 pcon=4.9218 forget=1.3806 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.8702 mle=1.5749 pcon=4.9186 forget=1.3767 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=8.1947 mle=1.9043 pcon=4.9150 forget=1.3754 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.2489 mle=1.9403 pcon=4.9115 forget=1.3972 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.8509 mle=1.5444 pcon=4.9082 forget=1.3982 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 17 it 20 total=8.0847 mle=1.7785 pcon=4.9050 forget=1.4011 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.0440 mle=1.7532 pcon=4.9020 forget=1.3888 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.7951 mle=1.4946 pcon=4.8984 forget=1.4022 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9472 mle=1.6707 pcon=4.8950 forget=1.3816 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=8.0998 mle=1.8161 pcon=4.8914 forget=1.3923 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.0996 mle=1.8269 pcon=4.8880 forget=1.3848 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8918 mle=1.6142 pcon=4.8846 forget=1.3930 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.8923 mle=1.6108 pcon=4.8811 forget=1.4004 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 18 it 30 total=7.7368 mle=1.4807 pcon=4.8779 forget=1.3782 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.0226 mle=1.7421 pcon=4.8747 forget=1.4058 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.0823 mle=1.8125 pcon=4.8715 forget=1.3983 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9145 mle=1.6533 pcon=4.8685 forget=1.3927 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.8025 mle=1.5493 pcon=4.8654 forget=1.3878 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.8730 mle=1.6284 pcon=4.8622 forget=1.3824 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.8862 mle=1.6437 pcon=4.8591 forget=1.3835 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.8339 mle=1.5931 pcon=4.8563 forget=1.3845 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 19 it 40 total=7.8915 mle=1.6531 pcon=4.8534 forget=1.3850 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.8708 mle=1.6356 pcon=4.8504 forget=1.3848 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.7605 mle=1.5319 pcon=4.8476 forget=1.3809 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.7494 mle=1.5270 pcon=4.8446 forget=1.3778 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8565 mle=1.6399 pcon=4.8418 forget=1.3749 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=7.8534 mle=1.6375 pcon=4.8393 forget=1.3765 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=7.7817 mle=1.5818 pcon=4.8369 forget=1.3631 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 20 it 0 total=7.6372 mle=1.4455 pcon=4.8343 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.8335 mle=1.6518 pcon=4.8317 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.7864 mle=1.5848 pcon=4.8292 forget=1.3723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 42%|████▏     | 21/50 [03:14<04:18,  8.91s/it] 44%|████▍     | 22/50 [03:27<04:44, 10.16s/it] 46%|████▌     | 23/50 [03:40<04:54, 10.90s/it] 48%|████▊     | 24/50 [03:49<04:31, 10.42s/it] 50%|█████     | 25/50 [03:58<04:13, 10.15s/it] 52%|█████▏    | 26/50 [04:08<03:58,  9.93s/it] 54%|█████▍    | 27/50 [04:17<03:42,  9.68s/it][loss] ep 20 it 150 total=7.7655 mle=1.5875 pcon=4.8267 forget=1.3513 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=7.7784 mle=1.5999 pcon=4.8242 forget=1.3543 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=7.9238 mle=1.7467 pcon=4.8218 forget=1.3553 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.9325 mle=1.7686 pcon=4.8196 forget=1.3444 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.8357 mle=1.6867 pcon=4.8172 forget=1.3319 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 21 it 10 total=7.5186 mle=1.3730 pcon=4.8147 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.7784 mle=1.6543 pcon=4.8123 forget=1.3117 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.7457 mle=1.5972 pcon=4.8102 forget=1.3383 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=7.7741 mle=1.6416 pcon=4.8080 forget=1.3246 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=7.6591 mle=1.5522 pcon=4.8056 forget=1.3013 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.0287 mle=1.9015 pcon=4.8035 forget=1.3237 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8067 mle=1.7021 pcon=4.8013 forget=1.3033 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.8014 mle=1.7194 pcon=4.7991 forget=1.2828 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 22 it 20 total=7.7256 mle=1.6360 pcon=4.7970 forget=1.2925 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=7.7340 mle=1.6568 pcon=4.7948 forget=1.2823 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=7.7695 mle=1.7041 pcon=4.7927 forget=1.2727 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.5966 mle=1.5378 pcon=4.7904 forget=1.2684 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.7824 mle=1.7240 pcon=4.7885 forget=1.2699 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=7.6102 mle=1.5724 pcon=4.7866 forget=1.2512 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.5716 mle=1.5317 pcon=4.7847 forget=1.2553 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=7.7484 mle=1.6941 pcon=4.7823 forget=1.2720 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 23 it 30 total=7.6763 mle=1.6548 pcon=4.7804 forget=1.2412 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=7.6498 mle=1.6370 pcon=4.7781 forget=1.2347 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=7.8464 mle=1.8055 pcon=4.7759 forget=1.2651 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=7.6005 mle=1.5812 pcon=4.7737 forget=1.2456 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=7.5960 mle=1.5896 pcon=4.7717 forget=1.2347 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.7300 mle=1.7201 pcon=4.7696 forget=1.2403 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.7222 mle=1.7121 pcon=4.7673 forget=1.2428 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=7.5150 mle=1.5098 pcon=4.7652 forget=1.2400 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 24 it 40 total=7.6463 mle=1.6376 pcon=4.7633 forget=1.2453 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.8033 mle=1.7826 pcon=4.7612 forget=1.2595 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.6568 mle=1.6216 pcon=4.7592 forget=1.2760 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.6561 mle=1.6328 pcon=4.7574 forget=1.2659 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=7.6735 mle=1.6407 pcon=4.7556 forget=1.2772 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=7.7168 mle=1.6908 pcon=4.7537 forget=1.2723 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=7.6578 mle=1.6158 pcon=4.7518 forget=1.2902 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 0 total=7.7110 mle=1.6698 pcon=4.7501 forget=1.2910 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=7.6843 mle=1.6351 pcon=4.7484 forget=1.3007 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=7.7704 mle=1.7223 pcon=4.7467 forget=1.3014 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.7550 mle=1.7037 pcon=4.7452 forget=1.3061 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.8438 mle=1.7818 pcon=4.7437 forget=1.3184 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.6389 mle=1.5783 pcon=4.7423 forget=1.3183 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.7281 mle=1.6630 pcon=4.7409 forget=1.3242 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.8443 mle=1.7739 pcon=4.7396 forget=1.3309 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.7740 mle=1.6989 pcon=4.7383 forget=1.3368 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.8202 mle=1.7295 pcon=4.7369 forget=1.3537 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.8147 mle=1.7233 pcon=4.7357 forget=1.3556 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.6641 mle=1.5713 pcon=4.7344 forget=1.3584 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.7835 mle=1.6911 pcon=4.7333 forget=1.3590 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.7366 mle=1.6383 pcon=4.7325 forget=1.3658 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=7.9346 mle=1.8168 pcon=4.7313 forget=1.3865 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=7.9583 mle=1.8483 pcon=4.7304 forget=1.3796 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=7.6701 mle=1.5634 pcon=4.7295 forget=1.3773 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.7598 mle=1.6481 pcon=4.7284 forget=1.3833 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.8026 mle=1.6994 pcon=4.7276 forget=1.3755 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.6495 mle=1.5403 pcon=4.7268 forget=1.3824 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 56%|█████▌    | 28/50 [04:27<03:32,  9.66s/it] 58%|█████▊    | 29/50 [04:35<03:16,  9.38s/it] 60%|██████    | 30/50 [04:45<03:10,  9.51s/it] 62%|██████▏   | 31/50 [04:55<03:05,  9.75s/it] 64%|██████▍   | 32/50 [05:05<02:52,  9.61s/it] 66%|██████▌   | 33/50 [05:13<02:36,  9.21s/it] 68%|██████▊   | 34/50 [05:21<02:20,  8.80s/it] 70%|███████   | 35/50 [05:30<02:12,  8.80s/it][loss] ep 27 it 220 total=7.7631 mle=1.6503 pcon=4.7261 forget=1.3867 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.7162 mle=1.5959 pcon=4.7253 forget=1.3951 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.7781 mle=1.6626 pcon=4.7246 forget=1.3910 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.6883 mle=1.5783 pcon=4.7239 forget=1.3861 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.7632 mle=1.6689 pcon=4.7233 forget=1.3711 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.8335 mle=1.7263 pcon=4.7224 forget=1.3848 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.5647 mle=1.4480 pcon=4.7219 forget=1.3948 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.6030 mle=1.4983 pcon=4.7210 forget=1.3838 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.7266 mle=1.6210 pcon=4.7203 forget=1.3854 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7497 mle=1.6469 pcon=4.7197 forget=1.3830 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=7.6469 mle=1.5403 pcon=4.7189 forget=1.3877 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=7.7720 mle=1.6703 pcon=4.7181 forget=1.3837 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=7.7365 mle=1.6332 pcon=4.7173 forget=1.3859 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.6605 mle=1.5718 pcon=4.7166 forget=1.3720 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.6266 mle=1.5394 pcon=4.7160 forget=1.3712 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.9574 mle=1.8597 pcon=4.7151 forget=1.3827 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.7503 mle=1.6554 pcon=4.7146 forget=1.3803 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.7207 mle=1.6302 pcon=4.7137 forget=1.3768 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.7531 mle=1.6790 pcon=4.7131 forget=1.3610 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.7632 mle=1.6880 pcon=4.7122 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.7158 mle=1.6314 pcon=4.7113 forget=1.3732 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.7210 mle=1.6445 pcon=4.7108 forget=1.3657 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.6153 mle=1.5387 pcon=4.7101 forget=1.3666 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.7154 mle=1.6420 pcon=4.7094 forget=1.3639 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.6963 mle=1.6224 pcon=4.7090 forget=1.3649 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=7.7825 mle=1.7118 pcon=4.7081 forget=1.3626 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.7344 mle=1.6778 pcon=4.7074 forget=1.3492 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.8183 mle=1.7610 pcon=4.7067 forget=1.3506 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.6353 mle=1.5709 pcon=4.7061 forget=1.3582 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=7.7261 mle=1.6687 pcon=4.7056 forget=1.3518 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=7.6001 mle=1.5547 pcon=4.7049 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.8195 mle=1.7714 pcon=4.7043 forget=1.3438 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.7111 mle=1.6661 pcon=4.7037 forget=1.3413 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=7.5881 mle=1.5443 pcon=4.7030 forget=1.3407 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=7.6482 mle=1.6056 pcon=4.7026 forget=1.3401 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=7.5646 mle=1.5393 pcon=4.7022 forget=1.3231 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=7.5478 mle=1.5113 pcon=4.7018 forget=1.3348 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=7.5865 mle=1.5501 pcon=4.7011 forget=1.3353 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.5821 mle=1.5335 pcon=4.7006 forget=1.3479 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.6419 mle=1.6091 pcon=4.6999 forget=1.3329 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=7.6045 mle=1.5728 pcon=4.6993 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=7.5394 mle=1.5106 pcon=4.6986 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.5080 mle=1.4899 pcon=4.6982 forget=1.3199 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.7346 mle=1.7240 pcon=4.6976 forget=1.3130 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=7.8597 mle=1.8513 pcon=4.6970 forget=1.3114 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=7.7175 mle=1.6925 pcon=4.6966 forget=1.3285 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=7.5724 mle=1.5547 pcon=4.6962 forget=1.3215 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=7.7922 mle=1.7754 pcon=4.6957 forget=1.3210 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=7.6603 mle=1.6409 pcon=4.6951 forget=1.3242 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=7.7802 mle=1.7775 pcon=4.6945 forget=1.3082 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=7.5874 mle=1.5681 pcon=4.6941 forget=1.3252 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=7.6864 mle=1.6764 pcon=4.6934 forget=1.3166 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=7.6700 mle=1.6447 pcon=4.6930 forget=1.3323 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=7.6097 mle=1.6117 pcon=4.6923 forget=1.3057 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.6035 mle=1.5947 pcon=4.6918 forget=1.3170 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=7.6864 mle=1.6846 pcon=4.6912 forget=1.3105 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=7.5649 mle=1.5622 pcon=4.6908 forget=1.3119 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=7.5447 mle=1.5401 pcon=4.6903 forget=1.3144 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=7.5500 mle=1.5456 pcon=4.6898 forget=1.3146 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=7.7514 mle=1.7471 pcon=4.6895 forget=1.3148 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=7.5777 mle=1.5730 pcon=4.6891 forget=1.3156 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=7.5222 mle=1.5249 pcon=4.6884 forget=1.3088 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 72%|███████▏  | 36/50 [05:38<02:03,  8.81s/it] 74%|███████▍  | 37/50 [05:49<02:00,  9.29s/it] 76%|███████▌  | 38/50 [05:58<01:49,  9.10s/it] 78%|███████▊  | 39/50 [06:06<01:38,  8.99s/it] 80%|████████  | 40/50 [06:16<01:31,  9.15s/it] 82%|████████▏ | 41/50 [06:25<01:21,  9.08s/it] 84%|████████▍ | 42/50 [06:34<01:12,  9.01s/it] 86%|████████▌ | 43/50 [06:42<01:02,  8.97s/it][loss] ep 35 it 200 total=7.6965 mle=1.6895 pcon=4.6880 forget=1.3190 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=7.6665 mle=1.6758 pcon=4.6876 forget=1.3031 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=7.6345 mle=1.6405 pcon=4.6872 forget=1.3069 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=7.6769 mle=1.6707 pcon=4.6868 forget=1.3194 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 36 it 10 total=7.7136 mle=1.7186 pcon=4.6863 forget=1.3087 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.7720 mle=1.7781 pcon=4.6858 forget=1.3082 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=7.8291 mle=1.8314 pcon=4.6854 forget=1.3123 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.7385 mle=1.7210 pcon=4.6850 forget=1.3326 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=7.8052 mle=1.8157 pcon=4.6844 forget=1.3051 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=7.8394 mle=1.8231 pcon=4.6840 forget=1.3324 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=7.5845 mle=1.6030 pcon=4.6836 forget=1.2979 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=7.5964 mle=1.5921 pcon=4.6835 forget=1.3208 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=7.7719 mle=1.7819 pcon=4.6832 forget=1.3069 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=7.7952 mle=1.8002 pcon=4.6828 forget=1.3122 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=7.5843 mle=1.5889 pcon=4.6823 forget=1.3132 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=7.5473 mle=1.5602 pcon=4.6820 forget=1.3050 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=7.5681 mle=1.5627 pcon=4.6815 forget=1.3239 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=7.5296 mle=1.5295 pcon=4.6813 forget=1.3188 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.6799 mle=1.6884 pcon=4.6810 forget=1.3106 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.5855 mle=1.5661 pcon=4.6807 forget=1.3388 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=7.6253 mle=1.6358 pcon=4.6804 forget=1.3092 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=7.6528 mle=1.6583 pcon=4.6800 forget=1.3145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=7.5711 mle=1.5705 pcon=4.6796 forget=1.3209 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=7.5113 mle=1.5064 pcon=4.6792 forget=1.3256 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=7.5866 mle=1.5859 pcon=4.6790 forget=1.3217 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=7.8367 mle=1.8362 pcon=4.6786 forget=1.3219 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=7.8533 mle=1.8425 pcon=4.6782 forget=1.3325 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=7.7062 mle=1.7082 pcon=4.6778 forget=1.3202 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-lambda0.2-epochgrid_runs-planB_adapter
[loss] ep 39 it 40 total=7.6485 mle=1.6481 pcon=4.6775 forget=1.3229 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=7.6439 mle=1.6356 pcon=4.6773 forget=1.3311 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=7.7028 mle=1.7147 pcon=4.6770 forget=1.3111 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=7.6360 mle=1.6291 pcon=4.6768 forget=1.3301 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=7.6467 mle=1.6522 pcon=4.6766 forget=1.3179 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=7.6137 mle=1.6189 pcon=4.6762 forget=1.3185 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=7.7343 mle=1.7386 pcon=4.6761 forget=1.3196 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=7.6443 mle=1.6440 pcon=4.6759 forget=1.3245 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=7.6170 mle=1.6116 pcon=4.6756 forget=1.3298 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=7.6920 mle=1.6959 pcon=4.6755 forget=1.3206 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=7.7212 mle=1.7315 pcon=4.6752 forget=1.3145 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=7.6471 mle=1.6521 pcon=4.6749 forget=1.3201 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=7.6308 mle=1.6219 pcon=4.6747 forget=1.3342 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=7.7062 mle=1.6950 pcon=4.6744 forget=1.3368 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=7.6173 mle=1.6197 pcon=4.6742 forget=1.3234 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=7.7007 mle=1.7044 pcon=4.6739 forget=1.3223 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=7.6769 mle=1.6747 pcon=4.6740 forget=1.3282 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=7.6850 mle=1.6654 pcon=4.6738 forget=1.3458 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=7.5404 mle=1.5349 pcon=4.6735 forget=1.3320 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=7.7111 mle=1.6957 pcon=4.6733 forget=1.3421 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=7.6496 mle=1.6507 pcon=4.6731 forget=1.3258 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=7.5841 mle=1.5861 pcon=4.6730 forget=1.3250 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=7.6778 mle=1.6717 pcon=4.6729 forget=1.3332 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=7.6841 mle=1.6685 pcon=4.6728 forget=1.3428 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=7.6027 mle=1.5972 pcon=4.6726 forget=1.3329 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=7.7320 mle=1.7163 pcon=4.6724 forget=1.3433 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=7.7971 mle=1.7872 pcon=4.6722 forget=1.3378 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=7.5543 mle=1.5544 pcon=4.6720 forget=1.3279 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=7.7179 mle=1.7094 pcon=4.6719 forget=1.3366 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=7.8877 mle=1.8770 pcon=4.6716 forget=1.3391 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=7.6728 mle=1.6495 pcon=4.6714 forget=1.3519 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
 88%|████████▊ | 44/50 [06:51<00:53,  8.99s/it] 90%|█████████ | 45/50 [07:00<00:44,  8.92s/it] 92%|█████████▏| 46/50 [07:10<00:36,  9.16s/it] 94%|█████████▍| 47/50 [07:20<00:28,  9.42s/it] 96%|█████████▌| 48/50 [07:29<00:18,  9.24s/it] 98%|█████████▊| 49/50 [07:38<00:09,  9.18s/it]100%|██████████| 50/50 [07:47<00:00,  9.28s/it]100%|██████████| 50/50 [07:47<00:00,  9.36s/it]
[loss] ep 43 it 30 total=7.7949 mle=1.7662 pcon=4.6713 forget=1.3573 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=7.8454 mle=1.8352 pcon=4.6711 forget=1.3391 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=7.8644 mle=1.8375 pcon=4.6709 forget=1.3560 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=7.5321 mle=1.5203 pcon=4.6708 forget=1.3410 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=7.5011 mle=1.5056 pcon=4.6706 forget=1.3249 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=7.5640 mle=1.5619 pcon=4.6705 forget=1.3316 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=7.7379 mle=1.7190 pcon=4.6704 forget=1.3485 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=7.7591 mle=1.7624 pcon=4.6703 forget=1.3265 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=7.7813 mle=1.7707 pcon=4.6701 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=7.6116 mle=1.6063 pcon=4.6700 forget=1.3353 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=7.7377 mle=1.7179 pcon=4.6698 forget=1.3500 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=7.7878 mle=1.7547 pcon=4.6696 forget=1.3635 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=7.6803 mle=1.6587 pcon=4.6695 forget=1.3521 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=7.8652 mle=1.8578 pcon=4.6694 forget=1.3379 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=7.6659 mle=1.6455 pcon=4.6693 forget=1.3511 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=7.5770 mle=1.5520 pcon=4.6693 forget=1.3557 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=7.6184 mle=1.6006 pcon=4.6690 forget=1.3488 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=7.7120 mle=1.6937 pcon=4.6690 forget=1.3493 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=7.7778 mle=1.7611 pcon=4.6688 forget=1.3479 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=7.7256 mle=1.7176 pcon=4.6687 forget=1.3393 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=7.6113 mle=1.5713 pcon=4.6684 forget=1.3716 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=7.6402 mle=1.6050 pcon=4.6683 forget=1.3668 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=7.6097 mle=1.5971 pcon=4.6685 forget=1.3442 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=7.5633 mle=1.5536 pcon=4.6684 forget=1.3413 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=7.8218 mle=1.7969 pcon=4.6683 forget=1.3566 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=7.6519 mle=1.6220 pcon=4.6682 forget=1.3617 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=7.7488 mle=1.7321 pcon=4.6680 forget=1.3487 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=7.7891 mle=1.7808 pcon=4.6679 forget=1.3405 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=7.7797 mle=1.7570 pcon=4.6678 forget=1.3549 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=7.6170 mle=1.5861 pcon=4.6676 forget=1.3632 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=7.8677 mle=1.8552 pcon=4.6676 forget=1.3449 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=7.7015 mle=1.6824 pcon=4.6675 forget=1.3515 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=7.6389 mle=1.6289 pcon=4.6674 forget=1.3426 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=7.7728 mle=1.7547 pcon=4.6673 forget=1.3507 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=7.8351 mle=1.8114 pcon=4.6671 forget=1.3566 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=7.5718 mle=1.5523 pcon=4.6670 forget=1.3525 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=7.8320 mle=1.7833 pcon=4.6669 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=7.7429 mle=1.7131 pcon=4.6669 forget=1.3629 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=7.6289 mle=1.6056 pcon=4.6667 forget=1.3566 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=7.6340 mle=1.6001 pcon=4.6667 forget=1.3673 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=7.7611 mle=1.7333 pcon=4.6667 forget=1.3611 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=7.6995 mle=1.6906 pcon=4.6668 forget=1.3421 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=7.6850 mle=1.6443 pcon=4.6667 forget=1.3741 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=7.6749 mle=1.6379 pcon=4.6666 forget=1.3704 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=7.6863 mle=1.6841 pcon=4.6667 forget=1.3355 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=7.6529 mle=1.6412 pcon=4.6666 forget=1.3450 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=7.7608 mle=1.7124 pcon=4.6666 forget=1.3818 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=7.6228 mle=1.5975 pcon=4.6665 forget=1.3588 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=7.6829 mle=1.6549 pcon=4.6665 forget=1.3616 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=7.6476 mle=1.6349 pcon=4.6664 forget=1.3463 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=7.5942 mle=1.5713 pcon=4.6664 forget=1.3565 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=7.6922 mle=1.6727 pcon=4.6663 forget=1.3532 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=7.7544 mle=1.7344 pcon=4.6663 forget=1.3538 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=7.6741 mle=1.6616 pcon=4.6665 forget=1.3460 orth=0.0000 favg=0.0000 nr=64 nf=64 protos=540 fproto_sim=NA
[Full Grid] Completed. Manifest saved to: evaluation_results/CIFAR-100-resnet34-top5-palm-cache6-ema0.999--lambda0.2-epochgrid_runs.csv
