nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.17, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:44<36:42, 44.94s/it]  4%|▍         | 2/50 [01:28<35:31, 44.41s/it]  6%|▌         | 3/50 [02:13<34:57, 44.63s/it]  8%|▊         | 4/50 [02:57<33:45, 44.04s/it] 10%|█         | 5/50 [03:39<32:36, 43.47s/it] 12%|█▏        | 6/50 [04:21<31:36, 43.09s/it] 14%|█▍        | 7/50 [05:04<30:48, 43.00s/it][loss] ep 0 it 0 total=7.7287 mle=1.5709 pcon=5.2950 forget=1.1692 favg=-0.3064 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.6439 mle=1.5423 pcon=5.2879 forget=1.1911 favg=-0.3774 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.7904 mle=1.7005 pcon=5.2809 forget=1.1679 favg=-0.3589 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=7.9583 mle=1.8997 pcon=5.2738 forget=1.1642 favg=-0.3794 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.8194 mle=1.7131 pcon=5.2670 forget=1.1752 favg=-0.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.5814 mle=1.5020 pcon=5.2603 forget=1.1716 favg=-0.3525 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.6787 mle=1.5596 pcon=5.2540 forget=1.1746 favg=-0.3096 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.7295 mle=1.6809 pcon=5.2476 forget=1.1812 favg=-0.3801 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=7.7143 mle=1.6714 pcon=5.2409 forget=1.1985 favg=-0.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=7.6812 mle=1.6373 pcon=5.2346 forget=1.1619 favg=-0.3525 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=7.5902 mle=1.5165 pcon=5.2284 forget=1.1809 favg=-0.3357 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=7.8380 mle=1.7800 pcon=5.2224 forget=1.1808 favg=-0.3452 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=7.7855 mle=1.7647 pcon=5.2167 forget=1.1774 favg=-0.3733 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=7.6744 mle=1.6048 pcon=5.2112 forget=1.1628 favg=-0.3044 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=7.7938 mle=1.7234 pcon=5.2056 forget=1.1712 favg=-0.3064 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=7.8054 mle=1.7942 pcon=5.2002 forget=1.1778 favg=-0.3669 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=7.5532 mle=1.5529 pcon=5.1950 forget=1.1699 favg=-0.3645 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=7.8507 mle=1.8883 pcon=5.1898 forget=1.1532 favg=-0.3806 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=7.7763 mle=1.7421 pcon=5.1846 forget=1.1686 favg=-0.3191 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=7.5115 mle=1.5265 pcon=5.1795 forget=1.1586 favg=-0.3530 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=7.5264 mle=1.5859 pcon=5.1743 forget=1.1767 favg=-0.4106 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=7.8573 mle=1.8829 pcon=5.1696 forget=1.1616 favg=-0.3569 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.4924 mle=1.5883 pcon=5.1648 forget=1.1504 favg=-0.4111 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=7.7026 mle=1.8089 pcon=5.1600 forget=1.1536 favg=-0.4199 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 3 it 30 total=7.4964 mle=1.6937 pcon=5.1552 forget=1.1587 favg=-0.5112 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=7.3754 mle=1.6679 pcon=5.1508 forget=1.1616 favg=-0.6050 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=7.3373 mle=1.7527 pcon=5.1460 forget=1.1485 favg=-0.7100 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=7.3080 mle=1.9192 pcon=5.1415 forget=1.1565 favg=-0.9092 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=6.7968 mle=1.5668 pcon=5.1366 forget=1.1745 favg=-1.0811 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=6.9346 mle=1.8632 pcon=5.1314 forget=1.1919 favg=-1.2520 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=6.7146 mle=1.7582 pcon=5.1260 forget=1.2240 favg=-1.3936 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=6.6014 mle=1.7346 pcon=5.1212 forget=1.2407 favg=-1.4951 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 4 it 40 total=6.4561 mle=1.6435 pcon=5.1162 forget=1.2491 favg=-1.5527 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=6.5593 mle=1.7842 pcon=5.1112 forget=1.2859 favg=-1.6221 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=6.4778 mle=1.6628 pcon=5.1067 forget=1.2991 favg=-1.5908 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=6.4018 mle=1.4814 pcon=5.1025 forget=1.3267 favg=-1.5088 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=7.4626 mle=1.8071 pcon=5.0981 forget=1.3362 favg=-0.7788 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=9.1652 mle=1.4942 pcon=5.0939 forget=1.3739 favg=1.2031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=10.0987 mle=2.0765 pcon=5.0898 forget=1.3768 favg=1.5557 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=9.8105 mle=1.8888 pcon=5.0857 forget=1.3496 favg=1.4863 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=9.3875 mle=1.7840 pcon=5.0815 forget=1.2661 favg=1.2559 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.9701 mle=1.5930 pcon=5.0779 forget=1.2416 favg=1.0576 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.6195 mle=1.6053 pcon=5.0741 forget=1.2044 favg=0.7358 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.4377 mle=1.6816 pcon=5.0711 forget=1.1757 favg=0.5093 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.3980 mle=1.7833 pcon=5.0681 forget=1.1619 favg=0.3848 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.1347 mle=1.5952 pcon=5.0651 forget=1.1672 favg=0.3071 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.4160 mle=1.7645 pcon=5.0624 forget=1.1739 favg=0.4153 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=8.0506 mle=1.4121 pcon=5.0597 forget=1.1899 favg=0.3889 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.0871 mle=1.5483 pcon=5.0570 forget=1.1537 favg=0.3281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1324 mle=1.5941 pcon=5.0545 forget=1.1808 favg=0.3030 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=7.9998 mle=1.6800 pcon=5.0520 forget=1.1632 favg=0.1046 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=7.7546 mle=1.6403 pcon=5.0500 forget=1.1654 favg=-0.1012 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.0393 mle=1.8189 pcon=5.0475 forget=1.1807 favg=-0.0078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.6139 mle=1.5256 pcon=5.0453 forget=1.1837 favg=-0.1407 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=7.5555 mle=1.6665 pcon=5.0430 forget=1.1715 favg=-0.3254 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=7.3920 mle=1.6269 pcon=5.0403 forget=1.1644 favg=-0.4397 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=7.3933 mle=1.7332 pcon=5.0379 forget=1.1642 favg=-0.5420 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=7.0796 mle=1.5961 pcon=5.0352 forget=1.1788 favg=-0.7305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=6.8246 mle=1.5614 pcon=5.0325 forget=1.2083 favg=-0.9775 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=6.7942 mle=1.6323 pcon=5.0301 forget=1.2275 favg=-1.0957 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.4210 mle=1.7764 pcon=5.0278 forget=1.2406 favg=0.3762 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=9.2673 mle=1.7111 pcon=5.0253 forget=1.2135 favg=1.3174 nr=64 nf=64 protos=540 fproto_sim=NA
 16%|█▌        | 8/50 [05:47<30:01, 42.90s/it] 18%|█▊        | 9/50 [06:30<29:18, 42.90s/it] 20%|██        | 10/50 [07:14<28:49, 43.23s/it] 22%|██▏       | 11/50 [07:58<28:21, 43.62s/it] 24%|██▍       | 12/50 [08:42<27:42, 43.76s/it] 26%|██▌       | 13/50 [09:25<26:48, 43.48s/it] 28%|██▊       | 14/50 [10:09<26:11, 43.65s/it] 30%|███       | 15/50 [10:52<25:18, 43.39s/it] 32%|███▏      | 16/50 [11:35<24:30, 43.24s/it][loss] ep 7 it 370 total=8.6902 mle=1.6405 pcon=5.0234 forget=1.1821 favg=0.8442 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 30 total=8.2776 mle=1.5311 pcon=5.0217 forget=1.1838 favg=0.5410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=8.1417 mle=1.6016 pcon=5.0199 forget=1.1788 favg=0.3416 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=7.8882 mle=1.4989 pcon=5.0178 forget=1.1700 favg=0.2014 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=7.8227 mle=1.7063 pcon=5.0161 forget=1.1636 favg=-0.0634 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=7.2971 mle=1.5326 pcon=5.0148 forget=1.1604 favg=-0.4106 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=7.0731 mle=1.6806 pcon=5.0128 forget=1.1604 favg=-0.7808 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=7.3563 mle=1.7387 pcon=5.0105 forget=1.1960 favg=-0.5889 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=7.5140 mle=1.4851 pcon=5.0082 forget=1.2263 favg=-0.2057 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 40 total=7.8206 mle=1.6210 pcon=5.0059 forget=1.2234 favg=-0.0298 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=7.7892 mle=1.6782 pcon=5.0034 forget=1.2113 favg=-0.1037 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=7.9548 mle=1.8189 pcon=5.0016 forget=1.2021 favg=-0.0679 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=7.6985 mle=1.5870 pcon=5.0000 forget=1.1628 favg=-0.0512 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.2897 mle=1.5846 pcon=4.9986 forget=1.1728 favg=0.5337 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.6857 mle=1.5705 pcon=4.9971 forget=1.1776 favg=0.9404 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=8.1809 mle=1.5705 pcon=4.9960 forget=1.1679 favg=0.4465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=7.3695 mle=1.6252 pcon=4.9945 forget=1.1656 favg=-0.4158 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=6.9507 mle=1.6018 pcon=4.9929 forget=1.1719 favg=-0.8159 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=7.6425 mle=1.7135 pcon=4.9914 forget=1.1915 favg=-0.2539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.2176 mle=1.8305 pcon=4.9898 forget=1.2159 favg=0.1814 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.1275 mle=1.8509 pcon=4.9881 forget=1.2277 favg=0.0609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=7.6897 mle=1.5823 pcon=4.9865 forget=1.2017 favg=-0.0807 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=7.4947 mle=1.5801 pcon=4.9852 forget=1.1714 favg=-0.2419 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.5256 mle=1.6489 pcon=4.9839 forget=1.1865 favg=-0.2937 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=8.2625 mle=1.5822 pcon=4.9827 forget=1.1771 favg=0.5205 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.9537 mle=1.6933 pcon=4.9818 forget=1.1692 favg=1.1094 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=8.1790 mle=1.5834 pcon=4.9810 forget=1.1615 favg=0.4531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=7.5755 mle=1.6642 pcon=4.9796 forget=1.1623 favg=-0.2306 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=7.4169 mle=1.7587 pcon=4.9786 forget=1.1593 favg=-0.4797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=7.0667 mle=1.6277 pcon=4.9778 forget=1.1623 favg=-0.7012 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=7.6122 mle=2.0129 pcon=4.9764 forget=1.1766 favg=-0.5537 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=7.5300 mle=1.6744 pcon=4.9748 forget=1.2152 favg=-0.3345 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=7.5184 mle=1.6019 pcon=4.9728 forget=1.2481 favg=-0.3044 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.4983 mle=1.7230 pcon=4.9710 forget=1.2128 favg=-0.4084 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=7.4987 mle=1.5986 pcon=4.9695 forget=1.1787 favg=-0.2482 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=9.2076 mle=1.7975 pcon=4.9685 forget=1.1681 favg=1.2734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=8.9493 mle=1.6315 pcon=4.9676 forget=1.1812 favg=1.1689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=8.2539 mle=1.5260 pcon=4.9671 forget=1.1890 favg=0.5718 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=7.6816 mle=1.5278 pcon=4.9660 forget=1.1666 favg=0.0212 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=7.5839 mle=1.8275 pcon=4.9646 forget=1.1697 favg=-0.3779 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=6.5815 mle=1.4183 pcon=4.9631 forget=1.1522 favg=-0.9521 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=6.1832 mle=1.4834 pcon=4.9613 forget=1.1809 favg=-1.4424 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=6.3344 mle=1.6015 pcon=4.9596 forget=1.1775 favg=-1.4043 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.7917 mle=1.5684 pcon=4.9586 forget=1.1865 favg=1.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=9.0904 mle=1.7063 pcon=4.9576 forget=1.1941 favg=1.2324 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=8.7915 mle=1.5588 pcon=4.9565 forget=1.1794 favg=1.0967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.4646 mle=1.5780 pcon=4.9551 forget=1.1839 favg=0.7476 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=8.1746 mle=1.5805 pcon=4.9537 forget=1.1660 favg=0.4744 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=8.1653 mle=1.7631 pcon=4.9518 forget=1.1574 favg=0.2930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.7209 mle=1.7694 pcon=4.9504 forget=1.1604 favg=-0.1593 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=6.6933 mle=1.6092 pcon=4.9490 forget=1.1468 favg=-1.0117 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=8.4246 mle=1.8472 pcon=4.9473 forget=1.1633 favg=0.4668 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=9.0694 mle=1.6811 pcon=4.9461 forget=1.1834 favg=1.2588 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=8.3441 mle=1.6904 pcon=4.9447 forget=1.1675 favg=0.5415 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=7.4765 mle=1.6822 pcon=4.9430 forget=1.1476 favg=-0.2964 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=7.2916 mle=1.6986 pcon=4.9415 forget=1.1540 favg=-0.5024 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=6.7798 mle=1.4815 pcon=4.9395 forget=1.1303 favg=-0.7715 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=6.6341 mle=1.5529 pcon=4.9377 forget=1.1248 favg=-0.9814 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=6.4668 mle=1.6951 pcon=4.9358 forget=1.1356 favg=-1.2998 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=6.2650 mle=1.5990 pcon=4.9338 forget=1.1423 favg=-1.4102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=6.8337 mle=2.0022 pcon=4.9318 forget=1.1801 favg=-1.2803 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=7.5011 mle=1.5998 pcon=4.9298 forget=1.2249 favg=-0.2534 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=9.0058 mle=1.5151 pcon=4.9275 forget=1.2585 favg=1.3047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=9.2946 mle=1.6025 pcon=4.9249 forget=1.2613 favg=1.5059 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=8.9009 mle=1.5204 pcon=4.9222 forget=1.2161 favg=1.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=8.3346 mle=1.5438 pcon=4.9196 forget=1.1690 favg=0.7021 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=7.8969 mle=1.6342 pcon=4.9166 forget=1.1524 favg=0.1937 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.3014 mle=1.5666 pcon=4.9137 forget=1.1383 favg=-0.3171 nr=64 nf=64 protos=540 fproto_sim=NA
 34%|███▍      | 17/50 [12:17<23:36, 42.91s/it] 36%|███▌      | 18/50 [13:00<22:51, 42.87s/it] 38%|███▊      | 19/50 [13:43<22:10, 42.93s/it] 40%|████      | 20/50 [14:26<21:34, 43.14s/it] 42%|████▏     | 21/50 [15:09<20:46, 42.97s/it] 44%|████▍     | 22/50 [15:53<20:08, 43.14s/it] 46%|████▌     | 23/50 [16:36<19:28, 43.29s/it] 48%|████▊     | 24/50 [17:20<18:46, 43.34s/it] 50%|█████     | 25/50 [18:03<18:01, 43.25s/it][loss] ep 16 it 260 total=6.9892 mle=1.8952 pcon=4.9106 forget=1.1374 favg=-0.9541 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=6.5758 mle=1.7592 pcon=4.9080 forget=1.1400 favg=-1.2314 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=7.6016 mle=1.6183 pcon=4.9054 forget=1.1429 favg=-0.0651 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 20 total=8.3811 mle=1.7665 pcon=4.9025 forget=1.1555 favg=0.5566 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.4685 mle=1.7633 pcon=4.8999 forget=1.1646 favg=0.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=8.1115 mle=1.5489 pcon=4.8967 forget=1.1791 favg=0.4868 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.9836 mle=1.5641 pcon=4.8930 forget=1.1805 favg=0.3459 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=7.8227 mle=1.5953 pcon=4.8894 forget=1.1911 favg=0.1470 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=7.5112 mle=1.4517 pcon=4.8861 forget=1.1802 favg=-0.0069 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=7.8255 mle=1.7913 pcon=4.8824 forget=1.1801 favg=-0.0284 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=7.9549 mle=1.7326 pcon=4.8784 forget=1.1752 favg=0.1687 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 30 total=8.1989 mle=1.5358 pcon=4.8751 forget=1.1694 favg=0.6187 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=8.4728 mle=1.6271 pcon=4.8715 forget=1.1851 favg=0.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=8.1625 mle=1.6307 pcon=4.8679 forget=1.1796 favg=0.4844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.7063 mle=1.5724 pcon=4.8644 forget=1.1648 favg=0.1047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.1981 mle=1.6615 pcon=4.8608 forget=1.1451 favg=-0.4692 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=6.7614 mle=1.6178 pcon=4.8575 forget=1.1351 favg=-0.8491 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=6.5964 mle=1.7199 pcon=4.8543 forget=1.1189 favg=-1.0967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=6.5197 mle=1.6810 pcon=4.8514 forget=1.1377 favg=-1.1504 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 40 total=6.7384 mle=1.5851 pcon=4.8485 forget=1.1592 favg=-0.8545 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=7.7887 mle=1.6210 pcon=4.8458 forget=1.1931 favg=0.1288 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=8.5261 mle=1.5859 pcon=4.8427 forget=1.2176 favg=0.8799 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=8.8367 mle=1.6637 pcon=4.8396 forget=1.2259 favg=1.1074 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=8.9530 mle=1.8355 pcon=4.8365 forget=1.2253 favg=1.0557 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=8.5574 mle=1.6479 pcon=4.8336 forget=1.2078 favg=0.8682 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=8.0127 mle=1.5207 pcon=4.8304 forget=1.1831 favg=0.4785 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=7.6267 mle=1.6415 pcon=4.8273 forget=1.1467 favg=0.0111 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=7.2245 mle=1.6893 pcon=4.8243 forget=1.1335 favg=-0.4226 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=7.1287 mle=1.7483 pcon=4.8217 forget=1.1447 favg=-0.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=7.0267 mle=1.7877 pcon=4.8190 forget=1.1358 favg=-0.7158 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=6.8831 mle=1.5617 pcon=4.8165 forget=1.1226 favg=-0.6177 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=7.3753 mle=1.9077 pcon=4.8141 forget=1.1166 favg=-0.4631 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.3239 mle=1.7467 pcon=4.8118 forget=1.1307 favg=-0.3652 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.2305 mle=1.4828 pcon=4.8095 forget=1.1428 favg=-0.2046 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=7.4291 mle=1.4764 pcon=4.8071 forget=1.1705 favg=-0.0248 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.8362 mle=1.6201 pcon=4.8045 forget=1.1944 favg=0.2172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=7.9880 mle=1.6059 pcon=4.8019 forget=1.2151 favg=0.3650 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=8.3305 mle=1.5788 pcon=4.7992 forget=1.2132 favg=0.7393 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=8.5290 mle=1.7417 pcon=4.7965 forget=1.2120 favg=0.7788 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=8.2361 mle=1.6376 pcon=4.7936 forget=1.1769 favg=0.6279 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=7.8488 mle=1.5552 pcon=4.7909 forget=1.1495 favg=0.3533 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=7.5751 mle=1.5822 pcon=4.7884 forget=1.1616 favg=0.0428 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=7.1893 mle=1.6140 pcon=4.7862 forget=1.1442 favg=-0.3552 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=6.8757 mle=1.6818 pcon=4.7842 forget=1.1289 favg=-0.7192 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=6.5462 mle=1.5876 pcon=4.7821 forget=1.1418 favg=-0.9653 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=6.4392 mle=1.5938 pcon=4.7803 forget=1.1237 favg=-1.0586 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=6.5495 mle=1.5731 pcon=4.7786 forget=1.1270 favg=-0.9292 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=6.8150 mle=1.4928 pcon=4.7766 forget=1.1535 favg=-0.6079 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.6602 mle=1.7185 pcon=4.7748 forget=1.1912 favg=-0.0243 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=8.3537 mle=1.8809 pcon=4.7725 forget=1.2564 favg=0.4438 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 23 it 30 total=8.3385 mle=1.5075 pcon=4.7706 forget=1.2801 favg=0.7803 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=8.5570 mle=1.6193 pcon=4.7682 forget=1.2779 favg=0.8916 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=8.4891 mle=1.5626 pcon=4.7659 forget=1.2515 favg=0.9092 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=8.5506 mle=1.7341 pcon=4.7637 forget=1.1768 favg=0.8760 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=8.3142 mle=1.6121 pcon=4.7619 forget=1.1574 favg=0.7827 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=7.9386 mle=1.5981 pcon=4.7601 forget=1.1571 favg=0.4233 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=7.4403 mle=1.6224 pcon=4.7584 forget=1.1491 favg=-0.0897 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=6.8293 mle=1.5702 pcon=4.7566 forget=1.1499 favg=-0.6475 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=6.3289 mle=1.5535 pcon=4.7549 forget=1.1229 favg=-1.1025 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=6.2811 mle=1.6084 pcon=4.7532 forget=1.1323 favg=-1.2129 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=6.6528 mle=1.5962 pcon=4.7514 forget=1.1539 favg=-0.8486 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=7.5810 mle=1.6348 pcon=4.7498 forget=1.1929 favg=0.0035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=8.0105 mle=1.5120 pcon=4.7481 forget=1.2318 favg=0.5186 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=8.3839 mle=1.7150 pcon=4.7465 forget=1.2486 favg=0.6738 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=8.2326 mle=1.5657 pcon=4.7450 forget=1.2365 favg=0.6855 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 0 total=8.1650 mle=1.5756 pcon=4.7433 forget=1.2211 favg=0.6250 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=8.1526 mle=1.7394 pcon=4.7419 forget=1.1798 favg=0.4915 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▏    | 26/50 [18:46<17:15, 43.14s/it] 54%|█████▍    | 27/50 [19:28<16:28, 42.99s/it] 56%|█████▌    | 28/50 [20:12<15:50, 43.19s/it] 58%|█████▊    | 29/50 [20:56<15:10, 43.35s/it] 60%|██████    | 30/50 [21:40<14:33, 43.67s/it] 62%|██████▏   | 31/50 [22:23<13:45, 43.43s/it] 64%|██████▍   | 32/50 [23:06<12:57, 43.20s/it] 66%|██████▌   | 33/50 [23:44<11:51, 41.83s/it][loss] ep 25 it 100 total=8.0017 mle=1.6240 pcon=4.7404 forget=1.1514 favg=0.4858 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=7.9144 mle=1.7257 pcon=4.7391 forget=1.1381 favg=0.3115 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=7.6336 mle=1.8236 pcon=4.7376 forget=1.1495 favg=-0.0771 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=7.1836 mle=1.7086 pcon=4.7360 forget=1.1550 favg=-0.4160 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=7.1344 mle=1.6172 pcon=4.7346 forget=1.1398 favg=-0.3572 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=7.0749 mle=1.5170 pcon=4.7335 forget=1.1339 favg=-0.3096 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.2532 mle=1.6266 pcon=4.7324 forget=1.1321 favg=-0.2379 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=7.2191 mle=1.5472 pcon=4.7313 forget=1.1340 favg=-0.1934 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=7.4809 mle=1.6926 pcon=4.7304 forget=1.1314 favg=-0.0735 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.4231 mle=1.5162 pcon=4.7294 forget=1.1388 favg=0.0388 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=7.6608 mle=1.6525 pcon=4.7282 forget=1.1523 favg=0.1278 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.5677 mle=1.4979 pcon=4.7273 forget=1.1611 favg=0.1813 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=8.2416 mle=1.8898 pcon=4.7264 forget=1.1707 favg=0.4548 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=8.0512 mle=1.5634 pcon=4.7252 forget=1.1772 favg=0.5854 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=8.1296 mle=1.6435 pcon=4.7240 forget=1.1840 favg=0.5781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=7.8791 mle=1.5595 pcon=4.7225 forget=1.1896 favg=0.4075 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=7.6282 mle=1.5468 pcon=4.7210 forget=1.1914 favg=0.1689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=7.3402 mle=1.5420 pcon=4.7195 forget=1.1726 favg=-0.0940 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=7.0848 mle=1.4776 pcon=4.7181 forget=1.1530 favg=-0.2639 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=7.0326 mle=1.5913 pcon=4.7167 forget=1.1387 favg=-0.4141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=7.1442 mle=1.6956 pcon=4.7156 forget=1.1341 favg=-0.4011 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=7.2801 mle=1.7354 pcon=4.7146 forget=1.1407 favg=-0.3105 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=7.1690 mle=1.6671 pcon=4.7138 forget=1.1309 favg=-0.3428 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=7.2299 mle=1.6904 pcon=4.7131 forget=1.1301 favg=-0.3037 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=7.1958 mle=1.5802 pcon=4.7125 forget=1.1369 favg=-0.2338 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=7.2421 mle=1.5605 pcon=4.7118 forget=1.1271 favg=-0.1573 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=7.4081 mle=1.4598 pcon=4.7109 forget=1.1393 favg=0.0980 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=7.7122 mle=1.5781 pcon=4.7100 forget=1.1525 favg=0.2715 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=8.1901 mle=1.7406 pcon=4.7090 forget=1.1691 favg=0.5713 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=8.1448 mle=1.6720 pcon=4.7081 forget=1.1763 favg=0.5884 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=8.1392 mle=1.6991 pcon=4.7069 forget=1.1868 favg=0.5464 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=7.8996 mle=1.5390 pcon=4.7057 forget=1.1837 favg=0.4712 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=7.8347 mle=1.6355 pcon=4.7046 forget=1.1837 favg=0.3110 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=7.5700 mle=1.5844 pcon=4.7034 forget=1.1693 favg=0.1129 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=7.5022 mle=1.5684 pcon=4.7023 forget=1.1626 favg=0.0689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=7.3610 mle=1.6855 pcon=4.7014 forget=1.1390 favg=-0.1649 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=7.4577 mle=1.5527 pcon=4.7005 forget=1.1487 favg=0.0557 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=7.6237 mle=1.6032 pcon=4.6997 forget=1.1410 favg=0.1798 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=7.6576 mle=1.6292 pcon=4.6992 forget=1.1619 favg=0.1674 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=7.5652 mle=1.5794 pcon=4.6986 forget=1.1489 favg=0.1382 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.5136 mle=1.7624 pcon=4.6980 forget=1.1385 favg=-0.0853 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.1514 mle=1.4938 pcon=4.6975 forget=1.1579 favg=-0.1979 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.1461 mle=1.7639 pcon=4.6970 forget=1.1347 favg=-0.4495 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=6.6692 mle=1.4652 pcon=4.6966 forget=1.1334 favg=-0.6260 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=6.7846 mle=1.7192 pcon=4.6960 forget=1.1350 favg=-0.7656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=6.5205 mle=1.6187 pcon=4.6955 forget=1.1478 favg=-0.9414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=6.4253 mle=1.5224 pcon=4.6948 forget=1.1676 favg=-0.9595 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=6.6127 mle=1.5727 pcon=4.6941 forget=1.1940 favg=-0.8481 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=6.7832 mle=1.5571 pcon=4.6932 forget=1.2267 favg=-0.6938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=7.2262 mle=1.5591 pcon=4.6923 forget=1.2484 favg=-0.2737 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=7.9088 mle=1.5113 pcon=4.6913 forget=1.2638 favg=0.4424 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=8.5803 mle=1.6160 pcon=4.6904 forget=1.2690 favg=1.0049 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=8.6468 mle=1.5455 pcon=4.6895 forget=1.2409 favg=1.1709 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=8.8147 mle=1.6842 pcon=4.6887 forget=1.2309 favg=1.2109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=8.4179 mle=1.5592 pcon=4.6878 forget=1.1968 favg=0.9741 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=8.2060 mle=1.5636 pcon=4.6871 forget=1.2083 favg=0.7471 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=7.8256 mle=1.5558 pcon=4.6866 forget=1.1772 favg=0.4060 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=7.3391 mle=1.6559 pcon=4.6860 forget=1.1407 favg=-0.1436 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=6.8805 mle=1.5737 pcon=4.6855 forget=1.1354 favg=-0.5142 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=6.9613 mle=1.4831 pcon=4.6850 forget=1.1309 favg=-0.3376 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=7.2886 mle=1.4745 pcon=4.6848 forget=1.1374 favg=-0.0081 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=7.4799 mle=1.6319 pcon=4.6846 forget=1.1534 favg=0.0101 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=7.5228 mle=1.8756 pcon=4.6843 forget=1.1346 favg=-0.1716 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=6.9276 mle=1.4989 pcon=4.6840 forget=1.1508 favg=-0.4060 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=6.8633 mle=1.6511 pcon=4.6836 forget=1.1663 favg=-0.6377 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=6.6927 mle=1.6086 pcon=4.6832 forget=1.1558 favg=-0.7549 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=6.6143 mle=1.6979 pcon=4.6826 forget=1.1649 favg=-0.9312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=6.5436 mle=1.7114 pcon=4.6822 forget=1.1677 favg=-1.0176 nr=64 nf=64 protos=540 fproto_sim=NA
 68%|██████▊   | 34/50 [24:19<10:34, 39.68s/it] 70%|███████   | 35/50 [24:55<09:38, 38.59s/it] 72%|███████▏  | 36/50 [25:30<08:46, 37.61s/it] 74%|███████▍  | 37/50 [26:11<08:23, 38.70s/it] 76%|███████▌  | 38/50 [26:48<07:37, 38.13s/it] 78%|███████▊  | 39/50 [27:24<06:52, 37.50s/it] 80%|████████  | 40/50 [28:00<06:08, 36.84s/it] 82%|████████▏ | 41/50 [28:34<05:25, 36.16s/it] 84%|████████▍ | 42/50 [29:10<04:47, 35.95s/it][loss] ep 33 it 380 total=6.3189 mle=1.5859 pcon=4.6815 forget=1.1991 favg=-1.1475 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 34 it 40 total=6.4448 mle=1.6900 pcon=4.6807 forget=1.1962 favg=-1.1221 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=6.4279 mle=1.5224 pcon=4.6799 forget=1.2124 favg=-0.9868 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=6.8889 mle=1.6122 pcon=4.6793 forget=1.2078 favg=-0.6104 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=7.5488 mle=1.6297 pcon=4.6786 forget=1.2357 favg=0.0047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=8.2306 mle=1.6754 pcon=4.6780 forget=1.2357 favg=0.6416 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=8.4847 mle=1.6077 pcon=4.6773 forget=1.2373 favg=0.9624 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=8.4753 mle=1.5243 pcon=4.6768 forget=1.2331 favg=1.0410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=8.5056 mle=1.5923 pcon=4.6763 forget=1.2116 favg=1.0254 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=8.4125 mle=1.5743 pcon=4.6758 forget=1.2048 favg=0.9575 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=8.5116 mle=1.7689 pcon=4.6753 forget=1.2066 favg=0.8608 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=8.1534 mle=1.6220 pcon=4.6749 forget=1.1793 favg=0.6772 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=7.9008 mle=1.5545 pcon=4.6745 forget=1.1854 favg=0.4863 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=7.8332 mle=1.6785 pcon=4.6739 forget=1.1726 favg=0.3081 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=7.4938 mle=1.5606 pcon=4.6734 forget=1.1631 favg=0.0967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=7.5598 mle=1.7098 pcon=4.6730 forget=1.1595 favg=0.0175 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=7.6482 mle=1.7695 pcon=4.6726 forget=1.1661 favg=0.0400 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=7.6104 mle=1.5214 pcon=4.6724 forget=1.1566 favg=0.2600 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=7.5711 mle=1.5835 pcon=4.6720 forget=1.1755 favg=0.1401 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=7.5567 mle=1.6468 pcon=4.6715 forget=1.1681 favg=0.0703 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=7.2211 mle=1.4997 pcon=4.6712 forget=1.1712 favg=-0.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=7.1567 mle=1.5911 pcon=4.6710 forget=1.1895 favg=-0.2949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=7.0063 mle=1.6434 pcon=4.6705 forget=1.1840 favg=-0.4915 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=6.7167 mle=1.6227 pcon=4.6700 forget=1.1843 favg=-0.7603 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=6.4091 mle=1.4694 pcon=4.6693 forget=1.1850 favg=-0.9146 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=6.5190 mle=1.6560 pcon=4.6689 forget=1.2038 favg=-1.0098 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=6.3739 mle=1.5902 pcon=4.6684 forget=1.1975 favg=-1.0820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=6.3600 mle=1.5637 pcon=4.6678 forget=1.2046 favg=-1.0762 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=6.6259 mle=1.7195 pcon=4.6672 forget=1.2206 favg=-0.9814 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=6.6586 mle=1.5793 pcon=4.6667 forget=1.2201 favg=-0.8076 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=7.0628 mle=1.6327 pcon=4.6662 forget=1.2297 favg=-0.4658 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=7.3837 mle=1.5840 pcon=4.6658 forget=1.2487 favg=-0.1148 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 38 it 30 total=7.8496 mle=1.6673 pcon=4.6656 forget=1.2352 favg=0.2815 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=7.9474 mle=1.4901 pcon=4.6653 forget=1.2227 favg=0.5693 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=8.2876 mle=1.6131 pcon=4.6649 forget=1.2176 favg=0.7920 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=8.4235 mle=1.5721 pcon=4.6646 forget=1.2098 favg=0.9771 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=8.4809 mle=1.5160 pcon=4.6643 forget=1.2040 favg=1.0967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=8.5482 mle=1.6450 pcon=4.6640 forget=1.1952 favg=1.0439 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=8.4892 mle=1.5895 pcon=4.6636 forget=1.1931 favg=1.0430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=8.2414 mle=1.4911 pcon=4.6635 forget=1.1864 favg=0.9004 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=8.2459 mle=1.7090 pcon=4.6634 forget=1.1767 favg=0.6968 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=8.0334 mle=1.6287 pcon=4.6631 forget=1.1932 favg=0.5483 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=7.7271 mle=1.6239 pcon=4.6629 forget=1.1663 favg=0.2739 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=7.4116 mle=1.4617 pcon=4.6627 forget=1.1615 favg=0.1257 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=7.3518 mle=1.6580 pcon=4.6624 forget=1.1711 favg=-0.1398 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=7.0964 mle=1.4866 pcon=4.6622 forget=1.1658 favg=-0.2183 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=7.0289 mle=1.5713 pcon=4.6621 forget=1.1730 favg=-0.3774 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=7.0215 mle=1.5394 pcon=4.6617 forget=1.1744 favg=-0.3540 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=6.9791 mle=1.6032 pcon=4.6615 forget=1.1831 favg=-0.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=6.9883 mle=1.6175 pcon=4.6611 forget=1.1775 favg=-0.4678 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=6.7432 mle=1.4354 pcon=4.6609 forget=1.1816 favg=-0.5347 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=6.9928 mle=1.7374 pcon=4.6606 forget=1.1988 favg=-0.6040 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=6.9291 mle=1.7774 pcon=4.6603 forget=1.2106 favg=-0.7192 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=6.6395 mle=1.5326 pcon=4.6601 forget=1.1993 favg=-0.7524 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=6.4223 mle=1.4354 pcon=4.6598 forget=1.2118 favg=-0.8848 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=6.4439 mle=1.5124 pcon=4.6595 forget=1.2075 favg=-0.9355 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=6.7098 mle=1.8369 pcon=4.6594 forget=1.2263 favg=-1.0127 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=6.3676 mle=1.5795 pcon=4.6589 forget=1.2326 favg=-1.1035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=6.3638 mle=1.5571 pcon=4.6588 forget=1.2261 favg=-1.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=6.5161 mle=1.6076 pcon=4.6586 forget=1.2441 favg=-0.9941 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=6.8095 mle=1.5312 pcon=4.6585 forget=1.2390 favg=-0.6191 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=7.4389 mle=1.5177 pcon=4.6585 forget=1.2451 favg=0.0175 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=8.0719 mle=1.6851 pcon=4.6584 forget=1.2504 favg=0.4780 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=8.1789 mle=1.6336 pcon=4.6583 forget=1.2464 favg=0.6406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=8.2747 mle=1.5705 pcon=4.6580 forget=1.2518 favg=0.7944 nr=64 nf=64 protos=540 fproto_sim=NA
 86%|████████▌ | 43/50 [29:44<04:09, 35.57s/it] 88%|████████▊ | 44/50 [30:20<03:33, 35.52s/it] 90%|█████████ | 45/50 [30:54<02:56, 35.29s/it] 92%|█████████▏| 46/50 [31:26<02:17, 34.28s/it] 94%|█████████▍| 47/50 [31:53<01:35, 31.89s/it] 96%|█████████▌| 48/50 [32:14<00:57, 28.73s/it] 98%|█████████▊| 49/50 [32:32<00:25, 25.50s/it]100%|██████████| 50/50 [32:47<00:00, 22.45s/it]100%|██████████| 50/50 [32:47<00:00, 39.36s/it]
[loss] ep 42 it 120 total=8.5326 mle=1.8228 pcon=4.6578 forget=1.2497 favg=0.8022 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=8.2758 mle=1.5934 pcon=4.6577 forget=1.2386 favg=0.7861 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=8.2780 mle=1.6286 pcon=4.6576 forget=1.2276 favg=0.7642 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.3495 mle=1.6972 pcon=4.6574 forget=1.2258 favg=0.7690 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=8.3006 mle=1.6635 pcon=4.6574 forget=1.2175 favg=0.7622 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=8.1945 mle=1.5863 pcon=4.6573 forget=1.2097 favg=0.7412 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=8.3014 mle=1.6010 pcon=4.6571 forget=1.2293 favg=0.8140 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=8.2728 mle=1.5756 pcon=4.6569 forget=1.2097 favg=0.8306 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=8.3518 mle=1.6544 pcon=4.6568 forget=1.2090 favg=0.8315 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=8.1709 mle=1.4935 pcon=4.6567 forget=1.2059 favg=0.8149 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=8.0523 mle=1.5090 pcon=4.6564 forget=1.1769 favg=0.7100 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=7.9692 mle=1.5228 pcon=4.6563 forget=1.1856 favg=0.6045 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=7.7756 mle=1.5137 pcon=4.6560 forget=1.1921 favg=0.4138 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=7.5386 mle=1.4768 pcon=4.6559 forget=1.1822 favg=0.2238 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=7.5081 mle=1.6666 pcon=4.6557 forget=1.1970 favg=-0.0112 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=7.2607 mle=1.5308 pcon=4.6555 forget=1.1839 favg=-0.1095 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=7.1803 mle=1.6298 pcon=4.6554 forget=1.1968 favg=-0.3018 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=6.9067 mle=1.4978 pcon=4.6553 forget=1.1816 favg=-0.4280 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=6.9090 mle=1.5317 pcon=4.6552 forget=1.1982 favg=-0.4761 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=7.0941 mle=1.7568 pcon=4.6551 forget=1.1891 favg=-0.5068 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=6.9565 mle=1.7507 pcon=4.6550 forget=1.1958 favg=-0.6450 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=6.7315 mle=1.5478 pcon=4.6548 forget=1.2052 favg=-0.6763 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=6.5956 mle=1.5228 pcon=4.6547 forget=1.1916 favg=-0.7734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=6.6301 mle=1.5388 pcon=4.6546 forget=1.1955 favg=-0.7588 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=6.5667 mle=1.5158 pcon=4.6544 forget=1.1959 favg=-0.7993 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=6.6270 mle=1.5712 pcon=4.6543 forget=1.2009 favg=-0.7993 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=6.5963 mle=1.5342 pcon=4.6541 forget=1.2025 favg=-0.7944 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=6.6846 mle=1.6099 pcon=4.6538 forget=1.1860 favg=-0.7651 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=6.6299 mle=1.5098 pcon=4.6537 forget=1.1910 favg=-0.7246 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=6.5472 mle=1.4628 pcon=4.6537 forget=1.2061 favg=-0.7754 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=6.6634 mle=1.5134 pcon=4.6535 forget=1.2065 favg=-0.7100 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=6.7558 mle=1.6268 pcon=4.6533 forget=1.2100 favg=-0.7344 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=6.6257 mle=1.4560 pcon=4.6532 forget=1.1991 favg=-0.6826 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=6.9088 mle=1.7337 pcon=4.6530 forget=1.1999 favg=-0.6777 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=6.8355 mle=1.6521 pcon=4.6529 forget=1.1940 favg=-0.6636 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=6.7052 mle=1.5010 pcon=4.6528 forget=1.2174 favg=-0.6660 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=6.9408 mle=1.7004 pcon=4.6527 forget=1.2156 favg=-0.6279 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=6.8224 mle=1.5463 pcon=4.6524 forget=1.2096 favg=-0.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=6.8440 mle=1.5232 pcon=4.6522 forget=1.1993 favg=-0.5308 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=6.9562 mle=1.6583 pcon=4.6520 forget=1.2172 favg=-0.5713 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=6.8508 mle=1.5339 pcon=4.6517 forget=1.2351 favg=-0.5698 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=6.7926 mle=1.4483 pcon=4.6516 forget=1.2098 favg=-0.5171 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=6.8418 mle=1.5238 pcon=4.6516 forget=1.2323 favg=-0.5659 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=6.8754 mle=1.5340 pcon=4.6514 forget=1.2349 favg=-0.5449 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=6.9778 mle=1.6182 pcon=4.6513 forget=1.2265 favg=-0.5181 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=6.9938 mle=1.5508 pcon=4.6512 forget=1.2393 favg=-0.4475 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=6.9764 mle=1.5535 pcon=4.6511 forget=1.2377 favg=-0.4658 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=7.0771 mle=1.6249 pcon=4.6510 forget=1.2175 favg=-0.4163 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=7.0831 mle=1.6299 pcon=4.6509 forget=1.2419 favg=-0.4397 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=7.1768 mle=1.6692 pcon=4.6508 forget=1.2111 favg=-0.3542 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=7.0719 mle=1.5432 pcon=4.6507 forget=1.2117 favg=-0.3337 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=7.1232 mle=1.5660 pcon=4.6505 forget=1.2037 favg=-0.2971 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=7.1000 mle=1.5083 pcon=4.6503 forget=1.2312 favg=-0.2898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=7.2063 mle=1.5458 pcon=4.6503 forget=1.2380 favg=-0.2278 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=7.2572 mle=1.5950 pcon=4.6502 forget=1.2335 favg=-0.2214 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=7.2915 mle=1.6047 pcon=4.6501 forget=1.2276 favg=-0.1910 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=7.4568 mle=1.7140 pcon=4.6499 forget=1.2193 favg=-0.1263 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=7.4449 mle=1.6682 pcon=4.6497 forget=1.2134 favg=-0.0863 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=7.3957 mle=1.5912 pcon=4.6495 forget=1.2225 favg=-0.0674 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=7.3762 mle=1.5055 pcon=4.6495 forget=1.2242 favg=-0.0030 nr=64 nf=64 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:21,  2.76it/s]  3%|▎         | 10/391 [00:00<00:13, 27.25it/s]  5%|▌         | 20/391 [00:00<00:07, 47.27it/s]  8%|▊         | 30/391 [00:00<00:05, 61.28it/s] 10%|█         | 40/391 [00:00<00:04, 71.23it/s] 13%|█▎        | 50/391 [00:00<00:04, 77.92it/s] 15%|█▌        | 60/391 [00:00<00:03, 83.06it/s] 18%|█▊        | 70/391 [00:01<00:03, 86.15it/s] 20%|██        | 80/391 [00:01<00:03, 88.53it/s] 23%|██▎       | 90/391 [00:01<00:03, 90.67it/s] 26%|██▌       | 100/391 [00:01<00:03, 92.19it/s] 28%|██▊       | 110/391 [00:01<00:03, 92.99it/s] 31%|███       | 120/391 [00:01<00:02, 93.74it/s] 33%|███▎      | 130/391 [00:01<00:02, 93.64it/s] 36%|███▌      | 140/391 [00:01<00:02, 93.68it/s] 38%|███▊      | 150/391 [00:01<00:02, 92.62it/s] 41%|████      | 160/391 [00:02<00:02, 93.51it/s] 43%|████▎     | 170/391 [00:02<00:02, 93.04it/s] 46%|████▌     | 180/391 [00:02<00:02, 93.06it/s] 49%|████▊     | 190/391 [00:02<00:02, 93.62it/s] 51%|█████     | 200/391 [00:02<00:02, 91.67it/s] 54%|█████▎    | 210/391 [00:02<00:01, 92.65it/s] 56%|█████▋    | 220/391 [00:02<00:01, 90.88it/s] 59%|█████▉    | 230/391 [00:02<00:01, 90.74it/s] 61%|██████▏   | 240/391 [00:02<00:01, 92.04it/s] 64%|██████▍   | 250/391 [00:03<00:01, 92.76it/s] 66%|██████▋   | 260/391 [00:03<00:01, 92.18it/s] 69%|██████▉   | 270/391 [00:03<00:01, 92.45it/s] 72%|███████▏  | 280/391 [00:03<00:01, 91.99it/s] 74%|███████▍  | 290/391 [00:03<00:01, 92.74it/s] 77%|███████▋  | 300/391 [00:03<00:00, 91.13it/s] 79%|███████▉  | 310/391 [00:03<00:00, 92.38it/s] 82%|████████▏ | 320/391 [00:03<00:00, 93.16it/s] 84%|████████▍ | 330/391 [00:03<00:00, 93.63it/s] 87%|████████▋ | 340/391 [00:04<00:00, 94.02it/s] 90%|████████▉ | 350/391 [00:04<00:00, 94.41it/s] 92%|█████████▏| 360/391 [00:04<00:00, 94.40it/s] 95%|█████████▍| 370/391 [00:04<00:00, 93.29it/s] 97%|█████████▋| 380/391 [00:04<00:00, 93.68it/s]100%|█████████▉| 390/391 [00:04<00:00, 94.66it/s]100%|██████████| 391/391 [00:04<00:00, 85.84it/s]
50000 images processed, 4.662196159362793 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:29,  2.65it/s] 14%|█▍        | 11/79 [00:00<00:02, 28.85it/s] 27%|██▋       | 21/79 [00:00<00:01, 47.31it/s] 39%|███▉      | 31/79 [00:00<00:00, 61.02it/s] 52%|█████▏    | 41/79 [00:00<00:00, 70.67it/s] 65%|██████▍   | 51/79 [00:00<00:00, 77.40it/s] 77%|███████▋  | 61/79 [00:01<00:00, 82.17it/s] 90%|████████▉ | 71/79 [00:01<00:00, 86.06it/s]100%|██████████| 79/79 [00:01<00:00, 40.85it/s]
10000 images processed, 1.9675102233886719 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:25,  2.38it/s]  5%|▍         | 10/204 [00:00<00:07, 24.42it/s]  9%|▉         | 19/204 [00:00<00:04, 41.39it/s] 14%|█▍        | 29/204 [00:00<00:03, 55.79it/s] 19%|█▉        | 39/204 [00:00<00:02, 66.58it/s] 24%|██▎       | 48/204 [00:00<00:02, 72.99it/s] 28%|██▊       | 58/204 [00:01<00:01, 79.24it/s] 33%|███▎      | 67/204 [00:01<00:01, 80.90it/s] 38%|███▊      | 77/204 [00:01<00:01, 84.95it/s] 42%|████▏     | 86/204 [00:01<00:01, 85.85it/s] 47%|████▋     | 96/204 [00:01<00:01, 87.38it/s] 52%|█████▏    | 106/204 [00:01<00:01, 88.49it/s] 56%|█████▋    | 115/204 [00:01<00:01, 88.53it/s] 61%|██████▏   | 125/204 [00:01<00:00, 89.69it/s] 66%|██████▌   | 135/204 [00:01<00:00, 90.07it/s] 71%|███████   | 145/204 [00:02<00:00, 91.08it/s] 76%|███████▌  | 155/204 [00:02<00:00, 89.06it/s] 81%|████████  | 165/204 [00:02<00:00, 90.15it/s] 86%|████████▌ | 175/204 [00:02<00:00, 91.25it/s] 91%|█████████ | 185/204 [00:02<00:00, 91.00it/s] 96%|█████████▌| 195/204 [00:02<00:00, 91.03it/s]100%|██████████| 204/204 [00:02<00:00, 76.51it/s]
26032 images processed, 2.7331695556640625 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:49,  1.59it/s] 11%|█▏        | 9/79 [00:00<00:04, 14.55it/s] 22%|██▏       | 17/79 [00:00<00:02, 24.24it/s] 32%|███▏      | 25/79 [00:01<00:01, 31.33it/s] 39%|███▉      | 31/79 [00:01<00:01, 36.95it/s] 46%|████▌     | 36/79 [00:01<00:01, 35.94it/s] 54%|█████▍    | 43/79 [00:01<00:00, 37.64it/s] 65%|██████▍   | 51/79 [00:01<00:00, 41.09it/s] 75%|███████▍  | 59/79 [00:01<00:00, 40.72it/s] 85%|████████▍ | 67/79 [00:02<00:00, 41.85it/s] 95%|█████████▍| 75/79 [00:02<00:00, 42.59it/s]100%|██████████| 79/79 [00:02<00:00, 34.42it/s]
10000 images processed, 2.333869695663452 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.37it/s] 14%|█▍        | 11/79 [00:00<00:02, 26.60it/s] 27%|██▋       | 21/79 [00:00<00:01, 44.74it/s] 38%|███▊      | 30/79 [00:00<00:00, 56.64it/s] 51%|█████     | 40/79 [00:00<00:00, 67.39it/s] 63%|██████▎   | 50/79 [00:00<00:00, 75.10it/s] 76%|███████▌  | 60/79 [00:01<00:00, 79.80it/s] 89%|████████▊ | 70/79 [00:01<00:00, 84.24it/s]100%|██████████| 79/79 [00:01<00:00, 62.92it/s]
10000 images processed, 1.282846212387085 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:26,  2.59it/s] 16%|█▌        | 11/70 [00:00<00:02, 28.44it/s] 30%|███       | 21/70 [00:00<00:01, 47.38it/s] 44%|████▍     | 31/70 [00:00<00:00, 61.06it/s] 59%|█████▊    | 41/70 [00:00<00:00, 70.87it/s] 73%|███████▎  | 51/70 [00:00<00:00, 77.77it/s] 87%|████████▋ | 61/70 [00:01<00:00, 82.90it/s]100%|██████████| 70/70 [00:01<00:00, 62.42it/s]
8925 images processed, 1.1557378768920898 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:47,  1.07s/it]  4%|▍         | 2/45 [00:01<00:22,  1.88it/s] 20%|██        | 9/45 [00:01<00:04,  8.87it/s] 24%|██▍       | 11/45 [00:01<00:04,  8.37it/s] 38%|███▊      | 17/45 [00:02<00:02, 13.36it/s] 42%|████▏     | 19/45 [00:02<00:02, 10.94it/s] 51%|█████     | 23/45 [00:02<00:01, 14.77it/s] 58%|█████▊    | 26/45 [00:02<00:01, 11.13it/s] 67%|██████▋   | 30/45 [00:03<00:01, 13.52it/s] 73%|███████▎  | 33/45 [00:03<00:00, 12.82it/s] 78%|███████▊  | 35/45 [00:03<00:00, 10.72it/s] 91%|█████████ | 41/45 [00:03<00:00, 14.74it/s] 96%|█████████▌| 43/45 [00:04<00:00,  9.54it/s]100%|██████████| 45/45 [00:04<00:00, 10.20it/s]
5640 images processed, 4.435792922973633 seconds used

20.41577458381653
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.47  99.01
places365     73.58  79.73
LSUN          19.90  96.01
iSUN          76.99  79.16
dtd           41.38  90.55
AVG           43.26  88.89
Retain-Acc: 0.7310
Forget-as-OOD (retain known vs forget novel):
  FPR: 44.00 AUROC: 90.80 AUIN: 98.78
9.395418882369995
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.17-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
