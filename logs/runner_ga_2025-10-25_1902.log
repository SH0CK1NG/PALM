nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=1e-06, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_ga_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='ga', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:503: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:591: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [00:44<02:57, 44.28s/it] 40%|████      | 2/5 [01:11<01:43, 34.44s/it] 60%|██████    | 3/5 [01:43<01:05, 32.97s/it] 80%|████████  | 4/5 [02:15<00:32, 32.85s/it]100%|██████████| 5/5 [02:47<00:00, 32.37s/it]100%|██████████| 5/5 [02:47<00:00, 33.45s/it]
[loss-ga] ep 0 it 0 total=0.1797 ce_r=0.2466 ce_f=0.3343
[loss-ga] ep 0 it 50 total=0.1472 ce_r=0.1971 ce_f=0.2498
[loss-ga] ep 0 it 100 total=0.1631 ce_r=0.2158 ce_f=0.2636
[loss-ga] ep 0 it 150 total=0.1854 ce_r=0.2407 ce_f=0.2765
[loss-ga] ep 0 it 200 total=0.0553 ce_r=0.0703 ce_f=0.0750
[loss-ga] ep 0 it 250 total=0.0515 ce_r=0.0658 ce_f=0.0712
[loss-ga] ep 0 it 300 total=0.0810 ce_r=0.1093 ce_f=0.1413
[loss-ga] ep 0 it 350 total=0.0246 ce_r=0.0323 ce_f=0.0389
[loss-ga] ep 1 it 10 total=0.0386 ce_r=0.0524 ce_f=0.0688
[loss-ga] ep 1 it 60 total=0.0174 ce_r=0.0197 ce_f=0.0116
[loss-ga] ep 1 it 110 total=0.0646 ce_r=0.0871 ce_f=0.1123
[loss-ga] ep 1 it 160 total=0.0228 ce_r=0.0297 ce_f=0.0342
[loss-ga] ep 1 it 210 total=0.0224 ce_r=0.0298 ce_f=0.0369
[loss-ga] ep 1 it 260 total=0.0518 ce_r=0.0709 ce_f=0.0955
[loss-ga] ep 1 it 310 total=0.0119 ce_r=0.0146 ce_f=0.0135
[loss-ga] ep 1 it 360 total=0.0412 ce_r=0.0465 ce_f=0.0262
[loss-ga] ep 2 it 20 total=0.0256 ce_r=0.0337 ce_f=0.0405
[loss-ga] ep 2 it 70 total=0.0081 ce_r=0.0102 ce_f=0.0102
[loss-ga] ep 2 it 120 total=0.0224 ce_r=0.0296 ce_f=0.0358
[loss-ga] ep 2 it 170 total=0.0436 ce_r=0.0582 ce_f=0.0729
[loss-ga] ep 2 it 220 total=0.0135 ce_r=0.0151 ce_f=0.0077
[loss-ga] ep 2 it 270 total=0.0850 ce_r=0.1146 ce_f=0.1479
[loss-ga] ep 2 it 320 total=0.0938 ce_r=0.1253 ce_f=0.1575
[loss-ga] ep 2 it 370 total=0.0504 ce_r=0.0641 ce_f=0.0686
[loss-ga] ep 3 it 30 total=0.0306 ce_r=0.0358 ce_f=0.0263
[loss-ga] ep 3 it 80 total=0.0134 ce_r=0.0159 ce_f=0.0129
[loss-ga] ep 3 it 130 total=0.0150 ce_r=0.0184 ce_f=0.0168
[loss-ga] ep 3 it 180 total=0.0329 ce_r=0.0405 ce_f=0.0380
[loss-ga] ep 3 it 230 total=0.0333 ce_r=0.0358 ce_f=0.0122
[loss-ga] ep 3 it 280 total=0.0062 ce_r=0.0077 ce_f=0.0078
[loss-ga] ep 3 it 330 total=0.0558 ce_r=0.0722 ce_f=0.0820
[loss-ga] ep 3 it 380 total=0.0166 ce_r=0.0212 ce_f=0.0229
[loss-ga] ep 4 it 40 total=0.0207 ce_r=0.0265 ce_f=0.0289
[loss-ga] ep 4 it 90 total=0.0410 ce_r=0.0443 ce_f=0.0167
[loss-ga] ep 4 it 140 total=0.0088 ce_r=0.0099 ce_f=0.0054
[loss-ga] ep 4 it 190 total=0.0434 ce_r=0.0466 ce_f=0.0161
[loss-ga] ep 4 it 240 total=0.0405 ce_r=0.0422 ce_f=0.0087
[loss-ga] ep 4 it 290 total=0.0438 ce_r=0.0517 ce_f=0.0398
[loss-ga] ep 4 it 340 total=0.0939 ce_r=0.1262 ce_f=0.1614
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_ga_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-6-fl0.2: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:41,  1.76it/s]  3%|▎         | 11/391 [00:00<00:17, 21.15it/s]  5%|▌         | 21/391 [00:00<00:09, 37.68it/s]  8%|▊         | 31/391 [00:00<00:07, 51.08it/s] 11%|█         | 42/391 [00:01<00:05, 64.16it/s] 13%|█▎        | 52/391 [00:01<00:04, 72.58it/s] 16%|█▌        | 62/391 [00:01<00:04, 79.75it/s] 18%|█▊        | 72/391 [00:01<00:03, 85.08it/s] 21%|██        | 82/391 [00:01<00:03, 87.67it/s] 24%|██▎       | 92/391 [00:01<00:03, 90.75it/s] 26%|██▌       | 102/391 [00:01<00:03, 92.49it/s] 29%|██▉       | 113/391 [00:01<00:02, 95.11it/s] 31%|███▏      | 123/391 [00:01<00:02, 95.25it/s] 34%|███▍      | 134/391 [00:01<00:02, 96.80it/s] 37%|███▋      | 144/391 [00:02<00:02, 96.30it/s] 39%|███▉      | 154/391 [00:02<00:02, 97.22it/s] 42%|████▏     | 164/391 [00:02<00:02, 97.51it/s] 45%|████▍     | 174/391 [00:02<00:02, 96.32it/s] 47%|████▋     | 184/391 [00:02<00:02, 95.37it/s] 50%|████▉     | 194/391 [00:02<00:02, 94.68it/s] 52%|█████▏    | 204/391 [00:02<00:01, 93.86it/s] 55%|█████▍    | 214/391 [00:02<00:01, 92.10it/s] 57%|█████▋    | 224/391 [00:02<00:01, 93.00it/s] 60%|█████▉    | 234/391 [00:03<00:01, 89.69it/s] 62%|██████▏   | 244/391 [00:03<00:01, 91.89it/s] 65%|██████▍   | 254/391 [00:03<00:01, 92.10it/s] 68%|██████▊   | 265/391 [00:03<00:01, 94.53it/s] 70%|███████   | 275/391 [00:03<00:01, 95.94it/s] 73%|███████▎  | 285/391 [00:03<00:01, 93.10it/s] 75%|███████▌  | 295/391 [00:03<00:01, 94.33it/s] 78%|███████▊  | 305/391 [00:03<00:00, 93.25it/s] 81%|████████  | 315/391 [00:03<00:00, 92.84it/s] 83%|████████▎ | 325/391 [00:03<00:00, 91.59it/s] 86%|████████▌ | 335/391 [00:04<00:00, 90.81it/s] 88%|████████▊ | 345/391 [00:04<00:00, 93.07it/s] 91%|█████████ | 356/391 [00:04<00:00, 95.33it/s] 94%|█████████▎| 366/391 [00:04<00:00, 95.55it/s] 96%|█████████▋| 377/391 [00:04<00:00, 97.53it/s] 99%|█████████▉| 388/391 [00:04<00:00, 98.81it/s]100%|██████████| 391/391 [00:04<00:00, 83.64it/s]
50000 images processed, 4.78961443901062 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:48,  1.62it/s] 14%|█▍        | 11/79 [00:00<00:03, 19.72it/s] 27%|██▋       | 21/79 [00:00<00:01, 35.96it/s] 39%|███▉      | 31/79 [00:00<00:00, 49.30it/s] 52%|█████▏    | 41/79 [00:01<00:00, 60.41it/s] 65%|██████▍   | 51/79 [00:01<00:00, 69.96it/s] 78%|███████▊  | 62/79 [00:01<00:00, 78.49it/s] 91%|█████████ | 72/79 [00:01<00:00, 84.12it/s]100%|██████████| 79/79 [00:01<00:00, 54.80it/s]
10000 images processed, 1.4700713157653809 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-6-fl0.2/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:16,  1.48it/s]  5%|▌         | 11/204 [00:00<00:10, 18.69it/s] 10%|█         | 21/204 [00:00<00:05, 34.41it/s] 15%|█▌        | 31/204 [00:00<00:03, 48.40it/s] 20%|██        | 41/204 [00:01<00:02, 59.87it/s] 25%|██▌       | 51/204 [00:01<00:02, 67.96it/s] 30%|██▉       | 61/204 [00:01<00:01, 74.52it/s] 34%|███▍      | 70/204 [00:01<00:01, 77.08it/s] 39%|███▉      | 80/204 [00:01<00:01, 82.77it/s] 44%|████▍     | 90/204 [00:01<00:01, 85.62it/s] 49%|████▉     | 100/204 [00:01<00:01, 88.33it/s] 54%|█████▍    | 110/204 [00:01<00:01, 87.94it/s] 59%|█████▉    | 120/204 [00:01<00:00, 88.47it/s] 64%|██████▎   | 130/204 [00:02<00:00, 91.08it/s] 69%|██████▊   | 140/204 [00:02<00:00, 91.51it/s] 74%|███████▎  | 150/204 [00:02<00:00, 90.03it/s] 78%|███████▊  | 160/204 [00:02<00:00, 90.79it/s] 83%|████████▎ | 170/204 [00:02<00:00, 90.03it/s] 88%|████████▊ | 180/204 [00:02<00:00, 91.49it/s] 94%|█████████▎| 191/204 [00:02<00:00, 94.31it/s] 99%|█████████▉| 202/204 [00:02<00:00, 96.30it/s]100%|██████████| 204/204 [00:02<00:00, 71.48it/s]
26032 images processed, 2.89496111869812 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:04,  1.22it/s] 14%|█▍        | 11/79 [00:00<00:04, 15.64it/s] 24%|██▍       | 19/79 [00:01<00:02, 26.14it/s] 37%|███▋      | 29/79 [00:01<00:01, 40.05it/s] 49%|████▉     | 39/79 [00:01<00:00, 52.04it/s] 62%|██████▏   | 49/79 [00:01<00:00, 62.52it/s] 75%|███████▍  | 59/79 [00:01<00:00, 71.73it/s] 87%|████████▋ | 69/79 [00:01<00:00, 78.95it/s]100%|██████████| 79/79 [00:01<00:00, 47.69it/s]
10000 images processed, 1.6787729263305664 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:47,  1.64it/s] 14%|█▍        | 11/79 [00:00<00:03, 19.95it/s] 27%|██▋       | 21/79 [00:00<00:01, 36.20it/s] 39%|███▉      | 31/79 [00:00<00:00, 49.71it/s] 52%|█████▏    | 41/79 [00:01<00:00, 60.69it/s] 65%|██████▍   | 51/79 [00:01<00:00, 70.39it/s] 77%|███████▋  | 61/79 [00:01<00:00, 78.06it/s] 90%|████████▉ | 71/79 [00:01<00:00, 83.27it/s]100%|██████████| 79/79 [00:01<00:00, 55.36it/s]
10000 images processed, 1.453869342803955 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:47,  1.47it/s] 11%|█▏        | 8/70 [00:00<00:04, 13.13it/s] 24%|██▍       | 17/70 [00:00<00:01, 28.08it/s] 37%|███▋      | 26/70 [00:01<00:01, 40.89it/s] 51%|█████▏    | 36/70 [00:01<00:00, 53.80it/s] 66%|██████▌   | 46/70 [00:01<00:00, 65.06it/s] 81%|████████▏ | 57/70 [00:01<00:00, 74.94it/s] 97%|█████████▋| 68/70 [00:01<00:00, 82.14it/s]100%|██████████| 70/70 [00:01<00:00, 48.25it/s]
8925 images processed, 1.48409104347229 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:52,  1.19s/it]  4%|▍         | 2/45 [00:01<00:26,  1.61it/s] 27%|██▋       | 12/45 [00:01<00:02, 13.26it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.16it/s] 47%|████▋     | 21/45 [00:01<00:01, 16.20it/s] 64%|██████▍   | 29/45 [00:02<00:00, 25.82it/s] 76%|███████▌  | 34/45 [00:02<00:00, 17.04it/s] 98%|█████████▊| 44/45 [00:02<00:00, 27.45it/s]100%|██████████| 45/45 [00:03<00:00, 14.64it/s]
5640 images processed, 3.1054606437683105 seconds used

18.634257316589355
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.70  99.31
places365     72.14  78.84
LSUN          21.59  95.26
iSUN          70.90  82.86
dtd           43.16  88.67
AVG           42.10  88.99
Retain-Acc: 0.7379
Forget-as-OOD (retain known vs forget novel):
  FPR: 40.70 AUROC: 91.42 AUIN: 98.88
38.077574729919434
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-6-fl0.2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-6-fl0.2_rf.png
