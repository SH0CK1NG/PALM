nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=25, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10,64,22,42,9,90', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/25 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
  4%|▍         | 1/25 [00:30<12:06, 30.27s/it]  8%|▊         | 2/25 [00:46<08:22, 21.83s/it] 12%|█▏        | 3/25 [01:01<06:59, 19.06s/it] 16%|█▌        | 4/25 [01:17<06:08, 17.56s/it] 20%|██        | 5/25 [01:32<05:35, 16.77s/it] 24%|██▍       | 6/25 [01:47<05:09, 16.29s/it] 28%|██▊       | 7/25 [02:04<04:57, 16.53s/it] 32%|███▏      | 8/25 [02:20<04:36, 16.29s/it] 36%|███▌      | 9/25 [02:36<04:19, 16.19s/it] 40%|████      | 10/25 [02:53<04:03, 16.26s/it] 44%|████▍     | 11/25 [03:08<03:45, 16.14s/it] 48%|████▊     | 12/25 [03:25<03:29, 16.14s/it] 52%|█████▏    | 13/25 [03:41<03:14, 16.24s/it] 56%|█████▌    | 14/25 [03:57<02:57, 16.13s/it] 60%|██████    | 15/25 [04:13<02:41, 16.14s/it][loss-randlabel] ep 0 it 0 total=10.0436 ce_r=0.0326 ce_f=10.0110
[loss-randlabel] ep 0 it 50 total=10.2828 ce_r=0.0165 ce_f=10.2663
[loss-randlabel] ep 0 it 100 total=9.7588 ce_r=0.0405 ce_f=9.7183
[loss-randlabel] ep 0 it 150 total=9.1963 ce_r=0.0850 ce_f=9.1112
[loss-randlabel] ep 0 it 200 total=7.2813 ce_r=0.6677 ce_f=6.6136
[loss-randlabel] ep 0 it 250 total=6.6554 ce_r=0.9718 ce_f=5.6836
[loss-randlabel] ep 0 it 300 total=6.8687 ce_r=0.9817 ce_f=5.8869
[loss-randlabel] ep 0 it 350 total=6.2598 ce_r=0.8205 ce_f=5.4393
[loss-randlabel] ep 1 it 10 total=6.2125 ce_r=0.8164 ce_f=5.3961
[loss-randlabel] ep 1 it 60 total=6.2540 ce_r=0.7244 ce_f=5.5296
[loss-randlabel] ep 1 it 110 total=6.0015 ce_r=0.8885 ce_f=5.1129
[loss-randlabel] ep 1 it 160 total=6.2784 ce_r=1.0113 ce_f=5.2671
[loss-randlabel] ep 1 it 210 total=6.2423 ce_r=0.7866 ce_f=5.4557
[loss-randlabel] ep 1 it 260 total=6.1768 ce_r=0.7042 ce_f=5.4727
[loss-randlabel] ep 1 it 310 total=6.1494 ce_r=0.8582 ce_f=5.2912
[loss-randlabel] ep 1 it 360 total=6.2068 ce_r=0.8201 ce_f=5.3867
[loss-randlabel] ep 2 it 20 total=6.1364 ce_r=0.9434 ce_f=5.1929
[loss-randlabel] ep 2 it 70 total=5.9635 ce_r=0.6481 ce_f=5.3154
[loss-randlabel] ep 2 it 120 total=5.9045 ce_r=0.5757 ce_f=5.3288
[loss-randlabel] ep 2 it 170 total=6.0243 ce_r=0.8728 ce_f=5.1515
[loss-randlabel] ep 2 it 220 total=5.9568 ce_r=0.7176 ce_f=5.2392
[loss-randlabel] ep 2 it 270 total=6.1160 ce_r=0.9319 ce_f=5.1841
[loss-randlabel] ep 2 it 320 total=5.8009 ce_r=0.7585 ce_f=5.0424
[loss-randlabel] ep 2 it 370 total=5.8429 ce_r=0.6027 ce_f=5.2402
[loss-randlabel] ep 3 it 30 total=5.8381 ce_r=0.8814 ce_f=4.9567
[loss-randlabel] ep 3 it 80 total=5.8656 ce_r=0.8308 ce_f=5.0348
[loss-randlabel] ep 3 it 130 total=6.0581 ce_r=0.8397 ce_f=5.2185
[loss-randlabel] ep 3 it 180 total=5.9213 ce_r=0.8721 ce_f=5.0492
[loss-randlabel] ep 3 it 230 total=5.8431 ce_r=0.7807 ce_f=5.0624
[loss-randlabel] ep 3 it 280 total=5.8770 ce_r=0.8383 ce_f=5.0387
[loss-randlabel] ep 3 it 330 total=5.8873 ce_r=0.8317 ce_f=5.0556
[loss-randlabel] ep 3 it 380 total=5.9330 ce_r=0.8003 ce_f=5.1327
[loss-randlabel] ep 4 it 40 total=5.8699 ce_r=0.6842 ce_f=5.1858
[loss-randlabel] ep 4 it 90 total=5.9563 ce_r=0.7644 ce_f=5.1919
[loss-randlabel] ep 4 it 140 total=5.7424 ce_r=0.7546 ce_f=4.9878
[loss-randlabel] ep 4 it 190 total=5.7665 ce_r=0.6541 ce_f=5.1124
[loss-randlabel] ep 4 it 240 total=5.6725 ce_r=0.7177 ce_f=4.9548
[loss-randlabel] ep 4 it 290 total=5.7168 ce_r=0.7199 ce_f=4.9968
[loss-randlabel] ep 4 it 340 total=5.8481 ce_r=0.5774 ce_f=5.2707
[loss-randlabel] ep 5 it 0 total=5.8629 ce_r=0.6598 ce_f=5.2031
[loss-randlabel] ep 5 it 50 total=5.7675 ce_r=0.7404 ce_f=5.0271
[loss-randlabel] ep 5 it 100 total=5.8743 ce_r=0.7082 ce_f=5.1662
[loss-randlabel] ep 5 it 150 total=5.7875 ce_r=0.7145 ce_f=5.0730
[loss-randlabel] ep 5 it 200 total=5.7933 ce_r=0.7557 ce_f=5.0376
[loss-randlabel] ep 5 it 250 total=5.6986 ce_r=0.7486 ce_f=4.9500
[loss-randlabel] ep 5 it 300 total=5.6957 ce_r=0.6650 ce_f=5.0307
[loss-randlabel] ep 5 it 350 total=5.7730 ce_r=0.6367 ce_f=5.1363
[loss-randlabel] ep 6 it 10 total=5.7966 ce_r=0.6195 ce_f=5.1771
[loss-randlabel] ep 6 it 60 total=5.7771 ce_r=0.7554 ce_f=5.0218
[loss-randlabel] ep 6 it 110 total=5.7723 ce_r=0.7548 ce_f=5.0174
[loss-randlabel] ep 6 it 160 total=5.7978 ce_r=0.6900 ce_f=5.1077
[loss-randlabel] ep 6 it 210 total=5.7644 ce_r=0.5966 ce_f=5.1678
[loss-randlabel] ep 6 it 260 total=5.6320 ce_r=0.7238 ce_f=4.9082
[loss-randlabel] ep 6 it 310 total=5.7985 ce_r=0.6899 ce_f=5.1086
[loss-randlabel] ep 6 it 360 total=5.8943 ce_r=0.6102 ce_f=5.2840
[loss-randlabel] ep 7 it 20 total=5.8110 ce_r=0.7043 ce_f=5.1067
[loss-randlabel] ep 7 it 70 total=5.8495 ce_r=0.7267 ce_f=5.1228
[loss-randlabel] ep 7 it 120 total=5.7748 ce_r=0.6265 ce_f=5.1484
[loss-randlabel] ep 7 it 170 total=5.7587 ce_r=0.6684 ce_f=5.0902
[loss-randlabel] ep 7 it 220 total=5.7307 ce_r=0.6712 ce_f=5.0596
[loss-randlabel] ep 7 it 270 total=5.7744 ce_r=0.6648 ce_f=5.1096
[loss-randlabel] ep 7 it 320 total=5.7264 ce_r=0.6760 ce_f=5.0504
[loss-randlabel] ep 7 it 370 total=5.6370 ce_r=0.7887 ce_f=4.8483
[loss-randlabel] ep 8 it 30 total=5.8058 ce_r=0.7192 ce_f=5.0866
[loss-randlabel] ep 8 it 80 total=5.7386 ce_r=0.6270 ce_f=5.1115
[loss-randlabel] ep 8 it 130 total=5.6137 ce_r=0.6903 ce_f=4.9233
[loss-randlabel] ep 8 it 180 total=5.7213 ce_r=0.7155 ce_f=5.0058
[loss-randlabel] ep 8 it 230 total=5.7436 ce_r=0.6461 ce_f=5.0975
[loss-randlabel] ep 8 it 280 total=5.8403 ce_r=0.6970 ce_f=5.1433
[loss-randlabel] ep 8 it 330 total=5.6493 ce_r=0.5216 ce_f=5.1277
[loss-randlabel] ep 8 it 380 total=5.7412 ce_r=0.7082 ce_f=5.0331
[loss-randlabel] ep 9 it 40 total=5.8363 ce_r=0.7184 ce_f=5.1179
[loss-randlabel] ep 9 it 90 total=5.6346 ce_r=0.7104 ce_f=4.9241
[loss-randlabel] ep 9 it 140 total=5.5854 ce_r=0.6441 ce_f=4.9413
[loss-randlabel] ep 9 it 190 total=5.7671 ce_r=0.6183 ce_f=5.1488
[loss-randlabel] ep 9 it 240 total=5.8058 ce_r=0.8053 ce_f=5.0005
[loss-randlabel] ep 9 it 290 total=5.8240 ce_r=0.8326 ce_f=4.9914
[loss-randlabel] ep 9 it 340 total=5.6275 ce_r=0.6010 ce_f=5.0265
[loss-randlabel] ep 10 it 0 total=5.8106 ce_r=0.6689 ce_f=5.1416
[loss-randlabel] ep 10 it 50 total=5.6003 ce_r=0.6468 ce_f=4.9535
[loss-randlabel] ep 10 it 100 total=5.7859 ce_r=0.6370 ce_f=5.1489
[loss-randlabel] ep 10 it 150 total=5.7322 ce_r=0.6551 ce_f=5.0771
[loss-randlabel] ep 10 it 200 total=5.7706 ce_r=0.6209 ce_f=5.1497
[loss-randlabel] ep 10 it 250 total=5.6962 ce_r=0.7153 ce_f=4.9809
[loss-randlabel] ep 10 it 300 total=5.6284 ce_r=0.5062 ce_f=5.1222
[loss-randlabel] ep 10 it 350 total=5.7181 ce_r=0.6080 ce_f=5.1101
[loss-randlabel] ep 11 it 10 total=5.7502 ce_r=0.5937 ce_f=5.1565
[loss-randlabel] ep 11 it 60 total=5.8124 ce_r=0.7125 ce_f=5.1000
[loss-randlabel] ep 11 it 110 total=5.6612 ce_r=0.6886 ce_f=4.9726
[loss-randlabel] ep 11 it 160 total=5.6795 ce_r=0.5835 ce_f=5.0959
[loss-randlabel] ep 11 it 210 total=5.7549 ce_r=0.7342 ce_f=5.0207
[loss-randlabel] ep 11 it 260 total=5.8114 ce_r=0.7399 ce_f=5.0715
[loss-randlabel] ep 11 it 310 total=5.7752 ce_r=0.6521 ce_f=5.1231
[loss-randlabel] ep 11 it 360 total=5.7527 ce_r=0.6661 ce_f=5.0866
[loss-randlabel] ep 12 it 20 total=5.7450 ce_r=0.6304 ce_f=5.1146
[loss-randlabel] ep 12 it 70 total=5.7537 ce_r=0.5642 ce_f=5.1895
[loss-randlabel] ep 12 it 120 total=5.6628 ce_r=0.7041 ce_f=4.9587
[loss-randlabel] ep 12 it 170 total=5.7738 ce_r=0.7571 ce_f=5.0167
[loss-randlabel] ep 12 it 220 total=5.7526 ce_r=0.6344 ce_f=5.1182
[loss-randlabel] ep 12 it 270 total=5.7062 ce_r=0.7793 ce_f=4.9269
[loss-randlabel] ep 12 it 320 total=5.6601 ce_r=0.6121 ce_f=5.0480
[loss-randlabel] ep 12 it 370 total=5.6577 ce_r=0.6978 ce_f=4.9599
[loss-randlabel] ep 13 it 30 total=5.6943 ce_r=0.5909 ce_f=5.1034
[loss-randlabel] ep 13 it 80 total=5.6586 ce_r=0.7133 ce_f=4.9453
[loss-randlabel] ep 13 it 130 total=5.6814 ce_r=0.6416 ce_f=5.0398
[loss-randlabel] ep 13 it 180 total=5.6895 ce_r=0.6894 ce_f=5.0000
[loss-randlabel] ep 13 it 230 total=5.6186 ce_r=0.6342 ce_f=4.9844
[loss-randlabel] ep 13 it 280 total=5.7184 ce_r=0.6483 ce_f=5.0702
[loss-randlabel] ep 13 it 330 total=5.7188 ce_r=0.8081 ce_f=4.9107
[loss-randlabel] ep 13 it 380 total=5.6327 ce_r=0.6874 ce_f=4.9453
[loss-randlabel] ep 14 it 40 total=5.7730 ce_r=0.7828 ce_f=4.9902
[loss-randlabel] ep 14 it 90 total=5.7075 ce_r=0.6458 ce_f=5.0617
[loss-randlabel] ep 14 it 140 total=5.7816 ce_r=0.6405 ce_f=5.1410
[loss-randlabel] ep 14 it 190 total=5.6326 ce_r=0.6379 ce_f=4.9947
[loss-randlabel] ep 14 it 240 total=5.7069 ce_r=0.6697 ce_f=5.0372
[loss-randlabel] ep 14 it 290 total=5.6351 ce_r=0.6316 ce_f=5.0035
[loss-randlabel] ep 14 it 340 total=5.7720 ce_r=0.5881 ce_f=5.1839
[loss-randlabel] ep 15 it 0 total=5.4758 ce_r=0.5944 ce_f=4.8813
[loss-randlabel] ep 15 it 50 total=5.7861 ce_r=0.6751 ce_f=5.1109
[loss-randlabel] ep 15 it 100 total=5.6703 ce_r=0.6225 ce_f=5.0478
[loss-randlabel] ep 15 it 150 total=5.7566 ce_r=0.6970 ce_f=5.0596
[loss-randlabel] ep 15 it 200 total=5.7261 ce_r=0.5943 ce_f=5.1318
[loss-randlabel] ep 15 it 250 total=5.6528 ce_r=0.5464 ce_f=5.1064
 64%|██████▍   | 16/25 [04:30<02:26, 16.23s/it] 68%|██████▊   | 17/25 [04:45<02:08, 16.11s/it] 72%|███████▏  | 18/25 [05:01<01:51, 15.94s/it] 76%|███████▌  | 19/25 [05:17<01:35, 15.99s/it] 80%|████████  | 20/25 [05:34<01:20, 16.12s/it] 84%|████████▍ | 21/25 [05:50<01:05, 16.35s/it] 88%|████████▊ | 22/25 [06:07<00:48, 16.29s/it] 92%|█████████▏| 23/25 [06:22<00:32, 16.07s/it] 96%|█████████▌| 24/25 [06:38<00:16, 16.04s/it]100%|██████████| 25/25 [06:54<00:00, 16.10s/it]100%|██████████| 25/25 [06:54<00:00, 16.59s/it]
[loss-randlabel] ep 15 it 300 total=5.6308 ce_r=0.6330 ce_f=4.9978
[loss-randlabel] ep 15 it 350 total=5.7780 ce_r=0.7335 ce_f=5.0445
[loss-randlabel] ep 16 it 10 total=5.6302 ce_r=0.6270 ce_f=5.0032
[loss-randlabel] ep 16 it 60 total=5.5835 ce_r=0.5839 ce_f=4.9996
[loss-randlabel] ep 16 it 110 total=5.6817 ce_r=0.6491 ce_f=5.0326
[loss-randlabel] ep 16 it 160 total=5.6725 ce_r=0.6553 ce_f=5.0172
[loss-randlabel] ep 16 it 210 total=5.6814 ce_r=0.6827 ce_f=4.9986
[loss-randlabel] ep 16 it 260 total=5.7581 ce_r=0.7133 ce_f=5.0448
[loss-randlabel] ep 16 it 310 total=5.6811 ce_r=0.6165 ce_f=5.0645
[loss-randlabel] ep 16 it 360 total=5.7341 ce_r=0.5957 ce_f=5.1384
[loss-randlabel] ep 17 it 20 total=5.7758 ce_r=0.7079 ce_f=5.0679
[loss-randlabel] ep 17 it 70 total=5.7686 ce_r=0.6378 ce_f=5.1308
[loss-randlabel] ep 17 it 120 total=5.6257 ce_r=0.6494 ce_f=4.9762
[loss-randlabel] ep 17 it 170 total=5.6228 ce_r=0.5926 ce_f=5.0302
[loss-randlabel] ep 17 it 220 total=5.7160 ce_r=0.6364 ce_f=5.0796
[loss-randlabel] ep 17 it 270 total=5.7686 ce_r=0.5977 ce_f=5.1709
[loss-randlabel] ep 17 it 320 total=5.7696 ce_r=0.5755 ce_f=5.1941
[loss-randlabel] ep 17 it 370 total=5.6172 ce_r=0.6427 ce_f=4.9746
[loss-randlabel] ep 18 it 30 total=5.7672 ce_r=0.7407 ce_f=5.0265
[loss-randlabel] ep 18 it 80 total=5.7196 ce_r=0.6259 ce_f=5.0937
[loss-randlabel] ep 18 it 130 total=5.6807 ce_r=0.6353 ce_f=5.0453
[loss-randlabel] ep 18 it 180 total=5.6477 ce_r=0.5741 ce_f=5.0737
[loss-randlabel] ep 18 it 230 total=5.6575 ce_r=0.6014 ce_f=5.0561
[loss-randlabel] ep 18 it 280 total=5.7034 ce_r=0.7559 ce_f=4.9475
[loss-randlabel] ep 18 it 330 total=5.6226 ce_r=0.6478 ce_f=4.9748
[loss-randlabel] ep 18 it 380 total=5.6877 ce_r=0.5777 ce_f=5.1099
[loss-randlabel] ep 19 it 40 total=5.6185 ce_r=0.6503 ce_f=4.9682
[loss-randlabel] ep 19 it 90 total=5.6800 ce_r=0.6403 ce_f=5.0398
[loss-randlabel] ep 19 it 140 total=5.7604 ce_r=0.6730 ce_f=5.0874
[loss-randlabel] ep 19 it 190 total=5.6483 ce_r=0.6446 ce_f=5.0037
[loss-randlabel] ep 19 it 240 total=5.6359 ce_r=0.6817 ce_f=4.9542
[loss-randlabel] ep 19 it 290 total=5.5254 ce_r=0.6319 ce_f=4.8935
[loss-randlabel] ep 19 it 340 total=5.6610 ce_r=0.6229 ce_f=5.0381
[loss-randlabel] ep 20 it 0 total=5.5941 ce_r=0.7345 ce_f=4.8596
[loss-randlabel] ep 20 it 50 total=5.6139 ce_r=0.5896 ce_f=5.0243
[loss-randlabel] ep 20 it 100 total=5.6140 ce_r=0.6580 ce_f=4.9560
[loss-randlabel] ep 20 it 150 total=5.7226 ce_r=0.6082 ce_f=5.1144
[loss-randlabel] ep 20 it 200 total=5.6841 ce_r=0.6958 ce_f=4.9883
[loss-randlabel] ep 20 it 250 total=5.6513 ce_r=0.6505 ce_f=5.0008
[loss-randlabel] ep 20 it 300 total=5.6621 ce_r=0.5721 ce_f=5.0901
[loss-randlabel] ep 20 it 350 total=5.7329 ce_r=0.6225 ce_f=5.1103
[loss-randlabel] ep 21 it 10 total=5.5959 ce_r=0.6764 ce_f=4.9195
[loss-randlabel] ep 21 it 60 total=5.6741 ce_r=0.7084 ce_f=4.9657
[loss-randlabel] ep 21 it 110 total=5.5403 ce_r=0.5604 ce_f=4.9800
[loss-randlabel] ep 21 it 160 total=5.7308 ce_r=0.6378 ce_f=5.0930
[loss-randlabel] ep 21 it 210 total=5.6294 ce_r=0.6386 ce_f=4.9909
[loss-randlabel] ep 21 it 260 total=5.7107 ce_r=0.7024 ce_f=5.0083
[loss-randlabel] ep 21 it 310 total=5.6413 ce_r=0.6590 ce_f=4.9824
[loss-randlabel] ep 21 it 360 total=5.5361 ce_r=0.6408 ce_f=4.8953
[loss-randlabel] ep 22 it 20 total=5.6428 ce_r=0.6407 ce_f=5.0021
[loss-randlabel] ep 22 it 70 total=5.6292 ce_r=0.6058 ce_f=5.0234
[loss-randlabel] ep 22 it 120 total=5.6351 ce_r=0.6470 ce_f=4.9880
[loss-randlabel] ep 22 it 170 total=5.6532 ce_r=0.6913 ce_f=4.9619
[loss-randlabel] ep 22 it 220 total=5.6850 ce_r=0.6511 ce_f=5.0339
[loss-randlabel] ep 22 it 270 total=5.6198 ce_r=0.6080 ce_f=5.0118
[loss-randlabel] ep 22 it 320 total=5.6294 ce_r=0.6068 ce_f=5.0227
[loss-randlabel] ep 22 it 370 total=5.5775 ce_r=0.6445 ce_f=4.9330
[loss-randlabel] ep 23 it 30 total=5.6211 ce_r=0.5116 ce_f=5.1095
[loss-randlabel] ep 23 it 80 total=5.7145 ce_r=0.5540 ce_f=5.1605
[loss-randlabel] ep 23 it 130 total=5.6775 ce_r=0.6094 ce_f=5.0682
[loss-randlabel] ep 23 it 180 total=5.6724 ce_r=0.5797 ce_f=5.0927
[loss-randlabel] ep 23 it 230 total=5.7964 ce_r=0.7095 ce_f=5.0869
[loss-randlabel] ep 23 it 280 total=5.7427 ce_r=0.7177 ce_f=5.0251
[loss-randlabel] ep 23 it 330 total=5.5364 ce_r=0.5657 ce_f=4.9707
[loss-randlabel] ep 23 it 380 total=5.5494 ce_r=0.6304 ce_f=4.9190
[loss-randlabel] ep 24 it 40 total=5.6268 ce_r=0.6649 ce_f=4.9618
[loss-randlabel] ep 24 it 90 total=5.6740 ce_r=0.6416 ce_f=5.0324
[loss-randlabel] ep 24 it 140 total=5.6929 ce_r=0.6780 ce_f=5.0149
[loss-randlabel] ep 24 it 190 total=5.6787 ce_r=0.6505 ce_f=5.0282
[loss-randlabel] ep 24 it 240 total=5.6833 ce_r=0.6155 ce_f=5.0678
[loss-randlabel] ep 24 it 290 total=5.6186 ce_r=0.5790 ce_f=5.0395
[loss-randlabel] ep 24 it 340 total=5.7328 ce_r=0.5865 ce_f=5.1463
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:48,  2.32it/s]  2%|▏         | 8/391 [00:00<00:20, 18.79it/s]  3%|▎         | 12/391 [00:00<00:15, 24.01it/s]  5%|▌         | 20/391 [00:00<00:09, 38.88it/s]  7%|▋         | 26/391 [00:00<00:08, 44.35it/s]  8%|▊         | 32/391 [00:00<00:07, 48.65it/s] 10%|█         | 41/391 [00:01<00:05, 59.51it/s] 13%|█▎        | 49/391 [00:01<00:05, 64.85it/s] 15%|█▍        | 57/391 [00:01<00:04, 68.35it/s] 17%|█▋        | 65/391 [00:01<00:04, 70.90it/s] 19%|█▉        | 74/391 [00:01<00:04, 75.10it/s] 21%|██▏       | 84/391 [00:01<00:03, 82.01it/s] 24%|██▍       | 94/391 [00:01<00:03, 87.21it/s] 27%|██▋       | 104/391 [00:01<00:03, 89.71it/s] 29%|██▉       | 115/391 [00:01<00:02, 93.14it/s] 32%|███▏      | 125/391 [00:01<00:02, 95.05it/s] 35%|███▍      | 136/391 [00:02<00:02, 96.61it/s] 38%|███▊      | 147/391 [00:02<00:02, 97.74it/s] 40%|████      | 157/391 [00:02<00:02, 97.93it/s] 43%|████▎     | 167/391 [00:02<00:02, 98.27it/s] 45%|████▌     | 177/391 [00:02<00:02, 97.55it/s] 48%|████▊     | 188/391 [00:02<00:02, 98.56it/s] 51%|█████     | 198/391 [00:02<00:01, 98.36it/s] 53%|█████▎    | 208/391 [00:02<00:01, 98.06it/s] 56%|█████▌    | 219/391 [00:02<00:01, 98.94it/s] 59%|█████▉    | 230/391 [00:03<00:01, 99.25it/s] 62%|██████▏   | 241/391 [00:03<00:01, 99.58it/s] 64%|██████▍   | 251/391 [00:03<00:01, 99.57it/s] 67%|██████▋   | 261/391 [00:03<00:01, 99.62it/s] 69%|██████▉   | 271/391 [00:03<00:01, 86.61it/s] 72%|███████▏  | 281/391 [00:03<00:01, 89.29it/s] 75%|███████▍  | 292/391 [00:03<00:01, 92.73it/s] 77%|███████▋  | 302/391 [00:03<00:00, 94.27it/s] 80%|████████  | 313/391 [00:03<00:00, 96.09it/s] 83%|████████▎ | 323/391 [00:04<00:00, 97.10it/s] 85%|████████▌ | 333/391 [00:04<00:00, 97.71it/s] 88%|████████▊ | 343/391 [00:04<00:00, 98.31it/s] 91%|█████████ | 354/391 [00:04<00:00, 99.16it/s] 93%|█████████▎| 364/391 [00:04<00:00, 98.27it/s] 96%|█████████▌| 375/391 [00:04<00:00, 99.58it/s] 99%|█████████▊| 386/391 [00:04<00:00, 100.43it/s]100%|██████████| 391/391 [00:04<00:00, 82.89it/s] 
50000 images processed, 4.825183629989624 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.02it/s] 14%|█▍        | 11/79 [00:00<00:02, 23.71it/s] 27%|██▋       | 21/79 [00:00<00:01, 41.66it/s] 39%|███▉      | 31/79 [00:00<00:00, 55.68it/s] 52%|█████▏    | 41/79 [00:00<00:00, 66.55it/s] 63%|██████▎   | 50/79 [00:01<00:00, 72.65it/s] 76%|███████▌  | 60/79 [00:01<00:00, 79.95it/s] 89%|████████▊ | 70/79 [00:01<00:00, 85.32it/s]100%|██████████| 79/79 [00:02<00:00, 31.59it/s]
10000 images processed, 2.5598182678222656 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:04,  1.63it/s]  3%|▎         | 7/204 [00:00<00:15, 12.59it/s]  8%|▊         | 17/204 [00:00<00:06, 30.52it/s] 13%|█▎        | 27/204 [00:00<00:03, 46.03it/s] 18%|█▊        | 37/204 [00:01<00:02, 58.76it/s] 23%|██▎       | 47/204 [00:01<00:02, 69.02it/s] 28%|██▊       | 57/204 [00:01<00:01, 77.11it/s] 33%|███▎      | 67/204 [00:01<00:01, 83.11it/s] 38%|███▊      | 77/204 [00:01<00:01, 87.75it/s] 43%|████▎     | 87/204 [00:01<00:01, 89.14it/s] 48%|████▊     | 97/204 [00:01<00:01, 90.30it/s] 52%|█████▏    | 107/204 [00:01<00:01, 80.04it/s] 57%|█████▋    | 116/204 [00:01<00:01, 75.42it/s] 61%|██████    | 124/204 [00:02<00:01, 72.61it/s] 65%|██████▌   | 133/204 [00:02<00:00, 76.09it/s] 70%|███████   | 143/204 [00:02<00:00, 82.36it/s] 75%|███████▌  | 153/204 [00:02<00:00, 86.48it/s] 80%|███████▉  | 163/204 [00:02<00:00, 89.79it/s] 85%|████████▍ | 173/204 [00:02<00:00, 92.46it/s] 90%|████████▉ | 183/204 [00:02<00:00, 94.29it/s] 95%|█████████▍| 193/204 [00:02<00:00, 90.04it/s]100%|█████████▉| 203/204 [00:02<00:00, 90.16it/s]100%|██████████| 204/204 [00:02<00:00, 69.75it/s]
26032 images processed, 2.9703495502471924 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:54,  1.44it/s] 14%|█▍        | 11/79 [00:00<00:03, 18.21it/s] 27%|██▋       | 21/79 [00:00<00:01, 34.02it/s] 39%|███▉      | 31/79 [00:01<00:01, 48.00it/s] 52%|█████▏    | 41/79 [00:01<00:00, 59.97it/s] 65%|██████▍   | 51/79 [00:01<00:00, 69.79it/s] 77%|███████▋  | 61/79 [00:01<00:00, 71.13it/s] 91%|█████████ | 72/79 [00:01<00:00, 64.72it/s]100%|██████████| 79/79 [00:01<00:00, 49.28it/s]
10000 images processed, 1.6307494640350342 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:40,  1.90it/s] 14%|█▍        | 11/79 [00:00<00:02, 22.81it/s] 27%|██▋       | 21/79 [00:00<00:01, 40.77it/s] 41%|████      | 32/79 [00:00<00:00, 56.71it/s] 53%|█████▎    | 42/79 [00:00<00:00, 67.81it/s] 67%|██████▋   | 53/79 [00:01<00:00, 77.37it/s] 81%|████████  | 64/79 [00:01<00:00, 84.36it/s] 95%|█████████▍| 75/79 [00:01<00:00, 89.33it/s]100%|██████████| 79/79 [00:01<00:00, 60.98it/s]
10000 images processed, 1.3176946640014648 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:50,  1.38it/s] 11%|█▏        | 8/70 [00:00<00:04, 12.46it/s] 24%|██▍       | 17/70 [00:00<00:01, 26.84it/s] 39%|███▊      | 27/70 [00:01<00:01, 41.67it/s] 53%|█████▎    | 37/70 [00:01<00:00, 53.89it/s] 67%|██████▋   | 47/70 [00:01<00:00, 64.89it/s] 83%|████████▎ | 58/70 [00:01<00:00, 74.80it/s] 99%|█████████▊| 69/70 [00:01<00:00, 82.16it/s]100%|██████████| 70/70 [00:01<00:00, 47.11it/s]
8925 images processed, 1.5203831195831299 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:43,  1.01it/s]  4%|▍         | 2/45 [00:01<00:23,  1.82it/s] 24%|██▍       | 11/45 [00:01<00:02, 13.47it/s] 38%|███▊      | 17/45 [00:01<00:01, 20.16it/s] 49%|████▉     | 22/45 [00:01<00:01, 20.03it/s] 73%|███████▎  | 33/45 [00:02<00:00, 20.32it/s] 91%|█████████ | 41/45 [00:02<00:00, 27.57it/s]100%|██████████| 45/45 [00:02<00:00, 18.88it/s]
5640 images processed, 2.404571294784546 seconds used

18.95208740234375
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.04  98.99  96.88
places365     70.42  79.92  75.29
LSUN          29.14  93.80  93.29
iSUN          55.35  87.28  87.58
dtd           46.61  88.78  91.77
AVG           41.11  89.75  88.96
Retain-Acc: 0.7611
Forget-as-OOD (retain known vs forget novel):
  FPR: 45.25 AUROC: 90.88 AUIN: 97.47
7.1201653480529785
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20_rf.png
