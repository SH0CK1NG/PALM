nohup: ignoring input
==== Stage 1: forget_inc={0,8,11,40,51}; forget_seen={}; all={0,8,11,40,51,66,67,88,94,57} ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=20, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1', adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name='train_s1', lora_stack=True, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] added trainable adapter 'train_s1'
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: train_s1
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 22082496
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.train_s1.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.train_s1.weight
[debug] trainable: base_model.model.head.2.lora_A.train_s1.weight
[debug] trainable: base_model.model.head.2.lora_B.train_s1.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.train_s1.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.train_s1.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.train_s1.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.train_s1.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.train_s1.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.train_s1.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.train_s1.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.train_s1.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.train_s1.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.train_s1.weight']
  0%|          | 0/20 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  5%|▌         | 1/20 [01:33<29:38, 93.62s/it] 10%|█         | 2/20 [01:58<15:53, 52.97s/it] 15%|█▌        | 3/20 [02:19<10:55, 38.58s/it] 20%|██        | 4/20 [02:44<08:49, 33.08s/it] 25%|██▌       | 5/20 [03:05<07:14, 28.95s/it] 30%|███       | 6/20 [03:27<06:11, 26.56s/it] 35%|███▌      | 7/20 [03:49<05:23, 24.89s/it][loss] ep 0 it 0 total=8.8609 mle=2.1075 pcon=5.2951 forget=1.4584 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 0 it 50 total=8.5065 mle=1.7679 pcon=5.2912 forget=1.4474 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 100 total=8.7541 mle=2.0170 pcon=5.2869 forget=1.4502 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 150 total=9.0634 mle=2.3301 pcon=5.2833 forget=1.4499 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 0 it 200 total=8.7183 mle=1.9565 pcon=5.2792 forget=1.4826 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 250 total=8.2315 mle=1.4707 pcon=5.2752 forget=1.4856 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 0 it 300 total=8.5746 mle=1.8219 pcon=5.2714 forget=1.4813 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 0 it 350 total=8.5492 mle=1.8183 pcon=5.2676 forget=1.4634 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 1 it 10 total=8.6587 mle=1.9368 pcon=5.2637 forget=1.4582 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 1 it 60 total=8.2951 mle=1.5961 pcon=5.2602 forget=1.4389 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 1 it 110 total=8.5688 mle=1.8965 pcon=5.2564 forget=1.4159 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 1 it 160 total=8.9048 mle=2.1531 pcon=5.2527 forget=1.4990 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 1 it 210 total=8.9402 mle=2.2522 pcon=5.2489 forget=1.4391 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 1 it 260 total=8.3601 mle=1.6893 pcon=5.2452 forget=1.4257 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 1 it 310 total=8.3140 mle=1.6443 pcon=5.2417 forget=1.4280 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 1 it 360 total=8.4358 mle=1.7437 pcon=5.2381 forget=1.4540 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 2 it 20 total=8.4946 mle=1.8257 pcon=5.2347 forget=1.4341 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 2 it 70 total=8.3885 mle=1.7292 pcon=5.2311 forget=1.4283 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 2 it 120 total=8.6775 mle=2.0308 pcon=5.2276 forget=1.4191 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 2 it 170 total=8.4889 mle=1.7810 pcon=5.2242 forget=1.4837 favg=0.0000 nr=24 nf=24 protos=570 fproto_sim=NA
[loss] ep 2 it 220 total=8.7008 mle=2.0870 pcon=5.2210 forget=1.3927 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 2 it 270 total=8.4994 mle=1.8194 pcon=5.2177 forget=1.4623 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 2 it 320 total=8.4406 mle=1.7779 pcon=5.2146 forget=1.4481 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 2 it 370 total=8.6233 mle=1.9536 pcon=5.2112 forget=1.4585 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 3 it 30 total=9.1450 mle=2.4583 pcon=5.2081 forget=1.4786 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 3 it 80 total=8.4339 mle=1.7714 pcon=5.2050 forget=1.4575 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 3 it 130 total=8.4290 mle=1.8115 pcon=5.2019 forget=1.4157 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 3 it 180 total=8.2826 mle=1.6189 pcon=5.1989 forget=1.4648 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 3 it 230 total=8.5760 mle=1.9233 pcon=5.1959 forget=1.4567 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 3 it 280 total=8.4163 mle=1.8166 pcon=5.1929 forget=1.4068 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 3 it 330 total=8.6551 mle=2.0153 pcon=5.1898 forget=1.4500 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 3 it 380 total=8.4981 mle=1.8669 pcon=5.1868 forget=1.4445 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 4 it 40 total=8.2958 mle=1.6805 pcon=5.1839 forget=1.4315 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 4 it 90 total=8.3728 mle=1.7412 pcon=5.1809 forget=1.4507 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 4 it 140 total=8.9597 mle=2.2984 pcon=5.1778 forget=1.4834 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 4 it 190 total=8.6958 mle=2.0472 pcon=5.1748 forget=1.4738 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 4 it 240 total=8.5810 mle=2.0075 pcon=5.1718 forget=1.4018 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 4 it 290 total=8.1866 mle=1.5612 pcon=5.1688 forget=1.4566 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 4 it 340 total=8.6952 mle=2.0944 pcon=5.1659 forget=1.4349 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 5 it 0 total=8.3766 mle=1.7656 pcon=5.1633 forget=1.4477 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 5 it 50 total=8.3574 mle=1.7140 pcon=5.1605 forget=1.4828 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 5 it 100 total=8.5171 mle=1.9343 pcon=5.1579 forget=1.4249 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 5 it 150 total=8.2543 mle=1.6723 pcon=5.1549 forget=1.4272 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 5 it 200 total=8.8729 mle=2.2926 pcon=5.1524 forget=1.4279 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 5 it 250 total=8.2813 mle=1.7122 pcon=5.1499 forget=1.4192 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 5 it 300 total=8.2822 mle=1.7117 pcon=5.1471 forget=1.4235 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 5 it 350 total=8.3331 mle=1.7850 pcon=5.1445 forget=1.4035 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 6 it 10 total=8.2107 mle=1.6606 pcon=5.1418 forget=1.4083 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 6 it 60 total=8.5631 mle=1.9938 pcon=5.1393 forget=1.4299 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 6 it 110 total=8.4076 mle=1.8645 pcon=5.1367 forget=1.4064 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 6 it 160 total=8.3696 mle=1.7977 pcon=5.1342 forget=1.4377 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 6 it 210 total=8.5389 mle=1.9522 pcon=5.1315 forget=1.4553 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 6 it 260 total=8.2796 mle=1.7251 pcon=5.1288 forget=1.4257 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 6 it 310 total=8.5208 mle=1.9581 pcon=5.1263 forget=1.4364 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 6 it 360 total=8.3355 mle=1.8101 pcon=5.1235 forget=1.4019 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 7 it 20 total=8.2938 mle=1.7308 pcon=5.1211 forget=1.4419 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 7 it 70 total=8.5683 mle=2.0639 pcon=5.1185 forget=1.3858 favg=0.0000 nr=38 nf=38 protos=570 fproto_sim=NA
[loss] ep 7 it 120 total=8.2153 mle=1.6653 pcon=5.1159 forget=1.4340 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 7 it 170 total=8.5265 mle=1.9737 pcon=5.1134 forget=1.4394 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
 40%|████      | 8/20 [04:11<04:48, 24.04s/it] 45%|████▌     | 9/20 [04:32<04:15, 23.19s/it] 50%|█████     | 10/20 [04:55<03:49, 22.94s/it] 55%|█████▌    | 11/20 [05:16<03:21, 22.44s/it] 60%|██████    | 12/20 [05:41<03:06, 23.28s/it] 65%|██████▌   | 13/20 [06:03<02:40, 22.91s/it] 70%|███████   | 14/20 [06:25<02:14, 22.48s/it] 75%|███████▌  | 15/20 [06:48<01:53, 22.75s/it][loss] ep 7 it 220 total=8.3736 mle=1.8712 pcon=5.1113 forget=1.3911 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 7 it 270 total=8.3026 mle=1.7532 pcon=5.1089 forget=1.4405 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 7 it 320 total=8.2094 mle=1.7010 pcon=5.1065 forget=1.4019 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 7 it 370 total=8.6183 mle=2.0999 pcon=5.1041 forget=1.4143 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 8 it 30 total=8.2720 mle=1.7660 pcon=5.1018 forget=1.4041 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 8 it 80 total=8.4870 mle=1.9937 pcon=5.0994 forget=1.3938 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 8 it 130 total=8.1617 mle=1.6816 pcon=5.0973 forget=1.3828 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 8 it 180 total=7.9680 mle=1.5105 pcon=5.0950 forget=1.3625 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 8 it 230 total=8.1762 mle=1.6534 pcon=5.0927 forget=1.4301 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 8 it 280 total=8.1288 mle=1.6961 pcon=5.0902 forget=1.3424 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 8 it 330 total=8.8147 mle=2.3257 pcon=5.0878 forget=1.4012 favg=0.0000 nr=23 nf=23 protos=570 fproto_sim=NA
[loss] ep 8 it 380 total=8.1423 mle=1.6601 pcon=5.0853 forget=1.3969 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 9 it 40 total=8.2197 mle=1.7311 pcon=5.0826 forget=1.4059 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 9 it 90 total=8.0256 mle=1.5571 pcon=5.0804 forget=1.3881 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 9 it 140 total=7.8620 mle=1.3887 pcon=5.0778 forget=1.3955 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 9 it 190 total=8.2029 mle=1.7769 pcon=5.0751 forget=1.3509 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 9 it 240 total=8.6385 mle=2.1990 pcon=5.0728 forget=1.3667 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 9 it 290 total=8.5449 mle=2.0575 pcon=5.0702 forget=1.4172 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 9 it 340 total=8.1654 mle=1.7380 pcon=5.0678 forget=1.3596 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 10 it 0 total=8.6407 mle=2.1627 pcon=5.0656 forget=1.4125 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 10 it 50 total=7.8195 mle=1.3910 pcon=5.0633 forget=1.3653 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 10 it 100 total=8.3421 mle=1.9122 pcon=5.0607 forget=1.3692 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 10 it 150 total=8.3062 mle=1.8523 pcon=5.0583 forget=1.3956 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 10 it 200 total=8.1294 mle=1.6870 pcon=5.0558 forget=1.3866 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 10 it 250 total=8.2739 mle=1.8490 pcon=5.0535 forget=1.3714 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 10 it 300 total=8.1662 mle=1.7509 pcon=5.0511 forget=1.3641 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 10 it 350 total=8.1183 mle=1.6920 pcon=5.0486 forget=1.3778 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 11 it 10 total=7.9924 mle=1.5439 pcon=5.0462 forget=1.4024 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 11 it 60 total=8.3479 mle=1.9129 pcon=5.0440 forget=1.3910 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 11 it 110 total=7.9873 mle=1.5535 pcon=5.0416 forget=1.3922 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 11 it 160 total=8.4268 mle=1.9627 pcon=5.0394 forget=1.4247 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 11 it 210 total=8.3015 mle=1.8674 pcon=5.0371 forget=1.3970 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 11 it 260 total=7.8762 mle=1.4365 pcon=5.0349 forget=1.4048 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 11 it 310 total=8.0767 mle=1.6373 pcon=5.0324 forget=1.4070 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 11 it 360 total=8.2549 mle=1.8022 pcon=5.0301 forget=1.4226 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 12 it 20 total=8.0291 mle=1.5906 pcon=5.0277 forget=1.4108 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 70 total=8.0329 mle=1.5776 pcon=5.0253 forget=1.4300 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 12 it 120 total=8.2052 mle=1.7404 pcon=5.0228 forget=1.4420 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 12 it 170 total=8.1666 mle=1.7068 pcon=5.0205 forget=1.4394 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 220 total=7.9269 mle=1.4914 pcon=5.0182 forget=1.4172 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 12 it 270 total=8.2337 mle=1.7843 pcon=5.0158 forget=1.4336 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 12 it 320 total=8.2117 mle=1.7543 pcon=5.0135 forget=1.4439 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 12 it 370 total=8.2688 mle=1.7935 pcon=5.0112 forget=1.4641 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 13 it 30 total=7.8683 mle=1.4089 pcon=5.0091 forget=1.4503 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 13 it 80 total=8.0907 mle=1.5862 pcon=5.0066 forget=1.4978 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 13 it 130 total=8.3062 mle=1.8404 pcon=5.0042 forget=1.4616 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 13 it 180 total=8.2349 mle=1.7700 pcon=5.0021 forget=1.4628 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 13 it 230 total=8.0985 mle=1.6307 pcon=4.9999 forget=1.4679 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 13 it 280 total=8.1351 mle=1.6551 pcon=4.9976 forget=1.4824 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 13 it 330 total=8.0188 mle=1.5391 pcon=4.9955 forget=1.4842 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 13 it 380 total=8.1715 mle=1.6742 pcon=4.9931 forget=1.5042 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 14 it 40 total=8.3236 mle=1.8128 pcon=4.9909 forget=1.5199 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 90 total=8.0933 mle=1.5574 pcon=4.9887 forget=1.5471 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 140 total=8.2136 mle=1.7362 pcon=4.9863 forget=1.4911 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 14 it 190 total=8.1494 mle=1.6855 pcon=4.9842 forget=1.4797 favg=0.0000 nr=35 nf=35 protos=570 fproto_sim=NA
[loss] ep 14 it 240 total=8.3977 mle=1.9006 pcon=4.9819 forget=1.5152 favg=0.0000 nr=41 nf=41 protos=570 fproto_sim=NA
[loss] ep 14 it 290 total=8.0636 mle=1.5919 pcon=4.9796 forget=1.4921 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 14 it 340 total=8.2415 mle=1.7646 pcon=4.9773 forget=1.4996 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 0 total=8.0133 mle=1.5491 pcon=4.9752 forget=1.4890 favg=0.0000 nr=26 nf=26 protos=570 fproto_sim=NA
[loss] ep 15 it 50 total=8.0175 mle=1.5614 pcon=4.9731 forget=1.4831 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
 80%|████████  | 16/20 [07:12<01:32, 23.15s/it] 85%|████████▌ | 17/20 [07:34<01:08, 22.82s/it] 90%|█████████ | 18/20 [07:56<00:44, 22.43s/it] 95%|█████████▌| 19/20 [08:17<00:22, 22.15s/it]100%|██████████| 20/20 [08:38<00:00, 21.76s/it]100%|██████████| 20/20 [08:38<00:00, 25.93s/it]
[loss] ep 15 it 100 total=8.2179 mle=1.7433 pcon=4.9711 forget=1.5035 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 150 total=8.0436 mle=1.5469 pcon=4.9691 forget=1.5276 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 200 total=8.0707 mle=1.6014 pcon=4.9669 forget=1.5024 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 15 it 250 total=8.0883 mle=1.6644 pcon=4.9648 forget=1.4590 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 15 it 300 total=7.9278 mle=1.5028 pcon=4.9629 forget=1.4621 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 15 it 350 total=8.1543 mle=1.7229 pcon=4.9609 forget=1.4704 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 16 it 10 total=8.0265 mle=1.5893 pcon=4.9591 forget=1.4780 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 16 it 60 total=7.9805 mle=1.5920 pcon=4.9573 forget=1.4312 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 16 it 110 total=8.0309 mle=1.6373 pcon=4.9554 forget=1.4382 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[loss] ep 16 it 160 total=8.2316 mle=1.8596 pcon=4.9535 forget=1.4184 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 16 it 210 total=8.0510 mle=1.6527 pcon=4.9517 forget=1.4466 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 16 it 260 total=7.8753 mle=1.4427 pcon=4.9500 forget=1.4826 favg=0.0000 nr=25 nf=25 protos=570 fproto_sim=NA
[loss] ep 16 it 310 total=7.8711 mle=1.4753 pcon=4.9482 forget=1.4476 favg=0.0000 nr=34 nf=34 protos=570 fproto_sim=NA
[loss] ep 16 it 360 total=8.0427 mle=1.6681 pcon=4.9463 forget=1.4282 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 17 it 20 total=7.8686 mle=1.5336 pcon=4.9448 forget=1.3901 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 70 total=8.1828 mle=1.7490 pcon=4.9433 forget=1.4905 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 120 total=8.2913 mle=1.9755 pcon=4.9417 forget=1.3740 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 17 it 170 total=7.9169 mle=1.5870 pcon=4.9405 forget=1.3894 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 17 it 220 total=7.9849 mle=1.6396 pcon=4.9387 forget=1.4065 favg=0.0000 nr=32 nf=32 protos=570 fproto_sim=NA
[loss] ep 17 it 270 total=7.9454 mle=1.6370 pcon=4.9373 forget=1.3712 favg=0.0000 nr=31 nf=31 protos=570 fproto_sim=NA
[loss] ep 17 it 320 total=7.7372 mle=1.4705 pcon=4.9358 forget=1.3309 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 17 it 370 total=7.9624 mle=1.6422 pcon=4.9342 forget=1.3860 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 18 it 30 total=8.0266 mle=1.7385 pcon=4.9328 forget=1.3554 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 18 it 80 total=8.2925 mle=2.0922 pcon=4.9313 forget=1.2690 favg=0.0000 nr=23 nf=23 protos=570 fproto_sim=NA
[loss] ep 18 it 130 total=8.0258 mle=1.6191 pcon=4.9299 forget=1.4768 favg=0.0000 nr=28 nf=28 protos=570 fproto_sim=NA
[loss] ep 18 it 180 total=7.8688 mle=1.6366 pcon=4.9287 forget=1.3036 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 18 it 230 total=7.8156 mle=1.6073 pcon=4.9274 forget=1.2809 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 18 it 280 total=7.9488 mle=1.6580 pcon=4.9262 forget=1.3646 favg=0.0000 nr=36 nf=36 protos=570 fproto_sim=NA
[loss] ep 18 it 330 total=7.8812 mle=1.5913 pcon=4.9249 forget=1.3650 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[loss] ep 18 it 380 total=8.0874 mle=1.8137 pcon=4.9236 forget=1.3501 favg=0.0000 nr=30 nf=30 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[loss] ep 19 it 40 total=8.0209 mle=1.7176 pcon=4.9224 forget=1.3808 favg=0.0000 nr=39 nf=39 protos=570 fproto_sim=NA
[loss] ep 19 it 90 total=7.9377 mle=1.6734 pcon=4.9212 forget=1.3431 favg=0.0000 nr=37 nf=37 protos=570 fproto_sim=NA
[loss] ep 19 it 140 total=8.0951 mle=1.8005 pcon=4.9200 forget=1.3746 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 19 it 190 total=7.9061 mle=1.6828 pcon=4.9190 forget=1.3043 favg=0.0000 nr=40 nf=40 protos=570 fproto_sim=NA
[loss] ep 19 it 240 total=8.1555 mle=1.8455 pcon=4.9180 forget=1.3920 favg=0.0000 nr=29 nf=29 protos=570 fproto_sim=NA
[loss] ep 19 it 290 total=7.8328 mle=1.5890 pcon=4.9170 forget=1.3267 favg=0.0000 nr=33 nf=33 protos=570 fproto_sim=NA
[loss] ep 19 it 340 total=7.8089 mle=1.6048 pcon=4.9161 forget=1.2880 favg=0.0000 nr=27 nf=27 protos=570 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage1
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-inc1: Number of model parameters: 22082496
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:14,  2.91it/s]  3%|▎         | 10/391 [00:00<00:13, 27.71it/s]  5%|▍         | 19/391 [00:00<00:08, 45.05it/s]  7%|▋         | 29/391 [00:00<00:06, 58.77it/s] 10%|▉         | 38/391 [00:00<00:05, 66.51it/s] 12%|█▏        | 48/391 [00:00<00:04, 75.29it/s] 15%|█▍        | 58/391 [00:00<00:04, 80.48it/s] 17%|█▋        | 67/391 [00:01<00:03, 82.15it/s] 19%|█▉        | 76/391 [00:01<00:03, 83.05it/s] 22%|██▏       | 85/391 [00:01<00:03, 84.28it/s] 24%|██▍       | 94/391 [00:01<00:03, 85.91it/s] 26%|██▋       | 103/391 [00:01<00:03, 84.43it/s] 29%|██▊       | 112/391 [00:01<00:03, 84.08it/s] 31%|███       | 121/391 [00:01<00:03, 85.61it/s] 33%|███▎      | 130/391 [00:01<00:03, 85.83it/s] 36%|███▌      | 139/391 [00:01<00:02, 86.01it/s] 38%|███▊      | 148/391 [00:02<00:02, 84.81it/s] 40%|████      | 157/391 [00:02<00:02, 84.84it/s] 42%|████▏     | 166/391 [00:02<00:02, 83.70it/s] 45%|████▍     | 175/391 [00:02<00:02, 85.09it/s] 47%|████▋     | 185/391 [00:02<00:02, 87.10it/s] 50%|████▉     | 194/391 [00:02<00:02, 84.01it/s] 52%|█████▏    | 203/391 [00:02<00:02, 85.19it/s] 54%|█████▍    | 213/391 [00:02<00:02, 88.31it/s] 57%|█████▋    | 223/391 [00:02<00:01, 88.99it/s] 60%|█████▉    | 233/391 [00:03<00:01, 91.07it/s] 62%|██████▏   | 243/391 [00:03<00:01, 90.52it/s] 65%|██████▍   | 253/391 [00:03<00:01, 87.99it/s] 67%|██████▋   | 263/391 [00:03<00:01, 89.07it/s] 70%|██████▉   | 272/391 [00:03<00:01, 87.08it/s] 72%|███████▏  | 281/391 [00:03<00:01, 83.91it/s] 74%|███████▍  | 290/391 [00:03<00:01, 83.62it/s] 76%|███████▋  | 299/391 [00:03<00:01, 85.16it/s] 79%|███████▉  | 308/391 [00:03<00:00, 86.01it/s] 81%|████████  | 317/391 [00:03<00:00, 84.21it/s] 83%|████████▎ | 326/391 [00:04<00:00, 82.30it/s] 86%|████████▌ | 335/391 [00:04<00:00, 82.39it/s] 88%|████████▊ | 344/391 [00:04<00:00, 82.35it/s] 91%|█████████ | 354/391 [00:04<00:00, 84.18it/s] 93%|█████████▎| 363/391 [00:04<00:00, 85.52it/s] 95%|█████████▌| 372/391 [00:04<00:00, 84.91it/s] 98%|█████████▊| 382/391 [00:04<00:00, 87.04it/s]100%|██████████| 391/391 [00:04<00:00, 87.06it/s]100%|██████████| 391/391 [00:04<00:00, 80.35it/s]
50000 images processed, 4.963170528411865 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:26,  2.93it/s] 13%|█▎        | 10/79 [00:00<00:02, 28.29it/s] 24%|██▍       | 19/79 [00:00<00:01, 45.60it/s] 35%|███▌      | 28/79 [00:00<00:00, 58.47it/s] 47%|████▋     | 37/79 [00:00<00:00, 65.88it/s] 58%|█████▊    | 46/79 [00:00<00:00, 70.91it/s] 70%|██████▉   | 55/79 [00:00<00:00, 74.84it/s] 81%|████████  | 64/79 [00:01<00:00, 78.19it/s] 94%|█████████▎| 74/79 [00:01<00:00, 83.60it/s]100%|██████████| 79/79 [00:01<00:00, 63.37it/s]
10000 images processed, 1.268378734588623 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:19,  2.56it/s]  5%|▍         | 10/204 [00:00<00:07, 25.68it/s]  9%|▉         | 18/204 [00:00<00:04, 40.41it/s] 13%|█▎        | 27/204 [00:00<00:03, 53.50it/s] 18%|█▊        | 36/204 [00:00<00:02, 61.73it/s] 22%|██▏       | 45/204 [00:00<00:02, 69.25it/s] 26%|██▋       | 54/204 [00:01<00:02, 74.42it/s] 31%|███       | 63/204 [00:01<00:01, 76.86it/s] 35%|███▌      | 72/204 [00:01<00:01, 80.30it/s] 40%|███▉      | 81/204 [00:01<00:01, 82.10it/s] 45%|████▍     | 91/204 [00:01<00:01, 85.17it/s] 50%|████▉     | 101/204 [00:01<00:01, 87.19it/s] 54%|█████▍    | 111/204 [00:01<00:01, 89.40it/s] 59%|█████▉    | 121/204 [00:01<00:00, 90.12it/s] 64%|██████▍   | 131/204 [00:01<00:00, 90.79it/s] 69%|██████▉   | 141/204 [00:01<00:00, 90.01it/s] 74%|███████▍  | 151/204 [00:02<00:00, 88.60it/s] 79%|███████▉  | 161/204 [00:02<00:00, 90.44it/s] 84%|████████▍ | 171/204 [00:02<00:00, 91.86it/s] 89%|████████▊ | 181/204 [00:02<00:00, 91.86it/s] 94%|█████████▎| 191/204 [00:02<00:00, 90.82it/s] 99%|█████████▊| 201/204 [00:02<00:00, 92.32it/s]100%|██████████| 204/204 [00:02<00:00, 76.14it/s]
26032 images processed, 2.724679708480835 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:41,  1.90it/s] 11%|█▏        | 9/79 [00:00<00:04, 16.40it/s] 22%|██▏       | 17/79 [00:00<00:02, 26.18it/s] 32%|███▏      | 25/79 [00:01<00:01, 32.97it/s] 41%|████      | 32/79 [00:01<00:01, 40.36it/s] 48%|████▊     | 38/79 [00:01<00:01, 40.84it/s] 54%|█████▍    | 43/79 [00:01<00:00, 39.53it/s] 62%|██████▏   | 49/79 [00:01<00:00, 41.49it/s] 68%|██████▊   | 54/79 [00:01<00:00, 42.45it/s] 76%|███████▌  | 60/79 [00:01<00:00, 39.34it/s] 86%|████████▌ | 68/79 [00:02<00:00, 39.85it/s] 96%|█████████▌| 76/79 [00:02<00:00, 40.19it/s]100%|██████████| 79/79 [00:02<00:00, 35.30it/s]
10000 images processed, 2.27207350730896 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:29,  2.65it/s] 14%|█▍        | 11/79 [00:00<00:02, 28.26it/s] 24%|██▍       | 19/79 [00:00<00:01, 41.37it/s] 34%|███▍      | 27/79 [00:00<00:01, 51.98it/s] 47%|████▋     | 37/79 [00:00<00:00, 64.02it/s] 58%|█████▊    | 46/79 [00:00<00:00, 71.09it/s] 70%|██████▉   | 55/79 [00:01<00:00, 75.50it/s] 81%|████████  | 64/79 [00:01<00:00, 76.76it/s] 94%|█████████▎| 74/79 [00:01<00:00, 82.27it/s]100%|██████████| 79/79 [00:01<00:00, 61.74it/s]
10000 images processed, 1.2991037368774414 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:23,  2.94it/s] 13%|█▎        | 9/70 [00:00<00:02, 24.85it/s] 24%|██▍       | 17/70 [00:00<00:01, 40.64it/s] 37%|███▋      | 26/70 [00:00<00:00, 53.53it/s] 49%|████▊     | 34/70 [00:00<00:00, 59.90it/s] 63%|██████▎   | 44/70 [00:00<00:00, 69.49it/s] 77%|███████▋  | 54/70 [00:00<00:00, 77.11it/s] 91%|█████████▏| 64/70 [00:01<00:00, 82.77it/s]100%|██████████| 70/70 [00:01<00:00, 60.45it/s]
8925 images processed, 1.1891953945159912 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:44,  1.02s/it] 20%|██        | 9/45 [00:01<00:04,  7.26it/s] 24%|██▍       | 11/45 [00:01<00:04,  7.67it/s] 31%|███       | 14/45 [00:01<00:03,  9.08it/s] 38%|███▊      | 17/45 [00:02<00:02, 10.68it/s] 42%|████▏     | 19/45 [00:02<00:02, 10.76it/s] 49%|████▉     | 22/45 [00:02<00:02, 11.22it/s] 56%|█████▌    | 25/45 [00:02<00:01, 13.27it/s] 60%|██████    | 27/45 [00:02<00:01, 12.63it/s] 67%|██████▋   | 30/45 [00:03<00:01, 11.43it/s] 73%|███████▎  | 33/45 [00:03<00:01, 11.37it/s] 78%|███████▊  | 35/45 [00:03<00:00, 11.86it/s] 89%|████████▉ | 40/45 [00:03<00:00, 12.59it/s] 93%|█████████▎| 42/45 [00:04<00:00,  9.82it/s]100%|██████████| 45/45 [00:04<00:00, 10.29it/s]
5640 images processed, 4.3925745487213135 seconds used

19.842163562774658
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.50  99.36
places365     67.90  80.57
LSUN          21.54  95.06
iSUN          72.28  81.40
dtd           38.17  91.27
AVG           40.48  89.53
Retain-Acc: 0.7433
Forget-as-OOD (retain known vs forget novel):
  FPR: 84.00 AUROC: 85.57 AUIN: 99.08
31.266951322555542
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-inc1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-inc1_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage1
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-all: Number of model parameters: 22082496
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:18,  2.82it/s]  3%|▎         | 10/391 [00:00<00:14, 27.12it/s]  5%|▍         | 19/391 [00:00<00:08, 44.02it/s]  7%|▋         | 28/391 [00:00<00:06, 56.69it/s]  9%|▉         | 37/391 [00:00<00:05, 64.95it/s] 12%|█▏        | 46/391 [00:00<00:04, 70.94it/s] 14%|█▍        | 55/391 [00:00<00:04, 75.90it/s] 16%|█▋        | 64/391 [00:01<00:04, 76.76it/s] 19%|█▊        | 73/391 [00:01<00:04, 79.25it/s] 21%|██        | 83/391 [00:01<00:03, 81.94it/s] 24%|██▎       | 92/391 [00:01<00:03, 83.26it/s] 26%|██▌       | 101/391 [00:01<00:03, 84.06it/s] 28%|██▊       | 110/391 [00:01<00:03, 84.08it/s] 30%|███       | 119/391 [00:01<00:03, 83.39it/s] 33%|███▎      | 129/391 [00:01<00:03, 85.45it/s] 36%|███▌      | 139/391 [00:01<00:02, 87.21it/s] 38%|███▊      | 148/391 [00:02<00:02, 84.01it/s] 40%|████      | 157/391 [00:02<00:02, 83.77it/s] 42%|████▏     | 166/391 [00:02<00:02, 83.09it/s] 45%|████▍     | 175/391 [00:02<00:02, 82.69it/s] 47%|████▋     | 184/391 [00:02<00:02, 82.40it/s] 49%|████▉     | 193/391 [00:02<00:02, 84.26it/s] 52%|█████▏    | 202/391 [00:02<00:02, 84.51it/s] 54%|█████▍    | 211/391 [00:02<00:02, 82.08it/s] 56%|█████▋    | 220/391 [00:02<00:02, 83.14it/s] 59%|█████▉    | 230/391 [00:03<00:01, 85.51it/s] 61%|██████    | 239/391 [00:03<00:01, 84.67it/s] 63%|██████▎   | 248/391 [00:03<00:01, 86.02it/s] 66%|██████▌   | 257/391 [00:03<00:01, 86.78it/s] 68%|██████▊   | 267/391 [00:03<00:01, 88.94it/s] 71%|███████   | 276/391 [00:03<00:01, 87.99it/s] 73%|███████▎  | 285/391 [00:03<00:01, 86.08it/s] 75%|███████▌  | 294/391 [00:03<00:01, 84.05it/s] 77%|███████▋  | 303/391 [00:03<00:01, 84.14it/s] 80%|███████▉  | 312/391 [00:04<00:00, 83.25it/s] 82%|████████▏ | 321/391 [00:04<00:00, 83.82it/s] 84%|████████▍ | 330/391 [00:04<00:00, 83.61it/s] 87%|████████▋ | 339/391 [00:04<00:00, 82.35it/s] 89%|████████▉ | 348/391 [00:04<00:00, 82.47it/s] 91%|█████████▏| 357/391 [00:04<00:00, 80.71it/s] 94%|█████████▎| 366/391 [00:04<00:00, 80.97it/s] 96%|█████████▌| 375/391 [00:04<00:00, 80.00it/s] 98%|█████████▊| 385/391 [00:04<00:00, 84.55it/s]100%|██████████| 391/391 [00:04<00:00, 78.46it/s]
50000 images processed, 5.097748517990112 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:27,  2.86it/s] 13%|█▎        | 10/79 [00:00<00:02, 27.25it/s] 24%|██▍       | 19/79 [00:00<00:01, 45.05it/s] 35%|███▌      | 28/79 [00:00<00:00, 56.71it/s] 47%|████▋     | 37/79 [00:00<00:00, 64.86it/s] 58%|█████▊    | 46/79 [00:00<00:00, 69.77it/s] 68%|██████▊   | 54/79 [00:00<00:00, 72.58it/s] 80%|███████▉  | 63/79 [00:01<00:00, 75.81it/s] 92%|█████████▏| 73/79 [00:01<00:00, 81.89it/s]100%|██████████| 79/79 [00:01<00:00, 62.03it/s]
10000 images processed, 1.3029015064239502 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:17,  2.63it/s]  4%|▍         | 9/204 [00:00<00:08, 23.28it/s]  9%|▉         | 18/204 [00:00<00:04, 40.93it/s] 13%|█▎        | 27/204 [00:00<00:03, 53.96it/s] 17%|█▋        | 35/204 [00:00<00:02, 60.73it/s] 22%|██▏       | 44/204 [00:00<00:02, 68.48it/s] 26%|██▌       | 53/204 [00:01<00:02, 72.85it/s] 30%|███       | 62/204 [00:01<00:01, 76.77it/s] 35%|███▍      | 71/204 [00:01<00:01, 77.75it/s] 39%|███▉      | 80/204 [00:01<00:01, 78.65it/s] 44%|████▎     | 89/204 [00:01<00:01, 81.16it/s] 48%|████▊     | 98/204 [00:01<00:01, 82.08it/s] 52%|█████▏    | 107/204 [00:01<00:01, 83.47it/s] 57%|█████▋    | 117/204 [00:01<00:01, 86.94it/s] 62%|██████▏   | 127/204 [00:01<00:00, 89.22it/s] 67%|██████▋   | 136/204 [00:01<00:00, 87.98it/s] 71%|███████   | 145/204 [00:02<00:00, 86.12it/s] 75%|███████▌  | 154/204 [00:02<00:00, 85.96it/s] 80%|███████▉  | 163/204 [00:02<00:00, 82.47it/s] 84%|████████▍ | 172/204 [00:02<00:00, 81.78it/s] 89%|████████▊ | 181/204 [00:02<00:00, 81.37it/s] 93%|█████████▎| 190/204 [00:02<00:00, 82.57it/s] 98%|█████████▊| 200/204 [00:02<00:00, 86.38it/s]100%|██████████| 204/204 [00:02<00:00, 73.13it/s]
26032 images processed, 2.8341786861419678 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:42,  1.82it/s] 11%|█▏        | 9/79 [00:00<00:04, 14.90it/s] 22%|██▏       | 17/79 [00:00<00:02, 23.10it/s] 32%|███▏      | 25/79 [00:01<00:01, 28.57it/s] 42%|████▏     | 33/79 [00:01<00:01, 32.11it/s] 52%|█████▏    | 41/79 [00:01<00:01, 36.12it/s] 62%|██████▏   | 49/79 [00:01<00:00, 39.69it/s] 72%|███████▏  | 57/79 [00:01<00:00, 41.36it/s] 82%|████████▏ | 65/79 [00:02<00:00, 43.43it/s] 92%|█████████▏| 73/79 [00:02<00:00, 44.68it/s]100%|██████████| 79/79 [00:02<00:00, 35.13it/s]
10000 images processed, 2.282374382019043 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.38it/s] 13%|█▎        | 10/79 [00:00<00:02, 24.42it/s] 23%|██▎       | 18/79 [00:00<00:01, 38.96it/s] 34%|███▍      | 27/79 [00:00<00:01, 51.56it/s] 46%|████▌     | 36/79 [00:00<00:00, 60.42it/s] 56%|█████▌    | 44/79 [00:00<00:00, 65.73it/s] 66%|██████▌   | 52/79 [00:01<00:00, 69.19it/s] 76%|███████▌  | 60/79 [00:01<00:00, 71.65it/s] 87%|████████▋ | 69/79 [00:01<00:00, 76.80it/s]100%|██████████| 79/79 [00:01<00:00, 58.54it/s]
10000 images processed, 1.3695852756500244 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:29,  2.34it/s] 14%|█▍        | 10/70 [00:00<00:02, 23.58it/s] 27%|██▋       | 19/70 [00:00<00:01, 39.80it/s] 40%|████      | 28/70 [00:00<00:00, 52.36it/s] 53%|█████▎    | 37/70 [00:00<00:00, 61.83it/s] 66%|██████▌   | 46/70 [00:00<00:00, 67.72it/s] 79%|███████▊  | 55/70 [00:01<00:00, 73.13it/s] 93%|█████████▎| 65/70 [00:01<00:00, 79.38it/s]100%|██████████| 70/70 [00:01<00:00, 56.61it/s]
8925 images processed, 1.267939567565918 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:40,  1.08it/s]  4%|▍         | 2/45 [00:01<00:23,  1.85it/s] 20%|██        | 9/45 [00:01<00:03,  9.13it/s] 24%|██▍       | 11/45 [00:01<00:04,  7.51it/s] 31%|███       | 14/45 [00:01<00:03,  9.81it/s] 40%|████      | 18/45 [00:02<00:02,  9.38it/s] 49%|████▉     | 22/45 [00:02<00:01, 11.51it/s] 58%|█████▊    | 26/45 [00:03<00:01, 10.60it/s] 67%|██████▋   | 30/45 [00:03<00:01, 11.62it/s] 76%|███████▌  | 34/45 [00:03<00:01,  9.66it/s] 93%|█████████▎| 42/45 [00:04<00:00,  9.71it/s]100%|██████████| 45/45 [00:04<00:00,  9.41it/s]
5640 images processed, 4.806403398513794 seconds used

20.72804284095764
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.53  99.36
places365     67.87  81.18
LSUN          17.60  96.07
iSUN          72.36  81.68
dtd           37.87  91.39
AVG           39.65  89.93
Retain-Acc: 0.7406
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.50 AUROC: 86.90 AUIN: 98.36
20.552960634231567
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-all_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage1-all_rf.png
==== Stage 2: forget_inc={66,67,88,94,57}; forget_seen={0,8,11,40,51}; all={0,8,11,40,51,66,67,88,94,57} ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=20, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2', adapter_load_path=None, adapter_load_paths='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1', lora_new_adapter_name='train_s2', lora_stack=True, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] added trainable adapter 'train_s2'
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: train_s2
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 22321088
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.train_s2.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.train_s2.weight
[debug] trainable: base_model.model.head.2.lora_A.train_s2.weight
[debug] trainable: base_model.model.head.2.lora_B.train_s2.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.train_s2.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.train_s2.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.train_s2.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.train_s2.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.train_s2.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.train_s2.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.train_s2.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.train_s2.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.train_s2.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.train_s2.weight']
  0%|          | 0/20 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  5%|▌         | 1/20 [01:34<29:46, 94.02s/it] 10%|█         | 2/20 [01:58<15:57, 53.19s/it] 15%|█▌        | 3/20 [02:20<10:59, 38.79s/it] 20%|██        | 4/20 [02:44<08:45, 32.84s/it] 25%|██▌       | 5/20 [03:06<07:14, 28.94s/it] 30%|███       | 6/20 [03:28<06:15, 26.79s/it] 35%|███▌      | 7/20 [03:49<05:24, 25.00s/it][loss] ep 0 it 0 total=8.8253 mle=2.0446 pcon=5.2951 forget=1.4856 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.4944 mle=1.7319 pcon=5.2899 forget=1.4726 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=8.6887 mle=1.9457 pcon=5.2851 forget=1.4579 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.8094 mle=2.0384 pcon=5.2798 forget=1.4912 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=8.7936 mle=2.1317 pcon=5.2746 forget=1.3873 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.8253 mle=2.1334 pcon=5.2695 forget=1.4224 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.7751 mle=2.0870 pcon=5.2644 forget=1.4237 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=8.7131 mle=2.0573 pcon=5.2593 forget=1.3965 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 1 it 10 total=8.7724 mle=2.0904 pcon=5.2544 forget=1.4276 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.3244 mle=1.6279 pcon=5.2497 forget=1.4468 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.8790 mle=2.2462 pcon=5.2449 forget=1.3879 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=8.5368 mle=1.8810 pcon=5.2404 forget=1.4155 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=8.4669 mle=1.8029 pcon=5.2357 forget=1.4282 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=8.3894 mle=1.7419 pcon=5.2312 forget=1.4163 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.6622 mle=1.9815 pcon=5.2265 forget=1.4542 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=9.0400 mle=2.3555 pcon=5.2219 forget=1.4625 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 2 it 20 total=8.2823 mle=1.6122 pcon=5.2178 forget=1.4524 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=9.1092 mle=2.4432 pcon=5.2134 forget=1.4525 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.5384 mle=1.8630 pcon=5.2091 forget=1.4663 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.2471 mle=1.6205 pcon=5.2053 forget=1.4213 favg=0.0000 nr=40 nf=40 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.5784 mle=1.9634 pcon=5.2010 forget=1.4140 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=9.1231 mle=2.4940 pcon=5.1969 forget=1.4323 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=8.3632 mle=1.7622 pcon=5.1927 forget=1.4082 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=8.1971 mle=1.6033 pcon=5.1885 forget=1.4053 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 3 it 30 total=8.4708 mle=1.8414 pcon=5.1845 forget=1.4449 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=8.1738 mle=1.6064 pcon=5.1803 forget=1.3871 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=8.3751 mle=1.7793 pcon=5.1767 forget=1.4191 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=8.5825 mle=1.9938 pcon=5.1731 forget=1.4157 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=8.9630 mle=2.3700 pcon=5.1691 forget=1.4239 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=8.6224 mle=2.0629 pcon=5.1655 forget=1.3940 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=8.4671 mle=1.9043 pcon=5.1617 forget=1.4012 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.4338 mle=1.9031 pcon=5.1581 forget=1.3726 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 4 it 40 total=8.5488 mle=2.0021 pcon=5.1546 forget=1.3922 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=8.7154 mle=2.1768 pcon=5.1514 forget=1.3873 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=8.6983 mle=2.1000 pcon=5.1479 forget=1.4504 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=8.3408 mle=1.7502 pcon=5.1442 forget=1.4464 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.5615 mle=1.9777 pcon=5.1411 forget=1.4427 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=8.3827 mle=1.8528 pcon=5.1379 forget=1.3920 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=8.7506 mle=2.1908 pcon=5.1346 forget=1.4252 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=8.8203 mle=2.3048 pcon=5.1312 forget=1.3843 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.4384 mle=1.9179 pcon=5.1281 forget=1.3923 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=9.0060 mle=2.4934 pcon=5.1249 forget=1.3877 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=8.5818 mle=2.0361 pcon=5.1215 forget=1.4242 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=8.2108 mle=1.7260 pcon=5.1184 forget=1.3664 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=8.3339 mle=1.8438 pcon=5.1153 forget=1.3748 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=8.2068 mle=1.6945 pcon=5.1122 forget=1.4001 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.8665 mle=2.3232 pcon=5.1091 forget=1.4343 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 6 it 10 total=8.1645 mle=1.6699 pcon=5.1061 forget=1.3884 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=8.6102 mle=2.1059 pcon=5.1033 forget=1.4010 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.1981 mle=1.7219 pcon=5.1002 forget=1.3760 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=8.5042 mle=1.9948 pcon=5.0973 forget=1.4120 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.9047 mle=2.4031 pcon=5.0944 forget=1.4072 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=8.7454 mle=2.2658 pcon=5.0916 forget=1.3880 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=7.8759 mle=1.3811 pcon=5.0890 forget=1.4058 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=8.6063 mle=2.1168 pcon=5.0862 forget=1.4033 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 7 it 20 total=7.8944 mle=1.4131 pcon=5.0835 forget=1.3979 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=8.3975 mle=1.9219 pcon=5.0803 forget=1.3953 favg=0.0000 nr=26 nf=26 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=8.2776 mle=1.7441 pcon=5.0777 forget=1.4558 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.2454 mle=1.7793 pcon=5.0751 forget=1.3910 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=8.3565 mle=1.8901 pcon=5.0725 forget=1.3939 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.2730 mle=1.8293 pcon=5.0698 forget=1.3738 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
 40%|████      | 8/20 [04:11<04:48, 24.03s/it] 45%|████▌     | 9/20 [04:34<04:17, 23.43s/it] 50%|█████     | 10/20 [04:56<03:49, 23.00s/it] 55%|█████▌    | 11/20 [05:17<03:21, 22.43s/it] 60%|██████    | 12/20 [05:40<03:00, 22.58s/it] 65%|██████▌   | 13/20 [06:00<02:32, 21.81s/it] 70%|███████   | 14/20 [06:22<02:11, 21.84s/it] 75%|███████▌  | 15/20 [06:43<01:47, 21.58s/it][loss] ep 7 it 320 total=8.1761 mle=1.7074 pcon=5.0669 forget=1.4019 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.5838 mle=2.1423 pcon=5.0642 forget=1.3773 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 8 it 30 total=8.3734 mle=1.9441 pcon=5.0618 forget=1.3675 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=8.7410 mle=2.2900 pcon=5.0590 forget=1.3920 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.1254 mle=1.6743 pcon=5.0564 forget=1.3947 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=8.2307 mle=1.7959 pcon=5.0538 forget=1.3811 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=8.0773 mle=1.6656 pcon=5.0513 forget=1.3605 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=8.2015 mle=1.7509 pcon=5.0485 forget=1.4021 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=8.4070 mle=2.0150 pcon=5.0464 forget=1.3456 favg=0.0000 nr=41 nf=41 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.3615 mle=1.9233 pcon=5.0441 forget=1.3941 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 9 it 40 total=8.3270 mle=1.9354 pcon=5.0416 forget=1.3499 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=8.3672 mle=1.9171 pcon=5.0389 forget=1.4111 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.3128 mle=1.9414 pcon=5.0361 forget=1.3354 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=8.2909 mle=1.8576 pcon=5.0337 forget=1.3996 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=8.0451 mle=1.6559 pcon=5.0313 forget=1.3579 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.0759 mle=1.6625 pcon=5.0287 forget=1.3847 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=7.9315 mle=1.5221 pcon=5.0263 forget=1.3831 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 10 it 0 total=8.5696 mle=2.1639 pcon=5.0235 forget=1.3822 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=8.0322 mle=1.6330 pcon=5.0212 forget=1.3780 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=8.4627 mle=2.0982 pcon=5.0189 forget=1.3456 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=8.1112 mle=1.7342 pcon=5.0166 forget=1.3605 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=8.4100 mle=1.9985 pcon=5.0142 forget=1.3973 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=8.0938 mle=1.7116 pcon=5.0122 forget=1.3699 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.1914 mle=1.8362 pcon=5.0100 forget=1.3451 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=8.1812 mle=1.7825 pcon=5.0080 forget=1.3907 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 11 it 10 total=8.0081 mle=1.6246 pcon=5.0059 forget=1.3775 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.3025 mle=1.9266 pcon=5.0040 forget=1.3718 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=7.9735 mle=1.5859 pcon=5.0019 forget=1.3857 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=8.3831 mle=2.0050 pcon=4.9997 forget=1.3784 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=8.1907 mle=1.8162 pcon=4.9978 forget=1.3766 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=8.3507 mle=1.9687 pcon=4.9957 forget=1.3863 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=8.3255 mle=1.9561 pcon=4.9937 forget=1.3757 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=8.1147 mle=1.7217 pcon=4.9916 forget=1.4014 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=8.2146 mle=1.8366 pcon=4.9895 forget=1.3885 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=8.0366 mle=1.6611 pcon=4.9875 forget=1.3880 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=8.3467 mle=1.9462 pcon=4.9853 forget=1.4153 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.4773 mle=2.0632 pcon=4.9831 forget=1.4309 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=8.4143 mle=2.0321 pcon=4.9810 forget=1.4012 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=8.1395 mle=1.7368 pcon=4.9785 forget=1.4241 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=8.3356 mle=1.9484 pcon=4.9761 forget=1.4111 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=8.2343 mle=1.8239 pcon=4.9738 forget=1.4366 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 13 it 30 total=7.9260 mle=1.5271 pcon=4.9712 forget=1.4277 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=8.2778 mle=1.8561 pcon=4.9688 forget=1.4529 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=8.3408 mle=1.8871 pcon=4.9663 forget=1.4874 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=8.2673 mle=1.8686 pcon=4.9640 forget=1.4347 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=8.2668 mle=1.8570 pcon=4.9617 forget=1.4481 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=7.7740 mle=1.3812 pcon=4.9597 forget=1.4331 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.3694 mle=1.9666 pcon=4.9573 forget=1.4455 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=7.9556 mle=1.5893 pcon=4.9548 forget=1.4115 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 14 it 40 total=8.7235 mle=2.2784 pcon=4.9527 forget=1.4924 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=8.1657 mle=1.7761 pcon=4.9502 forget=1.4394 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=8.6317 mle=2.2394 pcon=4.9478 forget=1.4444 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=8.3871 mle=1.9600 pcon=4.9455 forget=1.4816 favg=0.0000 nr=29 nf=29 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=8.4950 mle=2.0639 pcon=4.9431 forget=1.4880 favg=0.0000 nr=23 nf=23 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=8.5772 mle=2.2019 pcon=4.9407 forget=1.4346 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=8.1243 mle=1.7753 pcon=4.9384 forget=1.4107 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 15 it 0 total=7.9689 mle=1.5899 pcon=4.9360 forget=1.4430 favg=0.0000 nr=38 nf=38 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=8.2359 mle=1.8750 pcon=4.9338 forget=1.4271 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.7707 mle=1.4148 pcon=4.9316 forget=1.4243 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
 80%|████████  | 16/20 [07:05<01:27, 21.95s/it] 85%|████████▌ | 17/20 [07:27<01:05, 21.76s/it] 90%|█████████ | 18/20 [07:48<00:43, 21.61s/it] 95%|█████████▌| 19/20 [08:10<00:21, 21.84s/it]100%|██████████| 20/20 [08:33<00:00, 21.96s/it]100%|██████████| 20/20 [08:33<00:00, 25.65s/it]
[loss] ep 15 it 150 total=8.0504 mle=1.6911 pcon=4.9294 forget=1.4300 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=8.0601 mle=1.7226 pcon=4.9272 forget=1.4102 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=8.1504 mle=1.8286 pcon=4.9251 forget=1.3967 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=8.2395 mle=1.9239 pcon=4.9232 forget=1.3925 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.9320 mle=1.6444 pcon=4.9210 forget=1.3666 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 16 it 10 total=7.8108 mle=1.5116 pcon=4.9189 forget=1.3802 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=8.4646 mle=2.1922 pcon=4.9168 forget=1.3556 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.7852 mle=1.5461 pcon=4.9150 forget=1.3242 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=8.2101 mle=1.9130 pcon=4.9130 forget=1.3841 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=7.9565 mle=1.7013 pcon=4.9112 forget=1.3440 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=7.9300 mle=1.7053 pcon=4.9093 forget=1.3154 favg=0.0000 nr=39 nf=39 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=8.0647 mle=1.8402 pcon=4.9075 forget=1.3170 favg=0.0000 nr=30 nf=30 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=8.1799 mle=1.9680 pcon=4.9057 forget=1.3062 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 17 it 20 total=7.9035 mle=1.6592 pcon=4.9040 forget=1.3403 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.1174 mle=1.9647 pcon=4.9021 forget=1.2506 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=7.9745 mle=1.7741 pcon=4.9004 forget=1.3001 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=7.7797 mle=1.6249 pcon=4.8987 forget=1.2561 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=7.8195 mle=1.6867 pcon=4.8969 forget=1.2359 favg=0.0000 nr=32 nf=32 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.3934 mle=2.1513 pcon=4.8952 forget=1.3470 favg=0.0000 nr=33 nf=33 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=8.2153 mle=2.0025 pcon=4.8936 forget=1.3192 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=8.0336 mle=1.8500 pcon=4.8920 forget=1.2916 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 18 it 30 total=7.8900 mle=1.7185 pcon=4.8906 forget=1.2809 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=7.8654 mle=1.7570 pcon=4.8892 forget=1.2193 favg=0.0000 nr=41 nf=41 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=7.8937 mle=1.7809 pcon=4.8877 forget=1.2251 favg=0.0000 nr=36 nf=36 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=7.9741 mle=1.8269 pcon=4.8864 forget=1.2608 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=7.9944 mle=1.8964 pcon=4.8850 forget=1.2130 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=7.7619 mle=1.6570 pcon=4.8837 forget=1.2212 favg=0.0000 nr=28 nf=28 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=7.9760 mle=1.8839 pcon=4.8824 forget=1.2097 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=7.7087 mle=1.5814 pcon=4.8811 forget=1.2463 favg=0.0000 nr=34 nf=34 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[loss] ep 19 it 40 total=7.5522 mle=1.5170 pcon=4.8797 forget=1.1555 favg=0.0000 nr=25 nf=25 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=8.0397 mle=1.9300 pcon=4.8785 forget=1.2311 favg=0.0000 nr=27 nf=27 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=7.9302 mle=1.8266 pcon=4.8772 forget=1.2265 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.4871 mle=1.3932 pcon=4.8760 forget=1.2180 favg=0.0000 nr=24 nf=24 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=7.8254 mle=1.7316 pcon=4.8747 forget=1.2190 favg=0.0000 nr=35 nf=35 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=8.0340 mle=1.9542 pcon=4.8736 forget=1.2062 favg=0.0000 nr=31 nf=31 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=8.2118 mle=2.1509 pcon=4.8724 forget=1.1885 favg=0.0000 nr=37 nf=37 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] loaded adapter 'stage2' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage2
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc1: Number of model parameters: 22321088
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:19,  2.80it/s]  2%|▏         | 9/391 [00:00<00:15, 24.61it/s]  5%|▍         | 18/391 [00:00<00:08, 43.34it/s]  7%|▋         | 28/391 [00:00<00:06, 59.08it/s] 10%|▉         | 38/391 [00:00<00:05, 69.11it/s] 12%|█▏        | 47/391 [00:00<00:04, 74.43it/s] 14%|█▍        | 56/391 [00:00<00:04, 78.76it/s] 17%|█▋        | 65/391 [00:01<00:03, 81.93it/s] 19%|█▉        | 74/391 [00:01<00:03, 83.32it/s] 21%|██        | 83/391 [00:01<00:03, 83.68it/s] 24%|██▎       | 92/391 [00:01<00:03, 83.10it/s] 26%|██▌       | 101/391 [00:01<00:03, 84.91it/s] 28%|██▊       | 110/391 [00:01<00:03, 85.02it/s] 30%|███       | 119/391 [00:01<00:03, 86.10it/s] 33%|███▎      | 128/391 [00:01<00:03, 86.15it/s] 35%|███▌      | 137/391 [00:01<00:02, 85.85it/s] 37%|███▋      | 146/391 [00:02<00:02, 85.72it/s] 40%|███▉      | 155/391 [00:02<00:02, 85.43it/s] 42%|████▏     | 164/391 [00:02<00:02, 85.21it/s] 44%|████▍     | 173/391 [00:02<00:02, 84.14it/s] 47%|████▋     | 182/391 [00:02<00:02, 83.18it/s] 49%|████▉     | 192/391 [00:02<00:02, 85.07it/s] 51%|█████▏    | 201/391 [00:02<00:02, 83.61it/s] 54%|█████▎    | 210/391 [00:02<00:02, 84.04it/s] 56%|█████▌    | 219/391 [00:02<00:02, 83.57it/s] 58%|█████▊    | 228/391 [00:03<00:01, 83.04it/s] 61%|██████    | 237/391 [00:03<00:01, 83.87it/s] 63%|██████▎   | 246/391 [00:03<00:01, 84.15it/s] 65%|██████▌   | 255/391 [00:03<00:01, 82.55it/s] 68%|██████▊   | 264/391 [00:03<00:01, 82.56it/s] 70%|██████▉   | 273/391 [00:03<00:01, 84.61it/s] 72%|███████▏  | 282/391 [00:03<00:01, 85.44it/s] 74%|███████▍  | 291/391 [00:03<00:01, 86.53it/s] 77%|███████▋  | 301/391 [00:03<00:01, 88.24it/s] 79%|███████▉  | 310/391 [00:03<00:00, 87.88it/s] 82%|████████▏ | 320/391 [00:04<00:00, 90.10it/s] 84%|████████▍ | 330/391 [00:04<00:00, 90.31it/s] 87%|████████▋ | 340/391 [00:04<00:00, 89.30it/s] 90%|████████▉ | 350/391 [00:04<00:00, 90.13it/s] 92%|█████████▏| 360/391 [00:04<00:00, 88.05it/s] 94%|█████████▍| 369/391 [00:04<00:00, 85.99it/s] 97%|█████████▋| 378/391 [00:04<00:00, 86.73it/s] 99%|█████████▉| 388/391 [00:04<00:00, 89.76it/s]100%|██████████| 391/391 [00:04<00:00, 80.25it/s]
50000 images processed, 4.987778663635254 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:28,  2.78it/s] 13%|█▎        | 10/79 [00:00<00:02, 26.54it/s] 24%|██▍       | 19/79 [00:00<00:01, 43.81it/s] 35%|███▌      | 28/79 [00:00<00:00, 56.07it/s] 47%|████▋     | 37/79 [00:00<00:00, 65.17it/s] 58%|█████▊    | 46/79 [00:00<00:00, 70.30it/s] 70%|██████▉   | 55/79 [00:01<00:00, 75.16it/s] 81%|████████  | 64/79 [00:01<00:00, 78.61it/s] 94%|█████████▎| 74/79 [00:01<00:00, 83.95it/s]100%|██████████| 79/79 [00:01<00:00, 62.31it/s]
10000 images processed, 1.2898106575012207 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:06,  3.04it/s]  4%|▍         | 9/204 [00:00<00:07, 26.00it/s]  9%|▉         | 18/204 [00:00<00:04, 44.20it/s] 13%|█▎        | 27/204 [00:00<00:03, 56.57it/s] 17%|█▋        | 35/204 [00:00<00:02, 62.83it/s] 22%|██▏       | 44/204 [00:00<00:02, 69.12it/s] 26%|██▌       | 53/204 [00:00<00:02, 73.75it/s] 30%|███       | 62/204 [00:01<00:01, 76.42it/s] 35%|███▍      | 71/204 [00:01<00:01, 78.24it/s] 39%|███▉      | 80/204 [00:01<00:01, 80.17it/s] 44%|████▎     | 89/204 [00:01<00:01, 81.08it/s] 48%|████▊     | 98/204 [00:01<00:01, 81.81it/s] 52%|█████▏    | 107/204 [00:01<00:01, 81.85it/s] 57%|█████▋    | 116/204 [00:01<00:01, 80.47it/s] 61%|██████▏   | 125/204 [00:01<00:00, 80.00it/s] 66%|██████▌   | 134/204 [00:01<00:00, 78.20it/s] 70%|███████   | 143/204 [00:02<00:00, 80.21it/s] 75%|███████▍  | 152/204 [00:02<00:00, 81.04it/s] 79%|███████▉  | 162/204 [00:02<00:00, 84.38it/s] 84%|████████▍ | 171/204 [00:02<00:00, 84.73it/s] 88%|████████▊ | 180/204 [00:02<00:00, 82.93it/s] 93%|█████████▎| 189/204 [00:02<00:00, 82.89it/s] 98%|█████████▊| 199/204 [00:02<00:00, 86.71it/s]100%|██████████| 204/204 [00:02<00:00, 73.40it/s]
26032 images processed, 2.824488401412964 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.01it/s] 11%|█▏        | 9/79 [00:00<00:04, 16.38it/s] 22%|██▏       | 17/79 [00:00<00:02, 26.51it/s] 32%|███▏      | 25/79 [00:01<00:01, 32.76it/s] 41%|████      | 32/79 [00:01<00:01, 39.93it/s] 47%|████▋     | 37/79 [00:01<00:01, 41.66it/s] 53%|█████▎    | 42/79 [00:01<00:00, 39.37it/s] 59%|█████▉    | 47/79 [00:01<00:00, 38.57it/s] 68%|██████▊   | 54/79 [00:01<00:00, 45.36it/s] 75%|███████▍  | 59/79 [00:01<00:00, 39.78it/s] 81%|████████  | 64/79 [00:01<00:00, 38.16it/s] 90%|████████▉ | 71/79 [00:02<00:00, 37.88it/s]100%|██████████| 79/79 [00:02<00:00, 35.86it/s]
10000 images processed, 2.2421140670776367 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:30,  2.55it/s] 13%|█▎        | 10/79 [00:00<00:02, 25.72it/s] 25%|██▌       | 20/79 [00:00<00:01, 45.35it/s] 38%|███▊      | 30/79 [00:00<00:00, 58.70it/s] 49%|████▉     | 39/79 [00:00<00:00, 67.28it/s] 61%|██████    | 48/79 [00:00<00:00, 72.45it/s] 72%|███████▏  | 57/79 [00:01<00:00, 75.15it/s] 84%|████████▎ | 66/79 [00:01<00:00, 78.28it/s] 96%|█████████▌| 76/79 [00:01<00:00, 83.63it/s]100%|██████████| 79/79 [00:01<00:00, 62.55it/s]
10000 images processed, 1.284358263015747 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:29,  2.36it/s] 16%|█▌        | 11/70 [00:00<00:02, 26.40it/s] 29%|██▊       | 20/70 [00:00<00:01, 42.93it/s] 41%|████▏     | 29/70 [00:00<00:00, 54.35it/s] 54%|█████▍    | 38/70 [00:00<00:00, 62.67it/s] 67%|██████▋   | 47/70 [00:00<00:00, 69.33it/s] 80%|████████  | 56/70 [00:01<00:00, 74.85it/s] 94%|█████████▍| 66/70 [00:01<00:00, 81.14it/s]100%|██████████| 70/70 [00:01<00:00, 57.91it/s]
8925 images processed, 1.2395002841949463 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:40,  1.07it/s]  4%|▍         | 2/45 [00:01<00:19,  2.25it/s] 16%|█▌        | 7/45 [00:01<00:04,  8.87it/s] 20%|██        | 9/45 [00:01<00:03,  9.61it/s] 24%|██▍       | 11/45 [00:01<00:03,  9.23it/s] 33%|███▎      | 15/45 [00:01<00:02, 12.82it/s] 38%|███▊      | 17/45 [00:01<00:02, 12.28it/s] 42%|████▏     | 19/45 [00:02<00:02, 11.99it/s] 49%|████▉     | 22/45 [00:02<00:01, 14.63it/s] 53%|█████▎    | 24/45 [00:02<00:01, 11.17it/s] 58%|█████▊    | 26/45 [00:02<00:01, 12.08it/s] 62%|██████▏   | 28/45 [00:02<00:01, 12.69it/s] 69%|██████▉   | 31/45 [00:03<00:01, 10.32it/s] 76%|███████▌  | 34/45 [00:03<00:00, 11.09it/s] 84%|████████▍ | 38/45 [00:03<00:00, 15.45it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.40it/s] 96%|█████████▌| 43/45 [00:04<00:00,  9.57it/s]100%|██████████| 45/45 [00:04<00:00, 10.47it/s]
5640 images processed, 4.321930885314941 seconds used

19.999812126159668
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.50  99.36
places365     67.90  80.57
LSUN          21.54  95.06
iSUN          72.28  81.40
dtd           38.17  91.27
AVG           40.48  89.53
Retain-Acc: 0.7433
Forget-as-OOD (retain known vs forget novel):
  FPR: 84.00 AUROC: 85.57 AUIN: 99.08
29.6025869846344
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc1_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] loaded adapter 'stage2' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage2
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc2: Number of model parameters: 22321088
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:08,  3.03it/s]  3%|▎         | 10/391 [00:00<00:13, 28.92it/s]  5%|▍         | 19/391 [00:00<00:07, 46.92it/s]  7%|▋         | 28/391 [00:00<00:06, 58.20it/s]  9%|▉         | 36/391 [00:00<00:05, 64.04it/s] 12%|█▏        | 45/391 [00:00<00:04, 69.88it/s] 14%|█▍        | 54/391 [00:00<00:04, 74.72it/s] 16%|█▌        | 63/391 [00:01<00:04, 78.11it/s] 18%|█▊        | 72/391 [00:01<00:04, 79.31it/s] 21%|██        | 82/391 [00:01<00:03, 81.99it/s] 24%|██▎       | 92/391 [00:01<00:03, 84.21it/s] 26%|██▌       | 102/391 [00:01<00:03, 86.45it/s] 29%|██▊       | 112/391 [00:01<00:03, 89.13it/s] 31%|███       | 121/391 [00:01<00:03, 88.70it/s] 33%|███▎      | 130/391 [00:01<00:02, 88.67it/s] 36%|███▌      | 139/391 [00:01<00:02, 87.53it/s] 38%|███▊      | 148/391 [00:02<00:02, 85.54it/s] 40%|████      | 157/391 [00:02<00:02, 85.31it/s] 43%|████▎     | 167/391 [00:02<00:02, 87.01it/s] 45%|████▌     | 176/391 [00:02<00:02, 86.18it/s] 47%|████▋     | 185/391 [00:02<00:02, 86.23it/s] 50%|████▉     | 194/391 [00:02<00:02, 86.51it/s] 52%|█████▏    | 203/391 [00:02<00:02, 84.82it/s] 54%|█████▍    | 212/391 [00:02<00:02, 84.76it/s] 57%|█████▋    | 221/391 [00:02<00:02, 83.14it/s] 59%|█████▉    | 230/391 [00:02<00:01, 84.90it/s] 61%|██████    | 239/391 [00:03<00:01, 85.08it/s] 63%|██████▎   | 248/391 [00:03<00:01, 85.80it/s] 66%|██████▌   | 257/391 [00:03<00:01, 85.77it/s] 68%|██████▊   | 266/391 [00:03<00:01, 84.71it/s] 70%|███████   | 275/391 [00:03<00:01, 86.00it/s] 73%|███████▎  | 284/391 [00:03<00:01, 86.89it/s] 75%|███████▌  | 294/391 [00:03<00:01, 89.55it/s] 78%|███████▊  | 304/391 [00:03<00:00, 91.29it/s] 80%|████████  | 314/391 [00:03<00:00, 91.71it/s] 83%|████████▎ | 324/391 [00:04<00:00, 90.07it/s] 85%|████████▌ | 334/391 [00:04<00:00, 88.46it/s] 88%|████████▊ | 343/391 [00:04<00:00, 86.13it/s] 90%|█████████ | 352/391 [00:04<00:00, 86.23it/s] 92%|█████████▏| 361/391 [00:04<00:00, 84.22it/s] 95%|█████████▍| 370/391 [00:04<00:00, 81.64it/s] 97%|█████████▋| 379/391 [00:04<00:00, 83.87it/s] 99%|█████████▉| 389/391 [00:04<00:00, 87.70it/s]100%|██████████| 391/391 [00:04<00:00, 80.53it/s]
50000 images processed, 4.936263799667358 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:25,  3.08it/s] 13%|█▎        | 10/79 [00:00<00:02, 29.63it/s] 25%|██▌       | 20/79 [00:00<00:01, 49.87it/s] 37%|███▋      | 29/79 [00:00<00:00, 60.27it/s] 48%|████▊     | 38/79 [00:00<00:00, 68.69it/s] 59%|█████▉    | 47/79 [00:00<00:00, 71.20it/s] 71%|███████   | 56/79 [00:00<00:00, 76.31it/s] 84%|████████▎ | 66/79 [00:01<00:00, 81.35it/s] 96%|█████████▌| 76/79 [00:01<00:00, 85.80it/s]100%|██████████| 79/79 [00:01<00:00, 65.13it/s]
10000 images processed, 1.2366433143615723 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:23,  2.43it/s]  5%|▌         | 11/204 [00:00<00:07, 26.97it/s] 10%|▉         | 20/204 [00:00<00:04, 42.93it/s] 14%|█▍        | 29/204 [00:00<00:03, 54.61it/s] 19%|█▊        | 38/204 [00:00<00:02, 63.75it/s] 23%|██▎       | 47/204 [00:00<00:02, 70.87it/s] 27%|██▋       | 56/204 [00:01<00:01, 75.03it/s] 32%|███▏      | 65/204 [00:01<00:01, 78.04it/s] 36%|███▋      | 74/204 [00:01<00:01, 80.41it/s] 41%|████      | 84/204 [00:01<00:01, 82.81it/s] 46%|████▌     | 93/204 [00:01<00:01, 82.00it/s] 50%|█████     | 102/204 [00:01<00:01, 82.01it/s] 54%|█████▍    | 111/204 [00:01<00:01, 83.43it/s] 59%|█████▉    | 120/204 [00:01<00:00, 84.64it/s] 64%|██████▎   | 130/204 [00:01<00:00, 87.63it/s] 68%|██████▊   | 139/204 [00:02<00:00, 85.78it/s] 73%|███████▎  | 148/204 [00:02<00:00, 85.10it/s] 77%|███████▋  | 157/204 [00:02<00:00, 84.27it/s] 81%|████████▏ | 166/204 [00:02<00:00, 82.40it/s] 86%|████████▌ | 175/204 [00:02<00:00, 82.45it/s] 90%|█████████ | 184/204 [00:02<00:00, 81.05it/s] 95%|█████████▍| 193/204 [00:02<00:00, 82.02it/s]100%|█████████▉| 203/204 [00:02<00:00, 86.08it/s]100%|██████████| 204/204 [00:02<00:00, 72.96it/s]
26032 images processed, 2.840503215789795 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:37,  2.07it/s] 10%|█         | 8/79 [00:00<00:04, 17.31it/s] 16%|█▋        | 13/79 [00:00<00:02, 25.00it/s] 23%|██▎       | 18/79 [00:00<00:02, 29.08it/s] 32%|███▏      | 25/79 [00:00<00:01, 34.18it/s] 42%|████▏     | 33/79 [00:01<00:01, 38.48it/s] 51%|█████     | 40/79 [00:01<00:00, 44.98it/s] 58%|█████▊    | 46/79 [00:01<00:00, 41.53it/s] 65%|██████▍   | 51/79 [00:01<00:00, 37.66it/s] 75%|███████▍  | 59/79 [00:01<00:00, 38.25it/s] 85%|████████▍ | 67/79 [00:01<00:00, 39.48it/s] 95%|█████████▍| 75/79 [00:02<00:00, 42.57it/s]100%|██████████| 79/79 [00:02<00:00, 36.08it/s]
10000 images processed, 2.2229390144348145 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:30,  2.52it/s] 11%|█▏        | 9/79 [00:00<00:03, 22.91it/s] 22%|██▏       | 17/79 [00:00<00:01, 38.25it/s] 32%|███▏      | 25/79 [00:00<00:01, 49.64it/s] 42%|████▏     | 33/79 [00:00<00:00, 57.67it/s] 53%|█████▎    | 42/79 [00:00<00:00, 66.93it/s] 65%|██████▍   | 51/79 [00:01<00:00, 71.88it/s] 75%|███████▍  | 59/79 [00:01<00:00, 74.10it/s] 86%|████████▌ | 68/79 [00:01<00:00, 78.40it/s] 99%|█████████▊| 78/79 [00:01<00:00, 83.81it/s]100%|██████████| 79/79 [00:01<00:00, 59.63it/s]
10000 images processed, 1.3455402851104736 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:24,  2.82it/s] 13%|█▎        | 9/70 [00:00<00:02, 24.78it/s] 26%|██▌       | 18/70 [00:00<00:01, 43.17it/s] 40%|████      | 28/70 [00:00<00:00, 57.35it/s] 53%|█████▎    | 37/70 [00:00<00:00, 65.59it/s] 66%|██████▌   | 46/70 [00:00<00:00, 72.34it/s] 79%|███████▊  | 55/70 [00:00<00:00, 75.38it/s] 93%|█████████▎| 65/70 [00:01<00:00, 81.60it/s]100%|██████████| 70/70 [00:01<00:00, 60.74it/s]
8925 images processed, 1.1829397678375244 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:44,  1.00s/it]  4%|▍         | 2/45 [00:01<00:21,  2.04it/s] 20%|██        | 9/45 [00:01<00:04,  8.84it/s] 24%|██▍       | 11/45 [00:01<00:03,  9.18it/s] 31%|███       | 14/45 [00:01<00:03, 10.06it/s] 38%|███▊      | 17/45 [00:02<00:02, 12.03it/s] 42%|████▏     | 19/45 [00:02<00:02, 12.62it/s] 47%|████▋     | 21/45 [00:02<00:01, 12.36it/s] 51%|█████     | 23/45 [00:02<00:01, 11.20it/s] 58%|█████▊    | 26/45 [00:02<00:01, 13.40it/s] 62%|██████▏   | 28/45 [00:02<00:01, 12.36it/s] 67%|██████▋   | 30/45 [00:03<00:01,  9.84it/s] 73%|███████▎  | 33/45 [00:03<00:00, 12.69it/s] 78%|███████▊  | 35/45 [00:03<00:00, 13.71it/s] 82%|████████▏ | 37/45 [00:03<00:00, 14.51it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.78it/s] 96%|█████████▌| 43/45 [00:04<00:00, 10.11it/s]100%|██████████| 45/45 [00:04<00:00, 10.44it/s]
5640 images processed, 4.332634925842285 seconds used

19.868448495864868
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.53  99.36
places365     68.01  81.23
LSUN          17.64  96.11
iSUN          72.54  81.90
dtd           37.73  91.47
AVG           39.69  90.01
Retain-Acc: 0.7418
Forget-as-OOD (retain known vs forget novel):
  FPR: 73.20 AUROC: 88.35 AUIN: 99.33
31.6033034324646
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-inc2_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] loaded adapter 'stage2' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage2
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-seen: Number of model parameters: 22321088
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:23,  2.72it/s]  3%|▎         | 11/391 [00:00<00:12, 29.31it/s]  5%|▌         | 20/391 [00:00<00:08, 45.78it/s]  8%|▊         | 30/391 [00:00<00:06, 58.98it/s] 10%|▉         | 39/391 [00:00<00:05, 66.29it/s] 13%|█▎        | 49/391 [00:00<00:04, 73.79it/s] 15%|█▍        | 58/391 [00:01<00:04, 76.74it/s] 17%|█▋        | 67/391 [00:01<00:04, 80.44it/s] 19%|█▉        | 76/391 [00:01<00:03, 81.69it/s] 22%|██▏       | 86/391 [00:01<00:03, 84.93it/s] 24%|██▍       | 95/391 [00:01<00:03, 85.58it/s] 27%|██▋       | 105/391 [00:01<00:03, 87.47it/s] 29%|██▉       | 115/391 [00:01<00:03, 88.46it/s] 32%|███▏      | 125/391 [00:01<00:02, 89.93it/s] 35%|███▍      | 135/391 [00:01<00:02, 87.55it/s] 37%|███▋      | 145/391 [00:01<00:02, 89.95it/s] 40%|███▉      | 155/391 [00:02<00:02, 91.70it/s] 42%|████▏     | 165/391 [00:02<00:02, 90.03it/s] 45%|████▍     | 175/391 [00:02<00:02, 88.05it/s] 47%|████▋     | 185/391 [00:02<00:02, 89.55it/s] 50%|████▉     | 195/391 [00:02<00:02, 90.57it/s] 52%|█████▏    | 205/391 [00:02<00:02, 92.13it/s] 55%|█████▍    | 215/391 [00:02<00:01, 92.45it/s] 58%|█████▊    | 225/391 [00:02<00:01, 91.05it/s] 60%|██████    | 235/391 [00:02<00:01, 87.98it/s] 63%|██████▎   | 245/391 [00:03<00:01, 88.63it/s] 65%|██████▌   | 255/391 [00:03<00:01, 89.28it/s] 68%|██████▊   | 264/391 [00:03<00:01, 86.39it/s] 70%|██████▉   | 273/391 [00:03<00:01, 86.41it/s] 72%|███████▏  | 282/391 [00:03<00:01, 86.93it/s] 74%|███████▍  | 291/391 [00:03<00:01, 87.50it/s] 77%|███████▋  | 300/391 [00:03<00:01, 86.16it/s] 79%|███████▉  | 309/391 [00:03<00:00, 86.16it/s] 81%|████████▏ | 318/391 [00:03<00:00, 87.13it/s] 84%|████████▎ | 327/391 [00:04<00:00, 87.17it/s] 86%|████████▌ | 336/391 [00:04<00:00, 87.60it/s] 88%|████████▊ | 345/391 [00:04<00:00, 87.88it/s] 91%|█████████ | 354/391 [00:04<00:00, 88.41it/s] 93%|█████████▎| 363/391 [00:04<00:00, 88.73it/s] 95%|█████████▌| 373/391 [00:04<00:00, 88.23it/s] 98%|█████████▊| 383/391 [00:04<00:00, 89.85it/s]100%|██████████| 391/391 [00:04<00:00, 82.03it/s]
50000 images processed, 4.852794647216797 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:27,  2.82it/s] 11%|█▏        | 9/79 [00:00<00:02, 24.67it/s] 23%|██▎       | 18/79 [00:00<00:01, 42.40it/s] 34%|███▍      | 27/79 [00:00<00:00, 54.18it/s] 46%|████▌     | 36/79 [00:00<00:00, 62.79it/s] 56%|█████▌    | 44/79 [00:00<00:00, 67.46it/s] 67%|██████▋   | 53/79 [00:01<00:00, 71.75it/s] 78%|███████▊  | 62/79 [00:01<00:00, 75.01it/s] 91%|█████████ | 72/79 [00:01<00:00, 80.37it/s]100%|██████████| 79/79 [00:01<00:00, 47.75it/s]
10000 images processed, 1.6798982620239258 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:15,  2.70it/s]  5%|▍         | 10/204 [00:00<00:07, 26.84it/s]  9%|▉         | 19/204 [00:00<00:04, 43.55it/s] 14%|█▎        | 28/204 [00:00<00:03, 55.45it/s] 18%|█▊        | 37/204 [00:00<00:02, 62.87it/s] 23%|██▎       | 46/204 [00:00<00:02, 68.46it/s] 27%|██▋       | 55/204 [00:01<00:02, 72.88it/s] 31%|███       | 63/204 [00:01<00:01, 74.66it/s] 35%|███▌      | 72/204 [00:01<00:01, 76.77it/s] 40%|████      | 82/204 [00:01<00:01, 81.00it/s] 45%|████▍     | 91/204 [00:01<00:01, 82.35it/s] 49%|████▉     | 100/204 [00:01<00:01, 84.17it/s] 53%|█████▎    | 109/204 [00:01<00:01, 85.08it/s] 58%|█████▊    | 118/204 [00:01<00:01, 85.25it/s] 62%|██████▏   | 127/204 [00:01<00:00, 86.05it/s] 67%|██████▋   | 136/204 [00:01<00:00, 87.17it/s] 71%|███████   | 145/204 [00:02<00:00, 84.78it/s] 75%|███████▌  | 154/204 [00:02<00:00, 84.11it/s] 80%|███████▉  | 163/204 [00:02<00:00, 84.25it/s] 85%|████████▍ | 173/204 [00:02<00:00, 86.25it/s] 90%|████████▉ | 183/204 [00:02<00:00, 88.57it/s] 95%|█████████▍| 193/204 [00:02<00:00, 90.71it/s]100%|█████████▉| 203/204 [00:02<00:00, 92.35it/s]100%|██████████| 204/204 [00:02<00:00, 74.74it/s]
26032 images processed, 2.774064064025879 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:42,  1.84it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.38it/s] 22%|██▏       | 17/79 [00:00<00:02, 23.72it/s] 32%|███▏      | 25/79 [00:01<00:01, 29.03it/s] 42%|████▏     | 33/79 [00:01<00:01, 34.91it/s] 52%|█████▏    | 41/79 [00:01<00:00, 40.30it/s] 62%|██████▏   | 49/79 [00:01<00:00, 43.92it/s] 72%|███████▏  | 57/79 [00:01<00:00, 45.56it/s] 80%|███████▉  | 63/79 [00:01<00:00, 47.89it/s] 87%|████████▋ | 69/79 [00:02<00:00, 43.60it/s] 96%|█████████▌| 76/79 [00:02<00:00, 41.63it/s]100%|██████████| 79/79 [00:02<00:00, 35.49it/s]
10000 images processed, 2.261214017868042 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:33,  2.36it/s] 13%|█▎        | 10/79 [00:00<00:02, 24.20it/s] 24%|██▍       | 19/79 [00:00<00:01, 40.54it/s] 35%|███▌      | 28/79 [00:00<00:00, 52.04it/s] 47%|████▋     | 37/79 [00:00<00:00, 61.10it/s] 57%|█████▋    | 45/79 [00:00<00:00, 64.62it/s] 68%|██████▊   | 54/79 [00:01<00:00, 69.73it/s] 80%|███████▉  | 63/79 [00:01<00:00, 74.37it/s] 92%|█████████▏| 73/79 [00:01<00:00, 80.67it/s]100%|██████████| 79/79 [00:01<00:00, 58.92it/s]
10000 images processed, 1.36265230178833 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:28,  2.44it/s] 10%|█         | 7/70 [00:00<00:03, 17.09it/s] 23%|██▎       | 16/70 [00:00<00:01, 36.42it/s] 36%|███▌      | 25/70 [00:00<00:00, 49.76it/s] 49%|████▊     | 34/70 [00:00<00:00, 59.69it/s] 61%|██████▏   | 43/70 [00:00<00:00, 65.48it/s] 74%|███████▍  | 52/70 [00:01<00:00, 71.87it/s] 87%|████████▋ | 61/70 [00:01<00:00, 76.62it/s]100%|██████████| 70/70 [00:01<00:00, 55.90it/s]
8925 images processed, 1.2898681163787842 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:42,  1.03it/s]  4%|▍         | 2/45 [00:01<00:20,  2.07it/s] 20%|██        | 9/45 [00:01<00:03,  9.29it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.75it/s] 38%|███▊      | 17/45 [00:02<00:02, 12.03it/s] 42%|████▏     | 19/45 [00:02<00:02, 11.59it/s] 53%|█████▎    | 24/45 [00:02<00:01, 15.95it/s] 58%|█████▊    | 26/45 [00:02<00:01, 11.02it/s] 67%|██████▋   | 30/45 [00:02<00:01, 13.96it/s] 73%|███████▎  | 33/45 [00:03<00:01, 11.11it/s] 78%|███████▊  | 35/45 [00:03<00:00, 11.06it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.67it/s] 96%|█████████▌| 43/45 [00:04<00:00, 10.40it/s]100%|██████████| 45/45 [00:04<00:00, 10.53it/s]
5640 images processed, 4.294151782989502 seconds used

20.220539093017578
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.50  99.36
places365     67.90  80.57
LSUN          21.54  95.06
iSUN          72.28  81.40
dtd           38.17  91.27
AVG           40.48  89.53
Retain-Acc: 0.7433
Forget-as-OOD (retain known vs forget novel):
  FPR: 84.00 AUROC: 85.57 AUIN: 99.08
29.553348779678345
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-seen_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-seen_rf.png
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] loaded adapter 'stage1' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage1
[peft] loaded adapter 'stage2' from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stack/stage2
[peft] set_adapter(list) failed: unhashable type: 'list'; fallback to last adapter
[peft] active adapter set to: stage2
resnet34-top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-all: Number of model parameters: 22321088
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:24,  2.70it/s]  3%|▎         | 10/391 [00:00<00:14, 26.45it/s]  5%|▍         | 19/391 [00:00<00:08, 43.34it/s]  7%|▋         | 28/391 [00:00<00:06, 55.62it/s] 10%|▉         | 38/391 [00:00<00:05, 65.63it/s] 12%|█▏        | 47/391 [00:00<00:04, 72.28it/s] 15%|█▍        | 57/391 [00:01<00:04, 78.37it/s] 17%|█▋        | 66/391 [00:01<00:04, 80.90it/s] 19%|█▉        | 75/391 [00:01<00:03, 82.86it/s] 22%|██▏       | 85/391 [00:01<00:03, 84.95it/s] 24%|██▍       | 94/391 [00:01<00:03, 85.22it/s] 26%|██▋       | 103/391 [00:01<00:03, 84.60it/s] 29%|██▉       | 113/391 [00:01<00:03, 86.59it/s] 31%|███       | 122/391 [00:01<00:03, 85.32it/s] 34%|███▎      | 131/391 [00:01<00:03, 84.88it/s] 36%|███▌      | 140/391 [00:01<00:02, 86.22it/s] 38%|███▊      | 149/391 [00:02<00:02, 86.61it/s] 40%|████      | 158/391 [00:02<00:02, 84.77it/s] 43%|████▎     | 167/391 [00:02<00:02, 85.08it/s] 45%|████▌     | 176/391 [00:02<00:02, 85.30it/s] 47%|████▋     | 185/391 [00:02<00:02, 86.46it/s] 50%|████▉     | 194/391 [00:02<00:02, 86.90it/s] 52%|█████▏    | 204/391 [00:02<00:02, 88.73it/s] 55%|█████▍    | 214/391 [00:02<00:01, 90.34it/s] 57%|█████▋    | 224/391 [00:02<00:01, 90.05it/s] 60%|█████▉    | 234/391 [00:03<00:01, 87.26it/s] 62%|██████▏   | 243/391 [00:03<00:01, 86.14it/s] 64%|██████▍   | 252/391 [00:03<00:01, 85.10it/s] 67%|██████▋   | 261/391 [00:03<00:01, 84.63it/s] 69%|██████▉   | 270/391 [00:03<00:01, 85.27it/s] 71%|███████▏  | 279/391 [00:03<00:01, 85.57it/s] 74%|███████▎  | 288/391 [00:03<00:01, 85.72it/s] 76%|███████▌  | 297/391 [00:03<00:01, 85.88it/s] 78%|███████▊  | 306/391 [00:03<00:00, 85.78it/s] 81%|████████  | 315/391 [00:03<00:00, 85.53it/s] 83%|████████▎ | 324/391 [00:04<00:00, 84.98it/s] 85%|████████▌ | 333/391 [00:04<00:00, 85.22it/s] 87%|████████▋ | 342/391 [00:04<00:00, 85.93it/s] 90%|████████▉ | 351/391 [00:04<00:00, 83.92it/s] 92%|█████████▏| 360/391 [00:04<00:00, 85.43it/s] 94%|█████████▍| 369/391 [00:04<00:00, 85.64it/s] 97%|█████████▋| 378/391 [00:04<00:00, 86.16it/s] 99%|█████████▉| 388/391 [00:04<00:00, 89.41it/s]100%|██████████| 391/391 [00:04<00:00, 80.08it/s]
50000 images processed, 4.968712091445923 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:31,  2.48it/s] 10%|█         | 8/79 [00:00<00:03, 19.93it/s] 22%|██▏       | 17/79 [00:00<00:01, 37.94it/s] 33%|███▎      | 26/79 [00:00<00:01, 52.03it/s] 46%|████▌     | 36/79 [00:00<00:00, 63.65it/s] 57%|█████▋    | 45/79 [00:00<00:00, 70.80it/s] 68%|██████▊   | 54/79 [00:01<00:00, 73.96it/s] 80%|███████▉  | 63/79 [00:01<00:00, 77.08it/s] 92%|█████████▏| 73/79 [00:01<00:00, 82.67it/s]100%|██████████| 79/79 [00:01<00:00, 59.22it/s]
10000 images processed, 1.3566927909851074 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:19,  2.56it/s]  5%|▍         | 10/204 [00:00<00:07, 25.49it/s]  9%|▉         | 19/204 [00:00<00:04, 43.01it/s] 14%|█▎        | 28/204 [00:00<00:03, 56.03it/s] 19%|█▊        | 38/204 [00:00<00:02, 67.22it/s] 23%|██▎       | 47/204 [00:00<00:02, 71.67it/s] 27%|██▋       | 56/204 [00:01<00:01, 74.21it/s] 32%|███▏      | 65/204 [00:01<00:01, 75.48it/s] 36%|███▋      | 74/204 [00:01<00:01, 79.18it/s] 41%|████      | 83/204 [00:01<00:01, 79.41it/s] 45%|████▌     | 92/204 [00:01<00:01, 79.27it/s] 50%|████▉     | 101/204 [00:01<00:01, 79.68it/s] 54%|█████▍    | 110/204 [00:01<00:01, 81.77it/s] 58%|█████▊    | 119/204 [00:01<00:01, 57.65it/s] 63%|██████▎   | 128/204 [00:02<00:01, 63.29it/s] 67%|██████▋   | 137/204 [00:02<00:00, 68.55it/s] 71%|███████   | 145/204 [00:02<00:00, 70.86it/s] 75%|███████▌  | 154/204 [00:02<00:00, 73.23it/s] 80%|███████▉  | 163/204 [00:02<00:00, 76.93it/s] 84%|████████▍ | 172/204 [00:02<00:00, 79.28it/s] 89%|████████▊ | 181/204 [00:02<00:00, 81.22it/s] 93%|█████████▎| 190/204 [00:02<00:00, 81.23it/s] 98%|█████████▊| 200/204 [00:02<00:00, 85.43it/s]100%|██████████| 204/204 [00:02<00:00, 68.94it/s]
26032 images processed, 3.0041537284851074 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:43,  1.81it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.10it/s] 22%|██▏       | 17/79 [00:00<00:02, 25.34it/s] 27%|██▋       | 21/79 [00:00<00:02, 28.25it/s] 33%|███▎      | 26/79 [00:01<00:01, 28.67it/s] 43%|████▎     | 34/79 [00:01<00:01, 32.56it/s] 53%|█████▎    | 42/79 [00:01<00:01, 35.25it/s] 63%|██████▎   | 50/79 [00:01<00:00, 36.99it/s] 73%|███████▎  | 58/79 [00:01<00:00, 38.15it/s] 84%|████████▎ | 66/79 [00:02<00:00, 39.25it/s] 94%|█████████▎| 74/79 [00:02<00:00, 41.45it/s]100%|██████████| 79/79 [00:02<00:00, 33.39it/s]
10000 images processed, 2.4003665447235107 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:33,  2.35it/s] 11%|█▏        | 9/79 [00:00<00:03, 21.66it/s] 24%|██▍       | 19/79 [00:00<00:01, 40.76it/s] 37%|███▋      | 29/79 [00:00<00:00, 55.04it/s] 48%|████▊     | 38/79 [00:00<00:00, 64.05it/s] 59%|█████▉    | 47/79 [00:00<00:00, 69.53it/s] 71%|███████   | 56/79 [00:01<00:00, 74.56it/s] 82%|████████▏ | 65/79 [00:01<00:00, 76.45it/s] 95%|█████████▍| 75/79 [00:01<00:00, 82.24it/s]100%|██████████| 79/79 [00:01<00:00, 59.96it/s]
10000 images processed, 1.3377509117126465 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:30,  2.29it/s] 14%|█▍        | 10/70 [00:00<00:02, 23.51it/s] 26%|██▌       | 18/70 [00:00<00:01, 37.82it/s] 37%|███▋      | 26/70 [00:00<00:00, 48.85it/s] 49%|████▊     | 34/70 [00:00<00:00, 57.26it/s] 61%|██████▏   | 43/70 [00:00<00:00, 64.24it/s] 74%|███████▍  | 52/70 [00:01<00:00, 68.82it/s] 89%|████████▊ | 62/70 [00:01<00:00, 76.42it/s]100%|██████████| 70/70 [00:01<00:00, 55.11it/s]
8925 images processed, 1.3019232749938965 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:44,  1.02s/it] 13%|█▎        | 6/45 [00:01<00:05,  6.99it/s] 20%|██        | 9/45 [00:01<00:04,  7.38it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.95it/s] 31%|███       | 14/45 [00:01<00:02, 11.55it/s] 38%|███▊      | 17/45 [00:02<00:02, 10.20it/s] 49%|████▉     | 22/45 [00:02<00:01, 12.08it/s] 56%|█████▌    | 25/45 [00:02<00:01, 12.19it/s] 67%|██████▋   | 30/45 [00:03<00:01, 12.77it/s] 73%|███████▎  | 33/45 [00:03<00:01, 10.72it/s] 78%|███████▊  | 35/45 [00:03<00:00, 11.21it/s] 87%|████████▋ | 39/45 [00:03<00:00, 14.81it/s] 91%|█████████ | 41/45 [00:03<00:00, 12.74it/s] 96%|█████████▌| 43/45 [00:04<00:00,  9.13it/s]100%|██████████| 45/45 [00:04<00:00, 10.23it/s]
5640 images processed, 4.4256837368011475 seconds used

20.574865341186523
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.53  99.36
places365     67.87  81.18
LSUN          17.60  96.07
iSUN          72.36  81.68
dtd           37.87  91.39
AVG           39.65  89.93
Retain-Acc: 0.7406
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.50 AUROC: 86.90 AUIN: 98.36
29.066558122634888
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-all_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e20-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-stage2-all_rf.png
