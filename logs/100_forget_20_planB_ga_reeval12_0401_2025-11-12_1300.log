nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='ga', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [00:34<02:19, 34.98s/it] 40%|████      | 2/5 [00:52<01:13, 24.42s/it] 60%|██████    | 3/5 [01:08<00:41, 20.87s/it] 80%|████████  | 4/5 [01:25<00:19, 19.33s/it]100%|██████████| 5/5 [01:42<00:00, 18.34s/it]100%|██████████| 5/5 [01:42<00:00, 20.44s/it]
[loss-ga] ep 0 it 0 total=-0.0698 ce_r=0.0852 ce_f=0.1551
[loss-ga] ep 0 it 50 total=-0.0688 ce_r=0.0789 ce_f=0.1477
[loss-ga] ep 0 it 100 total=-0.0159 ce_r=0.0292 ce_f=0.0451
[loss-ga] ep 0 it 150 total=-0.0358 ce_r=0.1280 ce_f=0.1638
[loss-ga] ep 0 it 200 total=-0.0159 ce_r=0.0450 ce_f=0.0609
[loss-ga] ep 0 it 250 total=-0.0020 ce_r=0.0600 ce_f=0.0620
[loss-ga] ep 0 it 300 total=-0.1185 ce_r=0.1404 ce_f=0.2589
[loss-ga] ep 0 it 350 total=-0.0238 ce_r=0.0330 ce_f=0.0569
[loss-ga] ep 1 it 10 total=-0.0765 ce_r=0.0834 ce_f=0.1599
[loss-ga] ep 1 it 60 total=-0.1572 ce_r=0.1811 ce_f=0.3382
[loss-ga] ep 1 it 110 total=-0.4953 ce_r=0.5565 ce_f=1.0518
[loss-ga] ep 1 it 160 total=-1.1869 ce_r=1.2095 ce_f=2.3964
[loss-ga] ep 1 it 210 total=-1.3974 ce_r=1.4393 ce_f=2.8367
[loss-ga] ep 1 it 260 total=-2.6259 ce_r=2.6679 ce_f=5.2939
[loss-ga] ep 1 it 310 total=-3.1782 ce_r=3.3188 ce_f=6.4971
[loss-ga] ep 1 it 360 total=-3.4408 ce_r=3.5351 ce_f=6.9758
[loss-ga] ep 2 it 20 total=-4.3307 ce_r=4.5584 ce_f=8.8891
[loss-ga] ep 2 it 70 total=-3.9957 ce_r=4.3138 ce_f=8.3095
[loss-ga] ep 2 it 120 total=-4.6659 ce_r=4.7153 ce_f=9.3811
[loss-ga] ep 2 it 170 total=-4.4058 ce_r=4.7585 ce_f=9.1643
[loss-ga] ep 2 it 220 total=-5.1646 ce_r=5.4414 ce_f=10.6060
[loss-ga] ep 2 it 270 total=-5.4542 ce_r=5.5417 ce_f=10.9959
[loss-ga] ep 2 it 320 total=-5.5190 ce_r=5.8444 ce_f=11.3634
[loss-ga] ep 2 it 370 total=-6.6268 ce_r=6.8905 ce_f=13.5173
[loss-ga] ep 3 it 30 total=-6.4432 ce_r=6.6693 ce_f=13.1125
[loss-ga] ep 3 it 80 total=-6.6657 ce_r=6.7102 ce_f=13.3759
[loss-ga] ep 3 it 130 total=-6.6484 ce_r=6.9246 ce_f=13.5729
[loss-ga] ep 3 it 180 total=-6.4699 ce_r=6.6901 ce_f=13.1600
[loss-ga] ep 3 it 230 total=-6.8671 ce_r=7.0405 ce_f=13.9076
[loss-ga] ep 3 it 280 total=-6.6989 ce_r=6.9452 ce_f=13.6441
[loss-ga] ep 3 it 330 total=-6.6707 ce_r=6.9941 ce_f=13.6648
[loss-ga] ep 3 it 380 total=-6.9978 ce_r=7.2929 ce_f=14.2906
[loss-ga] ep 4 it 40 total=-7.0161 ce_r=7.1915 ce_f=14.2077
[loss-ga] ep 4 it 90 total=-6.9910 ce_r=7.1989 ce_f=14.1899
[loss-ga] ep 4 it 140 total=-7.2216 ce_r=7.2712 ce_f=14.4928
[loss-ga] ep 4 it 190 total=-7.1709 ce_r=7.4237 ce_f=14.5946
[loss-ga] ep 4 it 240 total=-7.2872 ce_r=7.4988 ce_f=14.7860
[loss-ga] ep 4 it 290 total=-7.2604 ce_r=7.4204 ce_f=14.6808
[loss-ga] ep 4 it 340 total=-7.4641 ce_r=7.5423 ce_f=15.0064
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10.pt
resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:36,  1.80it/s]  3%|▎         | 11/391 [00:00<00:17, 21.64it/s]  5%|▌         | 20/391 [00:00<00:10, 36.95it/s]  7%|▋         | 29/391 [00:00<00:07, 49.63it/s] 10%|▉         | 39/391 [00:00<00:05, 61.83it/s] 12%|█▏        | 48/391 [00:01<00:05, 68.21it/s] 15%|█▍        | 58/391 [00:01<00:04, 75.01it/s] 17%|█▋        | 68/391 [00:01<00:03, 81.74it/s] 20%|█▉        | 78/391 [00:01<00:03, 85.20it/s] 23%|██▎       | 88/391 [00:01<00:03, 88.91it/s] 25%|██▌       | 98/391 [00:01<00:03, 91.32it/s] 28%|██▊       | 108/391 [00:01<00:03, 93.02it/s] 30%|███       | 118/391 [00:01<00:02, 94.99it/s] 33%|███▎      | 129/391 [00:01<00:02, 96.59it/s] 36%|███▌      | 139/391 [00:02<00:02, 96.47it/s] 38%|███▊      | 149/391 [00:02<00:02, 97.19it/s] 41%|████      | 159/391 [00:02<00:02, 96.41it/s] 43%|████▎     | 169/391 [00:02<00:02, 93.87it/s] 46%|████▌     | 179/391 [00:02<00:02, 92.94it/s] 48%|████▊     | 189/391 [00:02<00:02, 92.06it/s] 51%|█████     | 199/391 [00:02<00:02, 93.16it/s] 53%|█████▎    | 209/391 [00:02<00:01, 94.00it/s] 56%|█████▌    | 219/391 [00:02<00:01, 93.25it/s] 59%|█████▊    | 229/391 [00:02<00:01, 93.46it/s] 61%|██████    | 239/391 [00:03<00:01, 94.69it/s] 64%|██████▎   | 249/391 [00:03<00:01, 95.83it/s] 66%|██████▌   | 259/391 [00:03<00:01, 95.73it/s] 69%|██████▉   | 269/391 [00:03<00:01, 96.64it/s] 71%|███████▏  | 279/391 [00:03<00:01, 97.62it/s] 74%|███████▍  | 289/391 [00:03<00:01, 97.56it/s] 76%|███████▋  | 299/391 [00:03<00:00, 97.58it/s] 79%|███████▉  | 309/391 [00:03<00:00, 97.17it/s] 82%|████████▏ | 319/391 [00:03<00:00, 96.11it/s] 84%|████████▍ | 329/391 [00:04<00:00, 96.82it/s] 87%|████████▋ | 339/391 [00:04<00:00, 97.20it/s] 89%|████████▉ | 349/391 [00:04<00:00, 97.82it/s] 92%|█████████▏| 359/391 [00:04<00:00, 93.29it/s] 95%|█████████▍| 370/391 [00:04<00:00, 95.65it/s] 97%|█████████▋| 380/391 [00:04<00:00, 96.73it/s]100%|██████████| 391/391 [00:04<00:00, 94.90it/s]100%|██████████| 391/391 [00:04<00:00, 83.98it/s]
50000 images processed, 4.780858755111694 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:41,  1.87it/s] 14%|█▍        | 11/79 [00:00<00:03, 22.11it/s] 27%|██▋       | 21/79 [00:00<00:01, 39.05it/s] 37%|███▋      | 29/79 [00:00<00:01, 48.81it/s] 49%|████▉     | 39/79 [00:00<00:00, 60.82it/s] 62%|██████▏   | 49/79 [00:01<00:00, 69.49it/s] 75%|███████▍  | 59/79 [00:01<00:00, 76.83it/s] 87%|████████▋ | 69/79 [00:01<00:00, 82.33it/s]100%|██████████| 79/79 [00:02<00:00, 19.86it/s]100%|██████████| 79/79 [00:02<00:00, 30.49it/s]
10000 images processed, 2.6285181045532227 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:08,  1.58it/s]  5%|▌         | 11/204 [00:00<00:09, 19.42it/s] 10%|▉         | 20/204 [00:00<00:05, 33.85it/s] 15%|█▍        | 30/204 [00:00<00:03, 48.49it/s] 19%|█▉        | 39/204 [00:01<00:03, 54.56it/s] 24%|██▍       | 49/204 [00:01<00:02, 64.22it/s] 29%|██▉       | 59/204 [00:01<00:02, 72.23it/s] 33%|███▎      | 68/204 [00:01<00:01, 74.64it/s] 38%|███▊      | 78/204 [00:01<00:01, 80.53it/s] 43%|████▎     | 88/204 [00:01<00:01, 84.39it/s] 48%|████▊     | 98/204 [00:01<00:01, 87.23it/s] 53%|█████▎    | 108/204 [00:01<00:01, 89.02it/s] 58%|█████▊    | 118/204 [00:01<00:00, 89.97it/s] 63%|██████▎   | 128/204 [00:02<00:00, 91.95it/s] 68%|██████▊   | 138/204 [00:02<00:00, 93.32it/s] 73%|███████▎  | 148/204 [00:02<00:00, 94.13it/s] 77%|███████▋  | 158/204 [00:02<00:00, 92.71it/s] 82%|████████▏ | 168/204 [00:02<00:00, 93.07it/s] 87%|████████▋ | 178/204 [00:02<00:00, 94.74it/s] 93%|█████████▎| 189/204 [00:02<00:00, 96.52it/s] 98%|█████████▊| 199/204 [00:02<00:00, 97.47it/s]100%|██████████| 204/204 [00:02<00:00, 72.05it/s]
26032 images processed, 2.899667501449585 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:16,  1.02it/s] 14%|█▍        | 11/79 [00:01<00:05, 13.51it/s] 27%|██▋       | 21/79 [00:01<00:02, 26.63it/s] 38%|███▊      | 30/79 [00:01<00:01, 37.52it/s] 51%|█████     | 40/79 [00:01<00:00, 49.76it/s] 62%|██████▏   | 49/79 [00:01<00:00, 51.75it/s] 75%|███████▍  | 59/79 [00:01<00:00, 61.22it/s] 87%|████████▋ | 69/79 [00:01<00:00, 69.76it/s]100%|██████████| 79/79 [00:01<00:00, 42.39it/s]
10000 images processed, 1.8955984115600586 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:04,  1.22it/s] 13%|█▎        | 10/79 [00:00<00:04, 14.29it/s] 24%|██▍       | 19/79 [00:01<00:02, 27.19it/s] 37%|███▋      | 29/79 [00:01<00:01, 41.14it/s] 49%|████▉     | 39/79 [00:01<00:00, 52.87it/s] 61%|██████    | 48/79 [00:01<00:00, 59.92it/s] 73%|███████▎  | 58/79 [00:01<00:00, 69.50it/s] 87%|████████▋ | 69/79 [00:01<00:00, 78.05it/s]100%|██████████| 79/79 [00:01<00:00, 47.51it/s]
10000 images processed, 1.6874041557312012 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:42,  1.63it/s]  6%|▌         | 4/70 [00:00<00:09,  7.00it/s] 20%|██        | 14/70 [00:00<00:02, 26.53it/s] 34%|███▍      | 24/70 [00:00<00:01, 43.25it/s] 47%|████▋     | 33/70 [00:01<00:00, 54.09it/s] 60%|██████    | 42/70 [00:01<00:00, 62.36it/s] 74%|███████▍  | 52/70 [00:01<00:00, 72.23it/s] 89%|████████▊ | 62/70 [00:01<00:00, 79.31it/s]100%|██████████| 70/70 [00:01<00:00, 49.06it/s]
8925 images processed, 1.4698677062988281 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:57,  1.31s/it]  4%|▍         | 2/45 [00:01<00:28,  1.51it/s] 24%|██▍       | 11/45 [00:01<00:02, 11.35it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.86it/s] 47%|████▋     | 21/45 [00:02<00:01, 13.54it/s] 69%|██████▉   | 31/45 [00:02<00:00, 24.57it/s] 82%|████████▏ | 37/45 [00:02<00:00, 16.63it/s] 96%|█████████▌| 43/45 [00:03<00:00, 20.89it/s]100%|██████████| 45/45 [00:03<00:00, 14.36it/s]
5640 images processed, 3.159029722213745 seconds used

20.54552388191223
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           8.53  98.16  95.11
places365     73.01  78.68  75.86
LSUN          35.31  92.70  92.70
iSUN          70.48  82.56  84.69
dtd           52.48  87.62  91.83
AVG           47.96  87.94  88.04
Retain-Acc: 0.7264
Forget-as-OOD (retain known vs forget novel):
  FPR: 81.90 AUROC: 73.65 AUIN: 95.99
12.101489543914795
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e5-lr0.001-wd1e-4-fl1-CIFAR-100forget10_rf.png
