nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:572: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [00:39<02:38, 39.60s/it] 40%|████      | 2/5 [01:02<01:30, 30.06s/it] 60%|██████    | 3/5 [01:25<00:53, 26.81s/it] 80%|████████  | 4/5 [01:49<00:25, 25.55s/it]100%|██████████| 5/5 [02:10<00:00, 23.98s/it]100%|██████████| 5/5 [02:10<00:00, 26.15s/it]
[loss-randlabel] ep 0 it 0 total=2.1747 ce_r=0.2466 ce_f=9.6406
[loss-randlabel] ep 0 it 50 total=2.1406 ce_r=0.2109 ce_f=9.6483
[loss-randlabel] ep 0 it 100 total=2.1673 ce_r=0.2422 ce_f=9.6256
[loss-randlabel] ep 0 it 150 total=2.1923 ce_r=0.3007 ce_f=9.4580
[loss-randlabel] ep 0 it 200 total=2.0155 ce_r=0.1276 ce_f=9.4395
[loss-randlabel] ep 0 it 250 total=2.0647 ce_r=0.1529 ce_f=9.5592
[loss-randlabel] ep 0 it 300 total=2.0528 ce_r=0.1848 ce_f=9.3400
[loss-randlabel] ep 0 it 350 total=1.9993 ce_r=0.1417 ce_f=9.2880
[loss-randlabel] ep 1 it 10 total=1.9045 ce_r=0.1927 ce_f=8.5590
[loss-randlabel] ep 1 it 60 total=1.9023 ce_r=0.0954 ce_f=9.0346
[loss-randlabel] ep 1 it 110 total=1.9580 ce_r=0.2244 ce_f=8.6679
[loss-randlabel] ep 1 it 160 total=1.7507 ce_r=0.1296 ce_f=8.1055
[loss-randlabel] ep 1 it 210 total=1.7542 ce_r=0.1419 ce_f=8.0614
[loss-randlabel] ep 1 it 260 total=1.7857 ce_r=0.1503 ce_f=8.1769
[loss-randlabel] ep 1 it 310 total=1.7117 ce_r=0.1655 ce_f=7.7309
[loss-randlabel] ep 1 it 360 total=1.7476 ce_r=0.2008 ce_f=7.7340
[loss-randlabel] ep 2 it 20 total=1.7874 ce_r=0.3014 ce_f=7.4296
[loss-randlabel] ep 2 it 70 total=1.7254 ce_r=0.1644 ce_f=7.8051
[loss-randlabel] ep 2 it 120 total=1.6499 ce_r=0.2197 ce_f=7.1506
[loss-randlabel] ep 2 it 170 total=1.7474 ce_r=0.3150 ce_f=7.1618
[loss-randlabel] ep 2 it 220 total=1.6067 ce_r=0.2134 ce_f=6.9661
[loss-randlabel] ep 2 it 270 total=1.7848 ce_r=0.3246 ce_f=7.3012
[loss-randlabel] ep 2 it 320 total=1.7415 ce_r=0.3166 ce_f=7.1244
[loss-randlabel] ep 2 it 370 total=1.6439 ce_r=0.2438 ce_f=7.0007
[loss-randlabel] ep 3 it 30 total=1.7085 ce_r=0.3074 ce_f=7.0057
[loss-randlabel] ep 3 it 80 total=1.6058 ce_r=0.1578 ce_f=7.2401
[loss-randlabel] ep 3 it 130 total=1.6652 ce_r=0.1518 ce_f=7.5668
[loss-randlabel] ep 3 it 180 total=1.6284 ce_r=0.1717 ce_f=7.2832
[loss-randlabel] ep 3 it 230 total=1.6146 ce_r=0.1813 ce_f=7.1667
[loss-randlabel] ep 3 it 280 total=1.5572 ce_r=0.1579 ce_f=6.9964
[loss-randlabel] ep 3 it 330 total=1.6728 ce_r=0.2755 ce_f=6.9862
[loss-randlabel] ep 3 it 380 total=1.5754 ce_r=0.2284 ce_f=6.7352
[loss-randlabel] ep 4 it 40 total=1.6610 ce_r=0.2317 ce_f=7.1462
[loss-randlabel] ep 4 it 90 total=1.6961 ce_r=0.3414 ce_f=6.7738
[loss-randlabel] ep 4 it 140 total=1.5824 ce_r=0.2141 ce_f=6.8414
[loss-randlabel] ep 4 it 190 total=1.6002 ce_r=0.2445 ce_f=6.7784
[loss-randlabel] ep 4 it 240 total=1.6227 ce_r=0.2746 ce_f=6.7407
[loss-randlabel] ep 4 it 290 total=1.5850 ce_r=0.2090 ce_f=6.8798
[loss-randlabel] ep 4 it 340 total=1.6818 ce_r=0.2994 ce_f=6.9124
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl0.2: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:35,  2.51it/s]  3%|▎         | 11/391 [00:00<00:13, 27.71it/s]  6%|▌         | 22/391 [00:00<00:07, 48.69it/s]  8%|▊         | 33/391 [00:00<00:05, 63.80it/s] 11%|█▏        | 44/391 [00:00<00:04, 74.53it/s] 14%|█▍        | 55/391 [00:00<00:04, 82.25it/s] 17%|█▋        | 65/391 [00:01<00:03, 86.67it/s] 19%|█▉        | 76/391 [00:01<00:03, 90.89it/s] 22%|██▏       | 87/391 [00:01<00:03, 93.81it/s] 25%|██▌       | 98/391 [00:01<00:03, 95.87it/s] 28%|██▊       | 109/391 [00:01<00:02, 97.22it/s] 31%|███       | 120/391 [00:01<00:02, 98.08it/s] 34%|███▎      | 131/391 [00:01<00:02, 98.99it/s] 36%|███▋      | 142/391 [00:01<00:02, 99.54it/s] 39%|███▉      | 153/391 [00:01<00:02, 100.02it/s] 42%|████▏     | 164/391 [00:02<00:02, 99.11it/s]  45%|████▍     | 175/391 [00:02<00:02, 99.54it/s] 48%|████▊     | 186/391 [00:02<00:02, 99.97it/s] 50%|█████     | 197/391 [00:02<00:01, 100.11it/s] 53%|█████▎    | 208/391 [00:02<00:01, 99.33it/s]  56%|█████▌    | 219/391 [00:02<00:01, 99.80it/s] 59%|█████▊    | 229/391 [00:02<00:01, 99.03it/s] 61%|██████▏   | 240/391 [00:02<00:01, 99.42it/s] 64%|██████▍   | 251/391 [00:02<00:01, 99.71it/s] 67%|██████▋   | 262/391 [00:03<00:01, 99.98it/s] 70%|██████▉   | 273/391 [00:03<00:01, 100.17it/s] 73%|███████▎  | 284/391 [00:03<00:01, 100.20it/s] 75%|███████▌  | 295/391 [00:03<00:00, 100.26it/s] 78%|███████▊  | 306/391 [00:03<00:00, 100.40it/s] 81%|████████  | 317/391 [00:03<00:00, 100.30it/s] 84%|████████▍ | 328/391 [00:03<00:00, 100.56it/s] 87%|████████▋ | 339/391 [00:03<00:00, 99.44it/s]  90%|████████▉ | 350/391 [00:03<00:00, 99.72it/s] 92%|█████████▏| 360/391 [00:03<00:00, 99.63it/s] 95%|█████████▍| 371/391 [00:04<00:00, 100.42it/s] 98%|█████████▊| 382/391 [00:04<00:00, 100.98it/s]100%|██████████| 391/391 [00:04<00:00, 90.80it/s] 
50000 images processed, 4.429265260696411 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:33,  2.31it/s] 14%|█▍        | 11/79 [00:00<00:02, 26.30it/s] 27%|██▋       | 21/79 [00:00<00:01, 45.22it/s] 39%|███▉      | 31/79 [00:00<00:00, 59.64it/s] 52%|█████▏    | 41/79 [00:00<00:00, 70.35it/s] 65%|██████▍   | 51/79 [00:00<00:00, 78.47it/s] 77%|███████▋  | 61/79 [00:01<00:00, 84.61it/s] 91%|█████████ | 72/79 [00:01<00:00, 89.43it/s]100%|██████████| 79/79 [00:02<00:00, 33.98it/s]
10000 images processed, 2.357098340988159 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl0.2/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:45,  1.93it/s]  5%|▌         | 11/204 [00:00<00:08, 23.04it/s] 10%|█         | 21/204 [00:00<00:04, 40.85it/s] 15%|█▌        | 31/204 [00:00<00:03, 55.54it/s] 20%|██        | 41/204 [00:00<00:02, 66.06it/s] 25%|██▌       | 51/204 [00:01<00:02, 74.99it/s] 30%|██▉       | 61/204 [00:01<00:01, 81.66it/s] 35%|███▍      | 71/204 [00:01<00:01, 86.70it/s] 40%|███▉      | 81/204 [00:01<00:01, 90.25it/s] 45%|████▍     | 91/204 [00:01<00:01, 91.32it/s] 50%|████▉     | 101/204 [00:01<00:01, 93.67it/s] 54%|█████▍    | 111/204 [00:01<00:00, 95.40it/s] 59%|█████▉    | 121/204 [00:01<00:00, 96.50it/s] 64%|██████▍   | 131/204 [00:01<00:00, 97.34it/s] 69%|██████▉   | 141/204 [00:01<00:00, 96.31it/s] 74%|███████▍  | 151/204 [00:02<00:00, 97.22it/s] 79%|███████▉  | 161/204 [00:02<00:00, 97.93it/s] 84%|████████▍ | 171/204 [00:02<00:00, 97.22it/s] 89%|████████▉ | 182/204 [00:02<00:00, 98.28it/s] 95%|█████████▍| 193/204 [00:02<00:00, 99.17it/s]100%|██████████| 204/204 [00:02<00:00, 98.84it/s]100%|██████████| 204/204 [00:02<00:00, 78.87it/s]
26032 images processed, 2.6285741329193115 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:50,  1.55it/s] 14%|█▍        | 11/79 [00:00<00:03, 19.09it/s] 23%|██▎       | 18/79 [00:00<00:02, 29.07it/s] 35%|███▌      | 28/79 [00:00<00:01, 44.67it/s] 46%|████▌     | 36/79 [00:01<00:00, 50.42it/s] 58%|█████▊    | 46/79 [00:01<00:00, 62.35it/s] 70%|██████▉   | 55/79 [00:01<00:00, 64.85it/s] 82%|████████▏ | 65/79 [00:01<00:00, 71.39it/s] 96%|█████████▌| 76/79 [00:01<00:00, 79.59it/s]100%|██████████| 79/79 [00:01<00:00, 50.63it/s]
10000 images processed, 1.5776004791259766 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.39it/s] 14%|█▍        | 11/79 [00:00<00:02, 26.52it/s] 27%|██▋       | 21/79 [00:00<00:01, 45.32it/s] 39%|███▉      | 31/79 [00:00<00:00, 58.58it/s] 52%|█████▏    | 41/79 [00:00<00:00, 68.56it/s] 65%|██████▍   | 51/79 [00:00<00:00, 76.37it/s] 77%|███████▋  | 61/79 [00:01<00:00, 82.75it/s] 90%|████████▉ | 71/79 [00:01<00:00, 87.64it/s]100%|██████████| 79/79 [00:01<00:00, 64.32it/s]
10000 images processed, 1.2811822891235352 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:35,  1.93it/s] 16%|█▌        | 11/70 [00:00<00:02, 23.08it/s] 30%|███       | 21/70 [00:00<00:01, 41.11it/s] 44%|████▍     | 31/70 [00:00<00:00, 55.75it/s] 59%|█████▊    | 41/70 [00:00<00:00, 67.24it/s] 74%|███████▍  | 52/70 [00:01<00:00, 77.00it/s] 90%|█████████ | 63/70 [00:01<00:00, 83.99it/s]100%|██████████| 70/70 [00:01<00:00, 57.64it/s]
8925 images processed, 1.2448358535766602 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:39,  1.10it/s]  4%|▍         | 2/45 [00:01<00:20,  2.09it/s] 29%|██▉       | 13/45 [00:01<00:01, 17.95it/s] 40%|████      | 18/45 [00:01<00:01, 15.49it/s] 51%|█████     | 23/45 [00:01<00:01, 18.31it/s] 73%|███████▎  | 33/45 [00:02<00:00, 22.84it/s] 82%|████████▏ | 37/45 [00:02<00:00, 24.22it/s] 96%|█████████▌| 43/45 [00:02<00:00, 29.88it/s]100%|██████████| 45/45 [00:02<00:00, 18.59it/s]
5640 images processed, 2.4530391693115234 seconds used

17.591092586517334
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.08  99.21
places365     72.80  78.76
LSUN          26.21  94.45
iSUN          68.58  84.09
dtd           44.49  88.47
AVG           43.03  88.99
Retain-Acc: 0.7366
Forget-as-OOD (retain known vs forget novel):
  FPR: 45.30 AUROC: 90.85 AUIN: 98.83
8.321112155914307
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl0.2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-4-fl0.2_rf.png
