nohup: ignoring input
==== Epoch 1/5: train 1 epoch, save adapter to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1, then evaluate ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:31<00:00, 31.80s/it]100%|██████████| 1/1 [00:31<00:00, 31.81s/it]
[loss] ep 0 it 0 total=7.8809 mle=1.5709 pcon=5.2950 forget=1.3755 favg=-0.3606 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.7875 mle=1.5424 pcon=5.2879 forget=1.4013 favg=-0.4441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.9330 mle=1.7005 pcon=5.2809 forget=1.3740 favg=-0.4224 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.0966 mle=1.8997 pcon=5.2738 forget=1.3696 favg=-0.4465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.9676 mle=1.7133 pcon=5.2670 forget=1.3826 favg=-0.3953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.7255 mle=1.5021 pcon=5.2603 forget=1.3784 favg=-0.4153 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.8313 mle=1.5596 pcon=5.2540 forget=1.3819 favg=-0.3643 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.8703 mle=1.6808 pcon=5.2476 forget=1.3896 favg=-0.4478 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1
resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep1: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:06,  2.09it/s]  3%|▎         | 10/391 [00:00<00:17, 21.87it/s]  5%|▍         | 19/391 [00:00<00:09, 38.30it/s]  7%|▋         | 29/391 [00:00<00:06, 52.47it/s] 10%|▉         | 38/391 [00:00<00:05, 61.95it/s] 12%|█▏        | 47/391 [00:01<00:05, 67.11it/s] 14%|█▍        | 56/391 [00:01<00:04, 71.61it/s] 17%|█▋        | 65/391 [00:01<00:04, 73.40it/s] 19%|█▉        | 74/391 [00:01<00:04, 76.31it/s] 21%|██        | 83/391 [00:01<00:03, 79.01it/s] 24%|██▎       | 92/391 [00:01<00:03, 80.19it/s] 26%|██▌       | 101/391 [00:01<00:03, 80.19it/s] 28%|██▊       | 110/391 [00:01<00:03, 78.43it/s] 30%|███       | 119/391 [00:01<00:03, 80.79it/s] 33%|███▎      | 128/391 [00:02<00:03, 82.94it/s] 35%|███▌      | 137/391 [00:02<00:03, 83.14it/s] 37%|███▋      | 146/391 [00:02<00:02, 84.96it/s] 40%|███▉      | 155/391 [00:02<00:02, 85.37it/s] 42%|████▏     | 164/391 [00:02<00:02, 83.63it/s] 44%|████▍     | 173/391 [00:02<00:02, 85.42it/s] 47%|████▋     | 182/391 [00:02<00:02, 85.88it/s] 49%|████▉     | 192/391 [00:02<00:02, 87.85it/s] 52%|█████▏    | 202/391 [00:02<00:02, 89.75it/s] 54%|█████▍    | 211/391 [00:02<00:02, 86.98it/s] 56%|█████▋    | 220/391 [00:03<00:01, 87.80it/s] 59%|█████▊    | 229/391 [00:03<00:01, 87.58it/s] 61%|██████    | 238/391 [00:03<00:01, 86.84it/s] 63%|██████▎   | 247/391 [00:03<00:01, 85.37it/s] 65%|██████▌   | 256/391 [00:03<00:01, 86.18it/s] 68%|██████▊   | 266/391 [00:03<00:01, 86.27it/s] 70%|███████   | 275/391 [00:03<00:01, 86.60it/s] 73%|███████▎  | 284/391 [00:03<00:01, 83.08it/s] 75%|███████▌  | 294/391 [00:03<00:01, 85.94it/s] 77%|███████▋  | 303/391 [00:04<00:01, 85.96it/s] 80%|███████▉  | 312/391 [00:04<00:00, 83.01it/s] 82%|████████▏ | 321/391 [00:04<00:00, 81.09it/s] 84%|████████▍ | 330/391 [00:04<00:00, 79.46it/s] 86%|████████▋ | 338/391 [00:04<00:00, 79.35it/s] 89%|████████▊ | 347/391 [00:04<00:00, 80.33it/s] 91%|█████████ | 356/391 [00:04<00:00, 81.01it/s] 93%|█████████▎| 365/391 [00:04<00:00, 80.62it/s] 96%|█████████▌| 374/391 [00:04<00:00, 80.62it/s] 98%|█████████▊| 384/391 [00:05<00:00, 83.61it/s]100%|██████████| 391/391 [00:05<00:00, 76.35it/s]
50000 images processed, 5.325613975524902 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:34,  2.28it/s] 13%|█▎        | 10/79 [00:00<00:02, 23.72it/s] 24%|██▍       | 19/79 [00:00<00:01, 40.55it/s] 35%|███▌      | 28/79 [00:00<00:00, 53.47it/s] 47%|████▋     | 37/79 [00:00<00:00, 62.83it/s] 58%|█████▊    | 46/79 [00:00<00:00, 67.34it/s] 70%|██████▉   | 55/79 [00:01<00:00, 72.93it/s] 81%|████████  | 64/79 [00:01<00:00, 75.63it/s] 94%|█████████▎| 74/79 [00:01<00:00, 81.25it/s]100%|██████████| 79/79 [00:01<00:00, 58.56it/s]
10000 images processed, 1.41331148147583 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:34,  2.15it/s]  5%|▍         | 10/204 [00:00<00:08, 22.66it/s]  9%|▉         | 19/204 [00:00<00:04, 39.39it/s] 14%|█▎        | 28/204 [00:00<00:03, 51.98it/s] 18%|█▊        | 37/204 [00:00<00:02, 61.51it/s] 23%|██▎       | 46/204 [00:00<00:02, 68.34it/s] 27%|██▋       | 55/204 [00:01<00:02, 72.40it/s] 31%|███▏      | 64/204 [00:01<00:01, 75.36it/s] 36%|███▌      | 73/204 [00:01<00:01, 78.67it/s] 40%|████      | 82/204 [00:01<00:01, 80.80it/s] 45%|████▍     | 91/204 [00:01<00:01, 81.04it/s] 49%|████▉     | 100/204 [00:01<00:01, 81.75it/s] 53%|█████▎    | 109/204 [00:01<00:01, 83.81it/s] 58%|█████▊    | 118/204 [00:01<00:01, 81.88it/s] 62%|██████▏   | 127/204 [00:01<00:00, 83.74it/s] 67%|██████▋   | 136/204 [00:02<00:00, 83.88it/s] 71%|███████   | 145/204 [00:02<00:00, 83.31it/s] 75%|███████▌  | 154/204 [00:02<00:00, 84.68it/s] 80%|███████▉  | 163/204 [00:02<00:00, 83.42it/s] 84%|████████▍ | 172/204 [00:02<00:00, 84.21it/s] 89%|████████▊ | 181/204 [00:02<00:00, 82.86it/s] 93%|█████████▎| 190/204 [00:02<00:00, 83.57it/s] 98%|█████████▊| 200/204 [00:02<00:00, 86.96it/s]100%|██████████| 204/204 [00:02<00:00, 71.44it/s]
26032 images processed, 3.0307674407958984 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:41,  1.89it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.82it/s] 22%|██▏       | 17/79 [00:00<00:02, 23.76it/s] 32%|███▏      | 25/79 [00:01<00:01, 29.13it/s] 39%|███▉      | 31/79 [00:01<00:01, 34.91it/s] 46%|████▌     | 36/79 [00:01<00:01, 32.75it/s] 52%|█████▏    | 41/79 [00:01<00:01, 32.98it/s] 62%|██████▏   | 49/79 [00:01<00:00, 36.10it/s] 72%|███████▏  | 57/79 [00:01<00:00, 38.81it/s] 82%|████████▏ | 65/79 [00:02<00:00, 41.55it/s] 92%|█████████▏| 73/79 [00:02<00:00, 43.03it/s]100%|██████████| 79/79 [00:02<00:00, 34.29it/s]
10000 images processed, 2.3371894359588623 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:30,  2.59it/s] 13%|█▎        | 10/79 [00:00<00:02, 25.36it/s] 24%|██▍       | 19/79 [00:00<00:01, 41.90it/s] 35%|███▌      | 28/79 [00:00<00:00, 54.28it/s] 46%|████▌     | 36/79 [00:00<00:00, 61.33it/s] 57%|█████▋    | 45/79 [00:00<00:00, 69.09it/s] 70%|██████▉   | 55/79 [00:01<00:00, 76.39it/s] 81%|████████  | 64/79 [00:01<00:00, 79.84it/s] 94%|█████████▎| 74/79 [00:01<00:00, 84.57it/s]100%|██████████| 79/79 [00:01<00:00, 61.96it/s]
10000 images processed, 1.3319127559661865 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:27,  2.48it/s] 14%|█▍        | 10/70 [00:00<00:02, 25.10it/s] 26%|██▌       | 18/70 [00:00<00:01, 38.96it/s] 37%|███▋      | 26/70 [00:00<00:00, 49.70it/s] 50%|█████     | 35/70 [00:00<00:00, 60.42it/s] 63%|██████▎   | 44/70 [00:00<00:00, 66.76it/s] 74%|███████▍  | 52/70 [00:01<00:00, 69.43it/s] 89%|████████▊ | 62/70 [00:01<00:00, 76.68it/s]100%|██████████| 70/70 [00:01<00:00, 56.71it/s]
8925 images processed, 1.2648463249206543 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:42,  1.04it/s]  4%|▍         | 2/45 [00:01<00:21,  2.00it/s] 20%|██        | 9/45 [00:01<00:03,  9.06it/s] 24%|██▍       | 11/45 [00:01<00:04,  8.48it/s] 36%|███▌      | 16/45 [00:01<00:02, 14.04it/s] 42%|████▏     | 19/45 [00:02<00:02, 10.78it/s] 49%|████▉     | 22/45 [00:02<00:01, 12.70it/s] 56%|█████▌    | 25/45 [00:02<00:01, 13.22it/s] 60%|██████    | 27/45 [00:02<00:01, 10.36it/s] 73%|███████▎  | 33/45 [00:03<00:01, 11.90it/s] 78%|███████▊  | 35/45 [00:03<00:00, 10.93it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.36it/s] 96%|█████████▌| 43/45 [00:04<00:00,  9.65it/s]100%|██████████| 45/45 [00:04<00:00, 10.11it/s]
5640 images processed, 4.473751068115234 seconds used

21.09183692932129
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.53  99.36
places365     67.87  81.18
LSUN          17.60  96.07
iSUN          72.36  81.67
dtd           37.87  91.39
AVG           39.65  89.93
Retain-Acc: 0.7406
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.50 AUROC: 86.90 AUIN: 98.36
71.44328927993774
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep1_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep1_rf.png
==== Epoch 2/5: train 1 epoch, save adapter to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2, then evaluate ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2', adapter_load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1', forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep1
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [03:06<00:00, 186.33s/it]100%|██████████| 1/1 [03:06<00:00, 186.33s/it]
[loss] ep 0 it 0 total=7.8796 mle=1.5712 pcon=5.2950 forget=1.3754 favg=-0.3621 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.7857 mle=1.5423 pcon=5.2879 forget=1.4013 favg=-0.4458 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.9304 mle=1.6999 pcon=5.2809 forget=1.3739 favg=-0.4243 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.0943 mle=1.8997 pcon=5.2738 forget=1.3695 favg=-0.4487 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.9654 mle=1.7127 pcon=5.2670 forget=1.3825 favg=-0.3967 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.7233 mle=1.5019 pcon=5.2603 forget=1.3783 favg=-0.4172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.8295 mle=1.5596 pcon=5.2540 forget=1.3818 favg=-0.3660 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.8680 mle=1.6809 pcon=5.2476 forget=1.3894 favg=-0.4500 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2
resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep2: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:14,  2.01it/s]  3%|▎         | 10/391 [00:00<00:17, 21.44it/s]  5%|▍         | 19/391 [00:00<00:10, 36.99it/s]  7%|▋         | 28/391 [00:00<00:07, 49.70it/s]  9%|▉         | 37/391 [00:00<00:05, 59.38it/s] 12%|█▏        | 46/391 [00:01<00:05, 65.73it/s] 14%|█▍        | 55/391 [00:01<00:04, 70.90it/s] 17%|█▋        | 65/391 [00:01<00:04, 77.94it/s] 19%|█▉        | 74/391 [00:01<00:03, 80.00it/s] 21%|██        | 83/391 [00:01<00:04, 62.08it/s] 23%|██▎       | 91/391 [00:01<00:04, 66.16it/s] 26%|██▌       | 100/391 [00:01<00:04, 71.84it/s] 28%|██▊       | 108/391 [00:01<00:03, 73.38it/s] 30%|██▉       | 117/391 [00:01<00:03, 77.28it/s] 32%|███▏      | 126/391 [00:02<00:03, 80.08it/s] 35%|███▍      | 135/391 [00:02<00:03, 82.42it/s] 37%|███▋      | 145/391 [00:02<00:02, 86.27it/s] 39%|███▉      | 154/391 [00:02<00:02, 84.28it/s] 42%|████▏     | 164/391 [00:02<00:02, 85.46it/s] 44%|████▍     | 173/391 [00:02<00:02, 85.77it/s] 47%|████▋     | 182/391 [00:02<00:02, 85.21it/s] 49%|████▉     | 191/391 [00:02<00:02, 84.05it/s] 51%|█████     | 200/391 [00:02<00:02, 82.71it/s] 53%|█████▎    | 209/391 [00:03<00:02, 83.72it/s] 56%|█████▌    | 218/391 [00:03<00:02, 81.22it/s] 58%|█████▊    | 228/391 [00:03<00:01, 83.88it/s] 61%|██████    | 237/391 [00:03<00:01, 83.87it/s] 63%|██████▎   | 246/391 [00:03<00:01, 83.45it/s] 65%|██████▌   | 255/391 [00:03<00:01, 81.74it/s] 68%|██████▊   | 264/391 [00:03<00:01, 78.35it/s] 70%|██████▉   | 273/391 [00:03<00:01, 79.12it/s] 72%|███████▏  | 282/391 [00:03<00:01, 79.30it/s] 74%|███████▍  | 290/391 [00:04<00:01, 79.22it/s] 76%|███████▌  | 298/391 [00:04<00:01, 79.03it/s] 79%|███████▊  | 307/391 [00:04<00:01, 80.51it/s] 81%|████████  | 316/391 [00:04<00:00, 81.44it/s] 83%|████████▎ | 325/391 [00:04<00:00, 81.76it/s] 85%|████████▌ | 334/391 [00:04<00:00, 82.20it/s] 88%|████████▊ | 343/391 [00:04<00:00, 83.18it/s] 90%|█████████ | 352/391 [00:04<00:00, 84.17it/s] 92%|█████████▏| 361/391 [00:04<00:00, 83.78it/s] 95%|█████████▍| 370/391 [00:05<00:00, 85.16it/s] 97%|█████████▋| 379/391 [00:05<00:00, 61.20it/s] 99%|█████████▉| 389/391 [00:05<00:00, 69.55it/s]100%|██████████| 391/391 [00:05<00:00, 72.19it/s]
50000 images processed, 5.525552272796631 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:27,  2.79it/s] 10%|█         | 8/79 [00:00<00:03, 21.67it/s] 22%|██▏       | 17/79 [00:00<00:01, 40.42it/s] 33%|███▎      | 26/79 [00:00<00:00, 53.08it/s] 44%|████▍     | 35/79 [00:00<00:00, 61.73it/s] 54%|█████▍    | 43/79 [00:00<00:00, 65.80it/s] 65%|██████▍   | 51/79 [00:00<00:00, 69.24it/s] 75%|███████▍  | 59/79 [00:01<00:00, 72.16it/s] 86%|████████▌ | 68/79 [00:01<00:00, 76.14it/s] 99%|█████████▊| 78/79 [00:01<00:00, 82.14it/s]100%|██████████| 79/79 [00:01<00:00, 59.02it/s]
10000 images processed, 1.3618457317352295 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:31,  2.22it/s]  4%|▍         | 9/204 [00:00<00:09, 20.59it/s]  9%|▉         | 18/204 [00:00<00:04, 37.33it/s] 13%|█▎        | 27/204 [00:00<00:03, 50.73it/s] 18%|█▊        | 36/204 [00:00<00:02, 59.82it/s] 22%|██▏       | 45/204 [00:00<00:02, 67.97it/s] 26%|██▋       | 54/204 [00:01<00:02, 70.15it/s] 31%|███       | 63/204 [00:01<00:01, 73.81it/s] 35%|███▌      | 72/204 [00:01<00:01, 76.49it/s] 40%|███▉      | 81/204 [00:01<00:01, 74.67it/s] 44%|████▍     | 90/204 [00:01<00:01, 75.59it/s] 49%|████▊     | 99/204 [00:01<00:01, 78.11it/s] 53%|█████▎    | 108/204 [00:01<00:01, 78.45it/s] 57%|█████▋    | 117/204 [00:01<00:01, 80.75it/s] 62%|██████▏   | 126/204 [00:02<00:00, 79.18it/s] 66%|██████▌   | 135/204 [00:02<00:00, 81.20it/s] 71%|███████   | 145/204 [00:02<00:00, 84.65it/s] 76%|███████▌  | 155/204 [00:02<00:00, 87.11it/s] 80%|████████  | 164/204 [00:02<00:00, 86.31it/s] 85%|████████▍ | 173/204 [00:02<00:00, 87.14it/s] 89%|████████▉ | 182/204 [00:02<00:00, 86.41it/s] 94%|█████████▎| 191/204 [00:02<00:00, 85.72it/s] 99%|█████████▊| 201/204 [00:02<00:00, 88.79it/s]100%|██████████| 204/204 [00:02<00:00, 70.75it/s]
26032 images processed, 2.9315855503082275 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:15,  1.03it/s] 11%|█▏        | 9/79 [00:01<00:08,  7.79it/s] 22%|██▏       | 17/79 [00:01<00:05, 11.84it/s] 32%|███▏      | 25/79 [00:02<00:03, 15.02it/s] 41%|████      | 32/79 [00:02<00:02, 20.84it/s] 46%|████▌     | 36/79 [00:02<00:02, 17.58it/s] 52%|█████▏    | 41/79 [00:02<00:02, 18.81it/s] 56%|█████▌    | 44/79 [00:03<00:02, 17.27it/s] 62%|██████▏   | 49/79 [00:03<00:01, 21.76it/s] 67%|██████▋   | 53/79 [00:03<00:01, 20.78it/s] 72%|███████▏  | 57/79 [00:03<00:00, 22.77it/s] 76%|███████▌  | 60/79 [00:03<00:00, 21.27it/s] 80%|███████▉  | 63/79 [00:03<00:00, 21.85it/s] 84%|████████▎ | 66/79 [00:03<00:00, 20.72it/s] 87%|████████▋ | 69/79 [00:04<00:00, 19.87it/s] 92%|█████████▏| 73/79 [00:04<00:00, 21.02it/s] 96%|█████████▌| 76/79 [00:04<00:00, 22.54it/s]100%|██████████| 79/79 [00:04<00:00, 17.72it/s]
10000 images processed, 4.498854875564575 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:46,  1.69it/s] 13%|█▎        | 10/79 [00:00<00:03, 18.85it/s] 24%|██▍       | 19/79 [00:00<00:01, 34.24it/s] 34%|███▍      | 27/79 [00:00<00:01, 44.84it/s] 46%|████▌     | 36/79 [00:01<00:00, 55.32it/s] 57%|█████▋    | 45/79 [00:01<00:00, 63.01it/s] 68%|██████▊   | 54/79 [00:01<00:00, 69.58it/s] 80%|███████▉  | 63/79 [00:01<00:00, 74.77it/s] 92%|█████████▏| 73/79 [00:01<00:00, 80.77it/s]100%|██████████| 79/79 [00:01<00:00, 53.52it/s]
10000 images processed, 1.5014638900756836 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:38,  1.80it/s] 14%|█▍        | 10/70 [00:00<00:03, 19.74it/s] 27%|██▋       | 19/70 [00:00<00:01, 35.18it/s] 41%|████▏     | 29/70 [00:00<00:00, 49.33it/s] 53%|█████▎    | 37/70 [00:00<00:00, 56.91it/s] 66%|██████▌   | 46/70 [00:01<00:00, 64.36it/s] 79%|███████▊  | 55/70 [00:01<00:00, 69.96it/s] 93%|█████████▎| 65/70 [00:01<00:00, 77.28it/s]100%|██████████| 70/70 [00:01<00:00, 51.67it/s]
8925 images processed, 1.3917393684387207 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:51,  1.18s/it]  4%|▍         | 2/45 [00:01<00:25,  1.66it/s] 16%|█▌        | 7/45 [00:01<00:06,  5.70it/s] 20%|██        | 9/45 [00:01<00:05,  6.92it/s] 22%|██▏       | 10/45 [00:02<00:05,  5.89it/s] 31%|███       | 14/45 [00:02<00:03,  9.91it/s] 36%|███▌      | 16/45 [00:02<00:03,  8.66it/s] 40%|████      | 18/45 [00:02<00:03,  7.81it/s] 47%|████▋     | 21/45 [00:03<00:02, 10.52it/s] 51%|█████     | 23/45 [00:03<00:03,  6.88it/s] 58%|█████▊    | 26/45 [00:03<00:02,  9.20it/s] 67%|██████▋   | 30/45 [00:04<00:01, 10.62it/s] 71%|███████   | 32/45 [00:04<00:01,  8.33it/s] 76%|███████▌  | 34/45 [00:04<00:01,  7.96it/s] 87%|████████▋ | 39/45 [00:05<00:00,  8.77it/s] 93%|█████████▎| 42/45 [00:05<00:00,  7.09it/s]100%|██████████| 45/45 [00:05<00:00,  7.56it/s]
5640 images processed, 5.975894451141357 seconds used

25.96425461769104
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.52  99.36
places365     67.87  81.18
LSUN          17.59  96.07
iSUN          72.35  81.67
dtd           37.85  91.39
AVG           39.64  89.93
Retain-Acc: 0.7406
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.50 AUROC: 86.90 AUIN: 98.36
27.04624891281128
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep2_rf.png
==== Epoch 3/5: train 1 epoch, save adapter to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3, then evaluate ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3', adapter_load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2', forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep2
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:30<00:00, 30.50s/it]100%|██████████| 1/1 [00:30<00:00, 30.50s/it]
[loss] ep 0 it 0 total=7.8773 mle=1.5713 pcon=5.2950 forget=1.3752 favg=-0.3643 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.7837 mle=1.5423 pcon=5.2879 forget=1.4012 favg=-0.4478 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.9276 mle=1.7000 pcon=5.2809 forget=1.3737 favg=-0.4270 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.0912 mle=1.8996 pcon=5.2738 forget=1.3694 favg=-0.4517 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.9629 mle=1.7126 pcon=5.2670 forget=1.3823 favg=-0.3989 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.7198 mle=1.5021 pcon=5.2603 forget=1.3781 favg=-0.4207 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.8263 mle=1.5593 pcon=5.2540 forget=1.3817 favg=-0.3687 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.8632 mle=1.6808 pcon=5.2475 forget=1.3892 favg=-0.4543 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3
resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep3: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:37,  1.79it/s]  2%|▏         | 9/391 [00:00<00:22, 17.08it/s]  4%|▍         | 17/391 [00:00<00:12, 30.74it/s]  6%|▌         | 23/391 [00:00<00:10, 35.41it/s]  7%|▋         | 29/391 [00:01<00:09, 39.60it/s]  9%|▉         | 37/391 [00:01<00:07, 48.80it/s] 12%|█▏        | 45/391 [00:01<00:06, 55.47it/s] 14%|█▎        | 53/391 [00:01<00:05, 61.72it/s] 15%|█▌        | 60/391 [00:01<00:05, 62.46it/s] 17%|█▋        | 67/391 [00:01<00:05, 64.27it/s] 19%|█▉        | 76/391 [00:01<00:04, 70.38it/s] 21%|██▏       | 84/391 [00:01<00:04, 72.91it/s] 24%|██▎       | 92/391 [00:01<00:04, 70.44it/s] 26%|██▌       | 100/391 [00:02<00:04, 61.33it/s] 27%|██▋       | 107/391 [00:02<00:04, 61.12it/s] 29%|██▉       | 114/391 [00:02<00:04, 59.51it/s] 31%|███       | 121/391 [00:02<00:04, 60.63it/s] 33%|███▎      | 128/391 [00:02<00:04, 62.90it/s] 35%|███▍      | 136/391 [00:02<00:03, 67.14it/s] 37%|███▋      | 144/391 [00:02<00:03, 70.21it/s] 39%|███▉      | 152/391 [00:02<00:03, 72.91it/s] 41%|████      | 160/391 [00:02<00:03, 74.72it/s] 43%|████▎     | 168/391 [00:03<00:03, 69.13it/s] 45%|████▌     | 177/391 [00:03<00:02, 74.28it/s] 48%|████▊     | 187/391 [00:03<00:02, 79.56it/s] 50%|█████     | 197/391 [00:03<00:02, 83.10it/s] 53%|█████▎    | 206/391 [00:03<00:02, 84.46it/s] 55%|█████▍    | 215/391 [00:03<00:02, 84.13it/s] 57%|█████▋    | 224/391 [00:03<00:01, 85.19it/s] 60%|█████▉    | 233/391 [00:03<00:01, 86.39it/s] 62%|██████▏   | 243/391 [00:03<00:01, 88.39it/s] 64%|██████▍   | 252/391 [00:03<00:01, 87.39it/s] 67%|██████▋   | 261/391 [00:04<00:01, 87.11it/s] 69%|██████▉   | 270/391 [00:04<00:01, 85.34it/s] 71%|███████▏  | 279/391 [00:04<00:01, 85.73it/s] 74%|███████▎  | 288/391 [00:04<00:01, 83.98it/s] 76%|███████▌  | 298/391 [00:04<00:01, 85.52it/s] 79%|███████▊  | 307/391 [00:04<00:00, 84.18it/s] 81%|████████  | 316/391 [00:04<00:00, 81.91it/s] 83%|████████▎ | 325/391 [00:04<00:00, 83.18it/s] 86%|████████▌ | 335/391 [00:04<00:00, 84.73it/s] 88%|████████▊ | 344/391 [00:05<00:00, 83.29it/s] 90%|█████████ | 353/391 [00:05<00:00, 83.87it/s] 93%|█████████▎| 362/391 [00:05<00:00, 82.69it/s] 95%|█████████▍| 371/391 [00:05<00:00, 83.34it/s] 97%|█████████▋| 381/391 [00:05<00:00, 85.70it/s]100%|██████████| 391/391 [00:05<00:00, 86.47it/s]100%|██████████| 391/391 [00:05<00:00, 69.31it/s]
50000 images processed, 5.729324817657471 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:28,  2.70it/s] 13%|█▎        | 10/79 [00:00<00:02, 26.48it/s] 24%|██▍       | 19/79 [00:00<00:01, 42.21it/s] 37%|███▋      | 29/79 [00:00<00:00, 56.73it/s] 48%|████▊     | 38/79 [00:00<00:00, 65.24it/s] 59%|█████▉    | 47/79 [00:00<00:00, 71.99it/s] 71%|███████   | 56/79 [00:01<00:00, 74.89it/s] 84%|████████▎ | 66/79 [00:01<00:00, 80.27it/s] 96%|█████████▌| 76/79 [00:01<00:00, 85.07it/s]100%|██████████| 79/79 [00:01<00:00, 62.17it/s]
10000 images processed, 1.2987408638000488 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:14,  2.72it/s]  5%|▍         | 10/204 [00:00<00:07, 26.68it/s]  9%|▉         | 19/204 [00:00<00:04, 42.48it/s] 14%|█▎        | 28/204 [00:00<00:03, 55.32it/s] 18%|█▊        | 37/204 [00:00<00:02, 63.72it/s] 22%|██▏       | 45/204 [00:00<00:02, 68.17it/s] 26%|██▋       | 54/204 [00:01<00:02, 74.27it/s] 31%|███       | 63/204 [00:01<00:01, 78.55it/s] 35%|███▌      | 72/204 [00:01<00:01, 80.67it/s] 40%|███▉      | 81/204 [00:01<00:01, 81.47it/s] 44%|████▍     | 90/204 [00:01<00:01, 81.63it/s] 49%|████▊     | 99/204 [00:01<00:01, 81.69it/s] 53%|█████▎    | 108/204 [00:01<00:01, 83.15it/s] 57%|█████▋    | 117/204 [00:01<00:01, 82.45it/s] 62%|██████▏   | 126/204 [00:01<00:00, 82.76it/s] 66%|██████▌   | 135/204 [00:01<00:00, 81.94it/s] 71%|███████   | 144/204 [00:02<00:00, 83.75it/s] 75%|███████▌  | 153/204 [00:02<00:00, 83.02it/s] 79%|███████▉  | 162/204 [00:02<00:00, 84.31it/s] 84%|████████▍ | 171/204 [00:02<00:00, 85.22it/s] 88%|████████▊ | 180/204 [00:02<00:00, 85.44it/s] 93%|█████████▎| 189/204 [00:02<00:00, 86.31it/s] 98%|█████████▊| 199/204 [00:02<00:00, 89.19it/s]100%|██████████| 204/204 [00:02<00:00, 73.93it/s]
26032 images processed, 2.8057117462158203 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:46,  1.69it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.60it/s] 16%|█▋        | 13/79 [00:00<00:03, 20.24it/s] 23%|██▎       | 18/79 [00:00<00:02, 26.46it/s] 28%|██▊       | 22/79 [00:01<00:02, 28.10it/s] 35%|███▌      | 28/79 [00:01<00:01, 30.47it/s] 46%|████▌     | 36/79 [00:01<00:01, 33.95it/s] 56%|█████▌    | 44/79 [00:01<00:00, 36.24it/s] 66%|██████▌   | 52/79 [00:01<00:00, 37.54it/s] 76%|███████▌  | 60/79 [00:02<00:00, 38.16it/s] 86%|████████▌ | 68/79 [00:02<00:00, 39.08it/s] 96%|█████████▌| 76/79 [00:02<00:00, 42.35it/s]100%|██████████| 79/79 [00:02<00:00, 32.63it/s]
10000 images processed, 2.458512544631958 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:46,  1.69it/s] 13%|█▎        | 10/79 [00:00<00:03, 18.79it/s] 24%|██▍       | 19/79 [00:00<00:01, 34.10it/s] 37%|███▋      | 29/79 [00:00<00:01, 49.09it/s] 49%|████▉     | 39/79 [00:01<00:00, 60.77it/s] 62%|██████▏   | 49/79 [00:01<00:00, 69.97it/s] 73%|███████▎  | 58/79 [00:01<00:00, 73.98it/s] 85%|████████▍ | 67/79 [00:01<00:00, 76.40it/s] 97%|█████████▋| 77/79 [00:01<00:00, 81.96it/s]100%|██████████| 79/79 [00:01<00:00, 54.60it/s]
10000 images processed, 1.468153953552246 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:29,  2.34it/s] 14%|█▍        | 10/70 [00:00<00:02, 24.21it/s] 27%|██▋       | 19/70 [00:00<00:01, 40.74it/s] 41%|████▏     | 29/70 [00:00<00:00, 55.42it/s] 54%|█████▍    | 38/70 [00:00<00:00, 63.30it/s] 69%|██████▊   | 48/70 [00:00<00:00, 71.42it/s] 81%|████████▏ | 57/70 [00:01<00:00, 76.12it/s] 96%|█████████▌| 67/70 [00:01<00:00, 81.91it/s]100%|██████████| 70/70 [00:01<00:00, 57.94it/s]
8925 images processed, 1.2406423091888428 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:42,  1.04it/s]  4%|▍         | 2/45 [00:01<00:21,  2.05it/s] 20%|██        | 9/45 [00:01<00:03,  9.21it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.61it/s] 31%|███       | 14/45 [00:01<00:02, 10.66it/s] 38%|███▊      | 17/45 [00:02<00:02, 12.35it/s] 42%|████▏     | 19/45 [00:02<00:02, 10.69it/s] 49%|████▉     | 22/45 [00:02<00:01, 12.24it/s] 56%|█████▌    | 25/45 [00:02<00:01, 14.61it/s] 60%|██████    | 27/45 [00:02<00:01, 10.75it/s] 67%|██████▋   | 30/45 [00:03<00:01, 11.89it/s] 73%|███████▎  | 33/45 [00:03<00:00, 12.35it/s] 78%|███████▊  | 35/45 [00:03<00:01,  8.91it/s] 91%|█████████ | 41/45 [00:03<00:00, 14.95it/s] 98%|█████████▊| 44/45 [00:04<00:00,  8.98it/s]100%|██████████| 45/45 [00:04<00:00,  9.69it/s]
5640 images processed, 4.664252042770386 seconds used

21.385801315307617
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.51  99.36
places365     67.81  81.18
LSUN          17.53  96.07
iSUN          72.32  81.67
dtd           37.82  91.39
AVG           39.60  89.93
Retain-Acc: 0.7406
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.40 AUROC: 86.90 AUIN: 98.36
36.26546597480774
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep3_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep3_rf.png
==== Epoch 4/5: train 1 epoch, save adapter to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4, then evaluate ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4', adapter_load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3', forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep3
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:29<00:00, 29.61s/it]100%|██████████| 1/1 [00:29<00:00, 29.61s/it]
[loss] ep 0 it 0 total=7.8728 mle=1.5712 pcon=5.2951 forget=1.3750 favg=-0.3684 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.7799 mle=1.5426 pcon=5.2879 forget=1.4011 favg=-0.4517 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.9228 mle=1.6996 pcon=5.2808 forget=1.3734 favg=-0.4312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.0855 mle=1.8996 pcon=5.2738 forget=1.3692 favg=-0.4570 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.9577 mle=1.7124 pcon=5.2669 forget=1.3820 favg=-0.4036 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.7136 mle=1.5022 pcon=5.2602 forget=1.3777 favg=-0.4265 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.8202 mle=1.5593 pcon=5.2539 forget=1.3814 favg=-0.3745 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.8554 mle=1.6807 pcon=5.2475 forget=1.3889 favg=-0.4617 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4
resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep4: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:19,  2.80it/s]  3%|▎         | 10/391 [00:00<00:13, 27.35it/s]  5%|▍         | 19/391 [00:00<00:08, 44.02it/s]  7%|▋         | 27/391 [00:00<00:06, 53.44it/s]  9%|▉         | 36/391 [00:00<00:05, 63.65it/s] 12%|█▏        | 45/391 [00:00<00:04, 71.15it/s] 14%|█▍        | 54/391 [00:00<00:04, 76.42it/s] 16%|█▋        | 64/391 [00:01<00:04, 81.17it/s] 19%|█▉        | 74/391 [00:01<00:03, 85.35it/s] 21%|██        | 83/391 [00:01<00:03, 86.59it/s] 24%|██▎       | 92/391 [00:01<00:03, 86.27it/s] 26%|██▌       | 102/391 [00:01<00:03, 88.76it/s] 28%|██▊       | 111/391 [00:01<00:03, 84.61it/s] 31%|███       | 120/391 [00:01<00:03, 82.91it/s] 33%|███▎      | 129/391 [00:01<00:03, 82.42it/s] 35%|███▌      | 138/391 [00:01<00:03, 81.28it/s] 38%|███▊      | 147/391 [00:02<00:02, 83.03it/s] 40%|███▉      | 156/391 [00:02<00:02, 82.86it/s] 42%|████▏     | 166/391 [00:02<00:02, 86.05it/s] 45%|████▍     | 175/391 [00:02<00:02, 86.74it/s] 47%|████▋     | 184/391 [00:02<00:02, 83.64it/s] 49%|████▉     | 193/391 [00:02<00:02, 84.13it/s] 52%|█████▏    | 202/391 [00:02<00:02, 85.44it/s] 54%|█████▍    | 211/391 [00:02<00:02, 85.80it/s] 56%|█████▋    | 220/391 [00:02<00:01, 86.14it/s] 59%|█████▊    | 229/391 [00:03<00:01, 85.25it/s] 61%|██████    | 238/391 [00:03<00:01, 86.17it/s] 63%|██████▎   | 247/391 [00:03<00:01, 87.14it/s] 65%|██████▌   | 256/391 [00:03<00:01, 87.57it/s] 68%|██████▊   | 265/391 [00:03<00:01, 85.61it/s] 70%|███████   | 275/391 [00:03<00:01, 87.98it/s] 73%|███████▎  | 285/391 [00:03<00:01, 90.30it/s] 75%|███████▌  | 295/391 [00:03<00:01, 90.09it/s] 78%|███████▊  | 305/391 [00:03<00:00, 91.11it/s] 81%|████████  | 315/391 [00:03<00:00, 89.90it/s] 83%|████████▎ | 325/391 [00:04<00:00, 91.72it/s] 86%|████████▌ | 335/391 [00:04<00:00, 89.29it/s] 88%|████████▊ | 344/391 [00:04<00:00, 89.28it/s] 90%|█████████ | 353/391 [00:04<00:00, 88.34it/s] 93%|█████████▎| 363/391 [00:04<00:00, 88.85it/s] 95%|█████████▌| 372/391 [00:04<00:00, 88.37it/s] 98%|█████████▊| 382/391 [00:04<00:00, 89.37it/s]100%|██████████| 391/391 [00:04<00:00, 88.37it/s]100%|██████████| 391/391 [00:04<00:00, 80.80it/s]
50000 images processed, 4.9336607456207275 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:29,  2.68it/s]  9%|▉         | 7/79 [00:00<00:03, 18.54it/s] 20%|██        | 16/79 [00:00<00:01, 37.66it/s] 32%|███▏      | 25/79 [00:00<00:01, 50.89it/s] 44%|████▍     | 35/79 [00:00<00:00, 63.15it/s] 56%|█████▌    | 44/79 [00:00<00:00, 69.06it/s] 66%|██████▌   | 52/79 [00:01<00:00, 71.77it/s] 78%|███████▊  | 62/79 [00:01<00:00, 77.95it/s] 91%|█████████ | 72/79 [00:01<00:00, 82.00it/s]100%|██████████| 79/79 [00:01<00:00, 60.15it/s]
10000 images processed, 1.3377318382263184 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:24,  2.41it/s]  4%|▍         | 9/204 [00:00<00:08, 22.23it/s]  8%|▊         | 17/204 [00:00<00:04, 37.53it/s] 13%|█▎        | 26/204 [00:00<00:03, 50.87it/s] 17%|█▋        | 35/204 [00:00<00:02, 60.74it/s] 22%|██▏       | 44/204 [00:00<00:02, 67.40it/s] 26%|██▋       | 54/204 [00:01<00:02, 74.29it/s] 31%|███       | 63/204 [00:01<00:01, 76.69it/s] 35%|███▌      | 72/204 [00:01<00:01, 77.66it/s] 40%|███▉      | 81/204 [00:01<00:01, 79.64it/s] 44%|████▍     | 90/204 [00:01<00:01, 80.09it/s] 49%|████▊     | 99/204 [00:01<00:01, 80.75it/s] 53%|█████▎    | 108/204 [00:01<00:01, 80.38it/s] 57%|█████▋    | 117/204 [00:01<00:01, 80.00it/s] 62%|██████▏   | 126/204 [00:01<00:00, 81.98it/s] 66%|██████▌   | 135/204 [00:02<00:00, 82.96it/s] 71%|███████   | 144/204 [00:02<00:00, 83.42it/s] 75%|███████▌  | 153/204 [00:02<00:00, 85.02it/s] 79%|███████▉  | 162/204 [00:02<00:00, 83.58it/s] 84%|████████▍ | 171/204 [00:02<00:00, 85.01it/s] 88%|████████▊ | 180/204 [00:02<00:00, 85.06it/s] 93%|█████████▎| 190/204 [00:02<00:00, 87.04it/s] 98%|█████████▊| 200/204 [00:02<00:00, 89.67it/s]100%|██████████| 204/204 [00:02<00:00, 72.23it/s]
26032 images processed, 2.8758389949798584 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.76it/s] 11%|█▏        | 9/79 [00:00<00:04, 14.73it/s] 22%|██▏       | 17/79 [00:00<00:02, 22.99it/s] 32%|███▏      | 25/79 [00:01<00:01, 29.62it/s] 42%|████▏     | 33/79 [00:01<00:01, 34.60it/s] 52%|█████▏    | 41/79 [00:01<00:00, 38.18it/s] 62%|██████▏   | 49/79 [00:01<00:00, 40.63it/s] 72%|███████▏  | 57/79 [00:01<00:00, 41.76it/s] 82%|████████▏ | 65/79 [00:01<00:00, 43.18it/s] 92%|█████████▏| 73/79 [00:02<00:00, 44.13it/s]100%|██████████| 79/79 [00:02<00:00, 35.45it/s]
10000 images processed, 2.2620344161987305 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:35,  2.17it/s] 13%|█▎        | 10/79 [00:00<00:03, 22.81it/s] 24%|██▍       | 19/79 [00:00<00:01, 38.93it/s] 34%|███▍      | 27/79 [00:00<00:01, 48.69it/s] 44%|████▍     | 35/79 [00:00<00:00, 56.62it/s] 57%|█████▋    | 45/79 [00:00<00:00, 67.19it/s] 68%|██████▊   | 54/79 [00:01<00:00, 72.85it/s] 80%|███████▉  | 63/79 [00:01<00:00, 77.06it/s] 92%|█████████▏| 73/79 [00:01<00:00, 82.65it/s]100%|██████████| 79/79 [00:01<00:00, 58.29it/s]
10000 images processed, 1.378164291381836 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:38,  1.79it/s] 13%|█▎        | 9/70 [00:00<00:03, 17.69it/s] 26%|██▌       | 18/70 [00:00<00:01, 33.49it/s] 39%|███▊      | 27/70 [00:00<00:00, 46.41it/s] 51%|█████▏    | 36/70 [00:00<00:00, 57.02it/s] 66%|██████▌   | 46/70 [00:01<00:00, 67.19it/s] 79%|███████▊  | 55/70 [00:01<00:00, 71.88it/s] 93%|█████████▎| 65/70 [00:01<00:00, 78.71it/s]100%|██████████| 70/70 [00:01<00:00, 51.78it/s]
8925 images processed, 1.3850815296173096 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:39,  1.10it/s]  4%|▍         | 2/45 [00:01<00:20,  2.05it/s] 20%|██        | 9/45 [00:01<00:03,  9.49it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.54it/s] 38%|███▊      | 17/45 [00:01<00:02, 12.16it/s] 42%|████▏     | 19/45 [00:02<00:02, 11.29it/s] 49%|████▉     | 22/45 [00:02<00:01, 13.26it/s] 56%|█████▌    | 25/45 [00:02<00:01, 13.74it/s] 60%|██████    | 27/45 [00:02<00:01, 12.47it/s] 67%|██████▋   | 30/45 [00:02<00:01, 12.74it/s] 73%|███████▎  | 33/45 [00:03<00:01, 11.35it/s] 78%|███████▊  | 35/45 [00:03<00:00, 11.41it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.68it/s] 96%|█████████▌| 43/45 [00:04<00:00, 10.70it/s]100%|██████████| 45/45 [00:04<00:00, 10.65it/s]
5640 images processed, 4.2450878620147705 seconds used

20.22298002243042
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.51  99.36
places365     67.81  81.18
LSUN          17.51  96.07
iSUN          72.31  81.67
dtd           37.78  91.39
AVG           39.59  89.93
Retain-Acc: 0.7407
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.40 AUROC: 86.90 AUIN: 98.36
28.08166193962097
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep4_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep4_rf.png
==== Epoch 5/5: train 1 epoch, save adapter to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep5, then evaluate ====
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep5', adapter_load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4', forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep4
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:28<00:00, 28.57s/it]100%|██████████| 1/1 [00:28<00:00, 28.57s/it]
[loss] ep 0 it 0 total=7.8645 mle=1.5714 pcon=5.2950 forget=1.3745 favg=-0.3765 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=7.7724 mle=1.5427 pcon=5.2879 forget=1.4008 favg=-0.4590 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=7.9128 mle=1.6992 pcon=5.2808 forget=1.3730 favg=-0.4402 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=8.0759 mle=1.8996 pcon=5.2737 forget=1.3688 favg=-0.4663 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=7.9486 mle=1.7117 pcon=5.2669 forget=1.3816 favg=-0.4116 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=7.7016 mle=1.5022 pcon=5.2602 forget=1.3772 favg=-0.4380 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=7.8085 mle=1.5590 pcon=5.2539 forget=1.3810 favg=-0.3853 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=7.8398 mle=1.6807 pcon=5.2474 forget=1.3883 favg=-0.4766 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep5
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter-ep5
resnet34-top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep5: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:56,  2.21it/s]  3%|▎         | 10/391 [00:00<00:16, 22.96it/s]  5%|▍         | 19/391 [00:00<00:09, 39.39it/s]  7%|▋         | 28/391 [00:00<00:06, 52.12it/s]  9%|▉         | 37/391 [00:00<00:05, 61.58it/s] 12%|█▏        | 46/391 [00:00<00:05, 67.78it/s] 14%|█▍        | 55/391 [00:01<00:04, 72.12it/s] 16%|█▋        | 64/391 [00:01<00:04, 76.69it/s] 19%|█▊        | 73/391 [00:01<00:04, 79.33it/s] 21%|██        | 82/391 [00:01<00:03, 80.95it/s] 23%|██▎       | 91/391 [00:01<00:03, 80.74it/s] 26%|██▌       | 100/391 [00:01<00:03, 82.22it/s] 28%|██▊       | 109/391 [00:01<00:03, 83.69it/s] 30%|███       | 118/391 [00:01<00:03, 81.38it/s] 32%|███▏      | 127/391 [00:01<00:03, 81.04it/s] 35%|███▍      | 136/391 [00:02<00:03, 82.22it/s] 37%|███▋      | 145/391 [00:02<00:02, 84.05it/s] 39%|███▉      | 154/391 [00:02<00:02, 85.10it/s] 42%|████▏     | 164/391 [00:02<00:02, 87.17it/s] 44%|████▍     | 173/391 [00:02<00:02, 87.05it/s] 47%|████▋     | 183/391 [00:02<00:02, 87.50it/s] 49%|████▉     | 192/391 [00:02<00:02, 86.20it/s] 52%|█████▏    | 202/391 [00:02<00:02, 87.91it/s] 54%|█████▍    | 211/391 [00:02<00:02, 87.21it/s] 56%|█████▋    | 220/391 [00:03<00:02, 85.35it/s] 59%|█████▊    | 229/391 [00:03<00:01, 86.65it/s] 61%|██████    | 238/391 [00:03<00:01, 85.43it/s] 63%|██████▎   | 247/391 [00:03<00:01, 83.54it/s] 65%|██████▌   | 256/391 [00:03<00:01, 83.56it/s] 68%|██████▊   | 266/391 [00:03<00:01, 85.53it/s] 70%|███████   | 275/391 [00:03<00:01, 85.29it/s] 73%|███████▎  | 284/391 [00:03<00:01, 83.66it/s] 75%|███████▍  | 293/391 [00:03<00:01, 84.48it/s] 77%|███████▋  | 302/391 [00:03<00:01, 83.87it/s] 80%|███████▉  | 311/391 [00:04<00:00, 85.30it/s] 82%|████████▏ | 321/391 [00:04<00:00, 87.56it/s] 84%|████████▍ | 330/391 [00:04<00:00, 87.58it/s] 87%|████████▋ | 339/391 [00:04<00:00, 87.21it/s] 89%|████████▉ | 349/391 [00:04<00:00, 89.04it/s] 92%|█████████▏| 358/391 [00:04<00:00, 86.93it/s] 94%|█████████▍| 368/391 [00:04<00:00, 88.65it/s] 97%|█████████▋| 378/391 [00:04<00:00, 90.34it/s] 99%|█████████▉| 388/391 [00:04<00:00, 92.26it/s]100%|██████████| 391/391 [00:04<00:00, 78.39it/s]
50000 images processed, 5.074681997299194 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:35,  2.17it/s] 13%|█▎        | 10/79 [00:00<00:03, 22.68it/s] 25%|██▌       | 20/79 [00:00<00:01, 36.38it/s] 35%|███▌      | 28/79 [00:00<00:01, 46.21it/s] 48%|████▊     | 38/79 [00:00<00:00, 58.28it/s] 61%|██████    | 48/79 [00:01<00:00, 67.28it/s] 72%|███████▏  | 57/79 [00:01<00:00, 73.23it/s] 84%|████████▎ | 66/79 [00:01<00:00, 77.18it/s] 96%|█████████▌| 76/79 [00:01<00:00, 82.69it/s]100%|██████████| 79/79 [00:01<00:00, 56.44it/s]
10000 images processed, 1.423811912536621 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:30,  2.23it/s]  5%|▍         | 10/204 [00:00<00:08, 23.18it/s]  9%|▉         | 19/204 [00:00<00:04, 39.64it/s] 14%|█▎        | 28/204 [00:00<00:03, 51.75it/s] 18%|█▊        | 37/204 [00:00<00:02, 61.06it/s] 23%|██▎       | 46/204 [00:00<00:02, 68.34it/s] 27%|██▋       | 55/204 [00:01<00:02, 72.76it/s] 31%|███▏      | 64/204 [00:01<00:01, 74.04it/s] 36%|███▌      | 73/204 [00:01<00:01, 77.82it/s] 40%|████      | 82/204 [00:01<00:01, 79.31it/s] 45%|████▍     | 91/204 [00:01<00:01, 80.09it/s] 49%|████▉     | 100/204 [00:01<00:01, 82.37it/s] 53%|█████▎    | 109/204 [00:01<00:01, 84.28it/s] 58%|█████▊    | 119/204 [00:01<00:00, 86.46it/s] 63%|██████▎   | 128/204 [00:01<00:00, 86.08it/s] 67%|██████▋   | 137/204 [00:02<00:00, 84.88it/s] 72%|███████▏  | 146/204 [00:02<00:00, 82.72it/s] 76%|███████▌  | 155/204 [00:02<00:00, 83.20it/s] 80%|████████  | 164/204 [00:02<00:00, 83.17it/s] 85%|████████▍ | 173/204 [00:02<00:00, 82.98it/s] 89%|████████▉ | 182/204 [00:02<00:00, 81.95it/s] 94%|█████████▍| 192/204 [00:02<00:00, 85.60it/s] 99%|█████████▉| 202/204 [00:02<00:00, 87.54it/s]100%|██████████| 204/204 [00:02<00:00, 71.70it/s]
26032 images processed, 2.8915789127349854 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:51,  1.53it/s] 11%|█▏        | 9/79 [00:00<00:04, 14.05it/s] 22%|██▏       | 17/79 [00:00<00:02, 23.27it/s] 29%|██▉       | 23/79 [00:01<00:01, 29.80it/s] 35%|███▌      | 28/79 [00:01<00:01, 31.85it/s] 42%|████▏     | 33/79 [00:01<00:01, 30.24it/s] 52%|█████▏    | 41/79 [00:01<00:01, 33.25it/s] 62%|██████▏   | 49/79 [00:01<00:00, 35.48it/s] 72%|███████▏  | 57/79 [00:02<00:00, 36.50it/s] 82%|████████▏ | 65/79 [00:02<00:00, 37.33it/s] 92%|█████████▏| 73/79 [00:02<00:00, 38.22it/s]100%|██████████| 79/79 [00:02<00:00, 31.78it/s]
10000 images processed, 2.521717071533203 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:31,  2.44it/s] 10%|█         | 8/79 [00:00<00:03, 19.71it/s] 22%|██▏       | 17/79 [00:00<00:01, 37.86it/s] 33%|███▎      | 26/79 [00:00<00:01, 51.77it/s] 44%|████▍     | 35/79 [00:00<00:00, 60.35it/s] 56%|█████▌    | 44/79 [00:00<00:00, 67.22it/s] 67%|██████▋   | 53/79 [00:01<00:00, 73.50it/s] 78%|███████▊  | 62/79 [00:01<00:00, 77.74it/s] 91%|█████████ | 72/79 [00:01<00:00, 83.13it/s]100%|██████████| 79/79 [00:01<00:00, 59.86it/s]
10000 images processed, 1.3410606384277344 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:34,  2.00it/s] 11%|█▏        | 8/70 [00:00<00:03, 16.87it/s] 26%|██▌       | 18/70 [00:00<00:01, 35.94it/s] 39%|███▊      | 27/70 [00:00<00:00, 49.37it/s] 51%|█████▏    | 36/70 [00:00<00:00, 59.34it/s] 64%|██████▍   | 45/70 [00:01<00:00, 67.39it/s] 79%|███████▊  | 55/70 [00:01<00:00, 74.83it/s] 93%|█████████▎| 65/70 [00:01<00:00, 80.89it/s]100%|██████████| 70/70 [00:01<00:00, 54.16it/s]
8925 images processed, 1.3297119140625 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:50,  1.14s/it] 18%|█▊        | 8/45 [00:01<00:04,  8.54it/s] 27%|██▋       | 12/45 [00:01<00:03,  8.57it/s] 33%|███▎      | 15/45 [00:02<00:03,  8.46it/s] 38%|███▊      | 17/45 [00:02<00:03,  7.98it/s] 49%|████▉     | 22/45 [00:02<00:02,  9.57it/s] 56%|█████▌    | 25/45 [00:03<00:01, 10.13it/s] 67%|██████▋   | 30/45 [00:03<00:01, 10.37it/s] 73%|███████▎  | 33/45 [00:03<00:01,  9.39it/s] 91%|█████████ | 41/45 [00:04<00:00, 11.35it/s]100%|██████████| 45/45 [00:04<00:00, 10.02it/s]
5640 images processed, 4.514906167984009 seconds used

21.03343415260315
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.51  99.36
places365     67.80  81.18
LSUN          17.51  96.07
iSUN          72.32  81.67
dtd           37.78  91.39
AVG           39.59  89.93
Retain-Acc: 0.7408
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.40 AUROC: 86.90 AUIN: 98.36
25.934570789337158
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep5_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e5-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-ep5_rf.png
