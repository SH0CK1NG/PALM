nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=5, batch_size=128, lr=0.001, weight_decay=1e-06, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/5 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:503: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:591: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 20%|██        | 1/5 [01:00<04:03, 60.97s/it] 40%|████      | 2/5 [01:45<02:33, 51.12s/it] 60%|██████    | 3/5 [02:17<01:25, 42.61s/it] 80%|████████  | 4/5 [02:48<00:38, 38.07s/it]100%|██████████| 5/5 [03:18<00:00, 35.13s/it]100%|██████████| 5/5 [03:18<00:00, 39.74s/it]
[loss-randlabel] ep 0 it 0 total=2.1745 ce_r=0.2464 ce_f=9.6406
[loss-randlabel] ep 0 it 50 total=2.1398 ce_r=0.2095 ce_f=9.6514
[loss-randlabel] ep 0 it 100 total=2.1678 ce_r=0.2424 ce_f=9.6271
[loss-randlabel] ep 0 it 150 total=2.1911 ce_r=0.3001 ce_f=9.4548
[loss-randlabel] ep 0 it 200 total=2.0155 ce_r=0.1289 ce_f=9.4331
[loss-randlabel] ep 0 it 250 total=2.0603 ce_r=0.1473 ce_f=9.5648
[loss-randlabel] ep 0 it 300 total=2.0498 ce_r=0.1824 ce_f=9.3371
[loss-randlabel] ep 0 it 350 total=1.9976 ce_r=0.1412 ce_f=9.2818
[loss-randlabel] ep 1 it 10 total=1.9036 ce_r=0.1919 ce_f=8.5584
[loss-randlabel] ep 1 it 60 total=1.9031 ce_r=0.0958 ce_f=9.0366
[loss-randlabel] ep 1 it 110 total=1.9599 ce_r=0.2252 ce_f=8.6735
[loss-randlabel] ep 1 it 160 total=1.7495 ce_r=0.1280 ce_f=8.1077
[loss-randlabel] ep 1 it 210 total=1.7528 ce_r=0.1399 ce_f=8.0643
[loss-randlabel] ep 1 it 260 total=1.7855 ce_r=0.1496 ce_f=8.1793
[loss-randlabel] ep 1 it 310 total=1.7123 ce_r=0.1656 ce_f=7.7338
[loss-randlabel] ep 1 it 360 total=1.7518 ce_r=0.2047 ce_f=7.7355
[loss-randlabel] ep 2 it 20 total=1.7938 ce_r=0.3074 ce_f=7.4321
[loss-randlabel] ep 2 it 70 total=1.7243 ce_r=0.1635 ce_f=7.8043
[loss-randlabel] ep 2 it 120 total=1.6504 ce_r=0.2210 ce_f=7.1466
[loss-randlabel] ep 2 it 170 total=1.7493 ce_r=0.3165 ce_f=7.1636
[loss-randlabel] ep 2 it 220 total=1.6057 ce_r=0.2128 ce_f=6.9649
[loss-randlabel] ep 2 it 270 total=1.7855 ce_r=0.3257 ce_f=7.2988
[loss-randlabel] ep 2 it 320 total=1.7443 ce_r=0.3198 ce_f=7.1225
[loss-randlabel] ep 2 it 370 total=1.6444 ce_r=0.2445 ce_f=6.9996
[loss-randlabel] ep 3 it 30 total=1.7106 ce_r=0.3085 ce_f=7.0103
[loss-randlabel] ep 3 it 80 total=1.6054 ce_r=0.1571 ce_f=7.2417
[loss-randlabel] ep 3 it 130 total=1.6656 ce_r=0.1523 ce_f=7.5663
[loss-randlabel] ep 3 it 180 total=1.6289 ce_r=0.1727 ce_f=7.2808
[loss-randlabel] ep 3 it 230 total=1.6144 ce_r=0.1806 ce_f=7.1685
[loss-randlabel] ep 3 it 280 total=1.5584 ce_r=0.1590 ce_f=6.9971
[loss-randlabel] ep 3 it 330 total=1.6726 ce_r=0.2741 ce_f=6.9926
[loss-randlabel] ep 3 it 380 total=1.5740 ce_r=0.2266 ce_f=6.7368
[loss-randlabel] ep 4 it 40 total=1.6624 ce_r=0.2328 ce_f=7.1479
[loss-randlabel] ep 4 it 90 total=1.6964 ce_r=0.3411 ce_f=6.7766
[loss-randlabel] ep 4 it 140 total=1.5819 ce_r=0.2135 ce_f=6.8418
[loss-randlabel] ep 4 it 190 total=1.6002 ce_r=0.2442 ce_f=6.7797
[loss-randlabel] ep 4 it 240 total=1.6239 ce_r=0.2751 ce_f=6.7439
[loss-randlabel] ep 4 it 290 total=1.5860 ce_r=0.2100 ce_f=6.8797
[loss-randlabel] ep 4 it 340 total=1.6809 ce_r=0.2983 ce_f=6.9129
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-6-fl0.2: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:12,  2.02it/s]  3%|▎         | 11/391 [00:00<00:15, 23.98it/s]  6%|▌         | 22/391 [00:00<00:08, 43.86it/s]  8%|▊         | 33/391 [00:00<00:06, 59.11it/s] 11%|█         | 42/391 [00:00<00:05, 66.51it/s] 13%|█▎        | 51/391 [00:01<00:05, 66.99it/s] 16%|█▌        | 61/391 [00:01<00:04, 74.53it/s] 18%|█▊        | 71/391 [00:01<00:03, 80.13it/s] 21%|██        | 81/391 [00:01<00:03, 83.34it/s] 23%|██▎       | 91/391 [00:01<00:03, 86.09it/s] 26%|██▌       | 101/391 [00:01<00:03, 88.21it/s] 28%|██▊       | 111/391 [00:01<00:03, 74.98it/s] 31%|███       | 120/391 [00:01<00:03, 67.96it/s] 33%|███▎      | 129/391 [00:02<00:03, 71.43it/s] 36%|███▌      | 139/391 [00:02<00:03, 76.79it/s] 38%|███▊      | 149/391 [00:02<00:02, 81.21it/s] 41%|████      | 159/391 [00:02<00:02, 84.41it/s] 43%|████▎     | 169/391 [00:02<00:02, 86.42it/s] 46%|████▌     | 178/391 [00:02<00:02, 75.76it/s] 48%|████▊     | 186/391 [00:02<00:02, 70.54it/s] 50%|████▉     | 194/391 [00:02<00:02, 67.72it/s] 52%|█████▏    | 204/391 [00:03<00:02, 73.44it/s] 54%|█████▍    | 213/391 [00:03<00:02, 77.53it/s] 57%|█████▋    | 223/391 [00:03<00:02, 81.71it/s] 59%|█████▉    | 232/391 [00:03<00:01, 83.89it/s] 62%|██████▏   | 241/391 [00:03<00:02, 70.50it/s] 64%|██████▎   | 249/391 [00:03<00:02, 64.72it/s] 66%|██████▌   | 258/391 [00:03<00:01, 69.72it/s] 69%|██████▊   | 268/391 [00:03<00:01, 75.53it/s] 71%|███████   | 277/391 [00:03<00:01, 79.17it/s] 73%|███████▎  | 287/391 [00:04<00:01, 82.88it/s] 76%|███████▌  | 296/391 [00:04<00:01, 82.77it/s] 78%|███████▊  | 305/391 [00:04<00:01, 67.91it/s] 80%|████████  | 313/391 [00:04<00:01, 64.61it/s] 83%|████████▎ | 323/391 [00:04<00:00, 71.27it/s] 85%|████████▌ | 333/391 [00:04<00:00, 76.75it/s] 87%|████████▋ | 342/391 [00:04<00:00, 79.25it/s] 90%|████████▉ | 351/391 [00:04<00:00, 81.39it/s] 92%|█████████▏| 360/391 [00:05<00:00, 67.72it/s] 94%|█████████▍| 368/391 [00:05<00:00, 63.11it/s] 97%|█████████▋| 378/391 [00:05<00:00, 70.66it/s] 99%|█████████▉| 388/391 [00:05<00:00, 76.67it/s]100%|██████████| 391/391 [00:05<00:00, 70.80it/s]
50000 images processed, 5.6183953285217285 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:35,  2.19it/s]  8%|▊         | 6/79 [00:00<00:05, 13.37it/s] 15%|█▌        | 12/79 [00:00<00:02, 24.34it/s] 24%|██▍       | 19/79 [00:00<00:01, 35.57it/s] 35%|███▌      | 28/79 [00:00<00:01, 49.27it/s] 47%|████▋     | 37/79 [00:00<00:00, 59.44it/s] 57%|█████▋    | 45/79 [00:01<00:00, 62.41it/s] 66%|██████▌   | 52/79 [00:01<00:00, 57.04it/s] 75%|███████▍  | 59/79 [00:01<00:00, 56.16it/s] 87%|████████▋ | 69/79 [00:01<00:00, 65.78it/s]100%|██████████| 79/79 [00:01<00:00, 70.05it/s]100%|██████████| 79/79 [00:01<00:00, 48.74it/s]
10000 images processed, 1.6552503108978271 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-6-fl0.2/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:26,  1.39it/s]  3%|▎         | 7/204 [00:00<00:18, 10.82it/s]  6%|▌         | 12/204 [00:00<00:10, 17.65it/s]  8%|▊         | 17/204 [00:01<00:07, 24.18it/s] 13%|█▎        | 26/204 [00:01<00:04, 38.00it/s] 17%|█▋        | 35/204 [00:01<00:03, 50.00it/s] 22%|██▏       | 44/204 [00:01<00:02, 60.09it/s] 25%|██▌       | 52/204 [00:01<00:02, 56.63it/s] 29%|██▉       | 59/204 [00:01<00:02, 55.40it/s] 32%|███▏      | 66/204 [00:01<00:02, 56.80it/s] 37%|███▋      | 76/204 [00:01<00:01, 65.95it/s] 42%|████▏     | 86/204 [00:01<00:01, 72.90it/s] 47%|████▋     | 96/204 [00:02<00:01, 76.17it/s] 51%|█████     | 104/204 [00:02<00:01, 63.22it/s] 54%|█████▍    | 111/204 [00:02<00:01, 60.06it/s] 59%|█████▉    | 121/204 [00:02<00:01, 68.02it/s] 64%|██████▎   | 130/204 [00:02<00:01, 73.49it/s] 69%|██████▊   | 140/204 [00:02<00:00, 78.47it/s] 74%|███████▎  | 150/204 [00:02<00:00, 82.09it/s] 78%|███████▊  | 159/204 [00:03<00:00, 68.01it/s] 82%|████████▏ | 167/204 [00:03<00:00, 62.54it/s] 87%|████████▋ | 177/204 [00:03<00:00, 69.63it/s] 92%|█████████▏| 187/204 [00:03<00:00, 75.59it/s] 96%|█████████▌| 196/204 [00:03<00:00, 79.23it/s]100%|██████████| 204/204 [00:03<00:00, 56.47it/s]
26032 images processed, 3.6683480739593506 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:52,  1.50it/s]  9%|▉         | 7/79 [00:00<00:06, 11.78it/s] 15%|█▌        | 12/79 [00:00<00:03, 18.80it/s] 23%|██▎       | 18/79 [00:00<00:02, 27.41it/s] 32%|███▏      | 25/79 [00:01<00:01, 36.74it/s] 44%|████▍     | 35/79 [00:01<00:00, 51.09it/s] 57%|█████▋    | 45/79 [00:01<00:00, 61.68it/s] 70%|██████▉   | 55/79 [00:01<00:00, 69.94it/s] 81%|████████  | 64/79 [00:01<00:00, 72.74it/s] 91%|█████████ | 72/79 [00:01<00:00, 61.99it/s]100%|██████████| 79/79 [00:01<00:00, 61.25it/s]100%|██████████| 79/79 [00:01<00:00, 42.94it/s]
10000 images processed, 1.863945484161377 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:46,  1.67it/s]  6%|▋         | 5/79 [00:00<00:08,  9.00it/s] 15%|█▌        | 12/79 [00:00<00:03, 21.09it/s] 27%|██▋       | 21/79 [00:00<00:01, 35.99it/s] 38%|███▊      | 30/79 [00:01<00:01, 47.76it/s] 48%|████▊     | 38/79 [00:01<00:00, 54.48it/s] 57%|█████▋    | 45/79 [00:01<00:00, 50.25it/s] 65%|██████▍   | 51/79 [00:01<00:00, 49.86it/s] 76%|███████▌  | 60/79 [00:01<00:00, 58.83it/s] 89%|████████▊ | 70/79 [00:01<00:00, 67.89it/s]100%|██████████| 79/79 [00:01<00:00, 45.26it/s]
10000 images processed, 1.7666833400726318 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:47,  1.46it/s]  9%|▊         | 6/70 [00:00<00:06,  9.65it/s] 21%|██▏       | 15/70 [00:00<00:02, 24.80it/s] 33%|███▎      | 23/70 [00:01<00:01, 36.39it/s] 46%|████▌     | 32/70 [00:01<00:00, 46.93it/s] 56%|█████▌    | 39/70 [00:01<00:00, 44.91it/s] 64%|██████▍   | 45/70 [00:01<00:00, 47.78it/s] 77%|███████▋  | 54/70 [00:01<00:00, 57.01it/s] 91%|█████████▏| 64/70 [00:01<00:00, 66.52it/s]100%|██████████| 70/70 [00:01<00:00, 41.51it/s]
8925 images processed, 1.7148642539978027 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:51,  1.17s/it]  9%|▉         | 4/45 [00:01<00:10,  4.01it/s] 18%|█▊        | 8/45 [00:01<00:04,  8.84it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.23it/s] 47%|████▋     | 21/45 [00:01<00:01, 18.46it/s] 56%|█████▌    | 25/45 [00:02<00:01, 19.53it/s] 69%|██████▉   | 31/45 [00:02<00:00, 26.45it/s] 78%|███████▊  | 35/45 [00:02<00:00, 21.07it/s] 98%|█████████▊| 44/45 [00:02<00:00, 32.63it/s]100%|██████████| 45/45 [00:02<00:00, 15.20it/s]
5640 images processed, 2.9849746227264404 seconds used

21.022186517715454
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.09  99.21
places365     72.82  78.76
LSUN          26.26  94.46
iSUN          68.66  84.08
dtd           44.77  88.45
AVG           43.12  88.99
Retain-Acc: 0.7369
Forget-as-OOD (retain known vs forget novel):
  FPR: 45.20 AUROC: 90.84 AUIN: 98.82
25.369680166244507
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-6-fl0.2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e5-lr0.001-wd1e-6-fl0.2_rf.png
