nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter', adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:14<11:31, 14.11s/it]  4%|▍         | 2/50 [00:23<09:03, 11.33s/it]  6%|▌         | 3/50 [00:32<08:10, 10.45s/it]  8%|▊         | 4/50 [00:43<08:00, 10.45s/it] 10%|█         | 5/50 [00:53<07:38, 10.20s/it] 12%|█▏        | 6/50 [01:03<07:24, 10.11s/it] 14%|█▍        | 7/50 [01:13<07:23, 10.31s/it][loss] ep 0 it 0 total=9.2609 mle=1.5804 pcon=5.2951 forget=2.3854 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 0 it 50 total=9.1361 mle=1.4911 pcon=5.2914 forget=2.3537 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 0 it 100 total=9.3082 mle=1.6391 pcon=5.2875 forget=2.3816 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 0 it 150 total=9.4497 mle=1.8131 pcon=5.2841 forget=2.3525 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 0 it 200 total=9.4173 mle=1.8135 pcon=5.2802 forget=2.3237 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 0 it 250 total=9.1013 mle=1.4459 pcon=5.2762 forget=2.3792 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 0 it 300 total=9.1334 mle=1.4832 pcon=5.2727 forget=2.3775 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 0 it 350 total=9.2041 mle=1.4992 pcon=5.2693 forget=2.4356 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 1 it 10 total=9.3431 mle=1.7195 pcon=5.2657 forget=2.3580 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 1 it 60 total=9.0097 mle=1.2957 pcon=5.2618 forget=2.4522 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 1 it 110 total=9.0657 mle=1.4150 pcon=5.2582 forget=2.3925 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 1 it 160 total=8.8546 mle=1.1729 pcon=5.2546 forget=2.4271 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 1 it 210 total=9.2263 mle=1.5842 pcon=5.2510 forget=2.3911 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 1 it 260 total=9.2180 mle=1.5956 pcon=5.2476 forget=2.3748 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 1 it 310 total=9.2164 mle=1.6190 pcon=5.2442 forget=2.3532 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 1 it 360 total=9.2267 mle=1.6113 pcon=5.2408 forget=2.3747 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 2 it 20 total=9.1307 mle=1.5311 pcon=5.2373 forget=2.3623 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 2 it 70 total=9.0184 mle=1.3546 pcon=5.2343 forget=2.4294 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 2 it 120 total=9.0142 mle=1.4288 pcon=5.2312 forget=2.3542 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 2 it 170 total=9.2492 mle=1.6418 pcon=5.2280 forget=2.3795 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 2 it 220 total=8.9893 mle=1.3786 pcon=5.2247 forget=2.3860 favg=0.0000 nr=128 nf=89 protos=600 fproto_sim=NA
[loss] ep 2 it 270 total=9.3291 mle=1.7264 pcon=5.2215 forget=2.3813 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 2 it 320 total=9.0047 mle=1.4101 pcon=5.2186 forget=2.3760 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 2 it 370 total=9.0195 mle=1.4127 pcon=5.2158 forget=2.3910 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 3 it 30 total=9.1784 mle=1.5895 pcon=5.2128 forget=2.3761 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 3 it 80 total=8.9799 mle=1.3902 pcon=5.2098 forget=2.3799 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 3 it 130 total=9.0625 mle=1.4646 pcon=5.2067 forget=2.3912 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 3 it 180 total=9.0829 mle=1.5148 pcon=5.2038 forget=2.3643 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 3 it 230 total=9.0024 mle=1.3875 pcon=5.2008 forget=2.4141 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 3 it 280 total=9.2098 mle=1.5827 pcon=5.1977 forget=2.4294 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 3 it 330 total=9.0820 mle=1.5270 pcon=5.1946 forget=2.3603 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 3 it 380 total=8.9806 mle=1.3898 pcon=5.1917 forget=2.3991 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 4 it 40 total=9.2927 mle=1.7809 pcon=5.1889 forget=2.3229 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 4 it 90 total=8.9412 mle=1.3268 pcon=5.1861 forget=2.4283 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 4 it 140 total=9.4904 mle=1.9414 pcon=5.1834 forget=2.3656 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 4 it 190 total=9.0718 mle=1.4839 pcon=5.1805 forget=2.4074 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 4 it 240 total=8.9741 mle=1.3889 pcon=5.1778 forget=2.4074 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 4 it 290 total=8.7671 mle=1.1694 pcon=5.1751 forget=2.4226 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 4 it 340 total=9.1431 mle=1.5753 pcon=5.1725 forget=2.3953 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 5 it 0 total=8.7171 mle=1.1161 pcon=5.1698 forget=2.4312 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 5 it 50 total=9.0182 mle=1.4544 pcon=5.1670 forget=2.3968 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 5 it 100 total=9.1199 mle=1.5172 pcon=5.1645 forget=2.4382 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 5 it 150 total=9.0127 mle=1.4415 pcon=5.1620 forget=2.4091 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 5 it 200 total=9.0499 mle=1.4966 pcon=5.1593 forget=2.3940 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 5 it 250 total=8.8982 mle=1.3476 pcon=5.1569 forget=2.3936 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 5 it 300 total=9.0317 mle=1.5203 pcon=5.1546 forget=2.3568 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 5 it 350 total=9.0420 mle=1.5104 pcon=5.1520 forget=2.3796 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 6 it 10 total=8.8372 mle=1.2331 pcon=5.1497 forget=2.4544 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 6 it 60 total=8.8833 mle=1.3234 pcon=5.1474 forget=2.4125 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 6 it 110 total=8.7691 mle=1.2237 pcon=5.1451 forget=2.4004 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 6 it 160 total=8.8553 mle=1.3155 pcon=5.1427 forget=2.3971 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 6 it 210 total=9.0919 mle=1.5845 pcon=5.1403 forget=2.3671 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 6 it 260 total=8.8389 mle=1.2672 pcon=5.1382 forget=2.4335 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 6 it 310 total=8.9731 mle=1.4603 pcon=5.1361 forget=2.3767 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 6 it 360 total=8.9217 mle=1.4077 pcon=5.1337 forget=2.3803 favg=0.0000 nr=128 nf=89 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 7 it 20 total=8.8089 mle=1.2814 pcon=5.1316 forget=2.3958 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 7 it 70 total=8.7158 mle=1.2060 pcon=5.1293 forget=2.3806 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 7 it 120 total=8.9481 mle=1.4381 pcon=5.1270 forget=2.3830 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 7 it 170 total=9.0647 mle=1.6106 pcon=5.1247 forget=2.3293 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
 16%|█▌        | 8/50 [01:23<07:07, 10.17s/it] 18%|█▊        | 9/50 [01:33<06:50, 10.00s/it] 20%|██        | 10/50 [01:43<06:43, 10.08s/it] 22%|██▏       | 11/50 [01:53<06:28,  9.97s/it] 24%|██▍       | 12/50 [02:03<06:26, 10.16s/it] 26%|██▌       | 13/50 [02:13<06:10, 10.03s/it] 28%|██▊       | 14/50 [02:23<06:04, 10.13s/it] 30%|███       | 15/50 [02:34<05:57, 10.21s/it][loss] ep 7 it 220 total=8.8317 mle=1.3258 pcon=5.1225 forget=2.3835 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 7 it 270 total=8.9420 mle=1.4416 pcon=5.1206 forget=2.3798 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 7 it 320 total=8.8431 mle=1.3321 pcon=5.1186 forget=2.3924 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 7 it 370 total=8.8568 mle=1.2991 pcon=5.1166 forget=2.4411 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 8 it 30 total=8.8356 mle=1.3559 pcon=5.1148 forget=2.3649 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 8 it 80 total=8.7776 mle=1.2522 pcon=5.1128 forget=2.4126 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 8 it 130 total=8.9653 mle=1.4892 pcon=5.1109 forget=2.3651 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 8 it 180 total=8.7389 mle=1.2562 pcon=5.1091 forget=2.3735 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 8 it 230 total=8.8129 mle=1.2923 pcon=5.1074 forget=2.4132 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 8 it 280 total=8.7337 mle=1.2457 pcon=5.1056 forget=2.3824 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 8 it 330 total=9.0294 mle=1.6253 pcon=5.1035 forget=2.3006 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 8 it 380 total=8.7840 mle=1.2895 pcon=5.1019 forget=2.3925 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 9 it 40 total=8.7319 mle=1.2897 pcon=5.1002 forget=2.3420 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 9 it 90 total=8.8442 mle=1.4393 pcon=5.0983 forget=2.3065 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 9 it 140 total=8.6402 mle=1.1622 pcon=5.0967 forget=2.3812 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 9 it 190 total=8.5975 mle=1.1624 pcon=5.0949 forget=2.3402 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 9 it 240 total=9.0002 mle=1.6279 pcon=5.0932 forget=2.2791 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 9 it 290 total=8.6966 mle=1.3259 pcon=5.0911 forget=2.2796 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 9 it 340 total=8.5876 mle=1.2746 pcon=5.0891 forget=2.2239 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 10 it 0 total=8.6629 mle=1.4460 pcon=5.0867 forget=2.1302 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 10 it 50 total=8.4513 mle=1.2752 pcon=5.0850 forget=2.0911 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 10 it 100 total=8.5272 mle=1.3928 pcon=5.0830 forget=2.0513 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 10 it 150 total=8.6091 mle=1.4588 pcon=5.0813 forget=2.0691 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 10 it 200 total=8.6377 mle=1.4892 pcon=5.0798 forget=2.0686 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 10 it 250 total=8.7811 mle=1.6209 pcon=5.0787 forget=2.0815 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 10 it 300 total=8.7943 mle=1.6812 pcon=5.0774 forget=2.0356 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 10 it 350 total=8.5985 mle=1.3901 pcon=5.0762 forget=2.1321 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 11 it 10 total=8.6932 mle=1.4632 pcon=5.0750 forget=2.1549 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 11 it 60 total=8.7331 mle=1.5440 pcon=5.0741 forget=2.1150 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 11 it 110 total=8.6922 mle=1.4670 pcon=5.0733 forget=2.1518 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 11 it 160 total=8.6233 mle=1.3823 pcon=5.0725 forget=2.1685 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 11 it 210 total=8.6236 mle=1.3741 pcon=5.0715 forget=2.1781 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 11 it 260 total=8.5437 mle=1.3497 pcon=5.0707 forget=2.1233 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 11 it 310 total=8.6004 mle=1.4281 pcon=5.0701 forget=2.1022 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 11 it 360 total=8.5587 mle=1.3905 pcon=5.0696 forget=2.0986 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 12 it 20 total=8.5601 mle=1.4724 pcon=5.0692 forget=2.0184 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 12 it 70 total=8.6860 mle=1.6045 pcon=5.0690 forget=2.0125 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 12 it 120 total=8.5141 mle=1.4981 pcon=5.0688 forget=1.9472 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 12 it 170 total=8.5201 mle=1.4795 pcon=5.0686 forget=1.9720 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 12 it 220 total=8.4531 mle=1.4337 pcon=5.0685 forget=1.9509 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 12 it 270 total=8.4718 mle=1.4853 pcon=5.0683 forget=1.9181 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 12 it 320 total=8.5052 mle=1.5331 pcon=5.0684 forget=1.9036 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 12 it 370 total=8.5536 mle=1.5665 pcon=5.0683 forget=1.9187 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 13 it 30 total=8.4560 mle=1.4869 pcon=5.0686 forget=1.9005 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 13 it 80 total=8.5332 mle=1.6137 pcon=5.0686 forget=1.8509 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 13 it 130 total=8.4789 mle=1.5492 pcon=5.0686 forget=1.8610 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 13 it 180 total=8.4630 mle=1.5210 pcon=5.0683 forget=1.8736 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 13 it 230 total=8.4011 mle=1.4698 pcon=5.0683 forget=1.8629 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 13 it 280 total=8.3332 mle=1.3874 pcon=5.0680 forget=1.8778 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 13 it 330 total=8.4532 mle=1.5374 pcon=5.0677 forget=1.8480 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 13 it 380 total=8.3276 mle=1.4330 pcon=5.0674 forget=1.8272 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 14 it 40 total=8.3697 mle=1.4723 pcon=5.0671 forget=1.8303 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 14 it 90 total=8.3865 mle=1.4819 pcon=5.0667 forget=1.8380 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 14 it 140 total=8.4087 mle=1.5224 pcon=5.0661 forget=1.8202 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 14 it 190 total=8.2641 mle=1.4076 pcon=5.0654 forget=1.7912 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 14 it 240 total=8.3661 mle=1.4777 pcon=5.0646 forget=1.8238 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 14 it 290 total=8.2263 mle=1.3963 pcon=5.0639 forget=1.7660 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 14 it 340 total=8.2897 mle=1.4484 pcon=5.0632 forget=1.7781 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
 32%|███▏      | 16/50 [02:44<05:45, 10.15s/it] 34%|███▍      | 17/50 [02:54<05:33, 10.11s/it] 36%|███▌      | 18/50 [03:04<05:25, 10.16s/it] 38%|███▊      | 19/50 [03:14<05:13, 10.10s/it] 40%|████      | 20/50 [03:24<04:59, 10.00s/it] 42%|████▏     | 21/50 [03:34<04:48,  9.94s/it] 44%|████▍     | 22/50 [03:44<04:42, 10.10s/it][loss] ep 15 it 0 total=8.2702 mle=1.4270 pcon=5.0622 forget=1.7810 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 50 total=8.2909 mle=1.4590 pcon=5.0613 forget=1.7705 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 15 it 100 total=8.2229 mle=1.4152 pcon=5.0605 forget=1.7471 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 15 it 150 total=8.2526 mle=1.4408 pcon=5.0595 forget=1.7522 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 15 it 200 total=8.1763 mle=1.3994 pcon=5.0583 forget=1.7186 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 250 total=8.2401 mle=1.4539 pcon=5.0571 forget=1.7292 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 15 it 300 total=8.2224 mle=1.4717 pcon=5.0558 forget=1.6949 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 350 total=8.2649 mle=1.4995 pcon=5.0544 forget=1.7110 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 16 it 10 total=8.2014 mle=1.4421 pcon=5.0531 forget=1.7062 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 16 it 60 total=8.1660 mle=1.4280 pcon=5.0514 forget=1.6865 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 16 it 110 total=8.0859 mle=1.3757 pcon=5.0496 forget=1.6606 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 16 it 160 total=8.1755 mle=1.4388 pcon=5.0481 forget=1.6886 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 16 it 210 total=8.1512 mle=1.3989 pcon=5.0462 forget=1.7061 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 16 it 260 total=8.2445 mle=1.5033 pcon=5.0443 forget=1.6969 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 16 it 310 total=8.2021 mle=1.5068 pcon=5.0423 forget=1.6531 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 16 it 360 total=8.1988 mle=1.4954 pcon=5.0403 forget=1.6632 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 17 it 20 total=8.2116 mle=1.5348 pcon=5.0384 forget=1.6384 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 17 it 70 total=8.1522 mle=1.4531 pcon=5.0365 forget=1.6626 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 17 it 120 total=8.1360 mle=1.4279 pcon=5.0343 forget=1.6738 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 17 it 170 total=8.0414 mle=1.3319 pcon=5.0320 forget=1.6776 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 17 it 220 total=8.0571 mle=1.3806 pcon=5.0298 forget=1.6466 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 17 it 270 total=8.1490 mle=1.4751 pcon=5.0274 forget=1.6464 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 17 it 320 total=8.0809 mle=1.4302 pcon=5.0251 forget=1.6255 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 17 it 370 total=8.0049 mle=1.3512 pcon=5.0226 forget=1.6311 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 18 it 30 total=8.0595 mle=1.3988 pcon=5.0199 forget=1.6408 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 18 it 80 total=8.1855 mle=1.5223 pcon=5.0173 forget=1.6459 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 18 it 130 total=8.0732 mle=1.3858 pcon=5.0148 forget=1.6726 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 18 it 180 total=7.9948 mle=1.3532 pcon=5.0121 forget=1.6296 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 230 total=8.1715 mle=1.4845 pcon=5.0093 forget=1.6777 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 280 total=8.1107 mle=1.4413 pcon=5.0065 forget=1.6629 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 330 total=8.0329 mle=1.3408 pcon=5.0040 forget=1.6881 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 18 it 380 total=8.0323 mle=1.3716 pcon=5.0014 forget=1.6593 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[loss] ep 19 it 40 total=8.1066 mle=1.4467 pcon=4.9987 forget=1.6612 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 90 total=8.1447 mle=1.4991 pcon=4.9961 forget=1.6495 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 19 it 140 total=8.0540 mle=1.3817 pcon=4.9937 forget=1.6786 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 190 total=8.1832 mle=1.5341 pcon=4.9913 forget=1.6578 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 19 it 240 total=8.0838 mle=1.3983 pcon=4.9888 forget=1.6967 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 290 total=8.1022 mle=1.4558 pcon=4.9867 forget=1.6597 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 19 it 340 total=8.0370 mle=1.3298 pcon=4.9847 forget=1.7225 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 20 it 0 total=8.0435 mle=1.3336 pcon=4.9826 forget=1.7274 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 20 it 50 total=8.1327 mle=1.4335 pcon=4.9805 forget=1.7187 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 20 it 100 total=8.0399 mle=1.3430 pcon=4.9782 forget=1.7187 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 20 it 150 total=8.1985 mle=1.4892 pcon=4.9760 forget=1.7332 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 20 it 200 total=8.1585 mle=1.4324 pcon=4.9742 forget=1.7519 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 20 it 250 total=8.1895 mle=1.4603 pcon=4.9726 forget=1.7566 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 20 it 300 total=8.1796 mle=1.4654 pcon=4.9708 forget=1.7435 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 20 it 350 total=8.2519 mle=1.5359 pcon=4.9692 forget=1.7467 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 10 total=8.0863 mle=1.3937 pcon=4.9677 forget=1.7249 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 21 it 60 total=8.1704 mle=1.4680 pcon=4.9664 forget=1.7360 favg=0.0000 nr=128 nf=89 protos=600 fproto_sim=NA
[loss] ep 21 it 110 total=8.2228 mle=1.5004 pcon=4.9649 forget=1.7576 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 160 total=8.2355 mle=1.5007 pcon=4.9635 forget=1.7713 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 210 total=8.0697 mle=1.3365 pcon=4.9620 forget=1.7712 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 21 it 260 total=8.2851 mle=1.5493 pcon=4.9609 forget=1.7749 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 21 it 310 total=8.2286 mle=1.4600 pcon=4.9598 forget=1.8087 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 21 it 360 total=8.2065 mle=1.4361 pcon=4.9591 forget=1.8113 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 22 it 20 total=8.1875 mle=1.4160 pcon=4.9584 forget=1.8130 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 22 it 70 total=8.2445 mle=1.4651 pcon=4.9575 forget=1.8220 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 22 it 120 total=8.2322 mle=1.4316 pcon=4.9570 forget=1.8437 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 22 it 170 total=8.1917 mle=1.4265 pcon=4.9565 forget=1.8088 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 22 it 220 total=8.2513 mle=1.4736 pcon=4.9561 forget=1.8215 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 22 it 270 total=8.2471 mle=1.4442 pcon=4.9557 forget=1.8472 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 22 it 320 total=8.1773 mle=1.4009 pcon=4.9555 forget=1.8209 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
 46%|████▌     | 23/50 [03:54<04:31, 10.07s/it] 48%|████▊     | 24/50 [04:04<04:20, 10.01s/it] 50%|█████     | 25/50 [04:14<04:12, 10.10s/it] 52%|█████▏    | 26/50 [04:25<04:03, 10.15s/it] 54%|█████▍    | 27/50 [04:35<03:53, 10.14s/it] 56%|█████▌    | 28/50 [04:45<03:43, 10.18s/it] 58%|█████▊    | 29/50 [04:54<03:29,  9.98s/it] 60%|██████    | 30/50 [05:05<03:22, 10.13s/it] 62%|██████▏   | 31/50 [05:15<03:12, 10.11s/it][loss] ep 22 it 370 total=8.3300 mle=1.5516 pcon=4.9551 forget=1.8233 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 23 it 30 total=8.1976 mle=1.4199 pcon=4.9549 forget=1.8228 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 23 it 80 total=8.2385 mle=1.4149 pcon=4.9547 forget=1.8688 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 23 it 130 total=8.2462 mle=1.4481 pcon=4.9546 forget=1.8435 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 23 it 180 total=8.3294 mle=1.5310 pcon=4.9542 forget=1.8441 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 23 it 230 total=8.3692 mle=1.5562 pcon=4.9539 forget=1.8591 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 280 total=8.3501 mle=1.5464 pcon=4.9538 forget=1.8499 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 330 total=8.2368 mle=1.4243 pcon=4.9535 forget=1.8590 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 380 total=8.3032 mle=1.4731 pcon=4.9535 forget=1.8766 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 24 it 40 total=8.1975 mle=1.4101 pcon=4.9535 forget=1.8340 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 24 it 90 total=8.3534 mle=1.5685 pcon=4.9535 forget=1.8314 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 24 it 140 total=8.2961 mle=1.4890 pcon=4.9534 forget=1.8538 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 24 it 190 total=8.2481 mle=1.4672 pcon=4.9532 forget=1.8276 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 24 it 240 total=8.2577 mle=1.4590 pcon=4.9533 forget=1.8455 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 24 it 290 total=8.1605 mle=1.3961 pcon=4.9533 forget=1.8111 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 24 it 340 total=8.2405 mle=1.4464 pcon=4.9529 forget=1.8411 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 25 it 0 total=8.2447 mle=1.4819 pcon=4.9528 forget=1.8100 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 25 it 50 total=8.2179 mle=1.4651 pcon=4.9525 forget=1.8003 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 25 it 100 total=8.2202 mle=1.4652 pcon=4.9522 forget=1.8028 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 25 it 150 total=8.2364 mle=1.4692 pcon=4.9520 forget=1.8153 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 25 it 200 total=8.2990 mle=1.5456 pcon=4.9517 forget=1.8018 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 25 it 250 total=8.1865 mle=1.4261 pcon=4.9514 forget=1.8089 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 25 it 300 total=8.2406 mle=1.4934 pcon=4.9508 forget=1.7964 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 25 it 350 total=8.1912 mle=1.4374 pcon=4.9502 forget=1.8035 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 26 it 10 total=8.1232 mle=1.3756 pcon=4.9493 forget=1.7983 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 26 it 60 total=8.2075 mle=1.4889 pcon=4.9485 forget=1.7702 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 26 it 110 total=8.1405 mle=1.4102 pcon=4.9479 forget=1.7824 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 26 it 160 total=8.0857 mle=1.3713 pcon=4.9469 forget=1.7676 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 26 it 210 total=8.1893 mle=1.4733 pcon=4.9460 forget=1.7700 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 26 it 260 total=8.1151 mle=1.4084 pcon=4.9452 forget=1.7615 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 26 it 310 total=8.2217 mle=1.5119 pcon=4.9442 forget=1.7655 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 26 it 360 total=8.1833 mle=1.4871 pcon=4.9432 forget=1.7530 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 27 it 20 total=8.0999 mle=1.3988 pcon=4.9421 forget=1.7589 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 27 it 70 total=8.1615 mle=1.4739 pcon=4.9410 forget=1.7465 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 120 total=8.1613 mle=1.4719 pcon=4.9398 forget=1.7497 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 170 total=8.1149 mle=1.4119 pcon=4.9385 forget=1.7645 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 220 total=8.0901 mle=1.3941 pcon=4.9372 forget=1.7588 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 270 total=8.1011 mle=1.3897 pcon=4.9357 forget=1.7757 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 320 total=8.1730 mle=1.4712 pcon=4.9343 forget=1.7675 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 370 total=8.0274 mle=1.3472 pcon=4.9327 forget=1.7475 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 30 total=8.1322 mle=1.4453 pcon=4.9311 forget=1.7558 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 28 it 80 total=8.2341 mle=1.5691 pcon=4.9293 forget=1.7357 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 28 it 130 total=8.0773 mle=1.4143 pcon=4.9277 forget=1.7353 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 180 total=7.9934 mle=1.3307 pcon=4.9259 forget=1.7368 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 28 it 230 total=8.1108 mle=1.4489 pcon=4.9240 forget=1.7379 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 280 total=8.1025 mle=1.4337 pcon=4.9222 forget=1.7466 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 28 it 330 total=8.1247 mle=1.4729 pcon=4.9203 forget=1.7314 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 28 it 380 total=8.0524 mle=1.3763 pcon=4.9183 forget=1.7578 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 29 it 40 total=8.0532 mle=1.3910 pcon=4.9163 forget=1.7459 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 29 it 90 total=8.1592 mle=1.4937 pcon=4.9142 forget=1.7513 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 29 it 140 total=8.0447 mle=1.3775 pcon=4.9123 forget=1.7548 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 29 it 190 total=8.2470 mle=1.5413 pcon=4.9103 forget=1.7954 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 29 it 240 total=8.1647 mle=1.4660 pcon=4.9082 forget=1.7905 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 29 it 290 total=8.1204 mle=1.4570 pcon=4.9061 forget=1.7573 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 29 it 340 total=8.1320 mle=1.4357 pcon=4.9041 forget=1.7922 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 30 it 0 total=8.1047 mle=1.4283 pcon=4.9021 forget=1.7744 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 30 it 50 total=8.0722 mle=1.3907 pcon=4.9002 forget=1.7814 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 30 it 100 total=8.1429 mle=1.4759 pcon=4.8982 forget=1.7688 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 30 it 150 total=8.1305 mle=1.4390 pcon=4.8962 forget=1.7953 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 30 it 200 total=8.1084 mle=1.4269 pcon=4.8942 forget=1.7873 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 30 it 250 total=8.1652 mle=1.4974 pcon=4.8925 forget=1.7753 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 30 it 300 total=8.0656 mle=1.3991 pcon=4.8904 forget=1.7761 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 30 it 350 total=8.0926 mle=1.3834 pcon=4.8886 forget=1.8206 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 31 it 10 total=8.1526 mle=1.4372 pcon=4.8867 forget=1.8287 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 31 it 60 total=8.1285 mle=1.4239 pcon=4.8851 forget=1.8196 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 31 it 110 total=8.1547 mle=1.4683 pcon=4.8834 forget=1.8030 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 31 it 160 total=8.2089 mle=1.4606 pcon=4.8817 forget=1.8666 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 31 it 210 total=8.1794 mle=1.4649 pcon=4.8801 forget=1.8344 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
 64%|██████▍   | 32/50 [05:25<03:02, 10.13s/it] 66%|██████▌   | 33/50 [05:36<02:54, 10.24s/it] 68%|██████▊   | 34/50 [05:46<02:43, 10.20s/it] 70%|███████   | 35/50 [05:56<02:33, 10.25s/it] 72%|███████▏  | 36/50 [06:06<02:21, 10.12s/it] 74%|███████▍  | 37/50 [06:16<02:10, 10.00s/it] 76%|███████▌  | 38/50 [06:26<02:00, 10.04s/it] 78%|███████▊  | 39/50 [06:35<01:48,  9.87s/it] 80%|████████  | 40/50 [06:46<01:39,  9.98s/it][loss] ep 31 it 260 total=8.2008 mle=1.4768 pcon=4.8787 forget=1.8453 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 31 it 310 total=8.1042 mle=1.3871 pcon=4.8771 forget=1.8400 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 31 it 360 total=8.2118 mle=1.4775 pcon=4.8759 forget=1.8585 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 20 total=8.2245 mle=1.4771 pcon=4.8747 forget=1.8727 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 32 it 70 total=8.1677 mle=1.4545 pcon=4.8734 forget=1.8398 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 32 it 120 total=8.1531 mle=1.3928 pcon=4.8721 forget=1.8881 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 170 total=8.2442 mle=1.5091 pcon=4.8708 forget=1.8642 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 32 it 220 total=8.1560 mle=1.4294 pcon=4.8697 forget=1.8569 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 270 total=8.1403 mle=1.3914 pcon=4.8687 forget=1.8803 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 32 it 320 total=8.2151 mle=1.4406 pcon=4.8676 forget=1.9069 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 370 total=8.1411 mle=1.3853 pcon=4.8670 forget=1.8887 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 33 it 30 total=8.2951 mle=1.5493 pcon=4.8661 forget=1.8797 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 33 it 80 total=8.1643 mle=1.3932 pcon=4.8653 forget=1.9058 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 33 it 130 total=8.1923 mle=1.4467 pcon=4.8646 forget=1.8810 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 33 it 180 total=8.2698 mle=1.5335 pcon=4.8639 forget=1.8724 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 33 it 230 total=8.3508 mle=1.5698 pcon=4.8636 forget=1.9175 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 33 it 280 total=8.2432 mle=1.4891 pcon=4.8630 forget=1.8911 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 33 it 330 total=8.2807 mle=1.4743 pcon=4.8624 forget=1.9440 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 33 it 380 total=8.2327 mle=1.4507 pcon=4.8622 forget=1.9198 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 34 it 40 total=8.2580 mle=1.4531 pcon=4.8619 forget=1.9430 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 34 it 90 total=8.3025 mle=1.5323 pcon=4.8619 forget=1.9083 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 34 it 140 total=8.2525 mle=1.4116 pcon=4.8615 forget=1.9794 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 34 it 190 total=8.2456 mle=1.4308 pcon=4.8614 forget=1.9533 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 34 it 240 total=8.2081 mle=1.4027 pcon=4.8616 forget=1.9438 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 34 it 290 total=8.2541 mle=1.4373 pcon=4.8618 forget=1.9551 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 34 it 340 total=8.2411 mle=1.3888 pcon=4.8618 forget=1.9904 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 35 it 0 total=8.2478 mle=1.4264 pcon=4.8621 forget=1.9593 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 35 it 50 total=8.3420 mle=1.5463 pcon=4.8626 forget=1.9332 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 35 it 100 total=8.3192 mle=1.5106 pcon=4.8630 forget=1.9456 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 35 it 150 total=8.2854 mle=1.3963 pcon=4.8634 forget=2.0258 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 35 it 200 total=8.2607 mle=1.4397 pcon=4.8637 forget=1.9572 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 35 it 250 total=8.3044 mle=1.4078 pcon=4.8642 forget=2.0323 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 35 it 300 total=8.3111 mle=1.4439 pcon=4.8648 forget=2.0024 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 35 it 350 total=8.3836 mle=1.5157 pcon=4.8655 forget=2.0024 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 36 it 10 total=8.4287 mle=1.5502 pcon=4.8661 forget=2.0124 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 36 it 60 total=8.4030 mle=1.5031 pcon=4.8668 forget=2.0331 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 36 it 110 total=8.4430 mle=1.5392 pcon=4.8676 forget=2.0362 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 36 it 160 total=8.3471 mle=1.4616 pcon=4.8686 forget=2.0170 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 36 it 210 total=8.4992 mle=1.6008 pcon=4.8695 forget=2.0290 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 36 it 260 total=8.4553 mle=1.5273 pcon=4.8704 forget=2.0575 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 36 it 310 total=8.3862 mle=1.4405 pcon=4.8713 forget=2.0744 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 36 it 360 total=8.3219 mle=1.3854 pcon=4.8725 forget=2.0641 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 20 total=8.3722 mle=1.4209 pcon=4.8734 forget=2.0779 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 37 it 70 total=8.4554 mle=1.5214 pcon=4.8743 forget=2.0596 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 37 it 120 total=8.3429 mle=1.3837 pcon=4.8751 forget=2.0841 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 170 total=8.3515 mle=1.3820 pcon=4.8761 forget=2.0933 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 37 it 220 total=8.4040 mle=1.4494 pcon=4.8772 forget=2.0774 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 37 it 270 total=8.3681 mle=1.4332 pcon=4.8784 forget=2.0565 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 320 total=8.4115 mle=1.4493 pcon=4.8795 forget=2.0828 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 37 it 370 total=8.3599 mle=1.4175 pcon=4.8807 forget=2.0617 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 38 it 30 total=8.4061 mle=1.4126 pcon=4.8819 forget=2.1116 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 38 it 80 total=8.4324 mle=1.4193 pcon=4.8831 forget=2.1300 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 38 it 130 total=8.4506 mle=1.4469 pcon=4.8842 forget=2.1194 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 38 it 180 total=8.3750 mle=1.3877 pcon=4.8852 forget=2.1021 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 38 it 230 total=8.4113 mle=1.4253 pcon=4.8862 forget=2.0998 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 38 it 280 total=8.4884 mle=1.4602 pcon=4.8875 forget=2.1408 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 38 it 330 total=8.5721 mle=1.5663 pcon=4.8885 forget=2.1173 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 38 it 380 total=8.3938 mle=1.3719 pcon=4.8894 forget=2.1325 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 39 it 40 total=8.3938 mle=1.3824 pcon=4.8905 forget=2.1210 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 39 it 90 total=8.4841 mle=1.4236 pcon=4.8914 forget=2.1691 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 39 it 140 total=8.5227 mle=1.4519 pcon=4.8923 forget=2.1785 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 39 it 190 total=8.3646 mle=1.3396 pcon=4.8934 forget=2.1315 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 39 it 240 total=8.3920 mle=1.3291 pcon=4.8944 forget=2.1684 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 39 it 290 total=8.4492 mle=1.4007 pcon=4.8955 forget=2.1530 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 39 it 340 total=8.4419 mle=1.3451 pcon=4.8965 forget=2.2003 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 0 total=8.3582 mle=1.2816 pcon=4.8975 forget=2.1791 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 50 total=8.5470 mle=1.4533 pcon=4.8984 forget=2.1953 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 40 it 100 total=8.3502 mle=1.2667 pcon=4.8992 forget=2.1843 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
 82%|████████▏ | 41/50 [06:56<01:30, 10.01s/it] 84%|████████▍ | 42/50 [07:05<01:19,  9.94s/it] 86%|████████▌ | 43/50 [07:15<01:09,  9.96s/it] 88%|████████▊ | 44/50 [07:26<01:01, 10.26s/it] 90%|█████████ | 45/50 [07:39<00:54, 10.82s/it] 92%|█████████▏| 46/50 [07:50<00:44, 11.15s/it] 94%|█████████▍| 47/50 [08:03<00:34, 11.53s/it] 96%|█████████▌| 48/50 [08:15<00:23, 11.58s/it] 98%|█████████▊| 49/50 [08:27<00:11, 11.81s/it][loss] ep 40 it 150 total=8.5160 mle=1.4036 pcon=4.9001 forget=2.2122 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 40 it 200 total=8.4635 mle=1.3528 pcon=4.9010 forget=2.2097 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 40 it 250 total=8.5390 mle=1.4041 pcon=4.9018 forget=2.2331 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 300 total=8.5704 mle=1.4384 pcon=4.9027 forget=2.2293 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 40 it 350 total=8.5110 mle=1.3590 pcon=4.9036 forget=2.2484 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 41 it 10 total=8.5428 mle=1.4033 pcon=4.9043 forget=2.2352 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 41 it 60 total=8.5548 mle=1.4039 pcon=4.9053 forget=2.2456 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 41 it 110 total=8.5432 mle=1.3660 pcon=4.9062 forget=2.2709 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 41 it 160 total=8.4975 mle=1.3316 pcon=4.9070 forget=2.2589 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 41 it 210 total=8.5684 mle=1.4281 pcon=4.9078 forget=2.2325 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 41 it 260 total=8.4519 mle=1.2461 pcon=4.9088 forget=2.2971 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 41 it 310 total=8.5975 mle=1.3879 pcon=4.9097 forget=2.2999 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 41 it 360 total=8.5867 mle=1.3674 pcon=4.9104 forget=2.3088 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 42 it 20 total=8.5273 mle=1.2930 pcon=4.9112 forget=2.3231 favg=0.0000 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 42 it 70 total=8.6013 mle=1.3634 pcon=4.9122 forget=2.3257 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 42 it 120 total=8.5151 mle=1.2963 pcon=4.9129 forget=2.3059 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 42 it 170 total=8.6574 mle=1.3835 pcon=4.9136 forget=2.3602 favg=0.0000 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 42 it 220 total=8.5554 mle=1.2994 pcon=4.9144 forget=2.3416 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 42 it 270 total=8.6409 mle=1.3817 pcon=4.9151 forget=2.3441 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 42 it 320 total=8.6154 mle=1.3352 pcon=4.9160 forget=2.3642 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 42 it 370 total=8.6626 mle=1.4061 pcon=4.9167 forget=2.3399 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 43 it 30 total=8.7551 mle=1.5014 pcon=4.9175 forget=2.3362 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 43 it 80 total=8.7201 mle=1.4207 pcon=4.9182 forget=2.3812 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 130 total=8.7821 mle=1.4706 pcon=4.9189 forget=2.3925 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 43 it 180 total=8.6446 mle=1.3216 pcon=4.9195 forget=2.4035 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 43 it 230 total=8.6971 mle=1.3481 pcon=4.9201 forget=2.4289 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 43 it 280 total=8.6847 mle=1.3227 pcon=4.9208 forget=2.4412 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 330 total=8.6805 mle=1.3282 pcon=4.9216 forget=2.4308 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 380 total=8.7895 mle=1.4438 pcon=4.9224 forget=2.4233 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 40 total=8.6390 mle=1.2663 pcon=4.9232 forget=2.4494 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 90 total=8.7177 mle=1.3366 pcon=4.9240 forget=2.4571 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 44 it 140 total=8.7631 mle=1.3892 pcon=4.9249 forget=2.4490 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 44 it 190 total=8.8002 mle=1.4512 pcon=4.9256 forget=2.4234 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 240 total=8.8227 mle=1.4137 pcon=4.9264 forget=2.4825 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 44 it 290 total=8.7557 mle=1.3745 pcon=4.9274 forget=2.4539 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 44 it 340 total=8.6927 mle=1.2785 pcon=4.9282 forget=2.4861 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 45 it 0 total=8.7335 mle=1.3342 pcon=4.9291 forget=2.4702 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 45 it 50 total=8.8707 mle=1.4378 pcon=4.9298 forget=2.5031 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 45 it 100 total=8.9127 mle=1.4824 pcon=4.9309 forget=2.4995 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 45 it 150 total=8.7178 mle=1.2905 pcon=4.9318 forget=2.4955 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 45 it 200 total=8.7753 mle=1.3124 pcon=4.9328 forget=2.5301 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 45 it 250 total=8.7090 mle=1.2705 pcon=4.9336 forget=2.5049 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 45 it 300 total=8.8300 mle=1.4106 pcon=4.9345 forget=2.4849 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 45 it 350 total=8.7175 mle=1.2754 pcon=4.9357 forget=2.5064 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 46 it 10 total=8.6840 mle=1.2154 pcon=4.9368 forget=2.5318 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 46 it 60 total=8.8112 mle=1.3382 pcon=4.9377 forget=2.5354 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 46 it 110 total=8.7881 mle=1.3383 pcon=4.9384 forget=2.5114 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 46 it 160 total=8.8853 mle=1.4334 pcon=4.9394 forget=2.5126 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 46 it 210 total=8.7957 mle=1.3045 pcon=4.9402 forget=2.5510 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 46 it 260 total=8.8571 mle=1.3872 pcon=4.9410 forget=2.5289 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 46 it 310 total=8.7766 mle=1.3048 pcon=4.9420 forget=2.5298 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 46 it 360 total=8.8102 mle=1.3222 pcon=4.9432 forget=2.5449 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 47 it 20 total=8.7872 mle=1.3257 pcon=4.9443 forget=2.5172 favg=0.0000 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 47 it 70 total=8.7746 mle=1.2742 pcon=4.9454 forget=2.5550 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 47 it 120 total=8.8665 mle=1.3488 pcon=4.9465 forget=2.5712 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 47 it 170 total=8.9669 mle=1.4592 pcon=4.9475 forget=2.5602 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 47 it 220 total=8.7907 mle=1.3018 pcon=4.9484 forget=2.5404 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 47 it 270 total=8.8671 mle=1.3630 pcon=4.9493 forget=2.5548 favg=0.0000 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 47 it 320 total=8.8228 mle=1.3443 pcon=4.9505 forget=2.5280 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 47 it 370 total=8.7959 mle=1.3157 pcon=4.9516 forget=2.5286 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 48 it 30 total=9.0088 mle=1.5426 pcon=4.9527 forget=2.5135 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 48 it 80 total=8.9012 mle=1.4029 pcon=4.9539 forget=2.5444 favg=0.0000 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 48 it 130 total=8.8532 mle=1.3195 pcon=4.9552 forget=2.5786 favg=0.0000 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 48 it 180 total=8.9358 mle=1.4125 pcon=4.9562 forget=2.5671 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 48 it 230 total=8.7943 mle=1.2689 pcon=4.9574 forget=2.5680 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 48 it 280 total=8.7665 mle=1.2324 pcon=4.9589 forget=2.5752 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 48 it 330 total=8.7629 mle=1.2198 pcon=4.9601 forget=2.5830 favg=0.0000 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 48 it 380 total=8.9256 mle=1.3939 pcon=4.9613 forget=2.5704 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
100%|██████████| 50/50 [08:40<00:00, 12.25s/it]100%|██████████| 50/50 [08:40<00:00, 10.41s/it]
[loss] ep 49 it 40 total=8.7915 mle=1.2518 pcon=4.9624 forget=2.5773 favg=0.0000 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 49 it 90 total=8.8654 mle=1.3311 pcon=4.9638 forget=2.5705 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 49 it 140 total=8.8428 mle=1.3024 pcon=4.9650 forget=2.5755 favg=0.0000 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 49 it 190 total=8.8738 mle=1.3218 pcon=4.9661 forget=2.5859 favg=0.0000 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 49 it 240 total=8.8334 mle=1.2919 pcon=4.9672 forget=2.5743 favg=0.0000 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 49 it 290 total=8.8337 mle=1.3204 pcon=4.9683 forget=2.5450 favg=0.0000 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 49 it 340 total=8.8433 mle=1.2977 pcon=4.9699 forget=2.5757 favg=0.0000 nr=128 nf=99 protos=600 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-planB_adapter
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:44,  2.37it/s]  3%|▎         | 11/391 [00:00<00:14, 26.79it/s]  5%|▌         | 21/391 [00:00<00:08, 45.62it/s]  8%|▊         | 31/391 [00:00<00:06, 59.88it/s] 10%|█         | 41/391 [00:00<00:04, 70.11it/s] 13%|█▎        | 51/391 [00:00<00:04, 77.66it/s] 16%|█▌        | 61/391 [00:01<00:04, 81.30it/s] 18%|█▊        | 71/391 [00:01<00:03, 85.75it/s] 21%|██        | 81/391 [00:01<00:03, 89.01it/s] 23%|██▎       | 91/391 [00:01<00:03, 91.14it/s] 26%|██▌       | 101/391 [00:01<00:03, 92.72it/s] 28%|██▊       | 111/391 [00:01<00:02, 93.88it/s] 31%|███       | 121/391 [00:01<00:02, 94.56it/s] 34%|███▎      | 131/391 [00:01<00:02, 95.06it/s] 36%|███▌      | 141/391 [00:01<00:02, 94.58it/s] 39%|███▊      | 151/391 [00:01<00:02, 93.42it/s] 41%|████      | 161/391 [00:02<00:02, 93.99it/s] 44%|████▎     | 171/391 [00:02<00:02, 94.33it/s] 46%|████▋     | 181/391 [00:02<00:02, 94.92it/s] 49%|████▉     | 191/391 [00:02<00:02, 95.21it/s] 51%|█████▏    | 201/391 [00:02<00:02, 94.24it/s] 54%|█████▍    | 211/391 [00:02<00:01, 94.74it/s] 57%|█████▋    | 221/391 [00:02<00:01, 95.01it/s] 59%|█████▉    | 231/391 [00:02<00:01, 95.25it/s] 62%|██████▏   | 241/391 [00:02<00:01, 95.55it/s] 64%|██████▍   | 251/391 [00:03<00:01, 95.70it/s] 67%|██████▋   | 261/391 [00:03<00:01, 94.61it/s] 69%|██████▉   | 271/391 [00:03<00:01, 94.82it/s] 72%|███████▏  | 281/391 [00:03<00:01, 95.17it/s] 74%|███████▍  | 291/391 [00:03<00:01, 94.15it/s] 77%|███████▋  | 301/391 [00:03<00:00, 94.51it/s] 80%|███████▉  | 311/391 [00:03<00:00, 93.77it/s] 82%|████████▏ | 321/391 [00:03<00:00, 94.30it/s] 85%|████████▍ | 331/391 [00:03<00:00, 94.87it/s] 87%|████████▋ | 341/391 [00:03<00:00, 94.96it/s] 90%|████████▉ | 351/391 [00:04<00:00, 94.09it/s] 92%|█████████▏| 361/391 [00:04<00:00, 93.84it/s] 95%|█████████▍| 371/391 [00:04<00:00, 94.94it/s] 97%|█████████▋| 381/391 [00:04<00:00, 95.77it/s]100%|██████████| 391/391 [00:04<00:00, 93.81it/s]100%|██████████| 391/391 [00:04<00:00, 86.31it/s]
50000 images processed, 4.630260467529297 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:34,  2.28it/s] 13%|█▎        | 10/79 [00:00<00:02, 23.25it/s] 25%|██▌       | 20/79 [00:00<00:01, 42.03it/s] 38%|███▊      | 30/79 [00:00<00:00, 56.23it/s] 51%|█████     | 40/79 [00:00<00:00, 66.42it/s] 63%|██████▎   | 50/79 [00:00<00:00, 74.32it/s] 76%|███████▌  | 60/79 [00:01<00:00, 80.48it/s] 89%|████████▊ | 70/79 [00:01<00:00, 85.00it/s]100%|██████████| 79/79 [00:01<00:00, 41.41it/s]
10000 images processed, 1.9698379039764404 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:44,  1.94it/s]  5%|▍         | 10/204 [00:00<00:09, 21.02it/s] 10%|▉         | 20/204 [00:00<00:04, 39.14it/s] 14%|█▍        | 29/204 [00:00<00:03, 51.32it/s] 19%|█▉        | 39/204 [00:00<00:02, 62.73it/s] 24%|██▍       | 49/204 [00:01<00:02, 70.97it/s] 29%|██▉       | 59/204 [00:01<00:01, 77.63it/s] 34%|███▍      | 69/204 [00:01<00:01, 82.32it/s] 39%|███▊      | 79/204 [00:01<00:01, 85.23it/s] 44%|████▎     | 89/204 [00:01<00:01, 87.68it/s] 49%|████▊     | 99/204 [00:01<00:01, 89.67it/s] 53%|█████▎    | 109/204 [00:01<00:01, 91.28it/s] 58%|█████▊    | 119/204 [00:01<00:00, 91.17it/s] 63%|██████▎   | 129/204 [00:01<00:00, 91.75it/s] 68%|██████▊   | 139/204 [00:02<00:00, 90.32it/s] 73%|███████▎  | 149/204 [00:02<00:00, 91.57it/s] 78%|███████▊  | 159/204 [00:02<00:00, 92.00it/s] 83%|████████▎ | 169/204 [00:02<00:00, 92.43it/s] 88%|████████▊ | 179/204 [00:02<00:00, 93.09it/s] 93%|█████████▎| 189/204 [00:02<00:00, 93.92it/s] 98%|█████████▊| 199/204 [00:02<00:00, 94.79it/s]100%|██████████| 204/204 [00:02<00:00, 75.48it/s]
26032 images processed, 2.7458224296569824 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:51,  1.52it/s] 14%|█▍        | 11/79 [00:00<00:03, 18.67it/s] 27%|██▋       | 21/79 [00:00<00:01, 34.28it/s] 39%|███▉      | 31/79 [00:00<00:01, 47.88it/s] 52%|█████▏    | 41/79 [00:01<00:00, 59.10it/s] 65%|██████▍   | 51/79 [00:01<00:00, 68.33it/s] 77%|███████▋  | 61/79 [00:01<00:00, 75.45it/s] 90%|████████▉ | 71/79 [00:01<00:00, 81.24it/s]100%|██████████| 79/79 [00:01<00:00, 53.21it/s]
10000 images processed, 1.5100913047790527 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.02it/s] 11%|█▏        | 9/79 [00:00<00:03, 19.30it/s] 23%|██▎       | 18/79 [00:00<00:01, 36.01it/s] 35%|███▌      | 28/79 [00:00<00:00, 51.40it/s] 48%|████▊     | 38/79 [00:00<00:00, 63.19it/s] 61%|██████    | 48/79 [00:01<00:00, 71.98it/s] 73%|███████▎  | 58/79 [00:01<00:00, 77.75it/s] 86%|████████▌ | 68/79 [00:01<00:00, 82.75it/s] 99%|█████████▊| 78/79 [00:01<00:00, 86.65it/s]100%|██████████| 79/79 [00:01<00:00, 58.79it/s]
10000 images processed, 1.3755500316619873 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:41,  1.67it/s] 14%|█▍        | 10/70 [00:00<00:03, 18.39it/s] 29%|██▊       | 20/70 [00:00<00:01, 35.45it/s] 43%|████▎     | 30/70 [00:00<00:00, 49.83it/s] 57%|█████▋    | 40/70 [00:01<00:00, 61.45it/s] 71%|███████▏  | 50/70 [00:01<00:00, 70.85it/s] 86%|████████▌ | 60/70 [00:01<00:00, 78.04it/s]100%|██████████| 70/70 [00:01<00:00, 82.39it/s]100%|██████████| 70/70 [00:01<00:00, 52.41it/s]
8925 images processed, 1.3666086196899414 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:42,  1.04it/s]  4%|▍         | 2/45 [00:01<00:23,  1.82it/s] 27%|██▋       | 12/45 [00:01<00:02, 14.71it/s] 38%|███▊      | 17/45 [00:01<00:01, 19.02it/s] 49%|████▉     | 22/45 [00:01<00:01, 17.24it/s] 58%|█████▊    | 26/45 [00:01<00:01, 18.55it/s] 73%|███████▎  | 33/45 [00:02<00:00, 25.62it/s] 82%|████████▏ | 37/45 [00:02<00:00, 20.90it/s] 89%|████████▉ | 40/45 [00:02<00:00, 22.17it/s]100%|██████████| 45/45 [00:02<00:00, 17.50it/s]
5640 images processed, 2.5925121307373047 seconds used

17.79142141342163
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.16  99.23
places365     72.26  80.38
LSUN          25.29  95.54
iSUN          74.61  81.69
dtd           41.26  90.74
AVG           43.32  89.51
Retain-Acc: 0.7448
Forget-as-OOD (retain known vs forget novel):
  FPR: 92.40 AUROC: 82.34 AUIN: 97.78
9.7830491065979
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08_rf.png
