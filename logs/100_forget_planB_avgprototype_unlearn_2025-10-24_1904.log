nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:23<18:57, 23.22s/it]  4%|▍         | 2/50 [00:42<16:37, 20.78s/it]  6%|▌         | 3/50 [01:01<15:41, 20.04s/it]  8%|▊         | 4/50 [01:20<15:08, 19.75s/it] 10%|█         | 5/50 [01:39<14:34, 19.43s/it] 12%|█▏        | 6/50 [01:58<14:06, 19.23s/it] 14%|█▍        | 7/50 [02:17<13:37, 19.02s/it][loss] ep 0 it 0 total=9.1227 mle=1.5804 pcon=5.2951 forget=2.3854 favg=-0.1382 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 0 it 50 total=8.9082 mle=1.4910 pcon=5.2914 forget=2.3537 favg=-0.2279 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 0 it 100 total=9.1771 mle=1.6390 pcon=5.2875 forget=2.3816 favg=-0.1311 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 0 it 150 total=9.2658 mle=1.8131 pcon=5.2841 forget=2.3525 favg=-0.1838 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 0 it 200 total=9.2344 mle=1.8134 pcon=5.2802 forget=2.3236 favg=-0.1829 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 0 it 250 total=8.8563 mle=1.4460 pcon=5.2762 forget=2.3791 favg=-0.2451 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 0 it 300 total=8.9972 mle=1.4830 pcon=5.2726 forget=2.3775 favg=-0.1360 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 0 it 350 total=9.1585 mle=1.4994 pcon=5.2693 forget=2.4357 favg=-0.0458 nr=128 nf=93 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=9.1161 mle=1.7196 pcon=5.2657 forget=2.3580 favg=-0.2272 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 1 it 60 total=8.8507 mle=1.2957 pcon=5.2618 forget=2.4521 favg=-0.1589 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 1 it 110 total=8.8874 mle=1.4152 pcon=5.2582 forget=2.3925 favg=-0.1785 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 1 it 160 total=8.6609 mle=1.1733 pcon=5.2546 forget=2.4271 favg=-0.1941 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 1 it 210 total=9.0907 mle=1.5838 pcon=5.2510 forget=2.3914 favg=-0.1355 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 1 it 260 total=8.9683 mle=1.5960 pcon=5.2475 forget=2.3748 favg=-0.2500 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 1 it 310 total=8.9579 mle=1.6191 pcon=5.2441 forget=2.3531 favg=-0.2583 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 1 it 360 total=9.0017 mle=1.6114 pcon=5.2407 forget=2.3750 favg=-0.2253 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=8.8867 mle=1.5295 pcon=5.2372 forget=2.3616 favg=-0.2416 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 2 it 70 total=8.8261 mle=1.3555 pcon=5.2341 forget=2.4297 favg=-0.1932 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 2 it 120 total=8.7297 mle=1.4283 pcon=5.2308 forget=2.3528 favg=-0.2822 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 2 it 170 total=9.0182 mle=1.6473 pcon=5.2275 forget=2.3772 favg=-0.2338 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 2 it 220 total=8.6924 mle=1.3785 pcon=5.2240 forget=2.3836 favg=-0.2937 nr=128 nf=89 protos=600 fproto_sim=NA
[loss] ep 2 it 270 total=9.0016 mle=1.7360 pcon=5.2205 forget=2.3696 favg=-0.3245 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 2 it 320 total=8.3981 mle=1.3941 pcon=5.2170 forget=2.3569 favg=-0.5698 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 2 it 370 total=8.1628 mle=1.4041 pcon=5.2133 forget=2.3360 favg=-0.7905 nr=128 nf=96 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 3 it 30 total=7.9793 mle=1.6235 pcon=5.2090 forget=2.2541 favg=-1.1074 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 3 it 80 total=7.4343 mle=1.4907 pcon=5.2042 forget=2.1817 favg=-1.4424 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 3 it 130 total=7.5212 mle=1.7708 pcon=5.1992 forget=2.1146 favg=-1.5635 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 3 it 180 total=7.3362 mle=1.8277 pcon=5.1944 forget=2.0779 favg=-1.7637 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 3 it 230 total=7.3969 mle=1.8663 pcon=5.1896 forget=2.0910 favg=-1.7500 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 3 it 280 total=7.7226 mle=1.8927 pcon=5.1847 forget=2.1316 favg=-1.4863 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 3 it 330 total=8.5442 mle=1.8685 pcon=5.1799 forget=2.1413 favg=-0.6455 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 3 it 380 total=9.9749 mle=1.7481 pcon=5.1753 forget=2.1872 favg=0.8643 nr=128 nf=97 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 4 it 40 total=10.4232 mle=1.7641 pcon=5.1709 forget=2.2050 favg=1.2832 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 4 it 90 total=10.0949 mle=1.3217 pcon=5.1670 forget=2.3357 favg=1.2705 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 4 it 140 total=10.3229 mle=1.7976 pcon=5.1635 forget=2.3012 favg=1.0605 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 4 it 190 total=9.8332 mle=1.5507 pcon=5.1604 forget=2.3398 favg=0.7822 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 4 it 240 total=9.4422 mle=1.3868 pcon=5.1579 forget=2.3463 favg=0.5513 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 4 it 290 total=9.1584 mle=1.1968 pcon=5.1556 forget=2.3581 favg=0.4480 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 4 it 340 total=9.3870 mle=1.5701 pcon=5.1535 forget=2.3171 favg=0.3462 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 5 it 0 total=9.0911 mle=1.1701 pcon=5.1515 forget=2.3783 favg=0.3911 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 5 it 50 total=9.3148 mle=1.5287 pcon=5.1493 forget=2.3419 favg=0.2949 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 5 it 100 total=9.2900 mle=1.5963 pcon=5.1474 forget=2.3523 favg=0.1940 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 5 it 150 total=9.1031 mle=1.5052 pcon=5.1456 forget=2.3393 favg=0.1129 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 5 it 200 total=8.6452 mle=1.5708 pcon=5.1436 forget=2.2607 favg=-0.3298 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 5 it 250 total=7.9322 mle=1.5223 pcon=5.1421 forget=2.0788 favg=-0.8110 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 5 it 300 total=9.4385 mle=1.7957 pcon=5.1405 forget=1.8954 favg=0.6069 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 5 it 350 total=9.9281 mle=1.6780 pcon=5.1379 forget=2.0838 favg=1.0283 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 6 it 10 total=9.6373 mle=1.3226 pcon=5.1352 forget=2.2904 favg=0.8892 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 6 it 60 total=9.4243 mle=1.3919 pcon=5.1323 forget=2.3845 favg=0.5156 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 6 it 110 total=9.0791 mle=1.2952 pcon=5.1293 forget=2.3941 favg=0.2605 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 6 it 160 total=8.8080 mle=1.3461 pcon=5.1262 forget=2.3484 favg=-0.0127 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 6 it 210 total=8.9134 mle=1.7122 pcon=5.1234 forget=2.2431 favg=-0.1653 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 6 it 260 total=8.4174 mle=1.4065 pcon=5.1212 forget=2.1689 favg=-0.2791 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 6 it 310 total=8.7981 mle=1.7532 pcon=5.1195 forget=1.9939 favg=-0.0685 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 6 it 360 total=9.5331 mle=1.8447 pcon=5.1181 forget=1.9077 favg=0.6626 nr=128 nf=89 protos=600 fproto_sim=NA
[loss] ep 7 it 20 total=9.6033 mle=1.6248 pcon=5.1175 forget=1.9172 favg=0.9438 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 7 it 70 total=9.3206 mle=1.5642 pcon=5.1167 forget=2.0065 favg=0.6333 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 7 it 120 total=8.7268 mle=1.6435 pcon=5.1157 forget=2.0420 favg=-0.0745 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 7 it 170 total=8.0207 mle=1.9491 pcon=5.1144 forget=1.7971 favg=-0.8398 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 7 it 220 total=7.4792 mle=1.6155 pcon=5.1126 forget=1.7667 favg=-1.0156 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 7 it 270 total=7.9274 mle=1.7316 pcon=5.1102 forget=1.7819 favg=-0.6963 nr=128 nf=94 protos=600 fproto_sim=NA
 16%|█▌        | 8/50 [02:35<13:06, 18.73s/it] 18%|█▊        | 9/50 [02:54<12:50, 18.80s/it] 20%|██        | 10/50 [03:12<12:32, 18.81s/it] 22%|██▏       | 11/50 [03:29<11:43, 18.03s/it] 24%|██▍       | 12/50 [03:48<11:35, 18.31s/it] 26%|██▌       | 13/50 [04:07<11:32, 18.72s/it] 28%|██▊       | 14/50 [04:27<11:20, 18.91s/it] 30%|███       | 15/50 [04:46<11:01, 18.91s/it] 32%|███▏      | 16/50 [05:05<10:46, 19.00s/it][loss] ep 7 it 320 total=8.6544 mle=1.6387 pcon=5.1072 forget=1.8612 favg=0.0474 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 7 it 370 total=9.2594 mle=1.5189 pcon=5.1039 forget=2.0126 favg=0.6240 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 8 it 30 total=9.5898 mle=1.6159 pcon=5.1007 forget=1.9772 favg=0.8960 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 8 it 80 total=9.4383 mle=1.4692 pcon=5.0977 forget=2.0160 favg=0.8555 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 8 it 130 total=9.5593 mle=1.7246 pcon=5.0954 forget=1.9376 favg=0.8018 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 8 it 180 total=9.3778 mle=1.7068 pcon=5.0937 forget=1.8210 favg=0.7563 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 8 it 230 total=9.3765 mle=1.7798 pcon=5.0928 forget=1.7763 favg=0.7275 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 8 it 280 total=9.2227 mle=1.8338 pcon=5.0922 forget=1.7478 favg=0.5488 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 8 it 330 total=9.1525 mle=2.2198 pcon=5.0917 forget=1.6853 favg=0.1556 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 8 it 380 total=8.3070 mle=1.8340 pcon=5.0916 forget=1.7361 favg=-0.3547 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 9 it 40 total=7.6074 mle=1.8789 pcon=5.0913 forget=1.6656 favg=-1.0283 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 9 it 90 total=7.3576 mle=1.9153 pcon=5.0903 forget=1.6303 favg=-1.2783 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 9 it 140 total=7.6741 mle=1.5512 pcon=5.0892 forget=1.7237 favg=-0.6899 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 9 it 190 total=9.0343 mle=1.4914 pcon=5.0874 forget=1.8530 favg=0.6025 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 9 it 240 total=9.8901 mle=1.7717 pcon=5.0855 forget=1.9841 favg=1.0488 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 9 it 290 total=9.5852 mle=1.4604 pcon=5.0834 forget=2.1049 favg=0.9365 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 9 it 340 total=9.2177 mle=1.3766 pcon=5.0817 forget=2.0987 favg=0.6606 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 10 it 0 total=8.9036 mle=1.5801 pcon=5.0801 forget=1.9829 favg=0.2605 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 10 it 50 total=7.9139 mle=1.5391 pcon=5.0796 forget=1.7527 favg=-0.4575 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 10 it 100 total=7.6584 mle=1.8820 pcon=5.0791 forget=1.6051 favg=-0.9077 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 10 it 150 total=7.5365 mle=1.9275 pcon=5.0786 forget=1.5715 favg=-1.0410 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 10 it 200 total=7.8814 mle=1.7489 pcon=5.0780 forget=1.6004 favg=-0.5459 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 10 it 250 total=8.7502 mle=1.6494 pcon=5.0771 forget=1.6882 favg=0.3354 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 10 it 300 total=9.1258 mle=1.6977 pcon=5.0756 forget=1.7529 favg=0.5996 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 10 it 350 total=8.8395 mle=1.2906 pcon=5.0739 forget=1.9033 favg=0.5718 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 11 it 10 total=8.7623 mle=1.4240 pcon=5.0719 forget=1.9302 favg=0.3362 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 11 it 60 total=8.2889 mle=1.4529 pcon=5.0703 forget=1.7802 favg=-0.0146 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 11 it 110 total=8.1862 mle=1.5215 pcon=5.0691 forget=1.7273 favg=-0.1317 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 11 it 160 total=8.5801 mle=1.6433 pcon=5.0682 forget=1.7198 favg=0.1488 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 11 it 210 total=8.8052 mle=1.5823 pcon=5.0672 forget=1.7351 favg=0.4207 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 11 it 260 total=8.9150 mle=1.5053 pcon=5.0664 forget=1.7671 favg=0.5762 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 11 it 310 total=8.9540 mle=1.5527 pcon=5.0657 forget=1.8383 favg=0.4973 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 11 it 360 total=8.5814 mle=1.4053 pcon=5.0649 forget=1.9079 favg=0.2034 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 12 it 20 total=8.1863 mle=1.4279 pcon=5.0639 forget=1.8885 favg=-0.1940 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 12 it 70 total=7.9533 mle=1.5592 pcon=5.0625 forget=1.8735 favg=-0.5420 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 12 it 120 total=7.4710 mle=1.4823 pcon=5.0607 forget=1.7044 favg=-0.7764 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 12 it 170 total=7.3308 mle=1.4580 pcon=5.0585 forget=1.7372 favg=-0.9229 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 12 it 220 total=7.4828 mle=1.4357 pcon=5.0561 forget=1.7234 favg=-0.7324 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 12 it 270 total=8.1714 mle=1.4815 pcon=5.0537 forget=1.6904 favg=-0.0541 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 12 it 320 total=8.9762 mle=1.5066 pcon=5.0516 forget=1.7032 favg=0.7148 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 12 it 370 total=9.3829 mle=1.5749 pcon=5.0496 forget=1.7637 favg=0.9946 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 13 it 30 total=9.3405 mle=1.4695 pcon=5.0483 forget=1.7573 favg=1.0654 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 13 it 80 total=9.2829 mle=1.6353 pcon=5.0471 forget=1.7294 favg=0.8711 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 13 it 130 total=8.6662 mle=1.5360 pcon=5.0462 forget=1.7153 favg=0.3687 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 13 it 180 total=8.1709 mle=1.5249 pcon=5.0452 forget=1.7369 favg=-0.1360 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 13 it 230 total=7.5023 mle=1.5564 pcon=5.0443 forget=1.6603 favg=-0.7588 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 13 it 280 total=7.1642 mle=1.4415 pcon=5.0429 forget=1.6895 favg=-1.0098 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 13 it 330 total=7.3373 mle=1.5877 pcon=5.0413 forget=1.6575 favg=-0.9492 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 13 it 380 total=8.2083 mle=1.4957 pcon=5.0393 forget=1.7090 favg=-0.0357 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 14 it 40 total=9.0963 mle=1.5020 pcon=5.0372 forget=1.8261 favg=0.7310 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 14 it 90 total=9.2695 mle=1.4113 pcon=5.0350 forget=1.9623 favg=0.8608 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 14 it 140 total=9.2142 mle=1.4496 pcon=5.0329 forget=1.9431 favg=0.7886 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 14 it 190 total=8.7281 mle=1.3462 pcon=5.0305 forget=1.8265 favg=0.5249 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 14 it 240 total=8.4254 mle=1.4539 pcon=5.0285 forget=1.7986 favg=0.1443 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 14 it 290 total=7.8629 mle=1.5042 pcon=5.0268 forget=1.6544 favg=-0.3225 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 14 it 340 total=7.5456 mle=1.6039 pcon=5.0251 forget=1.6114 favg=-0.6948 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 15 it 0 total=7.4076 mle=1.6519 pcon=5.0232 forget=1.6138 favg=-0.8813 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 50 total=7.3060 mle=1.5315 pcon=5.0216 forget=1.6005 favg=-0.8477 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 15 it 100 total=7.9374 mle=1.4805 pcon=5.0201 forget=1.6115 favg=-0.1747 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 15 it 150 total=8.8257 mle=1.4445 pcon=5.0183 forget=1.7091 favg=0.6538 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 15 it 200 total=9.1619 mle=1.3746 pcon=5.0164 forget=1.7998 favg=0.9712 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 250 total=9.3276 mle=1.4231 pcon=5.0146 forget=1.8577 favg=1.0322 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 15 it 300 total=9.0864 mle=1.4465 pcon=5.0129 forget=1.8247 favg=0.8022 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 15 it 350 total=8.9568 mle=1.4344 pcon=5.0115 forget=1.8678 favg=0.6431 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 16 it 10 total=8.4313 mle=1.4443 pcon=5.0101 forget=1.8063 favg=0.1705 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 16 it 60 total=8.0565 mle=1.5005 pcon=5.0087 forget=1.7085 favg=-0.1613 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 16 it 110 total=7.5912 mle=1.5099 pcon=5.0073 forget=1.6493 favg=-0.5752 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 16 it 160 total=7.4696 mle=1.5927 pcon=5.0059 forget=1.6483 favg=-0.7773 nr=128 nf=95 protos=600 fproto_sim=NA
 34%|███▍      | 17/50 [05:24<10:32, 19.15s/it] 36%|███▌      | 18/50 [05:44<10:20, 19.39s/it] 38%|███▊      | 19/50 [06:04<10:02, 19.42s/it] 40%|████      | 20/50 [06:23<09:44, 19.47s/it] 42%|████▏     | 21/50 [06:43<09:26, 19.52s/it] 44%|████▍     | 22/50 [07:02<09:06, 19.52s/it] 46%|████▌     | 23/50 [07:22<08:47, 19.55s/it] 48%|████▊     | 24/50 [07:42<08:30, 19.64s/it] 50%|█████     | 25/50 [08:01<08:09, 19.60s/it][loss] ep 16 it 210 total=7.2935 mle=1.5136 pcon=5.0041 forget=1.6733 favg=-0.8975 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 16 it 260 total=7.8558 mle=1.6002 pcon=5.0020 forget=1.7266 favg=-0.4731 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 16 it 310 total=8.5593 mle=1.5672 pcon=4.9998 forget=1.7538 favg=0.2385 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 16 it 360 total=9.0098 mle=1.5179 pcon=4.9975 forget=1.8099 favg=0.6846 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 17 it 20 total=9.0941 mle=1.4892 pcon=4.9955 forget=1.8072 favg=0.8022 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 17 it 70 total=8.9858 mle=1.4816 pcon=4.9934 forget=1.8023 favg=0.7085 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 17 it 120 total=8.7789 mle=1.4644 pcon=4.9913 forget=1.8144 favg=0.5088 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 17 it 170 total=8.3666 mle=1.3804 pcon=4.9896 forget=1.7271 favg=0.2695 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 17 it 220 total=8.2184 mle=1.4953 pcon=4.9880 forget=1.6706 favg=0.0645 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 17 it 270 total=8.0318 mle=1.6105 pcon=4.9864 forget=1.5993 favg=-0.1643 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 17 it 320 total=7.9785 mle=1.6236 pcon=4.9849 forget=1.5723 favg=-0.2024 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 17 it 370 total=7.7993 mle=1.5567 pcon=4.9833 forget=1.5612 favg=-0.3020 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 18 it 30 total=7.7551 mle=1.5719 pcon=4.9816 forget=1.5776 favg=-0.3760 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 18 it 80 total=8.1373 mle=1.7727 pcon=4.9799 forget=1.5985 favg=-0.2139 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 18 it 130 total=8.0283 mle=1.5538 pcon=4.9785 forget=1.6618 favg=-0.1658 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 18 it 180 total=8.1524 mle=1.4537 pcon=4.9767 forget=1.6184 favg=0.1035 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 230 total=8.5617 mle=1.5310 pcon=4.9749 forget=1.6971 favg=0.3586 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 280 total=8.7095 mle=1.4945 pcon=4.9732 forget=1.7305 favg=0.5112 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 18 it 330 total=8.6662 mle=1.3694 pcon=4.9718 forget=1.7459 favg=0.5791 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 18 it 380 total=8.6910 mle=1.4395 pcon=4.9703 forget=1.7041 favg=0.5771 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 40 total=8.6780 mle=1.5045 pcon=4.9688 forget=1.7028 favg=0.5020 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 90 total=8.6059 mle=1.5761 pcon=4.9674 forget=1.6647 favg=0.3977 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 19 it 140 total=8.3145 mle=1.4556 pcon=4.9662 forget=1.6966 favg=0.1960 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 190 total=8.2682 mle=1.6198 pcon=4.9649 forget=1.6473 favg=0.0362 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 19 it 240 total=7.8854 mle=1.4309 pcon=4.9634 forget=1.6284 favg=-0.1373 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 19 it 290 total=7.8481 mle=1.5642 pcon=4.9621 forget=1.6065 favg=-0.2847 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 19 it 340 total=7.8645 mle=1.4743 pcon=4.9608 forget=1.6527 favg=-0.2233 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 20 it 0 total=7.8748 mle=1.4057 pcon=4.9592 forget=1.6686 favg=-0.1588 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 20 it 50 total=8.1575 mle=1.5127 pcon=4.9576 forget=1.6564 favg=0.0308 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 20 it 100 total=8.2311 mle=1.4414 pcon=4.9557 forget=1.6726 favg=0.1614 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 20 it 150 total=8.5810 mle=1.5340 pcon=4.9540 forget=1.7029 favg=0.3901 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 20 it 200 total=8.5553 mle=1.4588 pcon=4.9526 forget=1.7005 favg=0.4434 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 20 it 250 total=8.6161 mle=1.5339 pcon=4.9513 forget=1.6831 favg=0.4478 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 20 it 300 total=8.4767 mle=1.5127 pcon=4.9499 forget=1.6681 favg=0.3459 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 20 it 350 total=8.4409 mle=1.6057 pcon=4.9489 forget=1.6503 favg=0.2360 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 10 total=8.0977 mle=1.5593 pcon=4.9477 forget=1.5851 favg=0.0057 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 21 it 60 total=7.9930 mle=1.6350 pcon=4.9466 forget=1.5852 favg=-0.1738 nr=128 nf=89 protos=600 fproto_sim=NA
[loss] ep 21 it 110 total=7.9794 mle=1.6974 pcon=4.9453 forget=1.6099 favg=-0.2732 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 160 total=8.0198 mle=1.6080 pcon=4.9439 forget=1.6146 favg=-0.1467 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 21 it 210 total=7.9272 mle=1.5133 pcon=4.9424 forget=1.6086 favg=-0.1370 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 21 it 260 total=8.2154 mle=1.6235 pcon=4.9410 forget=1.6446 favg=0.0063 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 21 it 310 total=8.3517 mle=1.4974 pcon=4.9395 forget=1.6923 favg=0.2224 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 21 it 360 total=8.5336 mle=1.4973 pcon=4.9381 forget=1.6790 favg=0.4192 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 22 it 20 total=8.5835 mle=1.4776 pcon=4.9368 forget=1.7168 favg=0.4524 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 22 it 70 total=8.6445 mle=1.5063 pcon=4.9351 forget=1.7285 favg=0.4746 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 22 it 120 total=8.5077 mle=1.4573 pcon=4.9338 forget=1.7324 favg=0.3843 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 22 it 170 total=8.3902 mle=1.4826 pcon=4.9324 forget=1.6617 favg=0.3135 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 22 it 220 total=8.2634 mle=1.4860 pcon=4.9311 forget=1.6580 favg=0.1882 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 22 it 270 total=8.2025 mle=1.5163 pcon=4.9300 forget=1.6360 favg=0.1202 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 22 it 320 total=8.0881 mle=1.5385 pcon=4.9289 forget=1.5856 favg=0.0351 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 22 it 370 total=8.1120 mle=1.6326 pcon=4.9277 forget=1.5687 favg=-0.0169 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 23 it 30 total=7.9749 mle=1.5191 pcon=4.9265 forget=1.5860 favg=-0.0566 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 23 it 80 total=8.0111 mle=1.5237 pcon=4.9253 forget=1.6316 favg=-0.0695 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 23 it 130 total=7.9649 mle=1.5382 pcon=4.9241 forget=1.5926 favg=-0.0900 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 23 it 180 total=7.9976 mle=1.5893 pcon=4.9225 forget=1.5989 favg=-0.1132 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 23 it 230 total=8.0194 mle=1.6181 pcon=4.9210 forget=1.6119 favg=-0.1316 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 280 total=7.9592 mle=1.6327 pcon=4.9194 forget=1.6154 favg=-0.2084 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 330 total=7.9402 mle=1.6030 pcon=4.9179 forget=1.6270 favg=-0.2076 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 23 it 380 total=8.1297 mle=1.5887 pcon=4.9164 forget=1.6437 favg=-0.0190 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 24 it 40 total=8.1844 mle=1.5371 pcon=4.9150 forget=1.6266 favg=0.1056 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 24 it 90 total=8.5919 mle=1.6367 pcon=4.9137 forget=1.6458 favg=0.3958 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 24 it 140 total=8.7376 mle=1.5224 pcon=4.9125 forget=1.6753 favg=0.6274 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 24 it 190 total=8.9552 mle=1.6037 pcon=4.9113 forget=1.6805 favg=0.7598 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 24 it 240 total=9.0570 mle=1.5740 pcon=4.9103 forget=1.7147 favg=0.8579 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 24 it 290 total=8.9579 mle=1.4698 pcon=4.9095 forget=1.7022 favg=0.8765 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 24 it 340 total=8.9305 mle=1.4646 pcon=4.9084 forget=1.7464 favg=0.8110 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 25 it 0 total=8.8255 mle=1.5272 pcon=4.9076 forget=1.7198 favg=0.6709 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 25 it 50 total=8.6353 mle=1.5431 pcon=4.9068 forget=1.6787 favg=0.5068 nr=128 nf=98 protos=600 fproto_sim=NA
 52%|█████▏    | 26/50 [08:21<07:50, 19.62s/it] 54%|█████▍    | 27/50 [08:41<07:29, 19.56s/it] 56%|█████▌    | 28/50 [09:00<07:12, 19.64s/it] 58%|█████▊    | 29/50 [09:20<06:53, 19.69s/it] 60%|██████    | 30/50 [09:40<06:32, 19.65s/it] 62%|██████▏   | 31/50 [09:59<06:12, 19.60s/it] 64%|██████▍   | 32/50 [10:19<05:52, 19.57s/it] 66%|██████▌   | 33/50 [10:38<05:30, 19.43s/it][loss] ep 25 it 100 total=8.4710 mle=1.5950 pcon=4.9060 forget=1.6542 favg=0.3159 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 25 it 150 total=8.1507 mle=1.5852 pcon=4.9052 forget=1.6387 favg=0.0216 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 25 it 200 total=7.9578 mle=1.6380 pcon=4.9042 forget=1.6139 favg=-0.1984 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 25 it 250 total=7.7685 mle=1.5675 pcon=4.9032 forget=1.6056 favg=-0.3079 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 25 it 300 total=7.6345 mle=1.5863 pcon=4.9019 forget=1.6099 favg=-0.4636 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 25 it 350 total=7.6343 mle=1.5285 pcon=4.9006 forget=1.6043 favg=-0.3992 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 26 it 10 total=7.7028 mle=1.5334 pcon=4.8990 forget=1.5991 favg=-0.3286 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 26 it 60 total=7.8323 mle=1.5581 pcon=4.8973 forget=1.5900 favg=-0.2131 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 26 it 110 total=8.0409 mle=1.5349 pcon=4.8960 forget=1.6395 favg=-0.0295 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 26 it 160 total=8.0520 mle=1.4778 pcon=4.8945 forget=1.6289 favg=0.0509 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 26 it 210 total=8.2957 mle=1.5637 pcon=4.8931 forget=1.6437 favg=0.1952 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 26 it 260 total=8.3259 mle=1.4978 pcon=4.8918 forget=1.6551 favg=0.2812 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 26 it 310 total=8.4931 mle=1.6779 pcon=4.8904 forget=1.6216 favg=0.3032 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 26 it 360 total=8.3325 mle=1.5464 pcon=4.8891 forget=1.6367 favg=0.2603 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 27 it 20 total=8.2363 mle=1.5274 pcon=4.8878 forget=1.6177 favg=0.2034 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 27 it 70 total=8.1881 mle=1.5979 pcon=4.8867 forget=1.5945 favg=0.1091 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 120 total=8.1453 mle=1.6072 pcon=4.8854 forget=1.6187 favg=0.0339 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 170 total=8.0560 mle=1.5266 pcon=4.8843 forget=1.6082 favg=0.0369 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 220 total=8.0113 mle=1.5167 pcon=4.8833 forget=1.6063 favg=0.0049 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 270 total=7.9894 mle=1.5062 pcon=4.8822 forget=1.6058 favg=-0.0047 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 320 total=8.1377 mle=1.6216 pcon=4.8812 forget=1.6164 favg=0.0184 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 27 it 370 total=7.9854 mle=1.4532 pcon=4.8801 forget=1.6242 favg=0.0278 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 30 total=8.1028 mle=1.5066 pcon=4.8792 forget=1.6525 favg=0.0646 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 28 it 80 total=8.2888 mle=1.6705 pcon=4.8780 forget=1.6311 favg=0.1092 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 28 it 130 total=8.1603 mle=1.4937 pcon=4.8772 forget=1.6569 favg=0.1326 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 180 total=8.1903 mle=1.4039 pcon=4.8760 forget=1.6508 favg=0.2595 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 28 it 230 total=8.2864 mle=1.4519 pcon=4.8750 forget=1.6720 favg=0.2876 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 28 it 280 total=8.4107 mle=1.4420 pcon=4.8740 forget=1.7142 favg=0.3804 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 28 it 330 total=8.4300 mle=1.4770 pcon=4.8730 forget=1.6851 favg=0.3948 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 28 it 380 total=8.4412 mle=1.3974 pcon=4.8720 forget=1.7271 favg=0.4446 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 29 it 40 total=8.4338 mle=1.4295 pcon=4.8710 forget=1.6827 favg=0.4507 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 29 it 90 total=8.7132 mle=1.5616 pcon=4.8701 forget=1.7179 favg=0.5635 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 29 it 140 total=8.4917 mle=1.4390 pcon=4.8693 forget=1.7298 favg=0.4536 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 29 it 190 total=8.5898 mle=1.5723 pcon=4.8683 forget=1.7429 favg=0.4062 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 29 it 240 total=8.5730 mle=1.5303 pcon=4.8675 forget=1.7323 favg=0.4429 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 29 it 290 total=8.4883 mle=1.5673 pcon=4.8665 forget=1.6608 favg=0.3938 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 29 it 340 total=8.4853 mle=1.5294 pcon=4.8657 forget=1.7021 favg=0.3882 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 30 it 0 total=8.4814 mle=1.5315 pcon=4.8649 forget=1.6958 favg=0.3892 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 30 it 50 total=8.3723 mle=1.4881 pcon=4.8640 forget=1.6799 favg=0.3403 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 30 it 100 total=8.3576 mle=1.6115 pcon=4.8631 forget=1.6329 favg=0.2500 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 30 it 150 total=8.2571 mle=1.5479 pcon=4.8621 forget=1.6407 favg=0.2064 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 30 it 200 total=8.2120 mle=1.5262 pcon=4.8611 forget=1.6450 favg=0.1798 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 30 it 250 total=8.1675 mle=1.6104 pcon=4.8602 forget=1.6098 favg=0.0871 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 30 it 300 total=8.0232 mle=1.5403 pcon=4.8590 forget=1.6057 favg=0.0182 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 30 it 350 total=7.9541 mle=1.5407 pcon=4.8579 forget=1.6426 favg=-0.0870 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 31 it 10 total=7.9226 mle=1.5609 pcon=4.8566 forget=1.6358 favg=-0.1306 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 31 it 60 total=7.7711 mle=1.5789 pcon=4.8555 forget=1.5882 favg=-0.2515 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 31 it 110 total=7.7558 mle=1.5665 pcon=4.8543 forget=1.5778 favg=-0.2428 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 31 it 160 total=7.7296 mle=1.5458 pcon=4.8529 forget=1.6085 favg=-0.2776 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 31 it 210 total=7.7978 mle=1.6216 pcon=4.8515 forget=1.5922 favg=-0.2676 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 31 it 260 total=7.7303 mle=1.5701 pcon=4.8504 forget=1.6093 favg=-0.2996 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 31 it 310 total=7.7697 mle=1.5119 pcon=4.8490 forget=1.5954 favg=-0.1865 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 31 it 360 total=7.8961 mle=1.5356 pcon=4.8479 forget=1.6136 favg=-0.1011 nr=128 nf=94 protos=600 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 32 it 20 total=8.1007 mle=1.5547 pcon=4.8468 forget=1.6275 favg=0.0717 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 32 it 70 total=8.1337 mle=1.5349 pcon=4.8456 forget=1.6123 favg=0.1409 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 32 it 120 total=8.2384 mle=1.4451 pcon=4.8445 forget=1.6663 favg=0.2825 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 170 total=8.4925 mle=1.5924 pcon=4.8433 forget=1.6392 favg=0.4175 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 32 it 220 total=8.4971 mle=1.4838 pcon=4.8423 forget=1.6776 favg=0.4934 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 270 total=8.6388 mle=1.4227 pcon=4.8413 forget=1.6917 favg=0.6831 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 32 it 320 total=8.7415 mle=1.4471 pcon=4.8404 forget=1.6912 favg=0.7627 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 32 it 370 total=8.6649 mle=1.4149 pcon=4.8399 forget=1.6957 favg=0.7144 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 33 it 30 total=8.9651 mle=1.6139 pcon=4.8391 forget=1.7090 favg=0.8032 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 33 it 80 total=8.7605 mle=1.4298 pcon=4.8384 forget=1.7247 favg=0.7676 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 33 it 130 total=8.7796 mle=1.4932 pcon=4.8377 forget=1.7231 favg=0.7256 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 33 it 180 total=8.7102 mle=1.5417 pcon=4.8369 forget=1.6686 favg=0.6631 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 33 it 230 total=8.8514 mle=1.5989 pcon=4.8366 forget=1.7303 favg=0.6855 nr=128 nf=96 protos=600 fproto_sim=NA
 68%|██████▊   | 34/50 [10:58<05:12, 19.55s/it] 70%|███████   | 35/50 [11:15<04:41, 18.77s/it] 72%|███████▏  | 36/50 [11:28<04:02, 17.29s/it] 74%|███████▍  | 37/50 [11:45<03:43, 17.20s/it] 76%|███████▌  | 38/50 [11:55<03:00, 15.02s/it] 78%|███████▊  | 39/50 [12:06<02:29, 13.57s/it] 80%|████████  | 40/50 [12:16<02:06, 12.61s/it] 82%|████████▏ | 41/50 [12:27<01:48, 12.03s/it] 84%|████████▍ | 42/50 [12:37<01:31, 11.45s/it][loss] ep 33 it 280 total=8.5866 mle=1.5214 pcon=4.8360 forget=1.6658 favg=0.5635 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 33 it 330 total=8.6802 mle=1.5399 pcon=4.8353 forget=1.7435 favg=0.5615 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 33 it 380 total=8.4549 mle=1.4704 pcon=4.8348 forget=1.7019 favg=0.4478 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 34 it 40 total=8.3974 mle=1.4338 pcon=4.8342 forget=1.7246 favg=0.4048 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 34 it 90 total=8.3785 mle=1.5255 pcon=4.8338 forget=1.6631 favg=0.3560 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 34 it 140 total=8.3460 mle=1.4814 pcon=4.8330 forget=1.7159 favg=0.3157 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 34 it 190 total=8.2217 mle=1.4430 pcon=4.8323 forget=1.6725 favg=0.2739 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 34 it 240 total=8.1740 mle=1.4397 pcon=4.8317 forget=1.6776 favg=0.2250 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 34 it 290 total=8.2347 mle=1.4991 pcon=4.8310 forget=1.6797 favg=0.2250 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 34 it 340 total=8.1578 mle=1.4343 pcon=4.8302 forget=1.7094 favg=0.1838 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 35 it 0 total=8.1455 mle=1.4564 pcon=4.8295 forget=1.6909 favg=0.1687 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 35 it 50 total=8.2637 mle=1.5764 pcon=4.8289 forget=1.6484 favg=0.2100 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 35 it 100 total=8.2984 mle=1.6112 pcon=4.8282 forget=1.6659 favg=0.1931 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 35 it 150 total=8.1291 mle=1.3824 pcon=4.8273 forget=1.7221 favg=0.1973 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 35 it 200 total=8.1619 mle=1.4585 pcon=4.8264 forget=1.6904 favg=0.1866 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 35 it 250 total=8.1618 mle=1.4026 pcon=4.8255 forget=1.7357 favg=0.1980 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 35 it 300 total=8.2564 mle=1.4972 pcon=4.8247 forget=1.6962 favg=0.2383 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 35 it 350 total=8.2745 mle=1.4956 pcon=4.8239 forget=1.7073 favg=0.2477 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 36 it 10 total=8.2577 mle=1.5192 pcon=4.8231 forget=1.7035 favg=0.2119 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 36 it 60 total=8.3228 mle=1.5345 pcon=4.8221 forget=1.7350 favg=0.2311 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 36 it 110 total=8.3205 mle=1.5507 pcon=4.8212 forget=1.7132 favg=0.2354 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 36 it 160 total=8.1076 mle=1.4322 pcon=4.8205 forget=1.7031 favg=0.1519 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 36 it 210 total=8.4271 mle=1.6300 pcon=4.8196 forget=1.6974 favg=0.2800 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 36 it 260 total=8.2340 mle=1.5040 pcon=4.8189 forget=1.6975 favg=0.2136 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 36 it 310 total=8.3764 mle=1.4821 pcon=4.8181 forget=1.7307 favg=0.3455 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 36 it 360 total=8.1673 mle=1.4481 pcon=4.8174 forget=1.6970 favg=0.2048 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 20 total=8.3281 mle=1.5189 pcon=4.8166 forget=1.7274 favg=0.2651 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 37 it 70 total=8.1872 mle=1.5509 pcon=4.8157 forget=1.6712 favg=0.1493 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 37 it 120 total=8.3299 mle=1.5144 pcon=4.8147 forget=1.7165 favg=0.2844 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 170 total=8.3332 mle=1.4711 pcon=4.8138 forget=1.6943 favg=0.3540 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 37 it 220 total=8.4274 mle=1.5648 pcon=4.8130 forget=1.6722 favg=0.3774 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 37 it 270 total=8.3691 mle=1.5569 pcon=4.8123 forget=1.6660 favg=0.3340 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 37 it 320 total=8.4512 mle=1.5071 pcon=4.8115 forget=1.6970 favg=0.4355 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 37 it 370 total=8.4317 mle=1.5418 pcon=4.8109 forget=1.6645 favg=0.4146 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 38 it 30 total=8.4706 mle=1.4978 pcon=4.8103 forget=1.7094 favg=0.4531 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 38 it 80 total=8.6188 mle=1.5128 pcon=4.8097 forget=1.7343 favg=0.5620 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 38 it 130 total=8.5828 mle=1.5793 pcon=4.8091 forget=1.6988 favg=0.4956 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 38 it 180 total=8.4983 mle=1.5130 pcon=4.8084 forget=1.7116 favg=0.4653 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 38 it 230 total=8.7837 mle=1.5720 pcon=4.8078 forget=1.7462 favg=0.6577 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 38 it 280 total=8.7159 mle=1.5266 pcon=4.8074 forget=1.7457 favg=0.6362 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 38 it 330 total=8.8007 mle=1.6299 pcon=4.8068 forget=1.7499 favg=0.6143 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 38 it 380 total=8.6409 mle=1.4276 pcon=4.8061 forget=1.7661 favg=0.6411 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 39 it 40 total=8.8333 mle=1.5011 pcon=4.8057 forget=1.7692 favg=0.7573 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 39 it 90 total=8.8369 mle=1.5549 pcon=4.8052 forget=1.7996 favg=0.6772 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 39 it 140 total=8.9620 mle=1.5810 pcon=4.8047 forget=1.7946 favg=0.7817 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 39 it 190 total=8.7386 mle=1.3973 pcon=4.8044 forget=1.8064 favg=0.7305 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 39 it 240 total=8.7662 mle=1.3970 pcon=4.8041 forget=1.8396 favg=0.7256 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 39 it 290 total=8.9154 mle=1.5174 pcon=4.8037 forget=1.8185 favg=0.7759 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 39 it 340 total=8.8055 mle=1.4450 pcon=4.8034 forget=1.8686 favg=0.6885 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 0 total=8.6360 mle=1.3252 pcon=4.8031 forget=1.8359 favg=0.6719 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 50 total=8.9859 mle=1.5386 pcon=4.8026 forget=1.8708 favg=0.7739 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 40 it 100 total=8.6679 mle=1.3372 pcon=4.8022 forget=1.8586 favg=0.6699 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 40 it 150 total=8.8955 mle=1.4616 pcon=4.8018 forget=1.8734 favg=0.7588 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 40 it 200 total=8.8644 mle=1.3663 pcon=4.8015 forget=1.8929 favg=0.8037 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 40 it 250 total=8.9037 mle=1.4585 pcon=4.8011 forget=1.9010 favg=0.7432 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 40 it 300 total=8.9244 mle=1.4816 pcon=4.8009 forget=1.8909 favg=0.7510 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 40 it 350 total=8.8176 mle=1.3750 pcon=4.8005 forget=1.8863 favg=0.7559 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 41 it 10 total=8.8651 mle=1.4108 pcon=4.8001 forget=1.9150 favg=0.7393 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 41 it 60 total=8.9314 mle=1.4206 pcon=4.8000 forget=1.9373 favg=0.7734 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 41 it 110 total=8.8725 mle=1.3839 pcon=4.7997 forget=1.9325 favg=0.7563 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 41 it 160 total=8.9228 mle=1.3708 pcon=4.7994 forget=1.9274 favg=0.8252 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 41 it 210 total=8.8303 mle=1.4031 pcon=4.7991 forget=1.9104 favg=0.7178 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 41 it 260 total=8.8310 mle=1.2861 pcon=4.7989 forget=1.9964 favg=0.7495 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 41 it 310 total=8.9243 mle=1.4149 pcon=4.7987 forget=1.9754 favg=0.7354 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 41 it 360 total=8.9493 mle=1.4323 pcon=4.7984 forget=1.9603 favg=0.7583 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 42 it 20 total=8.9864 mle=1.3657 pcon=4.7982 forget=1.9748 favg=0.8477 nr=128 nf=101 protos=600 fproto_sim=NA
[loss] ep 42 it 70 total=9.0130 mle=1.4239 pcon=4.7980 forget=1.9839 favg=0.8071 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 42 it 120 total=9.0081 mle=1.3680 pcon=4.7977 forget=1.9704 favg=0.8721 nr=128 nf=92 protos=600 fproto_sim=NA
 86%|████████▌ | 43/50 [12:47<01:17, 11.01s/it] 88%|████████▊ | 44/50 [12:57<01:04, 10.70s/it] 90%|█████████ | 45/50 [13:07<00:53, 10.62s/it] 92%|█████████▏| 46/50 [13:17<00:41, 10.41s/it] 94%|█████████▍| 47/50 [13:27<00:30, 10.28s/it] 96%|█████████▌| 48/50 [13:37<00:20, 10.18s/it] 98%|█████████▊| 49/50 [13:47<00:10, 10.08s/it]100%|██████████| 50/50 [13:57<00:00, 10.07s/it]100%|██████████| 50/50 [13:57<00:00, 16.75s/it]
[loss] ep 42 it 170 total=9.0279 mle=1.4212 pcon=4.7974 forget=2.0231 favg=0.7861 nr=128 nf=90 protos=600 fproto_sim=NA
[loss] ep 42 it 220 total=9.0257 mle=1.3621 pcon=4.7971 forget=2.0140 favg=0.8525 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 42 it 270 total=9.1626 mle=1.4562 pcon=4.7969 forget=2.0228 favg=0.8867 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 42 it 320 total=9.1389 mle=1.4302 pcon=4.7968 forget=2.0267 favg=0.8853 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 42 it 370 total=9.1556 mle=1.4908 pcon=4.7965 forget=2.0143 favg=0.8540 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 43 it 30 total=9.1644 mle=1.5079 pcon=4.7965 forget=2.0358 favg=0.8242 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 43 it 80 total=9.3412 mle=1.5298 pcon=4.7961 forget=2.0832 favg=0.9321 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 130 total=9.2258 mle=1.4686 pcon=4.7959 forget=2.0809 favg=0.8804 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 43 it 180 total=9.1943 mle=1.3748 pcon=4.7955 forget=2.1031 favg=0.9209 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 43 it 230 total=9.2669 mle=1.3722 pcon=4.7953 forget=2.1439 favg=0.9556 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 43 it 280 total=9.2457 mle=1.3766 pcon=4.7951 forget=2.1365 favg=0.9375 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 330 total=9.3319 mle=1.4162 pcon=4.7949 forget=2.1139 favg=1.0068 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 43 it 380 total=9.3134 mle=1.4205 pcon=4.7948 forget=2.1348 favg=0.9634 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 40 total=9.3414 mle=1.3383 pcon=4.7948 forget=2.1830 favg=1.0254 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 90 total=9.3891 mle=1.4107 pcon=4.7946 forget=2.1994 favg=0.9844 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 44 it 140 total=9.3849 mle=1.4448 pcon=4.7946 forget=2.2002 favg=0.9453 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 44 it 190 total=9.6094 mle=1.5263 pcon=4.7944 forget=2.1744 favg=1.1143 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 44 it 240 total=9.5287 mle=1.4694 pcon=4.7944 forget=2.2346 favg=1.0303 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 44 it 290 total=9.5637 mle=1.4801 pcon=4.7945 forget=2.2403 favg=1.0488 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 44 it 340 total=9.5260 mle=1.3545 pcon=4.7944 forget=2.2756 favg=1.1016 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 45 it 0 total=9.4774 mle=1.3544 pcon=4.7945 forget=2.2709 favg=1.0576 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 45 it 50 total=9.5968 mle=1.4438 pcon=4.7944 forget=2.2923 favg=1.0664 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 45 it 100 total=9.8187 mle=1.5022 pcon=4.7946 forget=2.3022 favg=1.2197 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 45 it 150 total=9.6718 mle=1.3955 pcon=4.7947 forget=2.3136 favg=1.1680 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 45 it 200 total=9.6869 mle=1.3560 pcon=4.7949 forget=2.3602 favg=1.1758 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 45 it 250 total=9.6703 mle=1.3657 pcon=4.7950 forget=2.3436 favg=1.1660 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 45 it 300 total=9.6289 mle=1.3521 pcon=4.7952 forget=2.3469 favg=1.1348 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 45 it 350 total=9.5615 mle=1.2701 pcon=4.7955 forget=2.3875 favg=1.1084 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 46 it 10 total=9.7673 mle=1.3412 pcon=4.7958 forget=2.3939 favg=1.2363 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 46 it 60 total=9.9773 mle=1.4716 pcon=4.7959 forget=2.4217 favg=1.2881 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 46 it 110 total=9.8549 mle=1.3770 pcon=4.7960 forget=2.4115 favg=1.2705 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 46 it 160 total=9.9969 mle=1.4796 pcon=4.7962 forget=2.4125 favg=1.3086 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 46 it 210 total=9.8581 mle=1.3813 pcon=4.7963 forget=2.4636 favg=1.2168 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 46 it 260 total=9.9585 mle=1.4735 pcon=4.7965 forget=2.4386 favg=1.2500 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 46 it 310 total=9.8470 mle=1.3399 pcon=4.7968 forget=2.4582 favg=1.2520 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 46 it 360 total=10.0384 mle=1.4414 pcon=4.7973 forget=2.4891 favg=1.3105 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 47 it 20 total=10.0147 mle=1.4202 pcon=4.7978 forget=2.4685 favg=1.3281 nr=128 nf=92 protos=600 fproto_sim=NA
[loss] ep 47 it 70 total=10.0248 mle=1.3799 pcon=4.7982 forget=2.5039 favg=1.3428 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 47 it 120 total=10.1108 mle=1.4240 pcon=4.7986 forget=2.5239 favg=1.3643 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 47 it 170 total=10.2548 mle=1.5480 pcon=4.7989 forget=2.5300 favg=1.3779 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 47 it 220 total=10.0318 mle=1.3984 pcon=4.7994 forget=2.5185 favg=1.3154 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 47 it 270 total=10.1518 mle=1.4398 pcon=4.7998 forget=2.5069 favg=1.4053 nr=128 nf=102 protos=600 fproto_sim=NA
[loss] ep 47 it 320 total=10.0784 mle=1.3445 pcon=4.8004 forget=2.5340 favg=1.3994 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 47 it 370 total=10.0984 mle=1.3386 pcon=4.8009 forget=2.5361 favg=1.4229 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 48 it 30 total=10.3437 mle=1.5718 pcon=4.8015 forget=2.5192 favg=1.4512 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 48 it 80 total=10.2165 mle=1.4843 pcon=4.8020 forget=2.5493 favg=1.3809 nr=128 nf=95 protos=600 fproto_sim=NA
[loss] ep 48 it 130 total=10.2230 mle=1.3528 pcon=4.8027 forget=2.5694 favg=1.4980 nr=128 nf=93 protos=600 fproto_sim=NA
[loss] ep 48 it 180 total=10.2316 mle=1.4718 pcon=4.8033 forget=2.5640 favg=1.3926 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 48 it 230 total=10.1087 mle=1.3170 pcon=4.8040 forget=2.5785 favg=1.4092 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 48 it 280 total=10.1167 mle=1.3074 pcon=4.8049 forget=2.5874 favg=1.4170 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 48 it 330 total=10.1551 mle=1.3122 pcon=4.8057 forget=2.6026 favg=1.4346 nr=128 nf=100 protos=600 fproto_sim=NA
[loss] ep 48 it 380 total=10.3314 mle=1.4424 pcon=4.8065 forget=2.5728 favg=1.5098 nr=128 nf=99 protos=600 fproto_sim=NA
[loss] ep 49 it 40 total=10.2822 mle=1.3156 pcon=4.8071 forget=2.6185 favg=1.5410 nr=128 nf=98 protos=600 fproto_sim=NA
[loss] ep 49 it 90 total=10.2997 mle=1.3980 pcon=4.8080 forget=2.6044 favg=1.4893 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 49 it 140 total=10.2559 mle=1.3579 pcon=4.8087 forget=2.6069 favg=1.4824 nr=128 nf=96 protos=600 fproto_sim=NA
[loss] ep 49 it 190 total=10.3766 mle=1.4064 pcon=4.8094 forget=2.6246 favg=1.5361 nr=128 nf=91 protos=600 fproto_sim=NA
[loss] ep 49 it 240 total=10.1987 mle=1.3245 pcon=4.8101 forget=2.5963 favg=1.4678 nr=128 nf=94 protos=600 fproto_sim=NA
[loss] ep 49 it 290 total=10.2794 mle=1.3721 pcon=4.8109 forget=2.6032 favg=1.4932 nr=128 nf=97 protos=600 fproto_sim=NA
[loss] ep 49 it 340 total=10.4226 mle=1.4244 pcon=4.8120 forget=2.6276 favg=1.5586 nr=128 nf=99 protos=600 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[peft] set_adapter(list) failed: unhashable type: 'list'; try adapter fusion
[peft] adapter fusion failed: adapter fusion API not available or single adapter provided; fallback to last adapter
[peft] active adapter set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:49,  2.30it/s]  3%|▎         | 11/391 [00:00<00:14, 26.24it/s]  5%|▌         | 21/391 [00:00<00:08, 45.03it/s]  8%|▊         | 31/391 [00:00<00:06, 59.16it/s] 10%|█         | 41/391 [00:00<00:05, 69.65it/s] 13%|█▎        | 51/391 [00:00<00:04, 77.25it/s] 16%|█▌        | 61/391 [00:01<00:03, 82.75it/s] 18%|█▊        | 71/391 [00:01<00:03, 86.60it/s] 21%|██        | 81/391 [00:01<00:03, 89.45it/s] 23%|██▎       | 91/391 [00:01<00:03, 91.61it/s] 26%|██▌       | 101/391 [00:01<00:03, 93.12it/s] 28%|██▊       | 111/391 [00:01<00:02, 93.83it/s] 31%|███       | 121/391 [00:01<00:02, 94.52it/s] 34%|███▎      | 131/391 [00:01<00:02, 95.03it/s] 36%|███▌      | 141/391 [00:01<00:02, 95.50it/s] 39%|███▊      | 151/391 [00:01<00:02, 95.64it/s] 41%|████      | 161/391 [00:02<00:02, 95.98it/s] 44%|████▎     | 171/391 [00:02<00:02, 96.14it/s] 46%|████▋     | 181/391 [00:02<00:02, 95.97it/s] 49%|████▉     | 191/391 [00:02<00:02, 96.00it/s] 51%|█████▏    | 201/391 [00:02<00:01, 96.18it/s] 54%|█████▍    | 211/391 [00:02<00:01, 96.17it/s] 57%|█████▋    | 221/391 [00:02<00:01, 96.18it/s] 59%|█████▉    | 231/391 [00:02<00:01, 96.17it/s] 62%|██████▏   | 241/391 [00:02<00:01, 96.07it/s] 64%|██████▍   | 251/391 [00:03<00:01, 96.10it/s] 67%|██████▋   | 261/391 [00:03<00:01, 95.89it/s] 69%|██████▉   | 271/391 [00:03<00:01, 95.97it/s] 72%|███████▏  | 281/391 [00:03<00:01, 95.97it/s] 74%|███████▍  | 291/391 [00:03<00:01, 96.12it/s] 77%|███████▋  | 301/391 [00:03<00:00, 96.20it/s] 80%|███████▉  | 311/391 [00:03<00:00, 96.05it/s] 82%|████████▏ | 321/391 [00:03<00:00, 96.04it/s] 85%|████████▍ | 331/391 [00:03<00:00, 96.18it/s] 87%|████████▋ | 341/391 [00:03<00:00, 96.23it/s] 90%|████████▉ | 351/391 [00:04<00:00, 96.22it/s] 92%|█████████▏| 361/391 [00:04<00:00, 95.87it/s] 95%|█████████▍| 371/391 [00:04<00:00, 96.48it/s] 97%|█████████▋| 381/391 [00:04<00:00, 96.95it/s]100%|██████████| 391/391 [00:04<00:00, 95.10it/s]100%|██████████| 391/391 [00:04<00:00, 87.04it/s]
50000 images processed, 4.5572919845581055 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:31,  2.44it/s] 13%|█▎        | 10/79 [00:00<00:02, 24.69it/s] 25%|██▌       | 20/79 [00:00<00:01, 44.27it/s] 38%|███▊      | 30/79 [00:00<00:00, 58.99it/s] 51%|█████     | 40/79 [00:00<00:00, 69.45it/s] 63%|██████▎   | 50/79 [00:00<00:00, 77.10it/s] 76%|███████▌  | 60/79 [00:01<00:00, 82.94it/s] 89%|████████▊ | 70/79 [00:01<00:00, 87.21it/s]100%|██████████| 79/79 [00:01<00:00, 44.93it/s]
10000 images processed, 1.7634148597717285 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:24,  2.39it/s]  5%|▍         | 10/204 [00:00<00:08, 24.24it/s] 10%|▉         | 20/204 [00:00<00:04, 43.47it/s] 15%|█▍        | 30/204 [00:00<00:03, 57.84it/s] 20%|█▉        | 40/204 [00:00<00:02, 68.49it/s] 25%|██▍       | 50/204 [00:00<00:02, 75.91it/s] 29%|██▉       | 60/204 [00:01<00:01, 81.17it/s] 34%|███▍      | 70/204 [00:01<00:01, 85.10it/s] 39%|███▉      | 80/204 [00:01<00:01, 87.69it/s] 44%|████▍     | 90/204 [00:01<00:01, 89.56it/s] 49%|████▉     | 100/204 [00:01<00:01, 90.94it/s] 54%|█████▍    | 110/204 [00:01<00:01, 92.10it/s] 59%|█████▉    | 120/204 [00:01<00:00, 92.76it/s] 64%|██████▎   | 130/204 [00:01<00:00, 93.01it/s] 69%|██████▊   | 140/204 [00:01<00:00, 93.57it/s] 74%|███████▎  | 150/204 [00:02<00:00, 93.57it/s] 78%|███████▊  | 160/204 [00:02<00:00, 93.90it/s] 83%|████████▎ | 170/204 [00:02<00:00, 94.23it/s] 88%|████████▊ | 180/204 [00:02<00:00, 94.60it/s] 93%|█████████▎| 190/204 [00:02<00:00, 95.41it/s] 98%|█████████▊| 200/204 [00:02<00:00, 95.90it/s]100%|██████████| 204/204 [00:02<00:00, 79.16it/s]
26032 images processed, 2.611785650253296 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.77it/s] 10%|█         | 8/79 [00:00<00:04, 15.34it/s] 23%|██▎       | 18/79 [00:00<00:01, 33.38it/s] 35%|███▌      | 28/79 [00:00<00:01, 48.25it/s] 48%|████▊     | 38/79 [00:00<00:00, 59.92it/s] 61%|██████    | 48/79 [00:01<00:00, 68.68it/s] 73%|███████▎  | 58/79 [00:01<00:00, 75.13it/s] 86%|████████▌ | 68/79 [00:01<00:00, 81.01it/s] 99%|█████████▊| 78/79 [00:01<00:00, 85.56it/s]100%|██████████| 79/79 [00:01<00:00, 55.41it/s]
10000 images processed, 1.4611124992370605 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:37,  2.08it/s] 13%|█▎        | 10/79 [00:00<00:03, 22.12it/s] 25%|██▌       | 20/79 [00:00<00:01, 40.59it/s] 38%|███▊      | 30/79 [00:00<00:00, 55.17it/s] 51%|█████     | 40/79 [00:00<00:00, 66.05it/s] 63%|██████▎   | 50/79 [00:01<00:00, 74.28it/s] 76%|███████▌  | 60/79 [00:01<00:00, 80.71it/s] 89%|████████▊ | 70/79 [00:01<00:00, 85.45it/s]100%|██████████| 79/79 [00:01<00:00, 60.90it/s]
10000 images processed, 1.3156142234802246 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:34,  1.99it/s] 16%|█▌        | 11/70 [00:00<00:02, 23.40it/s] 30%|███       | 21/70 [00:00<00:01, 41.06it/s] 44%|████▍     | 31/70 [00:00<00:00, 55.12it/s] 59%|█████▊    | 41/70 [00:00<00:00, 66.00it/s] 73%|███████▎  | 51/70 [00:01<00:00, 74.59it/s] 87%|████████▋ | 61/70 [00:01<00:00, 80.94it/s]100%|██████████| 70/70 [00:01<00:00, 57.07it/s]
8925 images processed, 1.2537009716033936 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:41,  1.07it/s] 11%|█         | 5/45 [00:01<00:06,  6.17it/s] 18%|█▊        | 8/45 [00:01<00:04,  9.22it/s] 38%|███▊      | 17/45 [00:01<00:01, 19.22it/s] 51%|█████     | 23/45 [00:01<00:01, 16.50it/s] 73%|███████▎  | 33/45 [00:02<00:00, 24.27it/s] 87%|████████▋ | 39/45 [00:02<00:00, 25.43it/s] 96%|█████████▌| 43/45 [00:02<00:00, 26.29it/s]100%|██████████| 45/45 [00:02<00:00, 18.55it/s]
5640 images processed, 2.443936586380005 seconds used

16.984456539154053
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Traceback (most recent call last):
  File "/home/shaokun/PALM/eval_cifar.py", line 19, in <module>
    eval_maha(args)
  File "/home/shaokun/PALM/util/evaluations/mahalanobis.py", line 53, in eval_maha
    ftest_ssd = prepos_feat_ssd(ftest)
  File "/home/shaokun/PALM/util/evaluations/mahalanobis.py", line 51, in <lambda>
    prepos_feat_ssd = lambda x: (x - mean_feat) / (std_feat + 1e-10)
ValueError: operands could not be broadcast together with shapes (0,) (512,) 
