nohup: ignoring input
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=25, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc=None, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10,64,22,42,9,90', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=1.0, forget_margin=100.0, forget_strategy='ga', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
[trainable] param_count=21605312 tensors=112
  0%|          | 0/25 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:638: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
  4%|▍         | 1/25 [00:30<12:21, 30.88s/it]  8%|▊         | 2/25 [00:48<08:56, 23.34s/it] 12%|█▏        | 3/25 [01:08<07:51, 21.43s/it] 16%|█▌        | 4/25 [01:26<07:08, 20.42s/it] 20%|██        | 5/25 [01:45<06:36, 19.82s/it] 24%|██▍       | 6/25 [02:03<06:01, 19.01s/it] 28%|██▊       | 7/25 [02:21<05:35, 18.66s/it] 32%|███▏      | 8/25 [02:39<05:15, 18.56s/it] 36%|███▌      | 9/25 [02:57<04:54, 18.39s/it] 40%|████      | 10/25 [03:15<04:32, 18.16s/it] 44%|████▍     | 11/25 [03:32<04:10, 17.86s/it] 48%|████▊     | 12/25 [03:49<03:49, 17.64s/it] 52%|█████▏    | 13/25 [04:06<03:30, 17.51s/it] 56%|█████▌    | 14/25 [04:24<03:13, 17.56s/it] 60%|██████    | 15/25 [04:41<02:55, 17.53s/it] 64%|██████▍   | 16/25 [04:59<02:37, 17.52s/it] 68%|██████▊   | 17/25 [05:16<02:19, 17.47s/it][loss-ga] ep 0 it 0 total=-0.0095 ce_r=0.0326 ce_f=0.0421
[loss-ga] ep 0 it 50 total=-0.0031 ce_r=0.0130 ce_f=0.0161
[loss-ga] ep 0 it 100 total=-0.0182 ce_r=0.0259 ce_f=0.0441
[loss-ga] ep 0 it 150 total=-0.0210 ce_r=0.0310 ce_f=0.0520
[loss-ga] ep 0 it 200 total=0.0156 ce_r=0.0243 ce_f=0.0087
[loss-ga] ep 0 it 250 total=-0.0177 ce_r=0.0290 ce_f=0.0467
[loss-ga] ep 0 it 300 total=-0.0131 ce_r=0.1056 ce_f=0.1187
[loss-ga] ep 0 it 350 total=-0.0154 ce_r=0.0425 ce_f=0.0579
[loss-ga] ep 1 it 10 total=-0.0031 ce_r=0.0152 ce_f=0.0183
[loss-ga] ep 1 it 60 total=0.0116 ce_r=0.0295 ce_f=0.0178
[loss-ga] ep 1 it 110 total=-0.0017 ce_r=0.0128 ce_f=0.0145
[loss-ga] ep 1 it 160 total=-0.0137 ce_r=0.0435 ce_f=0.0572
[loss-ga] ep 1 it 210 total=-0.0039 ce_r=0.0170 ce_f=0.0208
[loss-ga] ep 1 it 260 total=-0.0161 ce_r=0.0211 ce_f=0.0372
[loss-ga] ep 1 it 310 total=-0.0222 ce_r=0.0603 ce_f=0.0824
[loss-ga] ep 1 it 360 total=0.0001 ce_r=0.0296 ce_f=0.0295
[loss-ga] ep 2 it 20 total=-0.0518 ce_r=0.1707 ce_f=0.2225
[loss-ga] ep 2 it 70 total=0.0016 ce_r=0.0105 ce_f=0.0089
[loss-ga] ep 2 it 120 total=-0.0068 ce_r=0.0163 ce_f=0.0231
[loss-ga] ep 2 it 170 total=0.0054 ce_r=0.0272 ce_f=0.0219
[loss-ga] ep 2 it 220 total=-0.0588 ce_r=0.0739 ce_f=0.1326
[loss-ga] ep 2 it 270 total=-0.0341 ce_r=0.0572 ce_f=0.0913
[loss-ga] ep 2 it 320 total=-0.0108 ce_r=0.0785 ce_f=0.0893
[loss-ga] ep 2 it 370 total=-0.0341 ce_r=0.0540 ce_f=0.0881
[loss-ga] ep 3 it 30 total=-0.1427 ce_r=0.1674 ce_f=0.3101
[loss-ga] ep 3 it 80 total=-0.0561 ce_r=0.0665 ce_f=0.1227
[loss-ga] ep 3 it 130 total=-0.1794 ce_r=0.2901 ce_f=0.4695
[loss-ga] ep 3 it 180 total=-0.2022 ce_r=0.3341 ce_f=0.5363
[loss-ga] ep 3 it 230 total=-0.4867 ce_r=0.5099 ce_f=0.9965
[loss-ga] ep 3 it 280 total=-0.4014 ce_r=0.4363 ce_f=0.8377
[loss-ga] ep 3 it 330 total=-0.4921 ce_r=0.5034 ce_f=0.9955
[loss-ga] ep 3 it 380 total=-0.7296 ce_r=0.7622 ce_f=1.4918
[loss-ga] ep 4 it 40 total=-0.5893 ce_r=0.6059 ce_f=1.1952
[loss-ga] ep 4 it 90 total=-0.5758 ce_r=0.6390 ce_f=1.2148
[loss-ga] ep 4 it 140 total=-0.4826 ce_r=0.5232 ce_f=1.0058
[loss-ga] ep 4 it 190 total=-0.7909 ce_r=0.8166 ce_f=1.6075
[loss-ga] ep 4 it 240 total=-0.9840 ce_r=1.0414 ce_f=2.0254
[loss-ga] ep 4 it 290 total=-1.1162 ce_r=1.2248 ce_f=2.3410
[loss-ga] ep 4 it 340 total=-0.7343 ce_r=0.9524 ce_f=1.6867
[loss-ga] ep 5 it 0 total=-1.1723 ce_r=1.2395 ce_f=2.4118
[loss-ga] ep 5 it 50 total=-1.2910 ce_r=1.3072 ce_f=2.5982
[loss-ga] ep 5 it 100 total=-1.5626 ce_r=1.6264 ce_f=3.1890
[loss-ga] ep 5 it 150 total=-1.6221 ce_r=1.6278 ce_f=3.2500
[loss-ga] ep 5 it 200 total=-2.0978 ce_r=2.1557 ce_f=4.2535
[loss-ga] ep 5 it 250 total=-1.6631 ce_r=1.7885 ce_f=3.4516
[loss-ga] ep 5 it 300 total=-2.1273 ce_r=2.1424 ce_f=4.2697
[loss-ga] ep 5 it 350 total=-1.8478 ce_r=1.9433 ce_f=3.7911
[loss-ga] ep 6 it 10 total=-1.5714 ce_r=1.7351 ce_f=3.3065
[loss-ga] ep 6 it 60 total=-2.6266 ce_r=2.8774 ce_f=5.5040
[loss-ga] ep 6 it 110 total=-2.9764 ce_r=3.1517 ce_f=6.1281
[loss-ga] ep 6 it 160 total=-2.6743 ce_r=2.9223 ce_f=5.5966
[loss-ga] ep 6 it 210 total=-3.5251 ce_r=4.0626 ce_f=7.5877
[loss-ga] ep 6 it 260 total=-4.4107 ce_r=4.8047 ce_f=9.2154
[loss-ga] ep 6 it 310 total=-4.3779 ce_r=4.9682 ce_f=9.3461
[loss-ga] ep 6 it 360 total=-4.5234 ce_r=5.1267 ce_f=9.6501
[loss-ga] ep 7 it 20 total=-5.4012 ce_r=6.0898 ce_f=11.4910
[loss-ga] ep 7 it 70 total=-5.3333 ce_r=6.0233 ce_f=11.3566
[loss-ga] ep 7 it 120 total=-5.3958 ce_r=5.8321 ce_f=11.2279
[loss-ga] ep 7 it 170 total=-5.3951 ce_r=5.7786 ce_f=11.1738
[loss-ga] ep 7 it 220 total=-5.6935 ce_r=6.0687 ce_f=11.7622
[loss-ga] ep 7 it 270 total=-5.6172 ce_r=5.9445 ce_f=11.5617
[loss-ga] ep 7 it 320 total=-5.7896 ce_r=6.3144 ce_f=12.1040
[loss-ga] ep 7 it 370 total=-5.6915 ce_r=6.2338 ce_f=11.9253
[loss-ga] ep 8 it 30 total=-5.6736 ce_r=6.2062 ce_f=11.8797
[loss-ga] ep 8 it 80 total=-5.7806 ce_r=6.0263 ce_f=11.8068
[loss-ga] ep 8 it 130 total=-5.6936 ce_r=5.9437 ce_f=11.6374
[loss-ga] ep 8 it 180 total=-5.6451 ce_r=5.8248 ce_f=11.4698
[loss-ga] ep 8 it 230 total=-5.6058 ce_r=5.6810 ce_f=11.2868
[loss-ga] ep 8 it 280 total=-5.8199 ce_r=5.9220 ce_f=11.7419
[loss-ga] ep 8 it 330 total=-6.1533 ce_r=6.3952 ce_f=12.5485
[loss-ga] ep 8 it 380 total=-5.9782 ce_r=6.2048 ce_f=12.1831
[loss-ga] ep 9 it 40 total=-5.9220 ce_r=6.4574 ce_f=12.3794
[loss-ga] ep 9 it 90 total=-5.7763 ce_r=5.9922 ce_f=11.7685
[loss-ga] ep 9 it 140 total=-5.9948 ce_r=6.1069 ce_f=12.1017
[loss-ga] ep 9 it 190 total=-6.1707 ce_r=6.2836 ce_f=12.4542
[loss-ga] ep 9 it 240 total=-5.7299 ce_r=6.0628 ce_f=11.7927
[loss-ga] ep 9 it 290 total=-5.8611 ce_r=6.2040 ce_f=12.0651
[loss-ga] ep 9 it 340 total=-6.0660 ce_r=6.2821 ce_f=12.3481
[loss-ga] ep 10 it 0 total=-6.1251 ce_r=6.3471 ce_f=12.4722
[loss-ga] ep 10 it 50 total=-6.2335 ce_r=6.3801 ce_f=12.6136
[loss-ga] ep 10 it 100 total=-6.0707 ce_r=6.2191 ce_f=12.2898
[loss-ga] ep 10 it 150 total=-6.2131 ce_r=6.3672 ce_f=12.5803
[loss-ga] ep 10 it 200 total=-6.1100 ce_r=6.1856 ce_f=12.2956
[loss-ga] ep 10 it 250 total=-6.2126 ce_r=6.2948 ce_f=12.5073
[loss-ga] ep 10 it 300 total=-6.0647 ce_r=6.2217 ce_f=12.2865
[loss-ga] ep 10 it 350 total=-6.1046 ce_r=6.3298 ce_f=12.4344
[loss-ga] ep 11 it 10 total=-6.2093 ce_r=6.2633 ce_f=12.4726
[loss-ga] ep 11 it 60 total=-6.2051 ce_r=6.3971 ce_f=12.6022
[loss-ga] ep 11 it 110 total=-5.9733 ce_r=6.2087 ce_f=12.1820
[loss-ga] ep 11 it 160 total=-6.1436 ce_r=6.2126 ce_f=12.3562
[loss-ga] ep 11 it 210 total=-6.4499 ce_r=6.6782 ce_f=13.1280
[loss-ga] ep 11 it 260 total=-6.3578 ce_r=6.5180 ce_f=12.8759
[loss-ga] ep 11 it 310 total=-6.6093 ce_r=6.6550 ce_f=13.2643
[loss-ga] ep 11 it 360 total=-6.0900 ce_r=6.2654 ce_f=12.3554
[loss-ga] ep 12 it 20 total=-6.4587 ce_r=6.5818 ce_f=13.0405
[loss-ga] ep 12 it 70 total=-6.4642 ce_r=6.5506 ce_f=13.0148
[loss-ga] ep 12 it 120 total=-6.3697 ce_r=6.4007 ce_f=12.7704
[loss-ga] ep 12 it 170 total=-6.3498 ce_r=6.5227 ce_f=12.8725
[loss-ga] ep 12 it 220 total=-6.4562 ce_r=6.4908 ce_f=12.9470
[loss-ga] ep 12 it 270 total=-6.4040 ce_r=6.5334 ce_f=12.9374
[loss-ga] ep 12 it 320 total=-6.4067 ce_r=6.5173 ce_f=12.9239
[loss-ga] ep 12 it 370 total=-6.4286 ce_r=6.5556 ce_f=12.9843
[loss-ga] ep 13 it 30 total=-6.5396 ce_r=6.6050 ce_f=13.1446
[loss-ga] ep 13 it 80 total=-6.5226 ce_r=6.6168 ce_f=13.1394
[loss-ga] ep 13 it 130 total=-6.6783 ce_r=6.7249 ce_f=13.4033
[loss-ga] ep 13 it 180 total=-6.5143 ce_r=6.7893 ce_f=13.3036
[loss-ga] ep 13 it 230 total=-6.4983 ce_r=6.6098 ce_f=13.1082
[loss-ga] ep 13 it 280 total=-6.6015 ce_r=6.6456 ce_f=13.2472
[loss-ga] ep 13 it 330 total=-6.4388 ce_r=6.6115 ce_f=13.0503
[loss-ga] ep 13 it 380 total=-6.4433 ce_r=6.7659 ce_f=13.2092
[loss-ga] ep 14 it 40 total=-6.7417 ce_r=6.8274 ce_f=13.5691
[loss-ga] ep 14 it 90 total=-6.7010 ce_r=6.7982 ce_f=13.4992
[loss-ga] ep 14 it 140 total=-6.8384 ce_r=6.9458 ce_f=13.7842
[loss-ga] ep 14 it 190 total=-6.6257 ce_r=6.6403 ce_f=13.2659
[loss-ga] ep 14 it 240 total=-6.8654 ce_r=7.0411 ce_f=13.9065
[loss-ga] ep 14 it 290 total=-6.9414 ce_r=7.0627 ce_f=14.0042
[loss-ga] ep 14 it 340 total=-6.9455 ce_r=7.0342 ce_f=13.9797
[loss-ga] ep 15 it 0 total=-6.7194 ce_r=6.9175 ce_f=13.6369
[loss-ga] ep 15 it 50 total=-7.1325 ce_r=7.1702 ce_f=14.3027
[loss-ga] ep 15 it 100 total=-6.8547 ce_r=6.9350 ce_f=13.7897
[loss-ga] ep 15 it 150 total=-6.6686 ce_r=6.8352 ce_f=13.5038
[loss-ga] ep 15 it 200 total=-6.9154 ce_r=7.0045 ce_f=13.9200
[loss-ga] ep 15 it 250 total=-6.8592 ce_r=6.9144 ce_f=13.7737
[loss-ga] ep 15 it 300 total=-7.1433 ce_r=7.1962 ce_f=14.3396
[loss-ga] ep 15 it 350 total=-6.9007 ce_r=7.1555 ce_f=14.0561
[loss-ga] ep 16 it 10 total=-6.9831 ce_r=7.0138 ce_f=13.9969
[loss-ga] ep 16 it 60 total=-6.9350 ce_r=6.9759 ce_f=13.9110
[loss-ga] ep 16 it 110 total=-7.1824 ce_r=7.2936 ce_f=14.4760
[loss-ga] ep 16 it 160 total=-7.1205 ce_r=7.2625 ce_f=14.3830
[loss-ga] ep 16 it 210 total=-7.2751 ce_r=7.3303 ce_f=14.6054
[loss-ga] ep 16 it 260 total=-7.0806 ce_r=7.1327 ce_f=14.2132
[loss-ga] ep 16 it 310 total=-7.2705 ce_r=7.3109 ce_f=14.5814
[loss-ga] ep 16 it 360 total=-7.1402 ce_r=7.2330 ce_f=14.3733
[loss-ga] ep 17 it 20 total=-7.2552 ce_r=7.4751 ce_f=14.7303
[loss-ga] ep 17 it 70 total=-7.4999 ce_r=7.5646 ce_f=15.0645
 72%|███████▏  | 18/25 [05:34<02:03, 17.58s/it] 76%|███████▌  | 19/25 [05:51<01:44, 17.43s/it] 80%|████████  | 20/25 [06:09<01:27, 17.46s/it] 84%|████████▍ | 21/25 [06:26<01:10, 17.50s/it] 88%|████████▊ | 22/25 [06:43<00:52, 17.39s/it] 92%|█████████▏| 23/25 [07:01<00:34, 17.43s/it] 96%|█████████▌| 24/25 [07:19<00:17, 17.51s/it]100%|██████████| 25/25 [07:36<00:00, 17.51s/it]100%|██████████| 25/25 [07:36<00:00, 18.26s/it]
[loss-ga] ep 17 it 120 total=-7.1684 ce_r=7.2393 ce_f=14.4078
[loss-ga] ep 17 it 170 total=-7.3067 ce_r=7.4274 ce_f=14.7341
[loss-ga] ep 17 it 220 total=-7.3693 ce_r=7.5261 ce_f=14.8953
[loss-ga] ep 17 it 270 total=-7.5041 ce_r=7.5665 ce_f=15.0707
[loss-ga] ep 17 it 320 total=-7.2044 ce_r=7.2287 ce_f=14.4330
[loss-ga] ep 17 it 370 total=-7.2422 ce_r=7.4201 ce_f=14.6623
[loss-ga] ep 18 it 30 total=-7.1930 ce_r=7.4113 ce_f=14.6043
[loss-ga] ep 18 it 80 total=-7.4052 ce_r=7.4475 ce_f=14.8527
[loss-ga] ep 18 it 130 total=-7.3226 ce_r=7.3605 ce_f=14.6831
[loss-ga] ep 18 it 180 total=-7.3305 ce_r=7.3699 ce_f=14.7004
[loss-ga] ep 18 it 230 total=-7.4807 ce_r=7.5380 ce_f=15.0186
[loss-ga] ep 18 it 280 total=-7.4524 ce_r=7.5284 ce_f=14.9808
[loss-ga] ep 18 it 330 total=-7.6089 ce_r=7.7050 ce_f=15.3139
[loss-ga] ep 18 it 380 total=-7.4481 ce_r=7.4667 ce_f=14.9148
[loss-ga] ep 19 it 40 total=-7.3558 ce_r=7.4196 ce_f=14.7754
[loss-ga] ep 19 it 90 total=-7.6598 ce_r=7.7314 ce_f=15.3912
[loss-ga] ep 19 it 140 total=-7.6295 ce_r=7.6537 ce_f=15.2832
[loss-ga] ep 19 it 190 total=-7.5286 ce_r=7.6724 ce_f=15.2010
[loss-ga] ep 19 it 240 total=-7.3721 ce_r=7.5498 ce_f=14.9219
[loss-ga] ep 19 it 290 total=-7.4552 ce_r=7.6476 ce_f=15.1028
[loss-ga] ep 19 it 340 total=-7.5546 ce_r=7.6593 ce_f=15.2139
[loss-ga] ep 20 it 0 total=-7.4409 ce_r=7.6241 ce_f=15.0649
[loss-ga] ep 20 it 50 total=-7.6801 ce_r=7.7296 ce_f=15.4097
[loss-ga] ep 20 it 100 total=-7.7325 ce_r=7.7552 ce_f=15.4877
[loss-ga] ep 20 it 150 total=-7.7062 ce_r=7.7420 ce_f=15.4482
[loss-ga] ep 20 it 200 total=-7.7035 ce_r=7.7958 ce_f=15.4992
[loss-ga] ep 20 it 250 total=-7.6812 ce_r=7.7923 ce_f=15.4735
[loss-ga] ep 20 it 300 total=-7.5299 ce_r=7.6120 ce_f=15.1419
[loss-ga] ep 20 it 350 total=-7.6628 ce_r=7.7622 ce_f=15.4250
[loss-ga] ep 21 it 10 total=-7.7863 ce_r=7.8175 ce_f=15.6038
[loss-ga] ep 21 it 60 total=-7.5924 ce_r=7.6965 ce_f=15.2889
[loss-ga] ep 21 it 110 total=-7.5964 ce_r=7.6115 ce_f=15.2079
[loss-ga] ep 21 it 160 total=-7.6868 ce_r=7.7498 ce_f=15.4367
[loss-ga] ep 21 it 210 total=-7.5778 ce_r=7.6145 ce_f=15.1924
[loss-ga] ep 21 it 260 total=-7.7147 ce_r=7.8090 ce_f=15.5237
[loss-ga] ep 21 it 310 total=-7.5266 ce_r=7.5481 ce_f=15.0747
[loss-ga] ep 21 it 360 total=-7.8039 ce_r=7.8445 ce_f=15.6484
[loss-ga] ep 22 it 20 total=-7.7453 ce_r=7.9187 ce_f=15.6640
[loss-ga] ep 22 it 70 total=-7.7666 ce_r=7.7778 ce_f=15.5444
[loss-ga] ep 22 it 120 total=-7.8547 ce_r=7.9143 ce_f=15.7689
[loss-ga] ep 22 it 170 total=-7.8001 ce_r=7.8575 ce_f=15.6576
[loss-ga] ep 22 it 220 total=-7.8860 ce_r=7.9156 ce_f=15.8017
[loss-ga] ep 22 it 270 total=-7.8215 ce_r=7.8656 ce_f=15.6871
[loss-ga] ep 22 it 320 total=-7.8341 ce_r=7.8824 ce_f=15.7165
[loss-ga] ep 22 it 370 total=-7.5787 ce_r=7.8065 ce_f=15.3851
[loss-ga] ep 23 it 30 total=-8.1002 ce_r=8.1360 ce_f=16.2362
[loss-ga] ep 23 it 80 total=-7.6325 ce_r=7.8594 ce_f=15.4919
[loss-ga] ep 23 it 130 total=-7.7282 ce_r=7.7629 ce_f=15.4911
[loss-ga] ep 23 it 180 total=-7.8711 ce_r=7.8898 ce_f=15.7609
[loss-ga] ep 23 it 230 total=-7.8515 ce_r=8.0510 ce_f=15.9025
[loss-ga] ep 23 it 280 total=-7.7454 ce_r=7.8157 ce_f=15.5611
[loss-ga] ep 23 it 330 total=-7.7172 ce_r=7.7740 ce_f=15.4911
[loss-ga] ep 23 it 380 total=-7.7503 ce_r=7.7900 ce_f=15.5403
[loss-ga] ep 24 it 40 total=-7.5473 ce_r=7.5734 ce_f=15.1206
[loss-ga] ep 24 it 90 total=-7.7317 ce_r=7.7990 ce_f=15.5307
[loss-ga] ep 24 it 140 total=-7.9305 ce_r=8.0888 ce_f=16.0193
[loss-ga] ep 24 it 190 total=-7.8995 ce_r=7.9523 ce_f=15.8518
[loss-ga] ep 24 it 240 total=-7.8253 ce_r=7.8570 ce_f=15.6823
[loss-ga] ep 24 it 290 total=-7.9114 ce_r=8.0241 ce_f=15.9354
[loss-ga] ep 24 it 340 total=-8.1917 ce_r=8.2009 ce_f=16.3925
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20.pt
resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<03:46,  1.73it/s]  3%|▎         | 11/391 [00:00<00:18, 20.82it/s]  5%|▌         | 21/391 [00:00<00:09, 37.41it/s]  8%|▊         | 31/391 [00:00<00:07, 51.43it/s] 10%|█         | 41/391 [00:01<00:05, 63.04it/s] 13%|█▎        | 51/391 [00:01<00:04, 71.43it/s] 16%|█▌        | 61/391 [00:01<00:04, 78.62it/s] 18%|█▊        | 72/391 [00:01<00:03, 84.78it/s] 21%|██        | 82/391 [00:01<00:03, 88.88it/s] 24%|██▎       | 92/391 [00:01<00:03, 91.93it/s] 26%|██▌       | 102/391 [00:01<00:03, 93.55it/s] 29%|██▊       | 112/391 [00:01<00:03, 87.98it/s] 31%|███       | 122/391 [00:01<00:03, 86.16it/s] 34%|███▍      | 132/391 [00:01<00:02, 88.69it/s] 36%|███▋      | 142/391 [00:02<00:02, 90.41it/s] 39%|███▉      | 152/391 [00:02<00:02, 92.55it/s] 42%|████▏     | 163/391 [00:02<00:02, 94.90it/s] 44%|████▍     | 173/391 [00:02<00:02, 95.94it/s] 47%|████▋     | 183/391 [00:02<00:02, 96.35it/s] 49%|████▉     | 193/391 [00:02<00:02, 97.35it/s] 52%|█████▏    | 203/391 [00:02<00:01, 97.77it/s] 54%|█████▍    | 213/391 [00:02<00:01, 98.41it/s] 57%|█████▋    | 223/391 [00:02<00:01, 97.28it/s] 60%|█████▉    | 233/391 [00:03<00:01, 97.68it/s] 62%|██████▏   | 243/391 [00:03<00:01, 97.57it/s] 65%|██████▍   | 253/391 [00:03<00:01, 96.61it/s] 67%|██████▋   | 263/391 [00:03<00:01, 96.68it/s] 70%|██████▉   | 273/391 [00:03<00:01, 96.66it/s] 72%|███████▏  | 283/391 [00:03<00:01, 86.93it/s] 75%|███████▍  | 292/391 [00:03<00:01, 80.43it/s] 77%|███████▋  | 302/391 [00:03<00:01, 85.44it/s] 80%|███████▉  | 312/391 [00:03<00:00, 87.46it/s] 82%|████████▏ | 322/391 [00:04<00:00, 90.26it/s] 85%|████████▍ | 332/391 [00:04<00:00, 89.89it/s] 87%|████████▋ | 342/391 [00:04<00:00, 92.09it/s] 90%|█████████ | 353/391 [00:04<00:00, 94.69it/s] 93%|█████████▎| 363/391 [00:04<00:00, 95.98it/s] 96%|█████████▌| 374/391 [00:04<00:00, 97.63it/s] 98%|█████████▊| 385/391 [00:04<00:00, 98.78it/s]100%|██████████| 391/391 [00:04<00:00, 82.70it/s]
50000 images processed, 4.809641122817993 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.04it/s] 13%|█▎        | 10/79 [00:00<00:03, 21.58it/s] 24%|██▍       | 19/79 [00:00<00:01, 37.49it/s] 35%|███▌      | 28/79 [00:00<00:01, 49.37it/s] 48%|████▊     | 38/79 [00:00<00:00, 61.02it/s] 61%|██████    | 48/79 [00:01<00:00, 69.92it/s] 73%|███████▎  | 58/79 [00:01<00:00, 77.49it/s] 86%|████████▌ | 68/79 [00:01<00:00, 83.17it/s] 99%|█████████▊| 78/79 [00:01<00:00, 87.37it/s]100%|██████████| 79/79 [00:01<00:00, 39.64it/s]
10000 images processed, 2.0318827629089355 seconds used

Saved forget OOD features to cache/resnet34-top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20/CIFAR-100/forget
Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:46,  1.90it/s]  4%|▍         | 9/204 [00:00<00:10, 18.39it/s]  9%|▉         | 18/204 [00:00<00:05, 34.96it/s] 13%|█▎        | 27/204 [00:00<00:03, 48.45it/s] 18%|█▊        | 37/204 [00:00<00:02, 61.21it/s] 23%|██▎       | 47/204 [00:01<00:02, 70.55it/s] 28%|██▊       | 57/204 [00:01<00:01, 77.50it/s] 33%|███▎      | 67/204 [00:01<00:01, 82.22it/s] 38%|███▊      | 77/204 [00:01<00:01, 85.57it/s] 43%|████▎     | 87/204 [00:01<00:01, 87.14it/s] 48%|████▊     | 97/204 [00:01<00:01, 89.18it/s] 52%|█████▏    | 107/204 [00:01<00:01, 89.26it/s] 57%|█████▋    | 117/204 [00:01<00:00, 91.54it/s] 62%|██████▏   | 127/204 [00:01<00:00, 93.02it/s] 67%|██████▋   | 137/204 [00:02<00:00, 94.12it/s] 72%|███████▏  | 147/204 [00:02<00:00, 95.01it/s] 77%|███████▋  | 157/204 [00:02<00:00, 95.68it/s] 82%|████████▏ | 167/204 [00:02<00:00, 94.98it/s] 87%|████████▋ | 177/204 [00:02<00:00, 95.97it/s] 92%|█████████▏| 188/204 [00:02<00:00, 97.60it/s] 98%|█████████▊| 199/204 [00:02<00:00, 98.42it/s]100%|██████████| 204/204 [00:02<00:00, 75.79it/s]
26032 images processed, 2.731234312057495 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:48,  1.61it/s] 10%|█         | 8/79 [00:00<00:04, 14.33it/s] 23%|██▎       | 18/79 [00:00<00:01, 31.85it/s] 34%|███▍      | 27/79 [00:00<00:01, 44.74it/s] 44%|████▍     | 35/79 [00:01<00:00, 50.67it/s] 56%|█████▌    | 44/79 [00:01<00:00, 59.67it/s] 67%|██████▋   | 53/79 [00:01<00:00, 66.49it/s] 80%|███████▉  | 63/79 [00:01<00:00, 74.32it/s] 94%|█████████▎| 74/79 [00:01<00:00, 82.06it/s]100%|██████████| 79/79 [00:01<00:00, 51.69it/s]
10000 images processed, 1.5561010837554932 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:37,  2.06it/s] 11%|█▏        | 9/79 [00:00<00:03, 19.33it/s] 24%|██▍       | 19/79 [00:00<00:01, 38.53it/s] 37%|███▋      | 29/79 [00:00<00:00, 53.98it/s] 49%|████▉     | 39/79 [00:00<00:00, 65.99it/s] 62%|██████▏   | 49/79 [00:01<00:00, 74.19it/s] 75%|███████▍  | 59/79 [00:01<00:00, 81.22it/s] 89%|████████▊ | 70/79 [00:01<00:00, 87.01it/s]100%|██████████| 79/79 [00:01<00:00, 60.77it/s]
10000 images processed, 1.320725440979004 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:32,  2.12it/s] 13%|█▎        | 9/70 [00:00<00:03, 19.89it/s] 27%|██▋       | 19/70 [00:00<00:01, 39.44it/s] 41%|████▏     | 29/70 [00:00<00:00, 54.95it/s] 56%|█████▌    | 39/70 [00:00<00:00, 66.70it/s] 70%|███████   | 49/70 [00:00<00:00, 75.92it/s] 86%|████████▌ | 60/70 [00:01<00:00, 83.28it/s]100%|██████████| 70/70 [00:01<00:00, 87.54it/s]100%|██████████| 70/70 [00:01<00:00, 58.51it/s]
8925 images processed, 1.2262868881225586 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:43,  1.01it/s]  9%|▉         | 4/45 [00:01<00:08,  4.65it/s] 31%|███       | 14/45 [00:01<00:02, 14.73it/s] 44%|████▍     | 20/45 [00:01<00:01, 20.94it/s] 53%|█████▎    | 24/45 [00:01<00:01, 17.26it/s] 67%|██████▋   | 30/45 [00:01<00:00, 21.97it/s] 80%|████████  | 36/45 [00:02<00:00, 27.96it/s] 91%|█████████ | 41/45 [00:02<00:00, 21.58it/s]100%|██████████| 45/45 [00:02<00:00, 17.82it/s]
5640 images processed, 2.550034999847412 seconds used

17.88165044784546
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN          22.69  95.50  89.49
places365     73.19  79.64  76.24
LSUN          56.99  87.37  87.08
iSUN          55.15  88.37  88.88
dtd           62.68  85.76  90.18
AVG           54.14  87.33  86.37
Retain-Acc: 0.7394
Forget-as-OOD (retain known vs forget novel):
  FPR: 71.05 AUROC: 77.48 AUIN: 93.06
6.7987284660339355
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-ga-b128-e25-lr0.001-wd1e-4-fl1-CIFAR-100forget20_rf.png
