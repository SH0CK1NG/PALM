nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.1, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_center_set='all', forget_lambda=1.0, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:26<21:51, 26.76s/it]  4%|▍         | 2/50 [00:47<18:24, 23.00s/it]  6%|▌         | 3/50 [01:07<17:08, 21.88s/it]  8%|▊         | 4/50 [01:28<16:21, 21.34s/it] 10%|█         | 5/50 [01:48<15:49, 21.11s/it] 12%|█▏        | 6/50 [02:09<15:23, 20.98s/it] 14%|█▍        | 7/50 [02:29<14:53, 20.78s/it] 16%|█▌        | 8/50 [02:50<14:33, 20.79s/it][loss] ep 0 it 0 total=13.4199 mle=1.4969 pcon=5.2950 forget=6.6280 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 50 total=13.4477 mle=1.4709 pcon=5.2879 forget=6.6889 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 100 total=13.5021 mle=1.5969 pcon=5.2809 forget=6.6243 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 150 total=13.6314 mle=1.7521 pcon=5.2738 forget=6.6054 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 200 total=13.5350 mle=1.6197 pcon=5.2670 forget=6.6483 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 250 total=13.3387 mle=1.4374 pcon=5.2603 forget=6.6410 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 300 total=13.3810 mle=1.4844 pcon=5.2540 forget=6.6426 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 350 total=13.4970 mle=1.5890 pcon=5.2476 forget=6.6604 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 1 it 10 total=13.5409 mle=1.5754 pcon=5.2409 forget=6.7247 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 60 total=13.4007 mle=1.5656 pcon=5.2346 forget=6.6006 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 110 total=13.3307 mle=1.4494 pcon=5.2284 forget=6.6528 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 160 total=13.5478 mle=1.6637 pcon=5.2224 forget=6.6617 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 210 total=13.5127 mle=1.6526 pcon=5.2167 forget=6.6433 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 260 total=13.3436 mle=1.5306 pcon=5.2112 forget=6.6018 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 310 total=13.4533 mle=1.6296 pcon=5.2056 forget=6.6181 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 360 total=13.5240 mle=1.6850 pcon=5.2003 forget=6.6387 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 2 it 20 total=13.3063 mle=1.4935 pcon=5.1950 forget=6.6178 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 70 total=13.5029 mle=1.7523 pcon=5.1899 forget=6.5607 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 120 total=13.4411 mle=1.6371 pcon=5.1847 forget=6.6194 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 170 total=13.2326 mle=1.4587 pcon=5.1796 forget=6.5943 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 220 total=13.3318 mle=1.5210 pcon=5.1745 forget=6.6363 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 270 total=13.5350 mle=1.7609 pcon=5.1699 forget=6.6042 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 320 total=13.2530 mle=1.5192 pcon=5.1651 forget=6.5687 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 370 total=13.4533 mle=1.7167 pcon=5.1604 forget=6.5762 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 3 it 30 total=13.3770 mle=1.6249 pcon=5.1559 forget=6.5963 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 80 total=13.3577 mle=1.5783 pcon=5.1518 forget=6.6275 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 130 total=13.3901 mle=1.6598 pcon=5.1474 forget=6.5828 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 180 total=13.5042 mle=1.7920 pcon=5.1434 forget=6.5687 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 230 total=13.2084 mle=1.5001 pcon=5.1394 forget=6.5689 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 280 total=13.4172 mle=1.7224 pcon=5.1352 forget=6.5597 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 330 total=13.3540 mle=1.6110 pcon=5.1309 forget=6.6121 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 380 total=13.3348 mle=1.5922 pcon=5.1273 forget=6.6152 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 4 it 40 total=13.2077 mle=1.5628 pcon=5.1235 forget=6.5214 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 90 total=13.2994 mle=1.6328 pcon=5.1194 forget=6.5472 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 140 total=13.2676 mle=1.5738 pcon=5.1157 forget=6.5782 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 190 total=13.0960 mle=1.4068 pcon=5.1122 forget=6.5770 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 240 total=13.3256 mle=1.6708 pcon=5.1082 forget=6.5466 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 290 total=13.0902 mle=1.4385 pcon=5.1046 forget=6.5471 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 340 total=13.4346 mle=1.7740 pcon=5.1011 forget=6.5595 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 5 it 0 total=13.4045 mle=1.7697 pcon=5.0976 forget=6.5372 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 50 total=13.2988 mle=1.6955 pcon=5.0939 forget=6.5095 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 100 total=13.1512 mle=1.5229 pcon=5.0905 forget=6.5378 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 150 total=13.1339 mle=1.5206 pcon=5.0868 forget=6.5265 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 200 total=13.1810 mle=1.6067 pcon=5.0837 forget=6.4906 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 250 total=13.2249 mle=1.6771 pcon=5.0805 forget=6.4674 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 300 total=13.0773 mle=1.5239 pcon=5.0771 forget=6.4763 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 350 total=13.1949 mle=1.6446 pcon=5.0739 forget=6.4765 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 6 it 10 total=12.9951 mle=1.3785 pcon=5.0706 forget=6.5460 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 60 total=12.9693 mle=1.4824 pcon=5.0674 forget=6.4195 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 110 total=13.0748 mle=1.5339 pcon=5.0642 forget=6.4767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 160 total=13.1193 mle=1.6077 pcon=5.0610 forget=6.4506 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 210 total=13.0530 mle=1.5461 pcon=5.0582 forget=6.4487 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 260 total=13.2225 mle=1.6992 pcon=5.0548 forget=6.4685 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 310 total=13.0563 mle=1.4942 pcon=5.0520 forget=6.5101 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 360 total=13.1090 mle=1.5899 pcon=5.0490 forget=6.4701 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 7 it 20 total=13.0746 mle=1.5737 pcon=5.0460 forget=6.4549 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 70 total=13.1591 mle=1.6614 pcon=5.0433 forget=6.4545 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 120 total=13.0680 mle=1.5554 pcon=5.0404 forget=6.4722 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 170 total=13.0273 mle=1.5077 pcon=5.0377 forget=6.4819 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 220 total=13.1368 mle=1.5711 pcon=5.0355 forget=6.5302 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 270 total=13.2895 mle=1.6937 pcon=5.0332 forget=6.5626 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 320 total=13.2400 mle=1.6434 pcon=5.0306 forget=6.5660 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 370 total=13.1639 mle=1.5763 pcon=5.0285 forget=6.5591 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 30 total=13.1394 mle=1.5002 pcon=5.0266 forget=6.6126 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 80 total=13.1557 mle=1.5275 pcon=5.0247 forget=6.6035 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 130 total=13.0949 mle=1.4634 pcon=5.0226 forget=6.6089 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 180 total=13.2834 mle=1.6450 pcon=5.0207 forget=6.6177 nr=64 nf=64 protos=540 dmin_norm=NA
 18%|█▊        | 9/50 [03:11<14:10, 20.74s/it] 20%|██        | 10/50 [03:31<13:43, 20.59s/it] 22%|██▏       | 11/50 [03:52<13:23, 20.59s/it] 24%|██▍       | 12/50 [04:12<12:57, 20.47s/it] 26%|██▌       | 13/50 [04:33<12:38, 20.49s/it] 28%|██▊       | 14/50 [04:53<12:14, 20.40s/it] 30%|███       | 15/50 [05:13<11:57, 20.51s/it] 32%|███▏      | 16/50 [05:33<11:31, 20.34s/it] 34%|███▍      | 17/50 [05:54<11:17, 20.53s/it][loss] ep 8 it 230 total=13.1148 mle=1.4780 pcon=5.0193 forget=6.6174 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 280 total=13.2614 mle=1.6218 pcon=5.0174 forget=6.6222 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 330 total=13.3776 mle=1.6645 pcon=5.0155 forget=6.6977 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 380 total=13.1304 mle=1.4496 pcon=5.0137 forget=6.6671 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 40 total=13.2274 mle=1.5678 pcon=5.0119 forget=6.6476 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 90 total=13.3125 mle=1.6198 pcon=5.0099 forget=6.6827 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 140 total=13.4433 mle=1.7066 pcon=5.0085 forget=6.7282 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 190 total=13.2221 mle=1.5369 pcon=5.0069 forget=6.6783 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 240 total=13.2211 mle=1.5059 pcon=5.0054 forget=6.7099 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 290 total=13.2251 mle=1.5098 pcon=5.0034 forget=6.7118 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 340 total=13.2037 mle=1.5143 pcon=5.0018 forget=6.6876 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 0 total=13.2609 mle=1.5598 pcon=4.9999 forget=6.7013 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 50 total=13.2410 mle=1.5281 pcon=4.9979 forget=6.7150 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 100 total=13.3537 mle=1.6782 pcon=4.9961 forget=6.6794 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 150 total=13.3778 mle=1.7273 pcon=4.9944 forget=6.6560 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 200 total=13.4003 mle=1.7536 pcon=4.9925 forget=6.6542 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 250 total=13.1841 mle=1.5364 pcon=4.9908 forget=6.6569 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 300 total=13.1442 mle=1.5165 pcon=4.9892 forget=6.6385 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 350 total=13.2732 mle=1.5839 pcon=4.9874 forget=6.7020 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 10 total=13.1536 mle=1.5088 pcon=4.9855 forget=6.6593 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 60 total=13.1723 mle=1.5701 pcon=4.9836 forget=6.6187 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 110 total=13.1025 mle=1.5277 pcon=4.9819 forget=6.5929 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 160 total=13.1935 mle=1.5945 pcon=4.9797 forget=6.6194 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 210 total=13.2836 mle=1.6910 pcon=4.9780 forget=6.6147 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 260 total=13.1372 mle=1.5436 pcon=4.9765 forget=6.6171 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 310 total=13.4404 mle=1.8547 pcon=4.9746 forget=6.6111 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 360 total=13.1585 mle=1.6150 pcon=4.9727 forget=6.5707 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 20 total=13.1297 mle=1.5527 pcon=4.9707 forget=6.6063 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 70 total=13.1771 mle=1.6141 pcon=4.9689 forget=6.5940 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 120 total=13.1030 mle=1.5158 pcon=4.9671 forget=6.6201 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 170 total=13.2085 mle=1.6808 pcon=4.9654 forget=6.5623 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 220 total=13.0780 mle=1.5349 pcon=4.9635 forget=6.5796 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 270 total=13.0629 mle=1.4968 pcon=4.9622 forget=6.6039 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 320 total=13.0114 mle=1.4735 pcon=4.9605 forget=6.5774 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 370 total=13.2969 mle=1.7515 pcon=4.9587 forget=6.5867 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 30 total=12.9403 mle=1.4002 pcon=4.9571 forget=6.5829 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 80 total=13.0479 mle=1.4385 pcon=4.9555 forget=6.6539 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 130 total=13.0287 mle=1.5039 pcon=4.9537 forget=6.5711 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 180 total=13.0304 mle=1.5384 pcon=4.9522 forget=6.5397 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 230 total=13.1302 mle=1.6163 pcon=4.9507 forget=6.5633 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 280 total=13.0128 mle=1.5243 pcon=4.9491 forget=6.5395 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 330 total=13.0522 mle=1.5524 pcon=4.9474 forget=6.5524 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 380 total=13.0362 mle=1.5628 pcon=4.9459 forget=6.5274 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 14 it 40 total=13.1661 mle=1.7065 pcon=4.9441 forget=6.5155 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 90 total=13.1826 mle=1.7049 pcon=4.9428 forget=6.5349 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 140 total=13.0058 mle=1.5329 pcon=4.9418 forget=6.5312 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 190 total=13.2460 mle=1.7936 pcon=4.9401 forget=6.5123 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 240 total=13.0220 mle=1.5796 pcon=4.9388 forget=6.5036 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 290 total=13.0250 mle=1.6064 pcon=4.9373 forget=6.4813 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 340 total=13.0578 mle=1.6353 pcon=4.9357 forget=6.4869 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 15 it 0 total=13.0872 mle=1.6460 pcon=4.9343 forget=6.5069 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 50 total=12.8683 mle=1.4594 pcon=4.9326 forget=6.4764 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 100 total=12.9563 mle=1.5390 pcon=4.9310 forget=6.4863 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 150 total=13.0702 mle=1.6405 pcon=4.9294 forget=6.5003 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 200 total=12.9858 mle=1.6053 pcon=4.9278 forget=6.4528 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 250 total=13.2144 mle=1.8307 pcon=4.9261 forget=6.4576 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 300 total=12.9287 mle=1.5364 pcon=4.9246 forget=6.4677 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 350 total=12.9261 mle=1.5001 pcon=4.9229 forget=6.5032 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 16 it 10 total=12.9161 mle=1.5440 pcon=4.9210 forget=6.4511 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 60 total=12.8464 mle=1.4889 pcon=4.9193 forget=6.4382 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 110 total=12.8809 mle=1.5248 pcon=4.9177 forget=6.4384 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 160 total=12.9653 mle=1.6066 pcon=4.9156 forget=6.4431 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 210 total=12.8839 mle=1.5506 pcon=4.9134 forget=6.4199 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 260 total=13.1896 mle=1.8369 pcon=4.9112 forget=6.4415 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 310 total=13.0595 mle=1.7073 pcon=4.9091 forget=6.4431 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 360 total=12.8946 mle=1.5594 pcon=4.9070 forget=6.4282 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 17 it 20 total=13.0539 mle=1.7016 pcon=4.9045 forget=6.4478 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 70 total=13.0816 mle=1.7512 pcon=4.9025 forget=6.4280 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 120 total=12.8964 mle=1.5492 pcon=4.9000 forget=6.4471 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 170 total=12.9163 mle=1.5717 pcon=4.8973 forget=6.4473 nr=64 nf=64 protos=540 dmin_norm=NA
 36%|███▌      | 18/50 [06:16<11:03, 20.75s/it] 38%|███▊      | 19/50 [06:36<10:43, 20.75s/it] 40%|████      | 20/50 [06:57<10:19, 20.64s/it] 42%|████▏     | 21/50 [07:18<09:59, 20.69s/it] 44%|████▍     | 22/50 [07:38<09:39, 20.70s/it] 46%|████▌     | 23/50 [07:59<09:22, 20.82s/it] 48%|████▊     | 24/50 [08:21<09:03, 20.91s/it] 50%|█████     | 25/50 [08:41<08:41, 20.84s/it] 52%|█████▏    | 26/50 [09:02<08:16, 20.70s/it][loss] ep 17 it 220 total=12.9622 mle=1.6020 pcon=4.8947 forget=6.4656 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 270 total=12.7725 mle=1.4524 pcon=4.8925 forget=6.4276 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 320 total=13.0697 mle=1.7538 pcon=4.8899 forget=6.4260 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 370 total=12.9932 mle=1.6794 pcon=4.8870 forget=6.4268 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 18 it 30 total=12.8326 mle=1.5306 pcon=4.8847 forget=6.4172 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 80 total=12.8871 mle=1.5845 pcon=4.8820 forget=6.4206 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 130 total=12.9270 mle=1.6027 pcon=4.8793 forget=6.4451 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 180 total=12.8312 mle=1.5388 pcon=4.8765 forget=6.4159 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 230 total=12.8945 mle=1.5904 pcon=4.8737 forget=6.4304 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 280 total=12.9057 mle=1.6076 pcon=4.8709 forget=6.4271 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 330 total=12.9613 mle=1.6959 pcon=4.8682 forget=6.3972 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 380 total=12.9982 mle=1.6875 pcon=4.8656 forget=6.4452 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 19 it 40 total=12.8247 mle=1.4959 pcon=4.8630 forget=6.4658 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 90 total=12.9772 mle=1.6376 pcon=4.8604 forget=6.4791 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 140 total=12.8541 mle=1.5463 pcon=4.8575 forget=6.4504 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 190 total=12.9061 mle=1.6261 pcon=4.8546 forget=6.4254 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 240 total=13.0888 mle=1.8199 pcon=4.8520 forget=6.4170 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 290 total=12.9184 mle=1.6245 pcon=4.8495 forget=6.4444 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 340 total=12.8393 mle=1.5345 pcon=4.8470 forget=6.4578 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 20 it 0 total=12.8914 mle=1.6216 pcon=4.8443 forget=6.4255 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 50 total=12.8998 mle=1.6220 pcon=4.8416 forget=6.4362 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 100 total=13.0278 mle=1.6961 pcon=4.8392 forget=6.4925 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 150 total=13.0740 mle=1.7850 pcon=4.8364 forget=6.4526 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 200 total=12.8575 mle=1.5685 pcon=4.8336 forget=6.4553 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 250 total=13.1553 mle=1.8614 pcon=4.8309 forget=6.4630 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 300 total=13.0665 mle=1.7509 pcon=4.8283 forget=6.4873 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 350 total=12.7902 mle=1.4782 pcon=4.8257 forget=6.4862 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 10 total=12.7697 mle=1.4607 pcon=4.8232 forget=6.4858 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 60 total=12.9573 mle=1.6394 pcon=4.8208 forget=6.4972 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 110 total=12.8797 mle=1.5530 pcon=4.8184 forget=6.5083 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 160 total=12.8650 mle=1.5825 pcon=4.8162 forget=6.4663 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 210 total=13.0760 mle=1.7456 pcon=4.8139 forget=6.5165 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 260 total=12.9541 mle=1.6374 pcon=4.8116 forget=6.5051 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 310 total=12.8879 mle=1.5649 pcon=4.8092 forget=6.5138 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 360 total=12.9281 mle=1.5552 pcon=4.8068 forget=6.5661 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 20 total=12.9578 mle=1.6319 pcon=4.8044 forget=6.5215 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 70 total=12.9918 mle=1.7113 pcon=4.8021 forget=6.4783 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 120 total=12.9013 mle=1.5676 pcon=4.7997 forget=6.5340 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 170 total=12.8959 mle=1.5907 pcon=4.7975 forget=6.5076 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 220 total=12.8905 mle=1.5914 pcon=4.7955 forget=6.5036 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 270 total=12.8311 mle=1.5254 pcon=4.7933 forget=6.5123 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 320 total=12.9437 mle=1.6660 pcon=4.7914 forget=6.4862 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 370 total=13.1837 mle=1.8897 pcon=4.7892 forget=6.5048 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 30 total=12.7979 mle=1.5242 pcon=4.7875 forget=6.4863 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 80 total=12.9199 mle=1.6424 pcon=4.7854 forget=6.4921 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 130 total=12.8185 mle=1.5550 pcon=4.7832 forget=6.4803 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 180 total=12.9475 mle=1.7145 pcon=4.7811 forget=6.4518 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 230 total=12.8459 mle=1.6007 pcon=4.7792 forget=6.4659 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 280 total=12.8567 mle=1.5939 pcon=4.7771 forget=6.4857 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 330 total=12.8299 mle=1.6069 pcon=4.7751 forget=6.4479 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 380 total=12.8262 mle=1.5807 pcon=4.7732 forget=6.4723 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 24 it 40 total=12.7577 mle=1.5581 pcon=4.7714 forget=6.4282 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 90 total=12.8557 mle=1.6094 pcon=4.7696 forget=6.4767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 140 total=12.8104 mle=1.5831 pcon=4.7677 forget=6.4596 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 190 total=12.8588 mle=1.6535 pcon=4.7661 forget=6.4392 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 240 total=12.7551 mle=1.5304 pcon=4.7644 forget=6.4603 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 290 total=12.9347 mle=1.7131 pcon=4.7627 forget=6.4589 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 340 total=12.8219 mle=1.6272 pcon=4.7610 forget=6.4337 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 25 it 0 total=12.7961 mle=1.5853 pcon=4.7593 forget=6.4515 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 50 total=12.9644 mle=1.7355 pcon=4.7578 forget=6.4710 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 100 total=12.7940 mle=1.6095 pcon=4.7562 forget=6.4283 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 150 total=12.9425 mle=1.7619 pcon=4.7550 forget=6.4257 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 200 total=12.9840 mle=1.7769 pcon=4.7534 forget=6.4537 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 250 total=12.9105 mle=1.6986 pcon=4.7518 forget=6.4601 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 300 total=12.8039 mle=1.6276 pcon=4.7504 forget=6.4259 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 350 total=12.7382 mle=1.5618 pcon=4.7493 forget=6.4272 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 26 it 10 total=12.7737 mle=1.5928 pcon=4.7479 forget=6.4329 nr=64 nf=64 protos=540 dmin_norm=NA
 54%|█████▍    | 27/50 [09:22<07:56, 20.74s/it] 56%|█████▌    | 28/50 [09:43<07:35, 20.68s/it] 58%|█████▊    | 29/50 [10:04<07:16, 20.80s/it] 60%|██████    | 30/50 [10:24<06:53, 20.68s/it] 62%|██████▏   | 31/50 [10:45<06:32, 20.64s/it] 64%|██████▍   | 32/50 [11:05<06:08, 20.45s/it] 66%|██████▌   | 33/50 [11:26<05:52, 20.74s/it] 68%|██████▊   | 34/50 [11:47<05:29, 20.62s/it] 70%|███████   | 35/50 [12:07<05:07, 20.52s/it][loss] ep 26 it 60 total=12.7629 mle=1.5759 pcon=4.7466 forget=6.4404 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 110 total=12.8529 mle=1.6944 pcon=4.7454 forget=6.4131 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 160 total=12.7511 mle=1.5591 pcon=4.7441 forget=6.4480 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 210 total=12.8260 mle=1.6432 pcon=4.7426 forget=6.4402 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 260 total=12.6991 mle=1.5144 pcon=4.7415 forget=6.4432 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 310 total=13.0246 mle=1.8578 pcon=4.7403 forget=6.4265 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 360 total=12.7207 mle=1.5874 pcon=4.7389 forget=6.3944 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 27 it 20 total=12.7830 mle=1.6279 pcon=4.7378 forget=6.4173 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 70 total=12.7427 mle=1.5903 pcon=4.7364 forget=6.4160 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 120 total=12.6822 mle=1.5509 pcon=4.7352 forget=6.3960 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 170 total=12.7073 mle=1.5456 pcon=4.7339 forget=6.4278 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 220 total=12.6846 mle=1.5158 pcon=4.7326 forget=6.4363 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 270 total=12.7426 mle=1.5916 pcon=4.7313 forget=6.4197 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 320 total=12.8422 mle=1.6953 pcon=4.7303 forget=6.4166 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 370 total=12.8851 mle=1.7163 pcon=4.7292 forget=6.4395 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 28 it 30 total=12.7766 mle=1.6487 pcon=4.7282 forget=6.3997 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 80 total=12.8483 mle=1.6827 pcon=4.7273 forget=6.4383 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 130 total=12.7470 mle=1.5842 pcon=4.7264 forget=6.4364 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 180 total=12.7426 mle=1.6009 pcon=4.7254 forget=6.4164 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 230 total=12.5979 mle=1.4468 pcon=4.7242 forget=6.4269 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 280 total=12.7328 mle=1.5776 pcon=4.7231 forget=6.4321 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 330 total=12.9746 mle=1.7939 pcon=4.7219 forget=6.4588 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 380 total=12.8601 mle=1.6984 pcon=4.7208 forget=6.4409 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 29 it 40 total=12.8332 mle=1.6922 pcon=4.7196 forget=6.4214 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 90 total=12.7054 mle=1.5766 pcon=4.7184 forget=6.4104 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 140 total=12.7972 mle=1.6369 pcon=4.7175 forget=6.4427 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 190 total=12.7854 mle=1.6218 pcon=4.7166 forget=6.4469 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 240 total=12.7303 mle=1.5552 pcon=4.7158 forget=6.4593 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 290 total=12.8936 mle=1.7405 pcon=4.7150 forget=6.4381 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 340 total=12.7230 mle=1.5716 pcon=4.7143 forget=6.4372 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 0 total=12.8002 mle=1.6458 pcon=4.7134 forget=6.4410 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 50 total=12.8436 mle=1.6642 pcon=4.7127 forget=6.4667 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 100 total=12.7637 mle=1.5826 pcon=4.7119 forget=6.4691 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 150 total=12.9228 mle=1.7739 pcon=4.7110 forget=6.4378 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 200 total=12.7058 mle=1.5101 pcon=4.7102 forget=6.4854 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 250 total=12.9612 mle=1.7700 pcon=4.7095 forget=6.4818 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 300 total=12.7017 mle=1.5193 pcon=4.7088 forget=6.4736 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 350 total=12.9078 mle=1.7415 pcon=4.7081 forget=6.4581 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 10 total=12.7821 mle=1.6281 pcon=4.7075 forget=6.4465 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 60 total=12.7268 mle=1.5650 pcon=4.7069 forget=6.4549 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 110 total=12.7848 mle=1.6135 pcon=4.7063 forget=6.4651 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 160 total=12.7447 mle=1.5793 pcon=4.7056 forget=6.4598 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 210 total=12.6962 mle=1.5687 pcon=4.7049 forget=6.4226 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 260 total=12.6892 mle=1.5248 pcon=4.7042 forget=6.4602 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 310 total=12.7777 mle=1.5997 pcon=4.7035 forget=6.4745 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 360 total=12.7113 mle=1.5575 pcon=4.7028 forget=6.4510 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 20 total=12.8487 mle=1.7029 pcon=4.7021 forget=6.4436 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 70 total=12.7253 mle=1.5780 pcon=4.7014 forget=6.4460 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 120 total=12.8093 mle=1.6113 pcon=4.7008 forget=6.4973 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 170 total=12.7549 mle=1.5728 pcon=4.7003 forget=6.4818 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 220 total=12.8606 mle=1.6910 pcon=4.6998 forget=6.4698 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 270 total=12.7385 mle=1.5711 pcon=4.6993 forget=6.4681 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 320 total=12.6725 mle=1.5271 pcon=4.6987 forget=6.4467 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 370 total=12.6494 mle=1.4869 pcon=4.6983 forget=6.4642 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 30 total=12.8236 mle=1.6487 pcon=4.6978 forget=6.4771 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 80 total=13.0011 mle=1.8812 pcon=4.6973 forget=6.4225 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 130 total=12.6595 mle=1.5105 pcon=4.6968 forget=6.4522 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 180 total=12.9034 mle=1.7173 pcon=4.6963 forget=6.4897 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 230 total=12.8016 mle=1.6337 pcon=4.6959 forget=6.4720 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 280 total=12.8289 mle=1.6565 pcon=4.6954 forget=6.4771 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 330 total=12.8235 mle=1.6859 pcon=4.6950 forget=6.4426 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 380 total=12.7955 mle=1.6072 pcon=4.6945 forget=6.4938 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 40 total=12.8606 mle=1.7095 pcon=4.6938 forget=6.4572 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 90 total=12.6752 mle=1.5275 pcon=4.6932 forget=6.4545 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 140 total=12.7443 mle=1.6322 pcon=4.6928 forget=6.4193 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 190 total=12.8340 mle=1.6841 pcon=4.6924 forget=6.4575 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 240 total=12.8608 mle=1.7095 pcon=4.6919 forget=6.4595 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 290 total=12.7796 mle=1.6256 pcon=4.6913 forget=6.4627 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 340 total=12.8057 mle=1.6048 pcon=4.6909 forget=6.5100 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 0 total=12.8010 mle=1.6340 pcon=4.6904 forget=6.4767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 50 total=12.7876 mle=1.6089 pcon=4.6899 forget=6.4888 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 100 total=12.9841 mle=1.7831 pcon=4.6893 forget=6.5117 nr=64 nf=64 protos=540 dmin_norm=NA
 72%|███████▏  | 36/50 [12:27<04:46, 20.48s/it] 74%|███████▍  | 37/50 [12:47<04:24, 20.36s/it] 76%|███████▌  | 38/50 [13:07<04:02, 20.21s/it] 78%|███████▊  | 39/50 [13:28<03:43, 20.34s/it] 80%|████████  | 40/50 [13:49<03:24, 20.46s/it] 82%|████████▏ | 41/50 [14:09<03:04, 20.51s/it] 84%|████████▍ | 42/50 [14:30<02:43, 20.47s/it] 86%|████████▌ | 43/50 [14:50<02:22, 20.37s/it] 88%|████████▊ | 44/50 [15:11<02:04, 20.69s/it] 90%|█████████ | 45/50 [15:31<01:42, 20.54s/it][loss] ep 35 it 150 total=12.7766 mle=1.6362 pcon=4.6889 forget=6.4515 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 200 total=12.7286 mle=1.5670 pcon=4.6885 forget=6.4732 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 250 total=12.8552 mle=1.7100 pcon=4.6880 forget=6.4572 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 300 total=12.6844 mle=1.5568 pcon=4.6875 forget=6.4401 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 350 total=12.8478 mle=1.7115 pcon=4.6871 forget=6.4491 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 10 total=12.8928 mle=1.7377 pcon=4.6868 forget=6.4683 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 60 total=12.7245 mle=1.5715 pcon=4.6865 forget=6.4665 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 110 total=12.7257 mle=1.5758 pcon=4.6861 forget=6.4637 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 160 total=12.8183 mle=1.6521 pcon=4.6857 forget=6.4805 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 210 total=12.6894 mle=1.5314 pcon=4.6854 forget=6.4726 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 260 total=12.7870 mle=1.6027 pcon=4.6852 forget=6.4990 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 310 total=12.8658 mle=1.6828 pcon=4.6848 forget=6.4982 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 360 total=12.8109 mle=1.6438 pcon=4.6844 forget=6.4827 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 20 total=12.7019 mle=1.5217 pcon=4.6839 forget=6.4964 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 70 total=12.9345 mle=1.7404 pcon=4.6836 forget=6.5105 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 120 total=12.7923 mle=1.6153 pcon=4.6832 forget=6.4937 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 170 total=12.6938 mle=1.5553 pcon=4.6828 forget=6.4557 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 220 total=12.8943 mle=1.7241 pcon=4.6823 forget=6.4878 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 270 total=12.7716 mle=1.6194 pcon=4.6819 forget=6.4703 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 320 total=12.7918 mle=1.6237 pcon=4.6816 forget=6.4865 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 370 total=12.8828 mle=1.6525 pcon=4.6813 forget=6.5491 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 30 total=12.8723 mle=1.6773 pcon=4.6812 forget=6.5138 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 80 total=12.6765 mle=1.4937 pcon=4.6810 forget=6.5018 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 130 total=12.8192 mle=1.6446 pcon=4.6807 forget=6.4938 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 180 total=12.7597 mle=1.6038 pcon=4.6804 forget=6.4756 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 230 total=12.7361 mle=1.5508 pcon=4.6801 forget=6.5052 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 280 total=12.8593 mle=1.7145 pcon=4.6799 forget=6.4649 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 330 total=12.7740 mle=1.6093 pcon=4.6794 forget=6.4853 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 380 total=12.6756 mle=1.5082 pcon=4.6793 forget=6.4882 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 40 total=12.8920 mle=1.7311 pcon=4.6792 forget=6.4816 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 90 total=12.8562 mle=1.6469 pcon=4.6790 forget=6.5303 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 140 total=12.7869 mle=1.6334 pcon=4.6788 forget=6.4747 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 190 total=12.6689 mle=1.5000 pcon=4.6786 forget=6.4904 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 240 total=12.8460 mle=1.6534 pcon=4.6784 forget=6.5142 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 290 total=12.6850 mle=1.5116 pcon=4.6782 forget=6.4952 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 340 total=12.7891 mle=1.5936 pcon=4.6781 forget=6.5174 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 0 total=12.7466 mle=1.5575 pcon=4.6777 forget=6.5114 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 50 total=12.8191 mle=1.6181 pcon=4.6774 forget=6.5235 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 100 total=12.8140 mle=1.6407 pcon=4.6770 forget=6.4963 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 150 total=12.7010 mle=1.5275 pcon=4.6769 forget=6.4966 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 200 total=12.9680 mle=1.7794 pcon=4.6767 forget=6.5119 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 250 total=13.0193 mle=1.7984 pcon=4.6764 forget=6.5446 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 300 total=12.7214 mle=1.5609 pcon=4.6763 forget=6.4842 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 350 total=12.6432 mle=1.4699 pcon=4.6761 forget=6.4972 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 10 total=12.6992 mle=1.5286 pcon=4.6760 forget=6.4946 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 60 total=13.0566 mle=1.8393 pcon=4.6759 forget=6.5415 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 110 total=12.8257 mle=1.6155 pcon=4.6756 forget=6.5346 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 160 total=12.8034 mle=1.6057 pcon=4.6756 forget=6.5220 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 210 total=12.8618 mle=1.6649 pcon=4.6754 forget=6.5215 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 260 total=12.7104 mle=1.5381 pcon=4.6755 forget=6.4968 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 310 total=12.7245 mle=1.5339 pcon=4.6756 forget=6.5150 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 360 total=12.8927 mle=1.6863 pcon=4.6755 forget=6.5309 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 20 total=12.8709 mle=1.6760 pcon=4.6754 forget=6.5195 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 70 total=12.8443 mle=1.6360 pcon=4.6752 forget=6.5331 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 120 total=13.0944 mle=1.8590 pcon=4.6750 forget=6.5604 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 170 total=12.7629 mle=1.5980 pcon=4.6749 forget=6.4900 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 220 total=12.8051 mle=1.6281 pcon=4.6748 forget=6.5022 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 270 total=12.8922 mle=1.7004 pcon=4.6747 forget=6.5171 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 320 total=12.9057 mle=1.6984 pcon=4.6747 forget=6.5325 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 370 total=12.8019 mle=1.5979 pcon=4.6747 forget=6.5293 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 30 total=12.8508 mle=1.6053 pcon=4.6746 forget=6.5709 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 80 total=12.8335 mle=1.6123 pcon=4.6744 forget=6.5467 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 130 total=12.8850 mle=1.6648 pcon=4.6743 forget=6.5459 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 180 total=12.8151 mle=1.5395 pcon=4.6742 forget=6.6013 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 230 total=12.7533 mle=1.5726 pcon=4.6741 forget=6.5066 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 280 total=12.7583 mle=1.5542 pcon=4.6740 forget=6.5301 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 330 total=12.7991 mle=1.5487 pcon=4.6738 forget=6.5766 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 380 total=12.6927 mle=1.5229 pcon=4.6736 forget=6.4961 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 40 total=12.9211 mle=1.7150 pcon=4.6735 forget=6.5326 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 90 total=12.8135 mle=1.5948 pcon=4.6734 forget=6.5453 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 140 total=12.8986 mle=1.6503 pcon=4.6733 forget=6.5750 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 190 total=12.7685 mle=1.5441 pcon=4.6733 forget=6.5511 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 240 total=12.7970 mle=1.5552 pcon=4.6732 forget=6.5686 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 290 total=13.0414 mle=1.8062 pcon=4.6731 forget=6.5621 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 340 total=13.0249 mle=1.7749 pcon=4.6731 forget=6.5769 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 0 total=12.8490 mle=1.5804 pcon=4.6730 forget=6.5956 nr=64 nf=64 protos=540 dmin_norm=NA
 92%|█████████▏| 46/50 [15:52<01:21, 20.45s/it] 94%|█████████▍| 47/50 [16:12<01:01, 20.43s/it] 96%|█████████▌| 48/50 [16:32<00:40, 20.39s/it] 98%|█████████▊| 49/50 [16:53<00:20, 20.41s/it]100%|██████████| 50/50 [17:13<00:00, 20.33s/it]100%|██████████| 50/50 [17:13<00:00, 20.67s/it]
[loss] ep 45 it 50 total=12.7988 mle=1.5796 pcon=4.6729 forget=6.5463 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 100 total=12.8130 mle=1.5763 pcon=4.6728 forget=6.5639 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 150 total=12.7938 mle=1.5594 pcon=4.6727 forget=6.5617 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 200 total=12.8111 mle=1.5901 pcon=4.6726 forget=6.5484 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 250 total=12.8456 mle=1.5818 pcon=4.6725 forget=6.5913 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 300 total=12.8632 mle=1.6618 pcon=4.6723 forget=6.5292 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 350 total=12.7410 mle=1.5400 pcon=4.6722 forget=6.5288 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 10 total=12.7585 mle=1.5303 pcon=4.6722 forget=6.5561 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 60 total=12.8372 mle=1.5457 pcon=4.6721 forget=6.6195 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 110 total=12.9487 mle=1.6928 pcon=4.6720 forget=6.5840 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 160 total=12.7057 mle=1.5059 pcon=4.6719 forget=6.5279 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 210 total=12.9557 mle=1.7513 pcon=4.6717 forget=6.5327 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 260 total=12.8976 mle=1.6928 pcon=4.6716 forget=6.5333 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 310 total=12.8075 mle=1.5518 pcon=4.6716 forget=6.5841 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 360 total=12.9807 mle=1.7207 pcon=4.6715 forget=6.5885 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 20 total=12.8212 mle=1.5802 pcon=4.6713 forget=6.5697 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 70 total=12.7591 mle=1.5539 pcon=4.6712 forget=6.5340 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 120 total=12.8898 mle=1.6504 pcon=4.6710 forget=6.5685 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 170 total=12.8323 mle=1.5485 pcon=4.6707 forget=6.6131 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 220 total=12.6696 mle=1.4760 pcon=4.6707 forget=6.5229 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 270 total=12.9271 mle=1.6271 pcon=4.6707 forget=6.6293 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 320 total=12.8919 mle=1.5867 pcon=4.6706 forget=6.6346 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 370 total=12.9008 mle=1.6429 pcon=4.6705 forget=6.5874 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 30 total=12.9057 mle=1.5907 pcon=4.6706 forget=6.6445 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 80 total=12.8760 mle=1.6066 pcon=4.6704 forget=6.5990 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 130 total=12.8820 mle=1.6747 pcon=4.6704 forget=6.5369 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 180 total=13.0019 mle=1.6555 pcon=4.6704 forget=6.6760 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 230 total=12.8930 mle=1.6456 pcon=4.6704 forget=6.5770 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 280 total=12.7670 mle=1.5875 pcon=4.6703 forget=6.5092 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 330 total=12.7811 mle=1.5843 pcon=4.6703 forget=6.5266 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 380 total=12.8773 mle=1.5775 pcon=4.6701 forget=6.6297 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 40 total=12.9096 mle=1.5751 pcon=4.6700 forget=6.6645 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 90 total=12.9182 mle=1.6224 pcon=4.6700 forget=6.6258 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 140 total=12.9190 mle=1.6296 pcon=4.6700 forget=6.6195 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 190 total=13.0431 mle=1.7657 pcon=4.6698 forget=6.6076 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 240 total=12.8750 mle=1.6771 pcon=4.6696 forget=6.5283 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 290 total=12.8943 mle=1.6205 pcon=4.6694 forget=6.6044 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 340 total=12.8108 mle=1.5438 pcon=4.6695 forget=6.5976 nr=64 nf=64 protos=540 dmin_norm=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<01:55,  3.38it/s]  2%|▏         | 7/391 [00:00<00:18, 20.49it/s]  4%|▍         | 15/391 [00:00<00:10, 37.58it/s]  6%|▌         | 23/391 [00:00<00:07, 49.06it/s]  7%|▋         | 29/391 [00:00<00:07, 49.95it/s]  9%|▉         | 35/391 [00:00<00:07, 50.44it/s] 10%|█         | 41/391 [00:00<00:07, 49.71it/s] 12%|█▏        | 47/391 [00:01<00:06, 50.97it/s] 14%|█▎        | 53/391 [00:01<00:06, 50.44it/s] 15%|█▌        | 59/391 [00:01<00:06, 49.95it/s] 17%|█▋        | 65/391 [00:01<00:06, 50.81it/s] 18%|█▊        | 71/391 [00:01<00:06, 50.51it/s] 20%|█▉        | 77/391 [00:01<00:06, 51.24it/s] 21%|██        | 83/391 [00:01<00:06, 51.24it/s] 23%|██▎       | 89/391 [00:01<00:05, 51.26it/s] 24%|██▍       | 95/391 [00:02<00:05, 50.26it/s] 26%|██▌       | 101/391 [00:02<00:05, 50.63it/s] 27%|██▋       | 107/391 [00:02<00:05, 51.36it/s] 29%|██▉       | 113/391 [00:02<00:05, 51.20it/s] 30%|███       | 119/391 [00:02<00:05, 51.80it/s] 32%|███▏      | 125/391 [00:02<00:05, 51.68it/s] 34%|███▎      | 131/391 [00:02<00:05, 51.86it/s] 35%|███▌      | 137/391 [00:02<00:05, 50.79it/s] 37%|███▋      | 143/391 [00:02<00:04, 50.39it/s] 38%|███▊      | 150/391 [00:03<00:04, 53.04it/s] 40%|███▉      | 156/391 [00:03<00:04, 52.06it/s] 41%|████▏     | 162/391 [00:03<00:04, 52.74it/s] 43%|████▎     | 168/391 [00:03<00:04, 51.68it/s] 45%|████▌     | 176/391 [00:03<00:03, 57.25it/s] 47%|████▋     | 182/391 [00:03<00:03, 55.28it/s] 48%|████▊     | 188/391 [00:03<00:03, 54.52it/s] 50%|████▉     | 194/391 [00:03<00:03, 53.58it/s] 51%|█████▏    | 201/391 [00:04<00:03, 56.84it/s] 53%|█████▎    | 207/391 [00:04<00:03, 53.84it/s] 54%|█████▍    | 213/391 [00:04<00:03, 53.47it/s] 56%|█████▌    | 219/391 [00:04<00:03, 54.42it/s] 58%|█████▊    | 226/391 [00:04<00:02, 58.10it/s] 59%|█████▉    | 232/391 [00:04<00:02, 55.83it/s] 61%|██████    | 238/391 [00:04<00:02, 55.14it/s] 62%|██████▏   | 244/391 [00:04<00:02, 53.96it/s] 64%|██████▍   | 250/391 [00:04<00:02, 53.56it/s] 65%|██████▌   | 256/391 [00:05<00:02, 50.82it/s] 67%|██████▋   | 262/391 [00:05<00:02, 50.56it/s] 69%|██████▉   | 271/391 [00:05<00:02, 59.97it/s] 72%|███████▏  | 281/391 [00:05<00:01, 70.04it/s] 74%|███████▍  | 289/391 [00:05<00:01, 72.70it/s] 76%|███████▌  | 297/391 [00:05<00:01, 63.74it/s] 78%|███████▊  | 304/391 [00:05<00:01, 60.33it/s] 80%|███████▉  | 311/391 [00:05<00:01, 61.35it/s] 82%|████████▏ | 321/391 [00:06<00:00, 70.69it/s] 85%|████████▍ | 331/391 [00:06<00:00, 74.82it/s] 87%|████████▋ | 339/391 [00:06<00:00, 64.42it/s] 88%|████████▊ | 346/391 [00:06<00:00, 60.38it/s] 90%|█████████ | 353/391 [00:06<00:00, 59.33it/s] 92%|█████████▏| 360/391 [00:06<00:00, 56.00it/s] 94%|█████████▎| 366/391 [00:06<00:00, 55.34it/s] 95%|█████████▌| 372/391 [00:06<00:00, 54.24it/s] 97%|█████████▋| 378/391 [00:07<00:00, 54.74it/s] 98%|█████████▊| 384/391 [00:07<00:00, 53.08it/s]100%|█████████▉| 390/391 [00:07<00:00, 52.65it/s]100%|██████████| 391/391 [00:07<00:00, 53.63it/s]
50000 images processed, 7.388570547103882 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:21,  3.64it/s] 11%|█▏        | 9/79 [00:00<00:02, 29.61it/s] 19%|█▉        | 15/79 [00:00<00:01, 37.05it/s] 25%|██▌       | 20/79 [00:00<00:01, 40.67it/s] 32%|███▏      | 25/79 [00:00<00:01, 41.84it/s] 39%|███▉      | 31/79 [00:00<00:01, 46.60it/s] 47%|████▋     | 37/79 [00:00<00:00, 47.21it/s] 53%|█████▎    | 42/79 [00:01<00:00, 47.67it/s] 61%|██████    | 48/79 [00:01<00:00, 49.13it/s] 68%|██████▊   | 54/79 [00:01<00:00, 49.64it/s] 76%|███████▌  | 60/79 [00:01<00:00, 49.08it/s] 84%|████████▎ | 66/79 [00:01<00:00, 49.37it/s] 91%|█████████ | 72/79 [00:01<00:00, 52.16it/s] 99%|█████████▊| 78/79 [00:01<00:00, 50.68it/s]100%|██████████| 79/79 [00:02<00:00, 33.05it/s]
10000 images processed, 2.4113311767578125 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:11,  2.85it/s]  3%|▎         | 6/204 [00:00<00:12, 16.28it/s]  5%|▌         | 11/204 [00:00<00:07, 25.51it/s] 10%|█         | 21/204 [00:00<00:03, 45.82it/s] 13%|█▎        | 27/204 [00:00<00:03, 49.41it/s] 16%|█▌        | 33/204 [00:00<00:03, 47.29it/s] 19%|█▉        | 39/204 [00:01<00:03, 47.31it/s] 23%|██▎       | 47/204 [00:01<00:02, 55.87it/s] 26%|██▋       | 54/204 [00:01<00:02, 55.43it/s] 29%|██▉       | 60/204 [00:01<00:02, 51.93it/s] 32%|███▏      | 66/204 [00:01<00:02, 50.43it/s] 36%|███▌      | 73/204 [00:01<00:02, 54.89it/s] 39%|███▊      | 79/204 [00:01<00:02, 52.45it/s] 42%|████▏     | 85/204 [00:01<00:02, 51.34it/s] 45%|████▌     | 92/204 [00:01<00:02, 54.77it/s] 48%|████▊     | 98/204 [00:02<00:01, 53.61it/s] 51%|█████     | 104/204 [00:02<00:01, 50.66it/s] 54%|█████▍    | 110/204 [00:02<00:01, 49.53it/s] 59%|█████▉    | 120/204 [00:02<00:01, 61.38it/s] 63%|██████▎   | 128/204 [00:02<00:01, 63.80it/s] 66%|██████▌   | 135/204 [00:02<00:01, 58.04it/s] 69%|██████▉   | 141/204 [00:02<00:01, 53.93it/s] 73%|███████▎  | 149/204 [00:02<00:00, 60.22it/s] 77%|███████▋  | 158/204 [00:03<00:00, 65.36it/s] 81%|████████  | 165/204 [00:03<00:00, 58.86it/s] 84%|████████▍ | 172/204 [00:03<00:00, 55.83it/s] 88%|████████▊ | 179/204 [00:03<00:00, 58.12it/s] 91%|█████████ | 185/204 [00:03<00:00, 54.22it/s] 94%|█████████▎| 191/204 [00:03<00:00, 52.80it/s] 97%|█████████▋| 197/204 [00:03<00:00, 52.27it/s]100%|██████████| 204/204 [00:03<00:00, 54.08it/s]100%|██████████| 204/204 [00:03<00:00, 51.18it/s]
26032 images processed, 4.041366338729858 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:33,  2.32it/s]  8%|▊         | 6/79 [00:00<00:05, 13.86it/s] 15%|█▌        | 12/79 [00:00<00:02, 25.17it/s] 23%|██▎       | 18/79 [00:00<00:02, 28.41it/s] 29%|██▉       | 23/79 [00:00<00:01, 32.61it/s] 38%|███▊      | 30/79 [00:01<00:01, 41.34it/s] 44%|████▍     | 35/79 [00:01<00:01, 35.70it/s] 51%|█████     | 40/79 [00:01<00:01, 38.34it/s] 57%|█████▋    | 45/79 [00:01<00:00, 39.67it/s] 70%|██████▉   | 55/79 [00:01<00:00, 53.96it/s] 78%|███████▊  | 62/79 [00:01<00:00, 56.63it/s] 87%|████████▋ | 69/79 [00:01<00:00, 50.47it/s] 95%|█████████▍| 75/79 [00:01<00:00, 49.27it/s]100%|██████████| 79/79 [00:02<00:00, 39.32it/s]
10000 images processed, 2.042119026184082 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:24,  3.15it/s]  8%|▊         | 6/79 [00:00<00:04, 17.05it/s] 14%|█▍        | 11/79 [00:00<00:02, 26.58it/s] 22%|██▏       | 17/79 [00:00<00:01, 36.17it/s] 32%|███▏      | 25/79 [00:00<00:01, 46.61it/s] 39%|███▉      | 31/79 [00:00<00:01, 46.75it/s] 47%|████▋     | 37/79 [00:01<00:00, 47.20it/s] 54%|█████▍    | 43/79 [00:01<00:00, 50.31it/s] 62%|██████▏   | 49/79 [00:01<00:00, 50.47it/s] 70%|██████▉   | 55/79 [00:01<00:00, 48.50it/s] 76%|███████▌  | 60/79 [00:01<00:00, 46.91it/s] 85%|████████▍ | 67/79 [00:01<00:00, 51.05it/s] 92%|█████████▏| 73/79 [00:01<00:00, 49.09it/s] 99%|█████████▊| 78/79 [00:01<00:00, 49.17it/s]100%|██████████| 79/79 [00:01<00:00, 43.08it/s]
10000 images processed, 1.8556327819824219 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:27,  2.53it/s]  9%|▊         | 6/70 [00:00<00:04, 14.83it/s] 16%|█▌        | 11/70 [00:00<00:02, 23.72it/s] 23%|██▎       | 16/70 [00:00<00:01, 30.30it/s] 34%|███▍      | 24/70 [00:00<00:01, 42.18it/s] 43%|████▎     | 30/70 [00:00<00:00, 43.27it/s] 51%|█████▏    | 36/70 [00:01<00:00, 46.69it/s] 60%|██████    | 42/70 [00:01<00:00, 46.81it/s] 69%|██████▊   | 48/70 [00:01<00:00, 47.79it/s] 76%|███████▌  | 53/70 [00:01<00:00, 47.57it/s] 83%|████████▎ | 58/70 [00:01<00:00, 47.76it/s] 91%|█████████▏| 64/70 [00:01<00:00, 48.42it/s] 99%|█████████▊| 69/70 [00:01<00:00, 48.43it/s]100%|██████████| 70/70 [00:01<00:00, 39.33it/s]
8925 images processed, 1.805295705795288 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:31,  1.38it/s]  4%|▍         | 2/45 [00:00<00:16,  2.68it/s] 20%|██        | 9/45 [00:01<00:03, 11.34it/s] 24%|██▍       | 11/45 [00:01<00:03, 10.30it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.86it/s] 42%|████▏     | 19/45 [00:01<00:01, 13.51it/s] 51%|█████     | 23/45 [00:02<00:01, 14.63it/s] 58%|█████▊    | 26/45 [00:02<00:01, 13.39it/s] 69%|██████▉   | 31/45 [00:02<00:00, 16.30it/s] 73%|███████▎  | 33/45 [00:02<00:00, 13.32it/s] 78%|███████▊  | 35/45 [00:02<00:00, 12.61it/s] 91%|█████████ | 41/45 [00:03<00:00, 14.60it/s] 96%|█████████▌| 43/45 [00:03<00:00, 10.63it/s]100%|██████████| 45/45 [00:03<00:00, 11.93it/s]
5640 images processed, 3.79270339012146 seconds used

24.89511275291443
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
Evaluating forget
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           6.03  98.68
places365     78.68  78.11
LSUN          30.70  94.47
iSUN          80.16  79.29
dtd           47.41  89.17
forget        43.40  91.49
AVG           47.73  88.54
Forget-Acc: 0.7890 | Retain-Acc: 0.7376
Forget-as-OOD (retain known vs forget novel):
  FPR: 43.40 AUROC: 91.49 AUIN: 98.89
11.384788751602173
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05_rf.png
