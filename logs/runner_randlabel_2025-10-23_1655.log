nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=10, batch_size=128, lr=0.0005, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.0, epsilon=0.05, incremental=False, use_lora=False, lora_impl='native', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='head', adapter_save_path=None, adapter_load_path=None, adapter_load_paths=None, lora_new_adapter_name=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_classes_inc=None, forget_classes_seen=None, forget_lambda=0.2, forget_margin=100.0, forget_strategy='randlabel', centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21605312
[debug] trainable_count = 112
[debug] trainable: encoder.conv1.weight
[debug] trainable: encoder.bn1.weight
[debug] trainable: encoder.bn1.bias
[debug] trainable: encoder.layer1.0.conv1.weight
[debug] trainable: encoder.layer1.0.bn1.weight
[debug] trainable: encoder.layer1.0.bn1.bias
[debug] trainable: encoder.layer1.0.conv2.weight
[debug] trainable: encoder.layer1.0.bn2.weight
[debug] trainable: encoder.layer1.0.bn2.bias
[debug] trainable: encoder.layer1.1.conv1.weight
[debug] trainable: encoder.layer1.1.bn1.weight
[debug] trainable: encoder.layer1.1.bn1.bias
[debug] trainable: encoder.layer1.1.conv2.weight
[debug] trainable: encoder.layer1.1.bn2.weight
[debug] trainable: encoder.layer1.1.bn2.bias
[debug] trainable: encoder.layer1.2.conv1.weight
[debug] trainable: encoder.layer1.2.bn1.weight
[debug] trainable: encoder.layer1.2.bn1.bias
[debug] trainable: encoder.layer1.2.conv2.weight
[debug] trainable: encoder.layer1.2.bn2.weight
[debug] trainable: encoder.layer1.2.bn2.bias
[debug] trainable: encoder.layer2.0.conv1.weight
[debug] trainable: encoder.layer2.0.bn1.weight
[debug] trainable: encoder.layer2.0.bn1.bias
[debug] trainable: encoder.layer2.0.conv2.weight
[debug] trainable: encoder.layer2.0.bn2.weight
[debug] trainable: encoder.layer2.0.bn2.bias
[debug] trainable: encoder.layer2.0.shortcut.0.weight
[debug] trainable: encoder.layer2.0.shortcut.1.weight
[debug] trainable: encoder.layer2.0.shortcut.1.bias
[debug] trainable: encoder.layer2.1.conv1.weight
[debug] trainable: encoder.layer2.1.bn1.weight
[debug] trainable: encoder.layer2.1.bn1.bias
[debug] trainable: encoder.layer2.1.conv2.weight
[debug] trainable: encoder.layer2.1.bn2.weight
[debug] trainable: encoder.layer2.1.bn2.bias
[debug] trainable: encoder.layer2.2.conv1.weight
[debug] trainable: encoder.layer2.2.bn1.weight
[debug] trainable: encoder.layer2.2.bn1.bias
[debug] trainable: encoder.layer2.2.conv2.weight
[debug] trainable: encoder.layer2.2.bn2.weight
[debug] trainable: encoder.layer2.2.bn2.bias
[debug] trainable: encoder.layer2.3.conv1.weight
[debug] trainable: encoder.layer2.3.bn1.weight
[debug] trainable: encoder.layer2.3.bn1.bias
[debug] trainable: encoder.layer2.3.conv2.weight
[debug] trainable: encoder.layer2.3.bn2.weight
[debug] trainable: encoder.layer2.3.bn2.bias
[debug] trainable: encoder.layer3.0.conv1.weight
[debug] trainable: encoder.layer3.0.bn1.weight
[debug][warn] non-LoRA trainables detected: ['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.1.conv1.weight']
  0%|          | 0/10 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:472: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=bool(scaler is not None)):
/home/shaokun/PALM/trainer.py:560: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  print(f"[loss-{args.forget_strategy}] ep {epoch} it {it} total={loss.item():.4f} ce_r={float(loss_retain):.4f} ce_f={float(loss_forget):.4f}")
 10%|█         | 1/10 [00:47<07:06, 47.38s/it] 20%|██        | 2/10 [01:20<05:10, 38.87s/it] 30%|███       | 3/10 [01:52<04:12, 36.02s/it] 40%|████      | 4/10 [02:26<03:29, 34.90s/it] 50%|█████     | 5/10 [02:59<02:51, 34.23s/it] 60%|██████    | 6/10 [03:32<02:15, 33.89s/it] 70%|███████   | 7/10 [04:05<01:40, 33.54s/it] 80%|████████  | 8/10 [04:38<01:06, 33.34s/it] 90%|█████████ | 9/10 [05:07<00:32, 32.18s/it]100%|██████████| 10/10 [05:33<00:00, 30.10s/it]100%|██████████| 10/10 [05:33<00:00, 33.32s/it]
[loss-randlabel] ep 0 it 0 total=2.1746 ce_r=0.2464 ce_f=9.6407
[loss-randlabel] ep 0 it 50 total=2.0528 ce_r=0.2070 ce_f=9.2290
[loss-randlabel] ep 0 it 100 total=2.1955 ce_r=0.2917 ce_f=9.5193
[loss-randlabel] ep 0 it 150 total=2.1167 ce_r=0.1639 ce_f=9.7643
[loss-randlabel] ep 0 it 200 total=2.2097 ce_r=0.2214 ce_f=9.9411
[loss-randlabel] ep 0 it 250 total=2.0762 ce_r=0.1021 ce_f=9.8703
[loss-randlabel] ep 0 it 300 total=2.1475 ce_r=0.2088 ce_f=9.6939
[loss-randlabel] ep 0 it 350 total=1.9840 ce_r=0.0825 ce_f=9.5074
[loss-randlabel] ep 1 it 10 total=1.9492 ce_r=0.1003 ce_f=9.2448
[loss-randlabel] ep 1 it 60 total=1.9629 ce_r=0.0770 ce_f=9.4295
[loss-randlabel] ep 1 it 110 total=2.0360 ce_r=0.0828 ce_f=9.7659
[loss-randlabel] ep 1 it 160 total=2.0248 ce_r=0.1030 ce_f=9.6094
[loss-randlabel] ep 1 it 210 total=1.9563 ce_r=0.1326 ce_f=9.1184
[loss-randlabel] ep 1 it 260 total=1.9653 ce_r=0.0598 ce_f=9.5275
[loss-randlabel] ep 1 it 310 total=1.9680 ce_r=0.1676 ce_f=9.0021
[loss-randlabel] ep 1 it 360 total=1.9849 ce_r=0.1779 ce_f=9.0352
[loss-randlabel] ep 2 it 20 total=2.0309 ce_r=0.2122 ce_f=9.0935
[loss-randlabel] ep 2 it 70 total=2.0382 ce_r=0.2338 ce_f=9.0219
[loss-randlabel] ep 2 it 120 total=1.8113 ce_r=0.0889 ce_f=8.6120
[loss-randlabel] ep 2 it 170 total=1.9464 ce_r=0.2514 ce_f=8.4750
[loss-randlabel] ep 2 it 220 total=1.8520 ce_r=0.2447 ce_f=8.0363
[loss-randlabel] ep 2 it 270 total=1.9178 ce_r=0.3019 ce_f=8.0796
[loss-randlabel] ep 2 it 320 total=1.9274 ce_r=0.3264 ce_f=8.0050
[loss-randlabel] ep 2 it 370 total=1.7583 ce_r=0.1822 ce_f=7.8808
[loss-randlabel] ep 3 it 30 total=1.7791 ce_r=0.1844 ce_f=7.9735
[loss-randlabel] ep 3 it 80 total=1.7746 ce_r=0.1715 ce_f=8.0153
[loss-randlabel] ep 3 it 130 total=1.7740 ce_r=0.1715 ce_f=8.0121
[loss-randlabel] ep 3 it 180 total=1.7959 ce_r=0.2084 ce_f=7.9371
[loss-randlabel] ep 3 it 230 total=1.7893 ce_r=0.1856 ce_f=8.0181
[loss-randlabel] ep 3 it 280 total=1.7287 ce_r=0.1891 ce_f=7.6978
[loss-randlabel] ep 3 it 330 total=1.7609 ce_r=0.2451 ce_f=7.5790
[loss-randlabel] ep 3 it 380 total=1.7084 ce_r=0.1940 ce_f=7.5719
[loss-randlabel] ep 4 it 40 total=1.8515 ce_r=0.3405 ce_f=7.5546
[loss-randlabel] ep 4 it 90 total=1.8671 ce_r=0.3799 ce_f=7.4359
[loss-randlabel] ep 4 it 140 total=1.6968 ce_r=0.2615 ce_f=7.1766
[loss-randlabel] ep 4 it 190 total=1.6345 ce_r=0.1623 ce_f=7.3609
[loss-randlabel] ep 4 it 240 total=1.7175 ce_r=0.2802 ce_f=7.1862
[loss-randlabel] ep 4 it 290 total=1.6485 ce_r=0.1772 ce_f=7.3568
[loss-randlabel] ep 4 it 340 total=1.7066 ce_r=0.2349 ce_f=7.3586
[loss-randlabel] ep 5 it 0 total=1.7089 ce_r=0.2304 ce_f=7.3924
[loss-randlabel] ep 5 it 50 total=1.6264 ce_r=0.1814 ce_f=7.2248
[loss-randlabel] ep 5 it 100 total=1.7789 ce_r=0.3263 ce_f=7.2630
[loss-randlabel] ep 5 it 150 total=1.6976 ce_r=0.2173 ce_f=7.4015
[loss-randlabel] ep 5 it 200 total=1.6565 ce_r=0.1979 ce_f=7.2931
[loss-randlabel] ep 5 it 250 total=1.5985 ce_r=0.2218 ce_f=6.8840
[loss-randlabel] ep 5 it 300 total=1.6189 ce_r=0.1635 ce_f=7.2771
[loss-randlabel] ep 5 it 350 total=1.6396 ce_r=0.1709 ce_f=7.3435
[loss-randlabel] ep 6 it 10 total=1.6218 ce_r=0.1525 ce_f=7.3465
[loss-randlabel] ep 6 it 60 total=1.5841 ce_r=0.1928 ce_f=6.9561
[loss-randlabel] ep 6 it 110 total=1.6002 ce_r=0.1433 ce_f=7.2843
[loss-randlabel] ep 6 it 160 total=1.5960 ce_r=0.1983 ce_f=6.9889
[loss-randlabel] ep 6 it 210 total=1.5745 ce_r=0.1601 ce_f=7.0721
[loss-randlabel] ep 6 it 260 total=1.6139 ce_r=0.2260 ce_f=6.9392
[loss-randlabel] ep 6 it 310 total=1.6632 ce_r=0.2534 ce_f=7.0490
[loss-randlabel] ep 6 it 360 total=1.5489 ce_r=0.1590 ce_f=6.9499
[loss-randlabel] ep 7 it 20 total=1.5892 ce_r=0.1790 ce_f=7.0512
[loss-randlabel] ep 7 it 70 total=1.6155 ce_r=0.2181 ce_f=6.9865
[loss-randlabel] ep 7 it 120 total=1.6298 ce_r=0.2233 ce_f=7.0324
[loss-randlabel] ep 7 it 170 total=1.5982 ce_r=0.2182 ce_f=6.9002
[loss-randlabel] ep 7 it 220 total=1.6414 ce_r=0.1920 ce_f=7.2467
[loss-randlabel] ep 7 it 270 total=1.5880 ce_r=0.1544 ce_f=7.1678
[loss-randlabel] ep 7 it 320 total=1.5954 ce_r=0.2435 ce_f=6.7593
[loss-randlabel] ep 7 it 370 total=1.5673 ce_r=0.1884 ce_f=6.8946
[loss-randlabel] ep 8 it 30 total=1.6920 ce_r=0.3068 ce_f=6.9261
[loss-randlabel] ep 8 it 80 total=1.5688 ce_r=0.1568 ce_f=7.0599
[loss-randlabel] ep 8 it 130 total=1.6435 ce_r=0.2974 ce_f=6.7302
[loss-randlabel] ep 8 it 180 total=1.5929 ce_r=0.1874 ce_f=7.0275
[loss-randlabel] ep 8 it 230 total=1.5524 ce_r=0.1882 ce_f=6.8209
[loss-randlabel] ep 8 it 280 total=1.5903 ce_r=0.2506 ce_f=6.6985
[loss-randlabel] ep 8 it 330 total=1.6872 ce_r=0.3154 ce_f=6.8589
[loss-randlabel] ep 8 it 380 total=1.6128 ce_r=0.2331 ce_f=6.8985
[loss-randlabel] ep 9 it 40 total=1.5364 ce_r=0.1168 ce_f=7.0980
[loss-randlabel] ep 9 it 90 total=1.6698 ce_r=0.3478 ce_f=6.6101
[loss-randlabel] ep 9 it 140 total=1.5304 ce_r=0.1690 ce_f=6.8071
[loss-randlabel] ep 9 it 190 total=1.6000 ce_r=0.2887 ce_f=6.5565
[loss-randlabel] ep 9 it 240 total=1.5598 ce_r=0.1956 ce_f=6.8212
[loss-randlabel] ep 9 it 290 total=1.6637 ce_r=0.3746 ce_f=6.4454
[loss-randlabel] ep 9 it 340 total=1.5557 ce_r=0.2499 ce_f=6.5290
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-baseline_randlabel_forget.pt
resnet34-top5-palm-cache6-ema0.999-baseline-randlabel-b128-e10-lr0.0005-wd1e-4-fl0.2: Number of model parameters: 21605312
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<01:55,  3.39it/s]  3%|▎         | 12/391 [00:00<00:10, 36.98it/s]  6%|▌         | 22/391 [00:00<00:06, 56.58it/s]  8%|▊         | 32/391 [00:00<00:05, 69.17it/s] 11%|█         | 43/391 [00:00<00:04, 79.27it/s] 14%|█▎        | 53/391 [00:00<00:03, 85.00it/s] 16%|█▋        | 64/391 [00:00<00:03, 89.89it/s] 19%|█▉        | 74/391 [00:01<00:03, 90.91it/s] 22%|██▏       | 85/391 [00:01<00:03, 93.83it/s] 24%|██▍       | 95/391 [00:01<00:03, 95.37it/s] 27%|██▋       | 106/391 [00:01<00:02, 96.95it/s] 30%|██▉       | 117/391 [00:01<00:02, 98.19it/s] 32%|███▏      | 127/391 [00:01<00:02, 98.69it/s] 35%|███▌      | 138/391 [00:01<00:02, 99.33it/s] 38%|███▊      | 149/391 [00:01<00:02, 99.83it/s] 41%|████      | 160/391 [00:01<00:02, 100.18it/s] 44%|████▎     | 171/391 [00:02<00:02, 100.45it/s] 47%|████▋     | 182/391 [00:02<00:02, 100.18it/s] 49%|████▉     | 193/391 [00:02<00:01, 100.29it/s] 52%|█████▏    | 204/391 [00:02<00:01, 99.11it/s]  55%|█████▍    | 215/391 [00:02<00:01, 99.67it/s] 58%|█████▊    | 226/391 [00:02<00:01, 99.85it/s] 60%|██████    | 236/391 [00:02<00:01, 97.70it/s] 63%|██████▎   | 246/391 [00:02<00:01, 95.92it/s] 66%|██████▌   | 257/391 [00:02<00:01, 97.11it/s] 68%|██████▊   | 267/391 [00:02<00:01, 96.58it/s] 71%|███████   | 278/391 [00:03<00:01, 97.81it/s] 74%|███████▎  | 288/391 [00:03<00:01, 98.37it/s] 76%|███████▋  | 299/391 [00:03<00:00, 99.17it/s] 79%|███████▉  | 310/391 [00:03<00:00, 99.48it/s] 82%|████████▏ | 321/391 [00:03<00:00, 99.69it/s] 85%|████████▍ | 331/391 [00:03<00:00, 99.51it/s] 87%|████████▋ | 342/391 [00:03<00:00, 99.88it/s] 90%|█████████ | 353/391 [00:03<00:00, 100.06it/s] 93%|█████████▎| 364/391 [00:03<00:00, 100.28it/s] 96%|█████████▌| 375/391 [00:04<00:00, 98.35it/s]  99%|█████████▊| 386/391 [00:04<00:00, 99.48it/s]100%|██████████| 391/391 [00:04<00:00, 92.36it/s]
50000 images processed, 4.315991640090942 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:19,  4.00it/s] 14%|█▍        | 11/79 [00:00<00:01, 38.00it/s] 27%|██▋       | 21/79 [00:00<00:01, 57.83it/s] 41%|████      | 32/79 [00:00<00:00, 72.33it/s] 53%|█████▎    | 42/79 [00:00<00:00, 80.02it/s] 67%|██████▋   | 53/79 [00:00<00:00, 86.51it/s] 81%|████████  | 64/79 [00:00<00:00, 90.81it/s] 95%|█████████▍| 75/79 [00:01<00:00, 94.07it/s]100%|██████████| 79/79 [00:01<00:00, 52.76it/s]
10000 images processed, 1.5210082530975342 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<00:58,  3.47it/s]  4%|▍         | 9/204 [00:00<00:06, 28.11it/s]  9%|▉         | 19/204 [00:00<00:03, 50.56it/s] 14%|█▍        | 29/204 [00:00<00:02, 65.86it/s] 19%|█▉        | 39/204 [00:00<00:02, 76.30it/s] 24%|██▍       | 49/204 [00:00<00:01, 83.49it/s] 29%|██▉       | 59/204 [00:00<00:01, 87.75it/s] 34%|███▍      | 70/204 [00:01<00:01, 90.11it/s] 39%|███▉      | 80/204 [00:01<00:01, 92.78it/s] 44%|████▍     | 90/204 [00:01<00:01, 94.37it/s] 49%|████▉     | 100/204 [00:01<00:01, 93.77it/s] 54%|█████▍    | 110/204 [00:01<00:00, 95.15it/s] 59%|█████▉    | 120/204 [00:01<00:00, 95.51it/s] 64%|██████▎   | 130/204 [00:01<00:00, 95.58it/s] 69%|██████▊   | 140/204 [00:01<00:00, 96.25it/s] 74%|███████▎  | 150/204 [00:01<00:00, 97.17it/s] 78%|███████▊  | 160/204 [00:01<00:00, 96.93it/s] 83%|████████▎ | 170/204 [00:02<00:00, 97.71it/s] 88%|████████▊ | 180/204 [00:02<00:00, 97.89it/s] 93%|█████████▎| 190/204 [00:02<00:00, 98.42it/s] 99%|█████████▊| 201/204 [00:02<00:00, 99.20it/s]100%|██████████| 204/204 [00:02<00:00, 85.41it/s]
26032 images processed, 2.4253344535827637 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:35,  2.17it/s] 11%|█▏        | 9/79 [00:00<00:03, 19.17it/s] 22%|██▏       | 17/79 [00:00<00:01, 31.14it/s] 32%|███▏      | 25/79 [00:00<00:01, 39.88it/s] 39%|███▉      | 31/79 [00:00<00:01, 44.63it/s] 47%|████▋     | 37/79 [00:01<00:00, 43.65it/s] 54%|█████▍    | 43/79 [00:01<00:00, 45.48it/s] 63%|██████▎   | 50/79 [00:01<00:00, 48.19it/s] 73%|███████▎  | 58/79 [00:01<00:00, 47.04it/s] 84%|████████▎ | 66/79 [00:01<00:00, 47.66it/s] 94%|█████████▎| 74/79 [00:01<00:00, 48.45it/s]100%|██████████| 79/79 [00:01<00:00, 41.69it/s]
10000 images processed, 1.9335741996765137 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:24,  3.19it/s] 14%|█▍        | 11/79 [00:00<00:02, 32.56it/s] 27%|██▋       | 21/79 [00:00<00:01, 52.88it/s] 39%|███▉      | 31/79 [00:00<00:00, 66.84it/s] 52%|█████▏    | 41/79 [00:00<00:00, 76.40it/s] 65%|██████▍   | 51/79 [00:00<00:00, 83.30it/s] 77%|███████▋  | 61/79 [00:00<00:00, 88.28it/s] 91%|█████████ | 72/79 [00:01<00:00, 92.19it/s]100%|██████████| 79/79 [00:01<00:00, 71.90it/s]
10000 images processed, 1.1167266368865967 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:24,  2.80it/s] 16%|█▌        | 11/70 [00:00<00:01, 29.86it/s] 30%|███       | 21/70 [00:00<00:00, 49.77it/s] 44%|████▍     | 31/70 [00:00<00:00, 63.25it/s] 60%|██████    | 42/70 [00:00<00:00, 74.65it/s] 74%|███████▍  | 52/70 [00:00<00:00, 81.84it/s] 89%|████████▊ | 62/70 [00:00<00:00, 86.76it/s]100%|██████████| 70/70 [00:01<00:00, 65.64it/s]
8925 images processed, 1.0961127281188965 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:34,  1.29it/s]  4%|▍         | 2/45 [00:00<00:17,  2.51it/s] 20%|██        | 9/45 [00:01<00:03, 10.94it/s] 24%|██▍       | 11/45 [00:01<00:03, 10.33it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.32it/s] 42%|████▏     | 19/45 [00:01<00:01, 13.52it/s] 49%|████▉     | 22/45 [00:02<00:01, 14.61it/s] 56%|█████▌    | 25/45 [00:02<00:01, 15.17it/s] 60%|██████    | 27/45 [00:02<00:01, 15.69it/s] 67%|██████▋   | 30/45 [00:02<00:01, 13.61it/s] 73%|███████▎  | 33/45 [00:02<00:00, 12.42it/s] 87%|████████▋ | 39/45 [00:03<00:00, 16.06it/s] 91%|█████████ | 41/45 [00:03<00:00, 14.64it/s] 96%|█████████▌| 43/45 [00:03<00:00, 12.02it/s]100%|██████████| 45/45 [00:03<00:00, 12.36it/s]
5640 images processed, 3.65987491607666 seconds used

17.723599433898926
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.42  99.10
places365     71.48  78.83
LSUN          27.82  93.99
iSUN          67.92  83.79
dtd           40.67  90.17
AVG           42.26  89.18
Retain-Acc: 0.7352
Forget-as-OOD (retain known vs forget novel):
  FPR: 49.40 AUROC: 89.80 AUIN: 98.71
8.609821796417236
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e10-lr0.0005-wd1e-4-fl0.2_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-baseline-randlabel-b128-e10-lr0.0005-wd1e-4-fl0.2_rf.png
