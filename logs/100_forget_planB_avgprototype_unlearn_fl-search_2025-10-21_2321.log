nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.6, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:32<26:26, 32.38s/it]  4%|▍         | 2/50 [01:00<23:57, 29.95s/it]  6%|▌         | 3/50 [01:28<22:36, 28.87s/it]  8%|▊         | 4/50 [02:01<23:25, 30.54s/it] 10%|█         | 5/50 [02:43<26:04, 34.77s/it] 12%|█▏        | 6/50 [03:17<25:17, 34.48s/it] 14%|█▍        | 7/50 [03:49<24:08, 33.69s/it] 16%|█▌        | 8/50 [04:16<22:10, 31.67s/it][loss] ep 0 it 0 total=9.9104 mle=1.5709 pcon=5.2950 forget=4.1265 favg=-1.0820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=9.7022 mle=1.5424 pcon=5.2879 forget=4.2039 favg=-1.3320 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=9.8356 mle=1.7003 pcon=5.2809 forget=4.1219 favg=-1.2676 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=9.9402 mle=1.8995 pcon=5.2738 forget=4.1087 favg=-1.3418 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=9.9391 mle=1.7130 pcon=5.2670 forget=4.1476 favg=-1.1885 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=9.6472 mle=1.5020 pcon=5.2603 forget=4.1348 favg=-1.2500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=9.8604 mle=1.5596 pcon=5.2540 forget=4.1454 favg=-1.0986 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=9.7408 mle=1.6807 pcon=5.2476 forget=4.1679 favg=-1.3555 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=9.7194 mle=1.6718 pcon=5.2409 forget=4.2287 favg=-1.4219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=9.6917 mle=1.6372 pcon=5.2345 forget=4.0993 favg=-1.2793 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=9.6545 mle=1.5169 pcon=5.2284 forget=4.1642 favg=-1.2549 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=9.8017 mle=1.7799 pcon=5.2223 forget=4.1608 favg=-1.3613 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=9.5225 mle=1.7661 pcon=5.2165 forget=4.1435 favg=-1.6035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=9.1901 mle=1.5976 pcon=5.2108 forget=4.0731 favg=-1.6914 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=8.5564 mle=1.7096 pcon=5.2049 forget=4.1049 favg=-2.4629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=7.4611 mle=1.8144 pcon=5.1988 forget=4.1783 favg=-3.7305 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=6.2478 mle=1.5424 pcon=5.1927 forget=4.3018 favg=-4.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=5.9934 mle=1.9026 pcon=5.1864 forget=4.4084 favg=-5.5039 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=5.7938 mle=1.7856 pcon=5.1801 forget=4.5077 favg=-5.6797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=5.4292 mle=1.6060 pcon=5.1742 forget=4.6217 favg=-5.9727 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=5.8047 mle=1.7501 pcon=5.1685 forget=4.7650 favg=-5.8789 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=7.1316 mle=1.9589 pcon=5.1635 forget=4.9078 favg=-4.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=14.4897 mle=1.7152 pcon=5.1583 forget=5.1787 favg=2.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=17.9141 mle=1.8892 pcon=5.1530 forget=5.2274 favg=5.6445 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 3 it 30 total=17.2147 mle=1.6914 pcon=5.1476 forget=5.0085 favg=5.3672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=15.1574 mle=1.6490 pcon=5.1428 forget=4.5219 favg=3.8438 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=12.8332 mle=1.7631 pcon=5.1381 forget=4.2015 favg=1.7305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=12.5106 mle=1.9219 pcon=5.1342 forget=4.1820 favg=1.2725 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=12.0251 mle=1.5818 pcon=5.1303 forget=4.1685 favg=1.1445 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=11.6283 mle=1.8359 pcon=5.1263 forget=4.1530 favg=0.5132 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=9.1938 mle=1.7195 pcon=5.1225 forget=4.2736 favg=-1.9219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=8.5079 mle=1.7147 pcon=5.1200 forget=4.4018 favg=-2.7285 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 40 total=13.0223 mle=1.7270 pcon=5.1175 forget=4.3048 favg=1.8730 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=11.0293 mle=1.7565 pcon=5.1143 forget=4.1195 favg=0.0389 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=9.3317 mle=1.6492 pcon=5.1107 forget=4.2192 favg=-1.6475 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=7.2633 mle=1.4602 pcon=5.1068 forget=4.4912 favg=-3.7949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=8.4859 mle=1.8505 pcon=5.1023 forget=4.5721 favg=-3.0391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=16.1534 mle=1.4584 pcon=5.0981 forget=4.6359 favg=4.9609 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=12.4436 mle=1.9019 pcon=5.0940 forget=4.2476 favg=1.2002 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=10.4416 mle=1.8678 pcon=5.0904 forget=4.1474 favg=-0.6641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=8.1042 mle=1.8028 pcon=5.0870 forget=4.0347 favg=-2.8203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=11.4489 mle=1.6483 pcon=5.0847 forget=4.1704 favg=0.5454 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=16.1955 mle=1.6438 pcon=5.0826 forget=4.3168 favg=5.1523 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=11.0140 mle=1.6908 pcon=5.0804 forget=4.1287 favg=0.1141 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=6.3485 mle=1.7761 pcon=5.0772 forget=4.2062 favg=-4.7109 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=10.5009 mle=1.6967 pcon=5.0736 forget=4.5744 favg=-0.8438 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=14.9247 mle=1.7998 pcon=5.0701 forget=4.7305 favg=3.3242 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=11.8096 mle=1.4125 pcon=5.0670 forget=4.2569 favg=1.0732 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=9.1096 mle=1.5923 pcon=5.0648 forget=4.1215 favg=-1.6689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=12.8053 mle=1.7030 pcon=5.0634 forget=4.3328 favg=1.7061 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=13.0667 mle=1.6966 pcon=5.0616 forget=4.1210 favg=2.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=8.9494 mle=1.6106 pcon=5.0593 forget=4.1349 favg=-1.8555 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=7.7024 mle=1.7648 pcon=5.0560 forget=4.1961 favg=-3.3145 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=8.6329 mle=1.5570 pcon=5.0534 forget=4.2080 favg=-2.1855 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=13.0701 mle=1.7068 pcon=5.0513 forget=4.1284 favg=2.1836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=14.4190 mle=1.6801 pcon=5.0493 forget=4.1466 favg=3.5430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=11.9702 mle=1.8505 pcon=5.0475 forget=4.1396 favg=0.9326 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=7.4663 mle=1.7003 pcon=5.0450 forget=4.0589 favg=-3.3379 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=8.4814 mle=1.6576 pcon=5.0424 forget=4.1329 favg=-2.3516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=11.7827 mle=1.7162 pcon=5.0401 forget=4.4414 favg=0.5850 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=13.7968 mle=1.8873 pcon=5.0387 forget=4.1170 favg=2.7539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=15.9272 mle=1.8405 pcon=5.0378 forget=4.1504 favg=4.8984 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=14.0728 mle=1.6769 pcon=5.0370 forget=4.1987 favg=3.1602 nr=64 nf=64 protos=540 fproto_sim=NA
 18%|█▊        | 9/50 [04:41<20:04, 29.37s/it] 20%|██        | 10/50 [05:05<18:28, 27.72s/it] 22%|██▏       | 11/50 [05:43<20:12, 31.08s/it] 24%|██▍       | 12/50 [06:16<19:52, 31.38s/it] 26%|██▌       | 13/50 [06:49<19:42, 31.96s/it] 28%|██▊       | 14/50 [07:35<21:47, 36.31s/it] 30%|███       | 15/50 [08:11<21:08, 36.23s/it] 32%|███▏      | 16/50 [08:45<20:06, 35.48s/it][loss] ep 8 it 30 total=8.3990 mle=1.5937 pcon=5.0355 forget=4.0335 favg=-2.2637 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=6.0932 mle=1.7061 pcon=5.0334 forget=4.0529 favg=-4.6992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=8.2270 mle=1.6032 pcon=5.0316 forget=4.0609 favg=-2.4688 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=15.0171 mle=1.8558 pcon=5.0305 forget=4.0957 favg=4.0352 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=15.5375 mle=1.6121 pcon=5.0298 forget=4.1066 favg=4.7891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=15.1014 mle=1.8954 pcon=5.0286 forget=4.1111 favg=4.0664 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=12.2638 mle=1.8528 pcon=5.0268 forget=4.0483 favg=1.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=6.9444 mle=1.6327 pcon=5.0248 forget=3.9059 favg=-3.6191 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 40 total=7.0536 mle=1.8945 pcon=5.0230 forget=4.0190 favg=-3.8828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=15.6960 mle=1.9583 pcon=5.0216 forget=4.2630 favg=4.4531 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=15.4377 mle=1.8002 pcon=5.0208 forget=4.4018 favg=4.2148 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=11.8602 mle=1.6720 pcon=5.0199 forget=4.1937 favg=0.9746 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=6.4214 mle=1.7838 pcon=5.0185 forget=3.9121 favg=-4.2930 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=8.6881 mle=1.8696 pcon=5.0164 forget=3.9486 favg=-2.1465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=16.0884 mle=1.6759 pcon=5.0146 forget=4.0385 favg=5.3594 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=15.8650 mle=1.7174 pcon=5.0131 forget=4.1580 favg=4.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=13.1695 mle=1.6948 pcon=5.0116 forget=4.2112 favg=2.2520 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=7.8267 mle=1.9159 pcon=5.0107 forget=3.9938 favg=-3.0938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=6.2219 mle=2.0133 pcon=5.0099 forget=3.9605 favg=-4.7617 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=14.5824 mle=2.0515 pcon=5.0087 forget=4.1218 favg=3.4004 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=14.9304 mle=1.7149 pcon=5.0071 forget=4.3860 favg=3.8223 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=11.8102 mle=1.6105 pcon=5.0056 forget=4.2834 favg=0.9106 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=7.6283 mle=1.7184 pcon=5.0039 forget=3.9509 favg=-3.0449 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=5.4833 mle=1.7236 pcon=5.0027 forget=3.9328 favg=-5.1758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=11.7808 mle=1.8378 pcon=5.0017 forget=4.0741 favg=0.8672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=16.0215 mle=1.7396 pcon=5.0009 forget=4.0818 favg=5.1992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=15.4316 mle=1.7335 pcon=4.9995 forget=4.1595 favg=4.5391 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=13.9265 mle=1.7930 pcon=4.9983 forget=4.2172 favg=2.9180 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=10.5602 mle=1.6725 pcon=4.9965 forget=4.1678 favg=-0.2766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=6.5165 mle=2.1012 pcon=4.9936 forget=4.0076 favg=-4.5859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=11.6913 mle=1.8513 pcon=4.9910 forget=4.0511 favg=0.7979 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=15.1408 mle=1.6275 pcon=4.9888 forget=4.0987 favg=4.4258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=13.1539 mle=1.8326 pcon=4.9871 forget=4.0920 favg=2.2422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=9.1024 mle=1.6524 pcon=4.9856 forget=4.0572 favg=-1.5928 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=6.2576 mle=1.7540 pcon=4.9836 forget=3.9575 favg=-4.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=4.5836 mle=1.6645 pcon=4.9811 forget=3.9576 favg=-6.0195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=10.0809 mle=1.6404 pcon=4.9789 forget=4.1271 favg=-0.6655 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=15.2428 mle=1.6614 pcon=4.9767 forget=4.3743 favg=4.2305 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=15.1910 mle=1.7899 pcon=4.9749 forget=4.3285 favg=4.0977 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=14.1605 mle=1.4724 pcon=4.9733 forget=4.2030 favg=3.5117 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=13.5864 mle=1.5480 pcon=4.9715 forget=4.1333 favg=2.9336 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=12.1698 mle=1.6183 pcon=4.9692 forget=4.0930 favg=1.4893 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=11.2832 mle=1.7890 pcon=4.9668 forget=4.2989 favg=0.2284 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=12.8277 mle=1.7142 pcon=4.9643 forget=4.2811 favg=1.8682 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=13.0267 mle=1.6407 pcon=4.9618 forget=4.1839 favg=2.2402 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.5572 mle=1.5707 pcon=4.9592 forget=4.1172 favg=-2.0898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=5.4383 mle=1.6440 pcon=4.9569 forget=3.9780 favg=-5.1406 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=4.8307 mle=1.8814 pcon=4.9545 forget=3.9714 favg=-5.9766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=5.6924 mle=1.8870 pcon=4.9529 forget=4.0010 favg=-5.1484 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=16.3778 mle=1.7107 pcon=4.9515 forget=4.0984 favg=5.6172 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=16.7875 mle=1.7961 pcon=4.9496 forget=4.1668 favg=5.8750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=15.9151 mle=1.5907 pcon=4.9479 forget=4.1890 favg=5.1875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=14.3305 mle=1.6260 pcon=4.9456 forget=4.1924 favg=3.5664 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=12.9515 mle=1.7016 pcon=4.9430 forget=4.1780 favg=2.1289 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=11.2601 mle=1.7246 pcon=4.9402 forget=4.1604 favg=0.4348 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=8.5342 mle=1.5547 pcon=4.9371 forget=4.0600 favg=-2.0176 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=7.1067 mle=1.6909 pcon=4.9341 forget=3.9622 favg=-3.4805 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=10.0870 mle=1.7086 pcon=4.9313 forget=3.9851 favg=-0.5381 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=12.1597 mle=1.6677 pcon=4.9286 forget=4.0820 favg=1.4814 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=12.4951 mle=1.9251 pcon=4.9258 forget=4.1462 favg=1.4980 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=11.3174 mle=1.5955 pcon=4.9233 forget=4.1394 favg=0.6592 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=9.9865 mle=1.6119 pcon=4.9204 forget=4.0866 favg=-0.6323 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=8.6032 mle=1.5680 pcon=4.9173 forget=4.0280 favg=-1.9102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=7.6367 mle=1.5286 pcon=4.9142 forget=4.0065 favg=-2.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=7.7314 mle=1.6750 pcon=4.9113 forget=4.0865 favg=-2.9414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=8.7551 mle=1.6826 pcon=4.9080 forget=4.2603 favg=-2.0957 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=10.5828 mle=1.6193 pcon=4.9048 forget=4.4708 favg=-0.4121 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=12.9293 mle=1.9306 pcon=4.9017 forget=4.5843 favg=1.5127 nr=64 nf=64 protos=540 fproto_sim=NA
 34%|███▍      | 17/50 [09:18<19:03, 34.65s/it] 36%|███▌      | 18/50 [09:49<17:52, 33.52s/it] 38%|███▊      | 19/50 [10:18<16:43, 32.37s/it] 40%|████      | 20/50 [10:49<15:52, 31.76s/it] 42%|████▏     | 21/50 [11:19<15:09, 31.37s/it] 44%|████▍     | 22/50 [11:50<14:31, 31.14s/it] 46%|████▌     | 23/50 [12:29<15:05, 33.55s/it] 48%|████▊     | 24/50 [12:59<14:05, 32.51s/it] 50%|█████     | 25/50 [13:30<13:20, 32.03s/it][loss] ep 16 it 310 total=13.7837 mle=1.8943 pcon=4.8988 forget=4.5530 favg=2.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=13.3521 mle=1.7142 pcon=4.8960 forget=4.4294 favg=2.3125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 20 total=12.4970 mle=1.8135 pcon=4.8928 forget=4.3317 favg=1.4590 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=11.4547 mle=1.8447 pcon=4.8901 forget=4.2278 favg=0.4922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=10.3483 mle=1.6683 pcon=4.8869 forget=4.2089 favg=-0.4158 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=9.9481 mle=1.6563 pcon=4.8834 forget=4.2107 favg=-0.8022 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=10.9948 mle=1.6441 pcon=4.8801 forget=4.2238 favg=0.2468 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=12.9505 mle=1.6361 pcon=4.8771 forget=4.4022 favg=2.0352 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=13.9885 mle=1.9349 pcon=4.8739 forget=4.6289 favg=2.5508 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=13.1596 mle=1.8232 pcon=4.8705 forget=4.7061 favg=1.7598 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 30 total=11.7835 mle=1.6699 pcon=4.8677 forget=4.6444 favg=0.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=9.7666 mle=1.6356 pcon=4.8646 forget=4.3953 favg=-1.1289 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=7.3310 mle=1.7059 pcon=4.8615 forget=4.1034 favg=-3.3398 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=5.4097 mle=1.8222 pcon=4.8586 forget=4.0258 favg=-5.2969 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=10.8256 mle=1.7549 pcon=4.8559 forget=4.0664 favg=0.1483 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=15.1427 mle=1.8132 pcon=4.8534 forget=4.2613 favg=4.2148 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 330 total=15.7170 mle=1.7103 pcon=4.8509 forget=4.4488 favg=4.7070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=15.6901 mle=1.7199 pcon=4.8483 forget=4.5867 favg=4.5352 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 40 total=15.0195 mle=1.5498 pcon=4.8457 forget=4.6494 favg=3.9746 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=14.0552 mle=1.6630 pcon=4.8430 forget=4.6157 favg=2.9336 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=10.5066 mle=1.6889 pcon=4.8400 forget=4.3613 favg=-0.3835 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=7.0733 mle=2.0322 pcon=4.8371 forget=4.1865 favg=-3.9824 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=8.8548 mle=1.9671 pcon=4.8345 forget=4.3891 favg=-2.3359 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=12.5941 mle=1.8430 pcon=4.8323 forget=4.7509 favg=1.1680 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=13.0457 mle=1.6341 pcon=4.8300 forget=4.7300 favg=1.8516 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=12.7485 mle=1.6910 pcon=4.8276 forget=4.5648 favg=1.6650 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=11.8950 mle=1.7179 pcon=4.8251 forget=4.3886 favg=0.9634 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=10.4208 mle=1.7273 pcon=4.8227 forget=4.2895 favg=-0.4187 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=9.3325 mle=1.9084 pcon=4.8202 forget=4.2085 favg=-1.6045 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=8.2860 mle=1.6737 pcon=4.8178 forget=4.1227 favg=-2.3281 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=10.4856 mle=2.0042 pcon=4.8156 forget=4.1604 favg=-0.4946 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=12.3647 mle=1.8544 pcon=4.8137 forget=4.3850 favg=1.3115 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=12.6489 mle=1.5648 pcon=4.8118 forget=4.5281 favg=1.7441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=12.5930 mle=1.5593 pcon=4.8097 forget=4.5589 favg=1.6650 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=11.9634 mle=1.7207 pcon=4.8072 forget=4.4266 favg=1.0088 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=10.7765 mle=1.6236 pcon=4.8046 forget=4.2872 favg=0.0610 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=10.3942 mle=1.6425 pcon=4.8018 forget=4.2431 favg=-0.2932 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=9.6122 mle=1.8216 pcon=4.7991 forget=4.2405 favg=-1.2490 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=9.9630 mle=1.7708 pcon=4.7967 forget=4.2578 favg=-0.8623 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=11.2829 mle=1.6881 pcon=4.7946 forget=4.2225 favg=0.5776 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=11.2341 mle=1.6728 pcon=4.7930 forget=4.3423 favg=0.4260 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=10.4205 mle=1.7294 pcon=4.7913 forget=4.3568 favg=-0.4570 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=8.6197 mle=1.7539 pcon=4.7893 forget=4.2991 favg=-2.2227 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=10.2330 mle=1.6869 pcon=4.7870 forget=4.1834 favg=-0.4243 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=13.9911 mle=1.7007 pcon=4.7848 forget=4.3338 favg=3.1719 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=14.2483 mle=1.6696 pcon=4.7830 forget=4.5282 favg=3.2676 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=13.1901 mle=1.5201 pcon=4.7811 forget=4.6076 favg=2.2812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=11.6042 mle=1.6339 pcon=4.7795 forget=4.5345 favg=0.6562 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=9.5332 mle=1.9532 pcon=4.7776 forget=4.3102 favg=-1.5078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 30 total=6.3914 mle=1.5540 pcon=4.7761 forget=4.1473 favg=-4.0859 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=5.8987 mle=1.7715 pcon=4.7744 forget=4.0715 favg=-4.7188 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=12.5686 mle=1.6589 pcon=4.7732 forget=4.3260 favg=1.8105 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=14.8404 mle=1.7566 pcon=4.7720 forget=4.5344 favg=3.7773 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=15.0937 mle=1.7083 pcon=4.7708 forget=4.5793 favg=4.0352 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=14.0547 mle=1.6157 pcon=4.7691 forget=4.5097 favg=3.1602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=13.3990 mle=1.6733 pcon=4.7671 forget=4.4274 favg=2.5312 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=10.9382 mle=1.6633 pcon=4.7648 forget=4.3153 favg=0.1948 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=9.0154 mle=1.6906 pcon=4.7624 forget=4.2861 favg=-1.7236 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=8.9220 mle=1.8848 pcon=4.7599 forget=4.4237 favg=-2.1465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=10.3263 mle=1.7955 pcon=4.7579 forget=4.7573 favg=-0.9844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=11.4724 mle=1.7113 pcon=4.7565 forget=4.8964 favg=0.1083 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=11.0316 mle=1.5117 pcon=4.7552 forget=4.7114 favg=0.0532 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=10.6829 mle=1.8039 pcon=4.7540 forget=4.5405 favg=-0.4155 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=10.3671 mle=1.7000 pcon=4.7527 forget=4.5038 favg=-0.5894 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 0 total=11.7465 mle=1.6738 pcon=4.7511 forget=4.4920 favg=0.8296 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=13.2356 mle=1.8317 pcon=4.7496 forget=4.4649 favg=2.1895 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=13.1053 mle=1.6968 pcon=4.7479 forget=4.4360 favg=2.2246 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=13.0666 mle=1.8082 pcon=4.7465 forget=4.4007 favg=2.1113 nr=64 nf=64 protos=540 fproto_sim=NA
 52%|█████▏    | 26/50 [14:00<12:34, 31.45s/it] 54%|█████▍    | 27/50 [14:39<12:52, 33.61s/it] 56%|█████▌    | 28/50 [15:09<11:59, 32.70s/it] 58%|█████▊    | 29/50 [15:40<11:13, 32.06s/it] 60%|██████    | 30/50 [16:09<10:27, 31.36s/it] 62%|██████▏   | 31/50 [16:43<10:10, 32.15s/it] 64%|██████▍   | 32/50 [17:13<09:25, 31.41s/it] 66%|██████▌   | 33/50 [17:41<08:34, 30.24s/it] 68%|██████▊   | 34/50 [18:10<08:00, 30.02s/it][loss] ep 25 it 200 total=12.3447 mle=1.8776 pcon=4.7448 forget=4.4460 favg=1.2764 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=11.5253 mle=1.7151 pcon=4.7433 forget=4.4643 favg=0.6025 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=10.1664 mle=1.6766 pcon=4.7420 forget=4.4445 favg=-0.6968 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=8.3646 mle=1.5895 pcon=4.7410 forget=4.3544 favg=-2.3203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=7.0189 mle=1.6408 pcon=4.7399 forget=4.3452 favg=-3.7070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=6.9358 mle=1.8203 pcon=4.7389 forget=4.3961 favg=-4.0195 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=10.9195 mle=1.7989 pcon=4.7381 forget=4.7565 favg=-0.3740 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=13.4220 mle=1.6186 pcon=4.7373 forget=5.0681 favg=1.9980 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=13.9305 mle=1.7690 pcon=4.7362 forget=5.0307 favg=2.3945 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=12.3322 mle=1.5705 pcon=4.7351 forget=4.7951 favg=1.2314 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=11.5339 mle=1.8599 pcon=4.7337 forget=4.5492 favg=0.3911 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=10.6847 mle=1.6325 pcon=4.7319 forget=4.5364 favg=-0.2161 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=10.1501 mle=1.6699 pcon=4.7304 forget=4.4402 favg=-0.6904 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=10.3075 mle=1.5804 pcon=4.7290 forget=4.5470 favg=-0.5488 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=10.5467 mle=1.6112 pcon=4.7279 forget=4.5500 favg=-0.3423 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=10.2545 mle=1.6029 pcon=4.7270 forget=4.4941 favg=-0.5693 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=9.7923 mle=1.5661 pcon=4.7260 forget=4.4430 favg=-0.9429 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=9.4344 mle=1.6204 pcon=4.7251 forget=4.3888 favg=-1.2998 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=10.4171 mle=1.7735 pcon=4.7243 forget=4.5122 favg=-0.5928 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=12.3427 mle=1.7844 pcon=4.7233 forget=4.7187 favg=1.1162 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 30 total=12.9928 mle=1.6913 pcon=4.7223 forget=4.7970 favg=1.7822 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=12.7335 mle=1.6915 pcon=4.7213 forget=4.8861 favg=1.4346 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=11.7348 mle=1.5755 pcon=4.7202 forget=4.7515 favg=0.6875 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=10.5487 mle=1.6290 pcon=4.7190 forget=4.6338 favg=-0.4331 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=8.8360 mle=1.4748 pcon=4.7176 forget=4.4552 favg=-1.8115 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=8.2198 mle=1.6494 pcon=4.7162 forget=4.4557 favg=-2.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=8.3695 mle=1.8205 pcon=4.7150 forget=4.4278 favg=-2.5938 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=10.8936 mle=1.7630 pcon=4.7140 forget=4.4026 favg=0.0140 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=12.5627 mle=1.7241 pcon=4.7133 forget=4.4680 favg=1.6572 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=12.3762 mle=1.5904 pcon=4.7126 forget=4.5489 favg=1.5244 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=11.8083 mle=1.6621 pcon=4.7119 forget=4.5353 favg=0.8989 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=11.2111 mle=1.6238 pcon=4.7110 forget=4.5010 favg=0.3752 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=10.1477 mle=1.6482 pcon=4.7101 forget=4.4994 favg=-0.7100 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=9.3624 mle=1.7933 pcon=4.7092 forget=4.4498 favg=-1.5898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=9.3667 mle=1.6086 pcon=4.7082 forget=4.5430 favg=-1.4932 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=10.6542 mle=1.7459 pcon=4.7073 forget=4.6700 favg=-0.4690 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=11.9185 mle=1.6862 pcon=4.7065 forget=4.7806 favg=0.7451 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=11.7113 mle=1.6108 pcon=4.7059 forget=4.7614 favg=0.6333 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=11.3942 mle=1.7809 pcon=4.7051 forget=4.6906 favg=0.2177 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=10.3092 mle=1.5216 pcon=4.7043 forget=4.6189 favg=-0.5356 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=9.9238 mle=1.8134 pcon=4.7035 forget=4.5221 favg=-1.1152 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=9.1304 mle=1.5588 pcon=4.7028 forget=4.4704 favg=-1.6016 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=9.8293 mle=1.7788 pcon=4.7020 forget=4.4696 favg=-1.1211 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=10.7938 mle=1.6697 pcon=4.7013 forget=4.5561 favg=-0.1332 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=11.5275 mle=1.5827 pcon=4.7004 forget=4.5183 favg=0.7261 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=11.5065 mle=1.6226 pcon=4.6997 forget=4.5050 favg=0.6792 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=11.0019 mle=1.6063 pcon=4.6988 forget=4.4806 favg=0.2162 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=10.2950 mle=1.6060 pcon=4.6979 forget=4.4500 favg=-0.4590 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=9.9010 mle=1.5290 pcon=4.6971 forget=4.4815 favg=-0.8066 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=9.9041 mle=1.6304 pcon=4.6964 forget=4.5154 favg=-0.9380 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=10.2205 mle=1.6042 pcon=4.6957 forget=4.5807 favg=-0.6602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=11.2714 mle=1.7042 pcon=4.6953 forget=4.6257 favg=0.2462 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=11.6012 mle=1.5905 pcon=4.6949 forget=4.6429 favg=0.6729 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=11.7091 mle=1.6511 pcon=4.6946 forget=4.6100 favg=0.7534 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=11.1827 mle=1.6237 pcon=4.6943 forget=4.5177 favg=0.3469 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=10.7738 mle=1.6848 pcon=4.6939 forget=4.4961 favg=-0.1010 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=10.4132 mle=1.6050 pcon=4.6934 forget=4.4893 favg=-0.3745 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=10.3029 mle=1.5297 pcon=4.6927 forget=4.5180 favg=-0.4375 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=10.3502 mle=1.5182 pcon=4.6922 forget=4.5364 favg=-0.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=10.7935 mle=1.6479 pcon=4.6914 forget=4.5665 favg=-0.1123 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=10.9094 mle=1.9179 pcon=4.6906 forget=4.5098 favg=-0.2089 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=10.7992 mle=1.5601 pcon=4.6897 forget=4.4694 favg=0.0800 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=11.1701 mle=1.7520 pcon=4.6889 forget=4.5004 favg=0.2288 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=11.6002 mle=1.6450 pcon=4.6882 forget=4.5306 favg=0.7363 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=11.9091 mle=1.7505 pcon=4.6876 forget=4.5780 favg=0.8931 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=11.2536 mle=1.7674 pcon=4.6872 forget=4.5617 favg=0.2373 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=11.0571 mle=1.6875 pcon=4.6867 forget=4.6351 favg=0.0479 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=10.2486 mle=1.7526 pcon=4.6861 forget=4.5520 favg=-0.7422 nr=64 nf=64 protos=540 fproto_sim=NA
 70%|███████   | 35/50 [18:38<07:21, 29.44s/it] 72%|███████▏  | 36/50 [19:15<07:23, 31.71s/it] 74%|███████▍  | 37/50 [19:48<06:55, 31.99s/it] 76%|███████▌  | 38/50 [20:20<06:24, 32.03s/it] 78%|███████▊  | 39/50 [20:57<06:07, 33.45s/it] 80%|████████  | 40/50 [21:25<05:17, 31.75s/it] 82%|████████▏ | 41/50 [21:59<04:53, 32.60s/it] 84%|████████▍ | 42/50 [22:30<04:15, 31.98s/it][loss] ep 34 it 90 total=9.5422 mle=1.5069 pcon=4.6856 forget=4.5264 favg=-1.1768 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=9.2621 mle=1.6435 pcon=4.6852 forget=4.5202 favg=-1.5869 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=9.0605 mle=1.7295 pcon=4.6849 forget=4.4840 favg=-1.8379 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=10.0686 mle=1.7567 pcon=4.6846 forget=4.5404 favg=-0.9131 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=12.3811 mle=1.6835 pcon=4.6843 forget=4.5270 favg=1.4863 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=13.1747 mle=1.6750 pcon=4.6841 forget=4.6066 favg=2.2090 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=12.7250 mle=1.6419 pcon=4.6838 forget=4.5838 favg=1.8154 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=12.1568 mle=1.6111 pcon=4.6835 forget=4.5917 favg=1.2705 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=11.7846 mle=1.8139 pcon=4.6830 forget=4.5753 favg=0.7124 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=11.1593 mle=1.6950 pcon=4.6825 forget=4.5711 favg=0.2108 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=10.5733 mle=1.5973 pcon=4.6819 forget=4.5344 favg=-0.2402 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=10.0600 mle=1.7802 pcon=4.6812 forget=4.5923 favg=-0.9937 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=9.5003 mle=1.5405 pcon=4.6805 forget=4.5528 favg=-1.2734 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=9.5183 mle=1.7334 pcon=4.6798 forget=4.5816 favg=-1.4766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=10.2491 mle=1.8364 pcon=4.6791 forget=4.5461 favg=-0.8125 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=11.5801 mle=1.5797 pcon=4.6785 forget=4.5622 favg=0.7598 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=11.9018 mle=1.5927 pcon=4.6777 forget=4.6020 favg=1.0293 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=11.7771 mle=1.6778 pcon=4.6770 forget=4.5796 favg=0.8428 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=11.2036 mle=1.5566 pcon=4.6764 forget=4.5741 favg=0.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=11.1518 mle=1.6308 pcon=4.6759 forget=4.6388 favg=0.2063 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=10.6863 mle=1.6886 pcon=4.6752 forget=4.5937 favg=-0.2712 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=10.5667 mle=1.6151 pcon=4.6746 forget=4.5602 favg=-0.2832 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=10.4209 mle=1.5251 pcon=4.6739 forget=4.5700 favg=-0.3481 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=10.4378 mle=1.7766 pcon=4.6735 forget=4.5365 favg=-0.5488 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=9.9523 mle=1.6237 pcon=4.6730 forget=4.5398 favg=-0.8843 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=9.3944 mle=1.6404 pcon=4.6727 forget=4.5120 favg=-1.4307 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=10.1117 mle=1.7584 pcon=4.6722 forget=4.5161 favg=-0.8350 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=10.5074 mle=1.5899 pcon=4.6720 forget=4.4748 favg=-0.2294 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 320 total=11.2106 mle=1.6509 pcon=4.6718 forget=4.5050 favg=0.3828 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=11.8945 mle=1.6758 pcon=4.6718 forget=4.5660 favg=0.9810 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=11.9213 mle=1.7269 pcon=4.6718 forget=4.5949 favg=0.9277 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=11.5428 mle=1.5264 pcon=4.6717 forget=4.5908 favg=0.7539 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=11.1627 mle=1.6536 pcon=4.6714 forget=4.6252 favg=0.2126 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=10.6207 mle=1.6459 pcon=4.6710 forget=4.6478 favg=-0.3440 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=11.0805 mle=1.5665 pcon=4.6707 forget=4.5887 favg=0.2546 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=10.3318 mle=1.7093 pcon=4.6703 forget=4.6309 favg=-0.6787 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=9.7837 mle=1.6025 pcon=4.6697 forget=4.6707 favg=-1.1592 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=10.4501 mle=1.5106 pcon=4.6692 forget=4.6338 favg=-0.3635 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=10.2293 mle=1.7111 pcon=4.6688 forget=4.6908 favg=-0.8413 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=10.1642 mle=1.6726 pcon=4.6682 forget=4.7086 favg=-0.8853 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=10.9125 mle=1.6917 pcon=4.6677 forget=4.7192 favg=-0.1660 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=11.2631 mle=1.5123 pcon=4.6671 forget=4.7273 favg=0.3564 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=12.1625 mle=1.6459 pcon=4.6666 forget=4.7368 favg=1.1133 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=12.1324 mle=1.5204 pcon=4.6662 forget=4.7261 favg=1.2197 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=11.6709 mle=1.6369 pcon=4.6658 forget=4.6612 favg=0.7070 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=11.9868 mle=1.5626 pcon=4.6653 forget=4.6808 favg=1.0781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=11.2817 mle=1.6662 pcon=4.6649 forget=4.6429 favg=0.3076 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=11.5933 mle=1.6222 pcon=4.6644 forget=4.6823 favg=0.6245 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=10.3600 mle=1.4683 pcon=4.6641 forget=4.6161 favg=-0.3884 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=10.6446 mle=1.7343 pcon=4.6637 forget=4.6447 favg=-0.3982 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=10.4888 mle=1.7949 pcon=4.6634 forget=4.6087 favg=-0.5781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=10.3189 mle=1.6243 pcon=4.6632 forget=4.7003 favg=-0.6689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=9.7996 mle=1.4794 pcon=4.6630 forget=4.6059 favg=-0.9487 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=9.6980 mle=1.4934 pcon=4.6628 forget=4.5740 favg=-1.0322 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=10.2553 mle=1.9255 pcon=4.6628 forget=4.6108 favg=-0.9438 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=10.0412 mle=1.6202 pcon=4.6626 forget=4.6080 favg=-0.8496 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=9.8713 mle=1.6494 pcon=4.6626 forget=4.6306 favg=-1.0713 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=9.8992 mle=1.7098 pcon=4.6625 forget=4.6422 favg=-1.1152 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=10.1256 mle=1.5340 pcon=4.6626 forget=4.6340 favg=-0.7051 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=10.4958 mle=1.5516 pcon=4.6627 forget=4.6399 favg=-0.3584 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=11.0652 mle=1.7244 pcon=4.6627 forget=4.6680 favg=0.0102 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=10.8665 mle=1.6798 pcon=4.6626 forget=4.7182 favg=-0.1941 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=11.2790 mle=1.6587 pcon=4.6623 forget=4.7390 favg=0.2189 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=11.7836 mle=1.8563 pcon=4.6621 forget=4.7179 favg=0.5474 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=11.7474 mle=1.6065 pcon=4.6619 forget=4.7265 favg=0.7524 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=11.9396 mle=1.6761 pcon=4.6617 forget=4.7386 favg=0.8633 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=12.0872 mle=1.7431 pcon=4.6615 forget=4.7186 favg=0.9639 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=12.0526 mle=1.6909 pcon=4.6613 forget=4.7609 favg=0.9395 nr=64 nf=64 protos=540 fproto_sim=NA
 86%|████████▌ | 43/50 [22:58<03:35, 30.85s/it] 88%|████████▊ | 44/50 [23:35<03:16, 32.75s/it] 90%|█████████ | 45/50 [24:03<02:36, 31.25s/it] 92%|█████████▏| 46/50 [24:34<02:04, 31.21s/it] 94%|█████████▍| 47/50 [25:07<01:35, 31.89s/it] 96%|█████████▌| 48/50 [25:36<01:01, 30.76s/it] 98%|█████████▊| 49/50 [26:11<00:32, 32.15s/it]100%|██████████| 50/50 [26:38<00:00, 30.70s/it]100%|██████████| 50/50 [26:38<00:00, 31.97s/it]
[loss] ep 42 it 370 total=12.1456 mle=1.6116 pcon=4.6611 forget=4.7371 favg=1.1357 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=11.9486 mle=1.6230 pcon=4.6608 forget=4.7643 favg=0.9004 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=11.9525 mle=1.5968 pcon=4.6606 forget=4.7566 favg=0.9385 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=11.9648 mle=1.6904 pcon=4.6603 forget=4.7567 favg=0.8574 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=11.7461 mle=1.5758 pcon=4.6600 forget=4.7896 favg=0.7207 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=11.4878 mle=1.5611 pcon=4.6597 forget=4.6978 favg=0.5693 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=11.4113 mle=1.5423 pcon=4.6595 forget=4.6811 favg=0.5283 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=11.4523 mle=1.5494 pcon=4.6591 forget=4.6818 favg=0.5620 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=11.3805 mle=1.5308 pcon=4.6588 forget=4.6970 favg=0.4939 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=11.7424 mle=1.7089 pcon=4.6586 forget=4.7645 favg=0.6104 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=11.3950 mle=1.6058 pcon=4.6584 forget=4.7393 favg=0.3916 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=11.2484 mle=1.6373 pcon=4.6582 forget=4.7281 favg=0.2247 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=11.1649 mle=1.5355 pcon=4.6580 forget=4.7552 favg=0.2162 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=11.2263 mle=1.6254 pcon=4.6579 forget=4.7709 favg=0.1721 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=11.2103 mle=1.7960 pcon=4.6577 forget=4.7059 favg=0.0507 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=11.2472 mle=1.7685 pcon=4.6576 forget=4.7450 favg=0.0760 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=10.8962 mle=1.6046 pcon=4.6574 forget=4.7494 favg=-0.1152 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=10.8701 mle=1.5946 pcon=4.6573 forget=4.6784 favg=-0.0602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=10.5058 mle=1.6032 pcon=4.6571 forget=4.7791 favg=-0.5337 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=10.2802 mle=1.5361 pcon=4.6569 forget=4.7609 favg=-0.6738 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=10.4350 mle=1.5722 pcon=4.6569 forget=4.7630 favg=-0.5571 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=10.3870 mle=1.6095 pcon=4.6568 forget=4.7853 favg=-0.6646 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=10.2015 mle=1.6038 pcon=4.6565 forget=4.7439 favg=-0.8027 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=10.0459 mle=1.5174 pcon=4.6565 forget=4.7163 favg=-0.8442 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=10.2314 mle=1.5051 pcon=4.6565 forget=4.7382 favg=-0.6685 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=10.2812 mle=1.5527 pcon=4.6564 forget=4.8153 favg=-0.7432 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=10.2784 mle=1.7172 pcon=4.6563 forget=4.7637 favg=-0.8589 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=9.9939 mle=1.5065 pcon=4.6562 forget=4.7515 favg=-0.9204 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=10.6191 mle=1.8079 pcon=4.6560 forget=4.7372 favg=-0.5820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=10.5232 mle=1.6746 pcon=4.6559 forget=4.7074 favg=-0.5146 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=10.5144 mle=1.5541 pcon=4.6559 forget=4.7981 favg=-0.4937 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=10.5727 mle=1.7565 pcon=4.6558 forget=4.7928 favg=-0.6323 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=10.4745 mle=1.5585 pcon=4.6556 forget=4.7746 favg=-0.5142 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=10.4389 mle=1.5677 pcon=4.6555 forget=4.7096 favg=-0.4939 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=10.7984 mle=1.6871 pcon=4.6553 forget=4.7818 favg=-0.3257 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=10.7469 mle=1.5826 pcon=4.6551 forget=4.8318 favg=-0.3225 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 220 total=10.6173 mle=1.4828 pcon=4.6551 forget=4.7191 favg=-0.2396 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=10.8023 mle=1.6073 pcon=4.6550 forget=4.8720 favg=-0.3320 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=11.1275 mle=1.6173 pcon=4.6549 forget=4.9226 favg=-0.0672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=11.0903 mle=1.6514 pcon=4.6548 forget=4.8309 favg=-0.0468 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=11.0113 mle=1.6221 pcon=4.6548 forget=4.9001 favg=-0.1656 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=11.2665 mle=1.6677 pcon=4.6547 forget=4.8720 favg=0.0722 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=11.0841 mle=1.6825 pcon=4.6546 forget=4.7931 favg=-0.0462 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=11.1730 mle=1.6608 pcon=4.6547 forget=4.9244 favg=-0.0669 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=11.1515 mle=1.6617 pcon=4.6546 forget=4.8405 favg=-0.0053 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=11.0860 mle=1.6066 pcon=4.6545 forget=4.7579 favg=0.0670 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=11.2422 mle=1.5996 pcon=4.6544 forget=4.8058 favg=0.1824 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=11.0643 mle=1.5486 pcon=4.6543 forget=4.9372 favg=-0.0758 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=11.4280 mle=1.6082 pcon=4.6543 forget=4.9433 favg=0.2222 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=11.3333 mle=1.6558 pcon=4.6542 forget=4.8825 favg=0.1409 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=11.1325 mle=1.6246 pcon=4.6542 forget=4.8149 favg=0.0388 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=11.4457 mle=1.7508 pcon=4.6540 forget=4.8807 favg=0.1602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=11.4231 mle=1.7088 pcon=4.6538 forget=4.7905 favg=0.2700 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=11.3759 mle=1.7019 pcon=4.6537 forget=4.8774 favg=0.1428 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=11.3300 mle=1.5427 pcon=4.6538 forget=4.8313 favg=0.3022 nr=64 nf=64 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:22,  2.74it/s]  3%|▎         | 10/391 [00:00<00:14, 26.42it/s]  5%|▍         | 19/391 [00:00<00:08, 43.35it/s]  7%|▋         | 28/391 [00:00<00:06, 55.32it/s]  9%|▉         | 37/391 [00:00<00:05, 62.60it/s] 12%|█▏        | 46/391 [00:00<00:05, 68.29it/s] 14%|█▍        | 54/391 [00:01<00:04, 69.46it/s] 16%|█▌        | 63/391 [00:01<00:04, 74.68it/s] 18%|█▊        | 72/391 [00:01<00:04, 77.78it/s] 21%|██        | 81/391 [00:01<00:04, 77.40it/s] 23%|██▎       | 89/391 [00:01<00:03, 78.10it/s] 25%|██▍       | 97/391 [00:01<00:03, 76.92it/s] 27%|██▋       | 106/391 [00:01<00:03, 77.32it/s] 29%|██▉       | 114/391 [00:01<00:03, 77.69it/s] 31%|███▏      | 123/391 [00:01<00:03, 80.40it/s] 34%|███▍      | 132/391 [00:01<00:03, 81.67it/s] 36%|███▌      | 141/391 [00:02<00:03, 81.36it/s] 38%|███▊      | 150/391 [00:02<00:02, 81.56it/s] 41%|████      | 159/391 [00:02<00:02, 81.88it/s] 43%|████▎     | 168/391 [00:02<00:02, 80.77it/s] 45%|████▌     | 177/391 [00:02<00:02, 81.49it/s] 48%|████▊     | 186/391 [00:02<00:02, 80.31it/s] 50%|████▉     | 195/391 [00:02<00:02, 78.86it/s] 52%|█████▏    | 204/391 [00:02<00:02, 78.60it/s] 54%|█████▍    | 213/391 [00:03<00:02, 79.24it/s] 57%|█████▋    | 222/391 [00:03<00:02, 80.54it/s] 59%|█████▉    | 231/391 [00:03<00:01, 81.88it/s] 61%|██████▏   | 240/391 [00:03<00:01, 83.16it/s] 64%|██████▎   | 249/391 [00:03<00:01, 83.22it/s] 66%|██████▌   | 258/391 [00:03<00:01, 83.75it/s] 68%|██████▊   | 267/391 [00:03<00:01, 81.67it/s] 71%|███████   | 276/391 [00:03<00:01, 80.50it/s] 73%|███████▎  | 285/391 [00:03<00:01, 82.30it/s] 75%|███████▌  | 294/391 [00:03<00:01, 82.06it/s] 77%|███████▋  | 303/391 [00:04<00:01, 84.01it/s] 80%|███████▉  | 312/391 [00:04<00:00, 82.62it/s] 82%|████████▏ | 321/391 [00:04<00:00, 84.06it/s] 84%|████████▍ | 330/391 [00:04<00:00, 84.28it/s] 87%|████████▋ | 339/391 [00:04<00:00, 83.74it/s] 89%|████████▉ | 348/391 [00:04<00:00, 83.47it/s] 91%|█████████▏| 357/391 [00:04<00:00, 84.21it/s] 94%|█████████▎| 366/391 [00:04<00:00, 81.36it/s] 96%|█████████▌| 375/391 [00:04<00:00, 81.99it/s] 98%|█████████▊| 384/391 [00:05<00:00, 83.55it/s]100%|██████████| 391/391 [00:05<00:00, 76.01it/s]
50000 images processed, 5.292381286621094 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.03it/s] 11%|█▏        | 9/79 [00:00<00:03, 19.06it/s] 23%|██▎       | 18/79 [00:00<00:01, 35.07it/s] 33%|███▎      | 26/79 [00:00<00:01, 45.57it/s] 43%|████▎     | 34/79 [00:00<00:00, 52.41it/s] 53%|█████▎    | 42/79 [00:01<00:00, 58.86it/s] 65%|██████▍   | 51/79 [00:01<00:00, 66.77it/s] 75%|███████▍  | 59/79 [00:01<00:00, 69.03it/s] 85%|████████▍ | 67/79 [00:01<00:00, 71.30it/s] 96%|█████████▌| 76/79 [00:01<00:00, 76.46it/s]100%|██████████| 79/79 [00:01<00:00, 50.82it/s]
10000 images processed, 1.5802757740020752 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:16,  2.65it/s]  4%|▍         | 9/204 [00:00<00:08, 23.68it/s]  9%|▉         | 18/204 [00:00<00:04, 41.47it/s] 13%|█▎        | 26/204 [00:00<00:03, 50.94it/s] 17%|█▋        | 35/204 [00:00<00:02, 60.18it/s] 21%|██        | 43/204 [00:00<00:02, 63.92it/s] 25%|██▌       | 51/204 [00:01<00:02, 67.33it/s] 29%|██▉       | 60/204 [00:01<00:02, 71.37it/s] 34%|███▍      | 69/204 [00:01<00:01, 74.70it/s] 38%|███▊      | 77/204 [00:01<00:01, 74.83it/s] 42%|████▏     | 86/204 [00:01<00:01, 76.77it/s] 47%|████▋     | 95/204 [00:01<00:01, 79.62it/s] 51%|█████     | 104/204 [00:01<00:01, 80.25it/s] 55%|█████▌    | 113/204 [00:01<00:01, 81.42it/s] 60%|█████▉    | 122/204 [00:01<00:01, 81.52it/s] 64%|██████▍   | 131/204 [00:02<00:00, 80.88it/s] 69%|██████▊   | 140/204 [00:02<00:00, 80.78it/s] 73%|███████▎  | 149/204 [00:02<00:00, 79.95it/s] 77%|███████▋  | 158/204 [00:02<00:00, 82.28it/s] 82%|████████▏ | 167/204 [00:02<00:00, 83.76it/s] 86%|████████▋ | 176/204 [00:02<00:00, 81.92it/s] 91%|█████████ | 185/204 [00:02<00:00, 78.76it/s] 95%|█████████▌| 194/204 [00:02<00:00, 79.75it/s]100%|█████████▉| 203/204 [00:02<00:00, 81.19it/s]100%|██████████| 204/204 [00:02<00:00, 70.13it/s]
26032 images processed, 2.95223331451416 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.74it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.20it/s] 22%|██▏       | 17/79 [00:00<00:02, 25.69it/s] 30%|███       | 24/79 [00:01<00:01, 34.10it/s] 37%|███▋      | 29/79 [00:01<00:01, 35.17it/s] 43%|████▎     | 34/79 [00:01<00:01, 36.35it/s] 53%|█████▎    | 42/79 [00:01<00:00, 41.36it/s] 62%|██████▏   | 49/79 [00:01<00:00, 45.74it/s] 68%|██████▊   | 54/79 [00:01<00:00, 42.88it/s] 75%|███████▍  | 59/79 [00:01<00:00, 36.97it/s] 84%|████████▎ | 66/79 [00:02<00:00, 40.53it/s] 94%|█████████▎| 74/79 [00:02<00:00, 44.26it/s]100%|██████████| 79/79 [00:02<00:00, 35.80it/s]
10000 images processed, 2.2490317821502686 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:36,  2.14it/s] 13%|█▎        | 10/79 [00:00<00:03, 22.35it/s] 23%|██▎       | 18/79 [00:00<00:01, 36.55it/s] 34%|███▍      | 27/79 [00:00<00:01, 49.03it/s] 44%|████▍     | 35/79 [00:00<00:00, 55.87it/s] 56%|█████▌    | 44/79 [00:01<00:00, 63.72it/s] 66%|██████▌   | 52/79 [00:01<00:00, 66.43it/s] 76%|███████▌  | 60/79 [00:01<00:00, 67.87it/s] 87%|████████▋ | 69/79 [00:01<00:00, 73.47it/s] 99%|█████████▊| 78/79 [00:01<00:00, 77.77it/s]100%|██████████| 79/79 [00:01<00:00, 55.10it/s]
10000 images processed, 1.4542996883392334 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:30,  2.29it/s] 10%|█         | 7/70 [00:00<00:03, 16.09it/s] 21%|██▏       | 15/70 [00:00<00:01, 31.62it/s] 33%|███▎      | 23/70 [00:00<00:01, 43.67it/s] 44%|████▍     | 31/70 [00:00<00:00, 52.17it/s] 54%|█████▍    | 38/70 [00:00<00:00, 56.50it/s] 66%|██████▌   | 46/70 [00:01<00:00, 62.07it/s] 77%|███████▋  | 54/70 [00:01<00:00, 65.93it/s] 90%|█████████ | 63/70 [00:01<00:00, 71.64it/s]100%|██████████| 70/70 [00:01<00:00, 50.77it/s]
8925 images processed, 1.4099042415618896 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:45,  1.04s/it] 11%|█         | 5/45 [00:01<00:07,  5.66it/s] 20%|██        | 9/45 [00:01<00:04,  7.82it/s] 24%|██▍       | 11/45 [00:01<00:03,  8.56it/s] 38%|███▊      | 17/45 [00:02<00:02, 11.26it/s] 42%|████▏     | 19/45 [00:02<00:02, 12.09it/s] 49%|████▉     | 22/45 [00:02<00:01, 14.15it/s] 53%|█████▎    | 24/45 [00:02<00:01, 14.58it/s] 58%|█████▊    | 26/45 [00:02<00:01, 10.32it/s] 67%|██████▋   | 30/45 [00:02<00:01, 14.45it/s] 73%|███████▎  | 33/45 [00:03<00:01, 10.50it/s] 78%|███████▊  | 35/45 [00:03<00:00, 11.18it/s] 91%|█████████ | 41/45 [00:03<00:00, 13.79it/s] 96%|█████████▌| 43/45 [00:04<00:00,  9.87it/s]100%|██████████| 45/45 [00:04<00:00, 10.37it/s]
5640 images processed, 4.36395788192749 seconds used

21.051085710525513
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           2.52  99.36
places365     67.87  81.18
LSUN          17.50  96.07
iSUN          72.34  81.65
dtd           37.84  91.39
AVG           39.61  89.93
Retain-Acc: 0.7407
Forget-as-OOD (retain known vs forget novel):
  FPR: 79.50 AUROC: 86.91 AUIN: 98.36
36.144062995910645
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.6-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
