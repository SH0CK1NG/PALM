nohup: ignoring input
==== Stage 1: inc={0,8,11,40,51}; seen={}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='forget_only', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:08<06:53,  8.44s/it]  4%|▍         | 2/50 [00:09<03:21,  4.19s/it]  6%|▌         | 3/50 [00:10<02:08,  2.74s/it]  8%|▊         | 4/50 [00:11<01:30,  1.97s/it] 10%|█         | 5/50 [00:12<01:13,  1.64s/it] 12%|█▏        | 6/50 [00:13<00:55,  1.27s/it] 14%|█▍        | 7/50 [00:14<00:52,  1.23s/it] 16%|█▌        | 8/50 [00:15<00:49,  1.17s/it] 18%|█▊        | 9/50 [00:16<00:50,  1.23s/it] 20%|██        | 10/50 [00:17<00:43,  1.09s/it] 22%|██▏       | 11/50 [00:18<00:37,  1.03it/s] 24%|██▍       | 12/50 [00:19<00:38,  1.01s/it] 26%|██▌       | 13/50 [00:19<00:33,  1.11it/s] 28%|██▊       | 14/50 [00:20<00:28,  1.25it/s] 30%|███       | 15/50 [00:21<00:28,  1.23it/s] 32%|███▏      | 16/50 [00:22<00:30,  1.10it/s] 34%|███▍      | 17/50 [00:22<00:26,  1.25it/s] 36%|███▌      | 18/50 [00:24<00:28,  1.12it/s] 38%|███▊      | 19/50 [00:24<00:24,  1.25it/s] 40%|████      | 20/50 [00:25<00:22,  1.34it/s] 42%|████▏     | 21/50 [00:26<00:21,  1.32it/s] 44%|████▍     | 22/50 [00:26<00:21,  1.32it/s] 46%|████▌     | 23/50 [00:27<00:19,  1.36it/s] 48%|████▊     | 24/50 [00:28<00:17,  1.47it/s] 50%|█████     | 25/50 [00:28<00:16,  1.53it/s] 52%|█████▏    | 26/50 [00:29<00:16,  1.47it/s] 54%|█████▍    | 27/50 [00:30<00:16,  1.40it/s] 56%|█████▌    | 28/50 [00:30<00:15,  1.43it/s] 58%|█████▊    | 29/50 [00:31<00:14,  1.43it/s] 60%|██████    | 30/50 [00:32<00:13,  1.49it/s][loss] ep 0 it 0 total=17.3683 mle=11.7426 pcon=5.6257 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 2 it 10 total=17.0158 mle=11.3820 pcon=5.6338 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 5 it 0 total=13.1339 mle=7.4960 pcon=5.6378 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 7 it 10 total=10.8176 mle=5.1959 pcon=5.6217 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 10 it 0 total=10.3562 mle=4.7562 pcon=5.6000 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 12 it 10 total=10.1756 mle=4.5979 pcon=5.5777 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 15 it 0 total=9.8510 mle=4.2953 pcon=5.5557 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 17 it 10 total=9.6583 mle=4.1243 pcon=5.5339 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 20 it 0 total=9.5009 mle=3.9886 pcon=5.5123 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 22 it 10 total=9.2995 mle=3.8087 pcon=5.4908 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 25 it 0 total=9.1661 mle=3.6969 pcon=5.4692 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 27 it 10 total=9.0709 mle=3.6234 pcon=5.4475 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 30 it 0 total=8.9881 mle=3.5621 pcon=5.4260 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
 62%|██████▏   | 31/50 [00:33<00:14,  1.30it/s] 64%|██████▍   | 32/50 [00:33<00:13,  1.31it/s] 66%|██████▌   | 33/50 [00:34<00:14,  1.20it/s] 68%|██████▊   | 34/50 [00:35<00:12,  1.25it/s] 70%|███████   | 35/50 [00:36<00:11,  1.29it/s] 72%|███████▏  | 36/50 [00:36<00:10,  1.38it/s] 74%|███████▍  | 37/50 [00:37<00:09,  1.32it/s] 76%|███████▌  | 38/50 [00:38<00:09,  1.33it/s] 78%|███████▊  | 39/50 [00:39<00:08,  1.36it/s] 80%|████████  | 40/50 [00:39<00:07,  1.39it/s] 82%|████████▏ | 41/50 [00:40<00:06,  1.39it/s] 84%|████████▍ | 42/50 [00:41<00:05,  1.40it/s] 86%|████████▌ | 43/50 [00:41<00:04,  1.45it/s] 88%|████████▊ | 44/50 [00:42<00:03,  1.51it/s] 90%|█████████ | 45/50 [00:43<00:03,  1.43it/s] 92%|█████████▏| 46/50 [00:44<00:02,  1.37it/s] 94%|█████████▍| 47/50 [00:44<00:02,  1.39it/s] 96%|█████████▌| 48/50 [00:45<00:01,  1.37it/s] 98%|█████████▊| 49/50 [00:46<00:00,  1.36it/s]100%|██████████| 50/50 [00:47<00:00,  1.34it/s]100%|██████████| 50/50 [00:47<00:00,  1.06it/s]
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 32 it 10 total=8.9617 mle=3.5573 pcon=5.4044 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 35 it 0 total=8.8748 mle=3.4917 pcon=5.3832 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 37 it 10 total=8.8194 mle=3.4571 pcon=5.3623 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 40 it 0 total=8.7942 mle=3.4526 pcon=5.3416 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 42 it 10 total=8.7461 mle=3.4244 pcon=5.3217 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 45 it 0 total=8.7256 mle=3.4233 pcon=5.3023 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[loss] ep 47 it 10 total=8.6750 mle=3.3915 pcon=5.2835 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stage1-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:01<14:15,  1.99s/it]  2%|▏         | 8/430 [00:02<01:22,  5.12it/s]  4%|▍         | 18/430 [00:02<00:31, 13.20it/s]  7%|▋         | 28/430 [00:02<00:17, 22.45it/s]  9%|▉         | 38/430 [00:02<00:12, 32.61it/s] 11%|█         | 48/430 [00:02<00:08, 42.99it/s] 13%|█▎        | 58/430 [00:02<00:07, 53.04it/s] 16%|█▌        | 68/430 [00:02<00:05, 61.77it/s] 18%|█▊        | 78/430 [00:02<00:05, 69.82it/s] 20%|██        | 88/430 [00:02<00:04, 75.92it/s] 23%|██▎       | 98/430 [00:03<00:04, 80.59it/s] 25%|██▌       | 108/430 [00:03<00:03, 83.99it/s] 27%|██▋       | 118/430 [00:03<00:03, 87.29it/s] 30%|██▉       | 128/430 [00:03<00:03, 89.70it/s] 32%|███▏      | 138/430 [00:03<00:03, 91.00it/s] 34%|███▍      | 148/430 [00:03<00:03, 88.74it/s] 37%|███▋      | 158/430 [00:03<00:03, 90.48it/s] 39%|███▉      | 168/430 [00:03<00:02, 88.43it/s] 41%|████      | 177/430 [00:03<00:02, 84.77it/s] 43%|████▎     | 187/430 [00:04<00:02, 87.11it/s] 46%|████▌     | 197/430 [00:04<00:02, 88.93it/s] 48%|████▊     | 207/430 [00:04<00:02, 90.67it/s] 50%|█████     | 217/430 [00:04<00:02, 90.85it/s] 53%|█████▎    | 227/430 [00:04<00:02, 86.07it/s] 55%|█████▍    | 236/430 [00:04<00:02, 86.53it/s] 57%|█████▋    | 246/430 [00:04<00:02, 89.16it/s] 60%|█████▉    | 256/430 [00:04<00:01, 91.06it/s] 62%|██████▏   | 266/430 [00:04<00:01, 92.43it/s] 64%|██████▍   | 276/430 [00:05<00:01, 93.45it/s] 67%|██████▋   | 286/430 [00:05<00:01, 92.80it/s] 69%|██████▉   | 296/430 [00:05<00:01, 93.33it/s] 71%|███████   | 306/430 [00:05<00:01, 93.59it/s] 73%|███████▎  | 316/430 [00:05<00:01, 93.00it/s] 76%|███████▌  | 326/430 [00:05<00:01, 93.34it/s] 78%|███████▊  | 336/430 [00:05<00:01, 92.67it/s] 80%|████████  | 346/430 [00:05<00:00, 91.72it/s] 83%|████████▎ | 356/430 [00:05<00:00, 92.92it/s] 85%|████████▌ | 366/430 [00:05<00:00, 93.50it/s] 87%|████████▋ | 376/430 [00:06<00:00, 91.50it/s] 90%|████████▉ | 386/430 [00:06<00:00, 92.24it/s] 92%|█████████▏| 396/430 [00:06<00:00, 93.24it/s] 94%|█████████▍| 406/430 [00:06<00:00, 89.03it/s] 97%|█████████▋| 416/430 [00:06<00:00, 91.50it/s] 99%|█████████▉| 426/430 [00:06<00:00, 93.25it/s]100%|██████████| 430/430 [00:06<00:00, 64.16it/s]
55000 images processed, 6.7690534591674805 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<00:40,  2.10it/s] 13%|█▎        | 11/86 [00:00<00:03, 24.23it/s] 24%|██▍       | 21/86 [00:00<00:01, 41.82it/s] 36%|███▌      | 31/86 [00:00<00:00, 55.79it/s] 48%|████▊     | 41/86 [00:00<00:00, 66.17it/s] 59%|█████▉    | 51/86 [00:01<00:00, 74.03it/s] 71%|███████   | 61/86 [00:01<00:00, 79.89it/s] 83%|████████▎ | 71/86 [00:01<00:00, 77.12it/s] 94%|█████████▍| 81/86 [00:01<00:00, 81.20it/s]100%|██████████| 86/86 [00:01<00:00, 60.42it/s]
11000 images processed, 1.4380087852478027 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:59,  1.69it/s]  4%|▍         | 9/204 [00:00<00:11, 16.70it/s]  9%|▉         | 18/204 [00:00<00:05, 32.37it/s] 13%|█▎        | 26/204 [00:00<00:04, 42.67it/s] 17%|█▋        | 35/204 [00:01<00:03, 54.23it/s] 22%|██▏       | 44/204 [00:01<00:02, 62.57it/s] 25%|██▌       | 52/204 [00:01<00:02, 65.18it/s] 29%|██▉       | 60/204 [00:01<00:02, 67.23it/s] 34%|███▍      | 70/204 [00:01<00:01, 74.73it/s] 39%|███▉      | 80/204 [00:01<00:01, 80.34it/s] 44%|████▍     | 90/204 [00:01<00:01, 83.52it/s] 49%|████▉     | 100/204 [00:01<00:01, 84.29it/s] 54%|█████▍    | 110/204 [00:01<00:01, 86.73it/s] 58%|█████▊    | 119/204 [00:01<00:00, 86.26it/s] 63%|██████▎   | 128/204 [00:02<00:00, 82.03it/s] 68%|██████▊   | 138/204 [00:02<00:00, 84.83it/s] 72%|███████▏  | 147/204 [00:02<00:00, 86.18it/s] 76%|███████▋  | 156/204 [00:02<00:00, 84.40it/s] 81%|████████▏ | 166/204 [00:02<00:00, 87.74it/s] 86%|████████▋ | 176/204 [00:02<00:00, 89.94it/s] 91%|█████████ | 186/204 [00:02<00:00, 91.87it/s] 96%|█████████▌| 196/204 [00:02<00:00, 93.32it/s]100%|██████████| 204/204 [00:02<00:00, 69.40it/s]
26032 images processed, 2.998753309249878 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:52,  1.49it/s] 11%|█▏        | 9/79 [00:00<00:04, 15.04it/s] 24%|██▍       | 19/79 [00:00<00:01, 31.47it/s] 34%|███▍      | 27/79 [00:00<00:01, 41.82it/s] 47%|████▋     | 37/79 [00:01<00:00, 54.78it/s] 57%|█████▋    | 45/79 [00:01<00:00, 59.02it/s] 70%|██████▉   | 55/79 [00:01<00:00, 68.44it/s] 81%|████████  | 64/79 [00:01<00:00, 68.60it/s] 91%|█████████ | 72/79 [00:01<00:00, 71.50it/s]100%|██████████| 79/79 [00:01<00:00, 48.63it/s]
10000 images processed, 1.6466405391693115 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:47,  1.64it/s] 13%|█▎        | 10/79 [00:00<00:03, 18.15it/s] 25%|██▌       | 20/79 [00:00<00:01, 34.74it/s] 34%|███▍      | 27/79 [00:00<00:01, 41.80it/s] 43%|████▎     | 34/79 [00:01<00:00, 45.95it/s] 56%|█████▌    | 44/79 [00:01<00:00, 58.26it/s] 67%|██████▋   | 53/79 [00:01<00:00, 65.21it/s] 80%|███████▉  | 63/79 [00:01<00:00, 73.71it/s] 92%|█████████▏| 73/79 [00:01<00:00, 80.16it/s]100%|██████████| 79/79 [00:01<00:00, 51.38it/s]
10000 images processed, 1.563739538192749 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:41,  1.68it/s] 13%|█▎        | 9/70 [00:00<00:03, 16.54it/s] 26%|██▌       | 18/70 [00:00<00:01, 32.03it/s] 39%|███▊      | 27/70 [00:00<00:00, 45.51it/s] 53%|█████▎    | 37/70 [00:01<00:00, 57.77it/s] 67%|██████▋   | 47/70 [00:01<00:00, 67.82it/s] 81%|████████▏ | 57/70 [00:01<00:00, 75.56it/s] 96%|█████████▌| 67/70 [00:01<00:00, 81.03it/s]100%|██████████| 70/70 [00:01<00:00, 50.93it/s]
8925 images processed, 1.418086290359497 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:49,  1.11s/it]  4%|▍         | 2/45 [00:01<00:23,  1.82it/s] 27%|██▋       | 12/45 [00:01<00:02, 14.76it/s] 38%|███▊      | 17/45 [00:01<00:01, 15.03it/s] 47%|████▋     | 21/45 [00:01<00:01, 17.73it/s] 64%|██████▍   | 29/45 [00:01<00:00, 27.66it/s] 76%|███████▌  | 34/45 [00:02<00:00, 18.28it/s] 98%|█████████▊| 44/45 [00:02<00:00, 28.98it/s]100%|██████████| 45/45 [00:02<00:00, 17.65it/s]
5640 images processed, 2.5739409923553467 seconds used

20.361714124679565
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.54  99.04  73.65
places365     49.43  89.46  51.36
LSUN          25.66  95.16  76.03
iSUN          25.79  95.00  73.66
dtd           24.49  94.41  71.71
AVG           25.78  94.61  69.28
[incremental] Overall: 0.8500 New: 0.8500 Old: nan
[incremental] Final(Top-1): 0.5083  Average: 0.6628
3.512165069580078
==== Stage 2: inc={66,67,88,94,57}; seen={0,8,11,40,51}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1', lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='forget_only', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:08<06:37,  8.11s/it]  4%|▍         | 2/50 [00:09<03:26,  4.30s/it]  6%|▌         | 3/50 [00:11<02:23,  3.06s/it]  8%|▊         | 4/50 [00:11<01:36,  2.11s/it] 10%|█         | 5/50 [00:13<01:26,  1.93s/it] 12%|█▏        | 6/50 [00:14<01:05,  1.49s/it] 14%|█▍        | 7/50 [00:14<00:52,  1.21s/it] 16%|█▌        | 8/50 [00:16<00:54,  1.31s/it] 18%|█▊        | 9/50 [00:17<00:54,  1.34s/it] 20%|██        | 10/50 [00:18<00:47,  1.18s/it] 22%|██▏       | 11/50 [00:19<00:39,  1.00s/it] 24%|██▍       | 12/50 [00:19<00:33,  1.12it/s] 26%|██▌       | 13/50 [00:21<00:37,  1.01s/it] 28%|██▊       | 14/50 [00:21<00:32,  1.10it/s] 30%|███       | 15/50 [00:22<00:31,  1.11it/s] 32%|███▏      | 16/50 [00:23<00:29,  1.15it/s] 34%|███▍      | 17/50 [00:24<00:32,  1.01it/s] 36%|███▌      | 18/50 [00:25<00:27,  1.15it/s] 38%|███▊      | 19/50 [00:25<00:23,  1.29it/s] 40%|████      | 20/50 [00:26<00:21,  1.41it/s] 42%|████▏     | 21/50 [00:27<00:19,  1.49it/s] 44%|████▍     | 22/50 [00:27<00:17,  1.57it/s] 46%|████▌     | 23/50 [00:28<00:17,  1.56it/s] 48%|████▊     | 24/50 [00:28<00:15,  1.65it/s] 50%|█████     | 25/50 [00:29<00:15,  1.66it/s] 52%|█████▏    | 26/50 [00:29<00:13,  1.72it/s] 54%|█████▍    | 27/50 [00:30<00:13,  1.75it/s] 56%|█████▌    | 28/50 [00:30<00:12,  1.77it/s] 58%|█████▊    | 29/50 [00:31<00:12,  1.69it/s] 60%|██████    | 30/50 [00:32<00:11,  1.74it/s][loss] ep 0 it 0 total=14.5610 mle=5.5836 pcon=8.9774 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 2 it 10 total=14.1338 mle=5.1691 pcon=8.9647 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 5 it 0 total=13.7621 mle=4.8127 pcon=8.9494 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 7 it 10 total=13.4836 mle=4.5517 pcon=8.9320 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 10 it 0 total=13.1537 mle=4.2408 pcon=8.9130 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 12 it 10 total=12.9276 mle=4.0348 pcon=8.8928 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 15 it 0 total=12.7366 mle=3.8648 pcon=8.8717 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 17 it 10 total=12.6263 mle=3.7762 pcon=8.8501 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 20 it 0 total=12.4814 mle=3.6532 pcon=8.8282 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 22 it 10 total=12.3757 mle=3.5699 pcon=8.8058 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 25 it 0 total=12.3292 mle=3.5460 pcon=8.7833 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 27 it 10 total=12.2690 mle=3.5083 pcon=8.7607 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 30 it 0 total=12.2085 mle=3.4703 pcon=8.7383 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
 62%|██████▏   | 31/50 [00:32<00:10,  1.77it/s] 64%|██████▍   | 32/50 [00:33<00:09,  1.81it/s] 66%|██████▌   | 33/50 [00:33<00:09,  1.76it/s] 68%|██████▊   | 34/50 [00:34<00:08,  1.84it/s] 70%|███████   | 35/50 [00:34<00:08,  1.72it/s] 72%|███████▏  | 36/50 [00:35<00:08,  1.73it/s] 74%|███████▍  | 37/50 [00:36<00:07,  1.76it/s] 76%|███████▌  | 38/50 [00:36<00:06,  1.80it/s] 78%|███████▊  | 39/50 [00:37<00:06,  1.78it/s] 80%|████████  | 40/50 [00:37<00:05,  1.79it/s] 82%|████████▏ | 41/50 [00:38<00:04,  1.83it/s] 84%|████████▍ | 42/50 [00:38<00:04,  1.85it/s] 86%|████████▌ | 43/50 [00:39<00:03,  1.82it/s] 88%|████████▊ | 44/50 [00:39<00:03,  1.86it/s] 90%|█████████ | 45/50 [00:40<00:02,  1.88it/s] 92%|█████████▏| 46/50 [00:40<00:02,  1.88it/s] 94%|█████████▍| 47/50 [00:41<00:01,  1.87it/s] 96%|█████████▌| 48/50 [00:42<00:01,  1.87it/s] 98%|█████████▊| 49/50 [00:42<00:00,  1.81it/s]100%|██████████| 50/50 [00:43<00:00,  1.86it/s]100%|██████████| 50/50 [00:43<00:00,  1.16it/s]
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 32 it 10 total=12.1605 mle=3.4445 pcon=8.7160 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 35 it 0 total=12.1197 mle=3.4256 pcon=8.6942 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 37 it 10 total=12.0979 mle=3.4251 pcon=8.6728 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 40 it 0 total=12.0758 mle=3.4239 pcon=8.6519 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 42 it 10 total=12.0388 mle=3.4071 pcon=8.6317 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 45 it 0 total=12.0090 mle=3.3967 pcon=8.6123 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[loss] ep 47 it 10 total=11.9888 mle=3.3952 pcon=8.5935 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stage2-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:00<04:56,  1.44it/s]  2%|▏         | 9/430 [00:00<00:28, 14.78it/s]  4%|▎         | 16/430 [00:00<00:16, 25.08it/s]  5%|▌         | 23/430 [00:01<00:11, 34.39it/s]  7%|▋         | 31/430 [00:01<00:08, 44.47it/s]  9%|▉         | 38/430 [00:01<00:07, 49.87it/s] 11%|█         | 46/430 [00:01<00:06, 56.67it/s] 13%|█▎        | 55/430 [00:01<00:05, 63.17it/s] 15%|█▍        | 64/430 [00:01<00:05, 69.10it/s] 17%|█▋        | 72/430 [00:01<00:05, 71.11it/s] 19%|█▊        | 80/430 [00:01<00:04, 72.79it/s] 21%|██        | 89/430 [00:01<00:04, 75.17it/s] 23%|██▎       | 97/430 [00:02<00:04, 69.92it/s] 24%|██▍       | 105/430 [00:02<00:04, 71.34it/s] 27%|██▋       | 114/430 [00:02<00:04, 74.80it/s] 28%|██▊       | 122/430 [00:02<00:04, 73.17it/s] 30%|███       | 130/430 [00:02<00:04, 72.46it/s] 32%|███▏      | 139/430 [00:02<00:03, 75.74it/s] 34%|███▍      | 148/430 [00:02<00:03, 77.01it/s] 37%|███▋      | 157/430 [00:02<00:03, 77.29it/s] 38%|███▊      | 165/430 [00:02<00:03, 76.93it/s] 40%|████      | 173/430 [00:03<00:03, 74.63it/s] 42%|████▏     | 181/430 [00:03<00:03, 74.81it/s] 44%|████▍     | 189/430 [00:03<00:03, 76.08it/s] 46%|████▌     | 198/430 [00:03<00:02, 77.66it/s] 48%|████▊     | 206/430 [00:03<00:02, 77.06it/s] 50%|████▉     | 214/430 [00:03<00:02, 74.73it/s] 52%|█████▏    | 223/430 [00:03<00:02, 76.85it/s] 54%|█████▍    | 232/430 [00:03<00:02, 78.59it/s] 56%|█████▌    | 240/430 [00:03<00:02, 78.62it/s] 58%|█████▊    | 248/430 [00:03<00:02, 76.30it/s] 60%|█████▉    | 256/430 [00:04<00:02, 71.52it/s] 61%|██████▏   | 264/430 [00:04<00:02, 72.55it/s] 63%|██████▎   | 273/430 [00:04<00:02, 75.24it/s] 65%|██████▌   | 281/430 [00:04<00:02, 72.85it/s] 67%|██████▋   | 290/430 [00:04<00:01, 75.38it/s] 70%|██████▉   | 299/430 [00:04<00:01, 78.22it/s] 72%|███████▏  | 308/430 [00:04<00:01, 79.23it/s] 73%|███████▎  | 316/430 [00:04<00:01, 76.46it/s] 75%|███████▌  | 324/430 [00:04<00:01, 76.58it/s] 77%|███████▋  | 332/430 [00:05<00:01, 77.03it/s] 79%|███████▉  | 340/430 [00:05<00:01, 77.60it/s] 81%|████████  | 348/430 [00:05<00:01, 75.74it/s] 83%|████████▎ | 356/430 [00:05<00:00, 75.76it/s] 85%|████████▍ | 364/430 [00:05<00:00, 74.65it/s] 87%|████████▋ | 372/430 [00:05<00:00, 75.04it/s] 88%|████████▊ | 380/430 [00:05<00:00, 73.63it/s] 90%|█████████ | 388/430 [00:05<00:00, 75.00it/s] 92%|█████████▏| 396/430 [00:05<00:00, 74.70it/s] 94%|█████████▍| 404/430 [00:06<00:00, 73.63it/s] 96%|█████████▌| 412/430 [00:06<00:00, 72.18it/s] 98%|█████████▊| 420/430 [00:06<00:00, 72.43it/s]100%|█████████▉| 429/430 [00:06<00:00, 76.93it/s]100%|██████████| 430/430 [00:06<00:00, 67.11it/s]
55000 images processed, 6.472182989120483 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<01:19,  1.06it/s] 10%|█         | 9/86 [00:01<00:06, 11.39it/s] 20%|█▉        | 17/86 [00:01<00:03, 22.08it/s] 29%|██▉       | 25/86 [00:01<00:01, 32.46it/s] 38%|███▊      | 33/86 [00:01<00:01, 42.00it/s] 48%|████▊     | 41/86 [00:01<00:00, 47.83it/s] 56%|█████▌    | 48/86 [00:01<00:00, 53.00it/s] 65%|██████▌   | 56/86 [00:01<00:00, 58.17it/s] 74%|███████▍  | 64/86 [00:01<00:00, 62.64it/s] 84%|████████▎ | 72/86 [00:01<00:00, 66.50it/s] 94%|█████████▍| 81/86 [00:02<00:00, 70.27it/s]100%|██████████| 86/86 [00:02<00:00, 41.37it/s]
11000 images processed, 2.0962159633636475 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:29,  1.36it/s]  4%|▍         | 9/204 [00:00<00:14, 13.68it/s]  8%|▊         | 17/204 [00:00<00:07, 25.28it/s] 12%|█▏        | 25/204 [00:01<00:05, 35.50it/s] 16%|█▌        | 33/204 [00:01<00:03, 45.02it/s] 20%|██        | 41/204 [00:01<00:03, 51.90it/s] 24%|██▎       | 48/204 [00:01<00:02, 55.98it/s] 27%|██▋       | 55/204 [00:01<00:02, 59.14it/s] 30%|███       | 62/204 [00:01<00:02, 61.33it/s] 35%|███▍      | 71/204 [00:01<00:01, 67.05it/s] 39%|███▊      | 79/204 [00:01<00:01, 66.72it/s] 42%|████▏     | 86/204 [00:01<00:01, 66.38it/s] 46%|████▌     | 93/204 [00:02<00:01, 67.32it/s] 50%|████▉     | 101/204 [00:02<00:01, 68.96it/s] 53%|█████▎    | 109/204 [00:02<00:01, 71.24it/s] 57%|█████▋    | 117/204 [00:02<00:01, 70.20it/s] 61%|██████▏   | 125/204 [00:02<00:01, 69.76it/s] 65%|██████▌   | 133/204 [00:02<00:01, 69.48it/s] 69%|██████▉   | 141/204 [00:02<00:00, 70.65it/s] 73%|███████▎  | 149/204 [00:02<00:00, 70.61it/s] 77%|███████▋  | 157/204 [00:02<00:00, 69.00it/s] 81%|████████  | 165/204 [00:03<00:00, 70.31it/s] 85%|████████▌ | 174/204 [00:03<00:00, 73.56it/s] 89%|████████▉ | 182/204 [00:03<00:00, 72.75it/s] 94%|█████████▎| 191/204 [00:03<00:00, 76.80it/s] 98%|█████████▊| 200/204 [00:03<00:00, 78.42it/s]100%|██████████| 204/204 [00:03<00:00, 57.37it/s]
26032 images processed, 3.614359140396118 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:03,  1.24it/s]  5%|▌         | 4/79 [00:00<00:13,  5.51it/s] 14%|█▍        | 11/79 [00:01<00:04, 16.75it/s] 25%|██▌       | 20/79 [00:01<00:01, 31.24it/s] 38%|███▊      | 30/79 [00:01<00:01, 45.83it/s] 48%|████▊     | 38/79 [00:01<00:00, 53.77it/s] 58%|█████▊    | 46/79 [00:01<00:00, 59.72it/s] 68%|██████▊   | 54/79 [00:01<00:00, 63.80it/s] 78%|███████▊  | 62/79 [00:01<00:00, 66.28it/s] 89%|████████▊ | 70/79 [00:01<00:00, 66.57it/s] 99%|█████████▊| 78/79 [00:01<00:00, 66.78it/s]100%|██████████| 79/79 [00:02<00:00, 37.98it/s]
10000 images processed, 2.109454393386841 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:59,  1.32it/s] 10%|█         | 8/79 [00:00<00:05, 11.97it/s] 19%|█▉        | 15/79 [00:00<00:02, 22.43it/s] 28%|██▊       | 22/79 [00:01<00:01, 31.44it/s] 35%|███▌      | 28/79 [00:01<00:01, 37.26it/s] 44%|████▍     | 35/79 [00:01<00:00, 44.58it/s] 54%|█████▍    | 43/79 [00:01<00:00, 52.47it/s] 65%|██████▍   | 51/79 [00:01<00:00, 58.47it/s] 75%|███████▍  | 59/79 [00:01<00:00, 63.65it/s] 86%|████████▌ | 68/79 [00:01<00:00, 68.68it/s] 96%|█████████▌| 76/79 [00:01<00:00, 71.32it/s]100%|██████████| 79/79 [00:01<00:00, 42.34it/s]
10000 images processed, 1.8919854164123535 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:40,  1.72it/s] 10%|█         | 7/70 [00:00<00:04, 13.08it/s] 21%|██▏       | 15/70 [00:00<00:02, 27.36it/s] 33%|███▎      | 23/70 [00:00<00:01, 38.92it/s] 44%|████▍     | 31/70 [00:01<00:00, 48.01it/s] 54%|█████▍    | 38/70 [00:01<00:00, 52.87it/s] 66%|██████▌   | 46/70 [00:01<00:00, 58.93it/s] 76%|███████▌  | 53/70 [00:01<00:00, 60.91it/s] 87%|████████▋ | 61/70 [00:01<00:00, 64.81it/s] 97%|█████████▋| 68/70 [00:01<00:00, 66.04it/s]100%|██████████| 70/70 [00:01<00:00, 44.63it/s]
8925 images processed, 1.5996315479278564 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:50,  1.15s/it]  4%|▍         | 2/45 [00:01<00:23,  1.85it/s] 16%|█▌        | 7/45 [00:01<00:04,  8.27it/s] 33%|███▎      | 15/45 [00:01<00:01, 19.65it/s] 44%|████▍     | 20/45 [00:01<00:01, 16.12it/s] 58%|█████▊    | 26/45 [00:01<00:00, 22.11it/s] 73%|███████▎  | 33/45 [00:02<00:00, 20.02it/s] 82%|████████▏ | 37/45 [00:02<00:00, 21.93it/s] 98%|█████████▊| 44/45 [00:02<00:00, 29.08it/s]100%|██████████| 45/45 [00:02<00:00, 16.99it/s]
5640 images processed, 2.6714837551116943 seconds used

22.294694662094116
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           3.78  98.86  78.80
places365     52.89  85.09  47.12
LSUN          44.44  89.38  62.24
iSUN          35.80  91.31  65.41
dtd           32.96  92.09  73.37
AVG           33.97  91.35  65.39
[incremental] Overall: 0.7380 New: 0.7180 Old: 0.7580
[incremental] Final(Top-1): 0.5083  Average: 0.6623
22.936365365982056
==== Stage 3: inc={59,58,44,93,10}; seen={0,8,11,40,51,66,67,88,94,57}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, palm_enable=True, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2', lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94,100,101,102,103,104,105,106,107,108,109', forget_list_path=None, forget_classes_inc='59,58,44,93,10', forget_classes_seen='0,8,11,40,51,66,67,88,94,57', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='forget_only', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:11<09:39, 11.84s/it]  4%|▍         | 2/50 [00:13<04:29,  5.62s/it]  6%|▌         | 3/50 [00:13<02:40,  3.41s/it]  8%|▊         | 4/50 [00:14<01:52,  2.45s/it] 10%|█         | 5/50 [00:16<01:29,  1.99s/it] 12%|█▏        | 6/50 [00:17<01:12,  1.64s/it] 14%|█▍        | 7/50 [00:17<00:59,  1.37s/it] 16%|█▌        | 8/50 [00:18<00:48,  1.14s/it] 18%|█▊        | 9/50 [00:19<00:42,  1.04s/it] 20%|██        | 10/50 [00:19<00:37,  1.07it/s] 22%|██▏       | 11/50 [00:20<00:34,  1.13it/s] 24%|██▍       | 12/50 [00:21<00:34,  1.11it/s] 26%|██▌       | 13/50 [00:22<00:31,  1.16it/s] 28%|██▊       | 14/50 [00:23<00:31,  1.15it/s] 30%|███       | 15/50 [00:24<00:30,  1.14it/s] 32%|███▏      | 16/50 [00:24<00:27,  1.25it/s] 34%|███▍      | 17/50 [00:25<00:26,  1.23it/s] 36%|███▌      | 18/50 [00:26<00:24,  1.28it/s] 38%|███▊      | 19/50 [00:27<00:23,  1.34it/s] 40%|████      | 20/50 [00:27<00:20,  1.44it/s] 42%|████▏     | 21/50 [00:28<00:19,  1.46it/s] 44%|████▍     | 22/50 [00:28<00:18,  1.49it/s] 46%|████▌     | 23/50 [00:29<00:19,  1.38it/s] 48%|████▊     | 24/50 [00:30<00:19,  1.34it/s] 50%|█████     | 25/50 [00:31<00:16,  1.48it/s] 52%|█████▏    | 26/50 [00:31<00:15,  1.50it/s] 54%|█████▍    | 27/50 [00:32<00:15,  1.48it/s] 56%|█████▌    | 28/50 [00:33<00:15,  1.45it/s] 58%|█████▊    | 29/50 [00:33<00:14,  1.45it/s] 60%|██████    | 30/50 [00:34<00:13,  1.45it/s][loss] ep 0 it 0 total=15.1285 mle=5.4397 pcon=9.6888 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 2 it 10 total=14.7200 mle=5.0435 pcon=9.6765 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 5 it 0 total=14.3104 mle=4.6489 pcon=9.6615 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 7 it 10 total=13.9806 mle=4.3368 pcon=9.6438 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 10 it 0 total=13.6886 mle=4.0646 pcon=9.6240 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 12 it 10 total=13.4921 mle=3.8894 pcon=9.6027 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 15 it 0 total=13.3262 mle=3.7458 pcon=9.5804 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 17 it 10 total=13.2238 mle=3.6665 pcon=9.5572 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 20 it 0 total=13.1177 mle=3.5842 pcon=9.5335 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 22 it 10 total=13.0136 mle=3.5040 pcon=9.5096 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 25 it 0 total=12.9754 mle=3.4900 pcon=9.4854 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 27 it 10 total=12.8714 mle=3.4101 pcon=9.4613 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 30 it 0 total=12.8651 mle=3.4277 pcon=9.4374 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
 62%|██████▏   | 31/50 [00:35<00:13,  1.44it/s] 64%|██████▍   | 32/50 [00:35<00:12,  1.49it/s] 66%|██████▌   | 33/50 [00:36<00:11,  1.48it/s] 68%|██████▊   | 34/50 [00:37<00:10,  1.50it/s] 70%|███████   | 35/50 [00:37<00:09,  1.53it/s] 72%|███████▏  | 36/50 [00:38<00:09,  1.50it/s] 74%|███████▍  | 37/50 [00:39<00:08,  1.53it/s] 76%|███████▌  | 38/50 [00:39<00:07,  1.56it/s] 78%|███████▊  | 39/50 [00:40<00:06,  1.60it/s] 80%|████████  | 40/50 [00:41<00:06,  1.59it/s] 82%|████████▏ | 41/50 [00:41<00:05,  1.52it/s] 84%|████████▍ | 42/50 [00:42<00:05,  1.56it/s] 86%|████████▌ | 43/50 [00:42<00:04,  1.60it/s] 88%|████████▊ | 44/50 [00:43<00:03,  1.61it/s] 90%|█████████ | 45/50 [00:44<00:03,  1.57it/s] 92%|█████████▏| 46/50 [00:44<00:02,  1.60it/s] 94%|█████████▍| 47/50 [00:45<00:01,  1.61it/s] 96%|█████████▌| 48/50 [00:46<00:01,  1.64it/s] 98%|█████████▊| 49/50 [00:46<00:00,  1.63it/s]100%|██████████| 50/50 [00:47<00:00,  1.56it/s]100%|██████████| 50/50 [00:47<00:00,  1.06it/s]
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 32 it 10 total=12.8290 mle=3.4150 pcon=9.4139 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 35 it 0 total=12.7847 mle=3.3938 pcon=9.3909 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 37 it 10 total=12.7477 mle=3.3792 pcon=9.3685 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 40 it 0 total=12.7262 mle=3.3796 pcon=9.3467 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 42 it 10 total=12.7154 mle=3.3898 pcon=9.3257 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 45 it 0 total=12.6737 mle=3.3682 pcon=9.3054 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[loss] ep 47 it 10 total=12.6564 mle=3.3703 pcon=9.2861 forget=0.0000 orth=0.0000 favg=0.0000 nr=0 nf=128 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmforget_only-fl0.2-lora_r8a32d0.05-temp0.08-continual-from-c80-to-CIFAR-110-pcon_split-stage3-seen-inc: Number of model parameters: 21843904
Processing in-distribution CIFAR-110 images
  0%|          | 0/430 [00:00<?, ?it/s]  0%|          | 1/430 [00:00<04:28,  1.60it/s]  2%|▏         | 9/430 [00:00<00:26, 16.08it/s]  4%|▍         | 17/430 [00:00<00:14, 28.97it/s]  6%|▌         | 25/430 [00:00<00:10, 39.62it/s]  8%|▊         | 34/430 [00:01<00:07, 49.67it/s] 10%|█         | 43/430 [00:01<00:06, 58.18it/s] 12%|█▏        | 51/430 [00:01<00:06, 63.06it/s] 14%|█▎        | 59/430 [00:01<00:05, 64.80it/s] 16%|█▌        | 68/430 [00:01<00:05, 69.58it/s] 18%|█▊        | 76/430 [00:01<00:04, 71.67it/s] 20%|█▉        | 84/430 [00:01<00:04, 71.06it/s] 21%|██▏       | 92/430 [00:01<00:04, 69.08it/s] 23%|██▎       | 100/430 [00:02<00:05, 62.63it/s] 25%|██▌       | 109/430 [00:02<00:04, 68.04it/s] 27%|██▋       | 117/430 [00:02<00:04, 70.29it/s] 29%|██▉       | 126/430 [00:02<00:04, 74.46it/s] 31%|███       | 134/430 [00:02<00:03, 74.84it/s] 33%|███▎      | 142/430 [00:02<00:03, 74.01it/s] 35%|███▍      | 150/430 [00:02<00:03, 70.77it/s] 37%|███▋      | 158/430 [00:02<00:03, 70.20it/s] 39%|███▊      | 166/430 [00:02<00:03, 71.55it/s] 40%|████      | 174/430 [00:02<00:03, 71.42it/s] 42%|████▏     | 182/430 [00:03<00:03, 71.28it/s] 44%|████▍     | 190/430 [00:03<00:03, 69.57it/s] 46%|████▌     | 198/430 [00:03<00:03, 72.27it/s] 48%|████▊     | 207/430 [00:03<00:02, 74.57it/s] 50%|█████     | 215/430 [00:03<00:02, 75.37it/s] 52%|█████▏    | 223/430 [00:03<00:02, 75.10it/s] 54%|█████▎    | 231/430 [00:03<00:02, 75.69it/s] 56%|█████▌    | 239/430 [00:03<00:02, 73.87it/s] 57%|█████▋    | 247/430 [00:03<00:02, 72.20it/s] 59%|█████▉    | 255/430 [00:04<00:02, 71.97it/s] 61%|██████    | 263/430 [00:04<00:02, 72.38it/s] 63%|██████▎   | 271/430 [00:04<00:02, 72.34it/s] 65%|██████▍   | 279/430 [00:04<00:02, 66.62it/s] 67%|██████▋   | 286/430 [00:04<00:02, 62.37it/s] 68%|██████▊   | 293/430 [00:04<00:02, 60.23it/s] 70%|██████▉   | 300/430 [00:04<00:02, 58.37it/s] 71%|███████   | 306/430 [00:04<00:02, 56.83it/s] 73%|███████▎  | 313/430 [00:05<00:01, 59.28it/s] 74%|███████▍  | 320/430 [00:05<00:01, 61.80it/s] 76%|███████▋  | 328/430 [00:05<00:01, 65.79it/s] 78%|███████▊  | 336/430 [00:05<00:01, 67.83it/s] 80%|████████  | 344/430 [00:05<00:01, 69.40it/s] 82%|████████▏ | 352/430 [00:05<00:01, 71.13it/s] 84%|████████▎ | 360/430 [00:05<00:00, 70.71it/s] 86%|████████▌ | 368/430 [00:05<00:00, 70.48it/s] 87%|████████▋ | 376/430 [00:05<00:00, 71.20it/s] 90%|████████▉ | 385/430 [00:06<00:00, 73.79it/s] 91%|█████████▏| 393/430 [00:06<00:00, 73.54it/s] 93%|█████████▎| 401/430 [00:06<00:00, 72.66it/s] 95%|█████████▌| 410/430 [00:06<00:00, 74.98it/s] 97%|█████████▋| 418/430 [00:06<00:00, 75.00it/s] 99%|█████████▉| 426/430 [00:06<00:00, 71.60it/s]100%|██████████| 430/430 [00:06<00:00, 64.02it/s]
55000 images processed, 6.851371765136719 seconds used

Processing in-distribution CIFAR-110 images
  0%|          | 0/86 [00:00<?, ?it/s]  1%|          | 1/86 [00:00<00:55,  1.53it/s] 10%|█         | 9/86 [00:00<00:04, 15.42it/s] 21%|██        | 18/86 [00:00<00:02, 29.77it/s] 29%|██▉       | 25/86 [00:00<00:01, 37.98it/s] 37%|███▋      | 32/86 [00:01<00:01, 45.34it/s] 47%|████▋     | 40/86 [00:01<00:00, 53.62it/s] 56%|█████▌    | 48/86 [00:01<00:00, 59.72it/s] 65%|██████▌   | 56/86 [00:01<00:00, 57.70it/s] 74%|███████▍  | 64/86 [00:01<00:00, 61.80it/s] 83%|████████▎ | 71/86 [00:01<00:00, 63.27it/s] 93%|█████████▎| 80/86 [00:01<00:00, 69.58it/s]100%|██████████| 86/86 [00:01<00:00, 46.59it/s]
11000 images processed, 1.8643598556518555 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<02:24,  1.41it/s]  5%|▍         | 10/204 [00:00<00:12, 16.11it/s]  9%|▉         | 18/204 [00:00<00:06, 27.76it/s] 12%|█▏        | 25/204 [00:01<00:04, 36.56it/s] 16%|█▌        | 32/204 [00:01<00:03, 43.98it/s] 20%|██        | 41/204 [00:01<00:03, 54.29it/s] 25%|██▍       | 50/204 [00:01<00:02, 60.81it/s] 28%|██▊       | 58/204 [00:01<00:02, 63.55it/s] 32%|███▏      | 66/204 [00:01<00:02, 66.42it/s] 36%|███▋      | 74/204 [00:01<00:01, 68.42it/s] 41%|████      | 83/204 [00:01<00:01, 71.64it/s] 45%|████▍     | 91/204 [00:01<00:01, 60.94it/s] 48%|████▊     | 98/204 [00:02<00:01, 58.82it/s] 51%|█████▏    | 105/204 [00:02<00:01, 58.58it/s] 56%|█████▌    | 114/204 [00:02<00:01, 65.12it/s] 60%|█████▉    | 122/204 [00:02<00:01, 68.88it/s] 64%|██████▎   | 130/204 [00:02<00:01, 70.01it/s] 68%|██████▊   | 139/204 [00:02<00:00, 70.72it/s] 72%|███████▏  | 147/204 [00:02<00:00, 64.55it/s] 75%|███████▌  | 154/204 [00:02<00:00, 65.20it/s] 79%|███████▉  | 161/204 [00:03<00:00, 66.13it/s] 82%|████████▏ | 168/204 [00:03<00:00, 66.75it/s] 86%|████████▋ | 176/204 [00:03<00:00, 68.80it/s] 91%|█████████ | 185/204 [00:03<00:00, 73.54it/s] 95%|█████████▍| 193/204 [00:03<00:00, 72.57it/s] 99%|█████████▊| 201/204 [00:03<00:00, 65.34it/s]100%|██████████| 204/204 [00:03<00:00, 55.92it/s]
26032 images processed, 3.6894705295562744 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<01:12,  1.07it/s]  4%|▍         | 3/79 [00:01<00:21,  3.47it/s] 11%|█▏        | 9/79 [00:01<00:05, 12.09it/s] 20%|██        | 16/79 [00:01<00:02, 22.30it/s] 28%|██▊       | 22/79 [00:01<00:01, 29.68it/s] 37%|███▋      | 29/79 [00:01<00:01, 38.47it/s] 47%|████▋     | 37/79 [00:01<00:00, 48.03it/s] 57%|█████▋    | 45/79 [00:01<00:00, 55.21it/s] 67%|██████▋   | 53/79 [00:01<00:00, 59.98it/s] 76%|███████▌  | 60/79 [00:01<00:00, 61.16it/s] 85%|████████▍ | 67/79 [00:02<00:00, 62.27it/s] 96%|█████████▌| 76/79 [00:02<00:00, 68.13it/s]100%|██████████| 79/79 [00:02<00:00, 36.32it/s]
10000 images processed, 2.2009220123291016 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:42,  1.83it/s]  8%|▊         | 6/79 [00:00<00:06, 11.61it/s] 14%|█▍        | 11/79 [00:00<00:03, 19.74it/s] 23%|██▎       | 18/79 [00:00<00:01, 31.61it/s] 34%|███▍      | 27/79 [00:00<00:01, 44.55it/s] 44%|████▍     | 35/79 [00:01<00:00, 52.34it/s] 53%|█████▎    | 42/79 [00:01<00:00, 54.68it/s] 62%|██████▏   | 49/79 [00:01<00:00, 56.70it/s] 71%|███████   | 56/79 [00:01<00:00, 60.09it/s] 82%|████████▏ | 65/79 [00:01<00:00, 66.98it/s] 92%|█████████▏| 73/79 [00:01<00:00, 70.17it/s]100%|██████████| 79/79 [00:01<00:00, 46.13it/s]
10000 images processed, 1.7297444343566895 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:39,  1.73it/s] 11%|█▏        | 8/70 [00:00<00:04, 15.09it/s] 23%|██▎       | 16/70 [00:00<00:01, 28.98it/s] 34%|███▍      | 24/70 [00:00<00:01, 39.97it/s] 44%|████▍     | 31/70 [00:01<00:00, 45.68it/s] 54%|█████▍    | 38/70 [00:01<00:00, 51.63it/s] 66%|██████▌   | 46/70 [00:01<00:00, 58.12it/s] 77%|███████▋  | 54/70 [00:01<00:00, 63.45it/s] 89%|████████▊ | 62/70 [00:01<00:00, 67.45it/s]100%|██████████| 70/70 [00:01<00:00, 70.17it/s]100%|██████████| 70/70 [00:01<00:00, 45.61it/s]
8925 images processed, 1.564579725265503 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:59,  1.36s/it]  4%|▍         | 2/45 [00:01<00:29,  1.47it/s] 16%|█▌        | 7/45 [00:01<00:06,  6.06it/s] 31%|███       | 14/45 [00:01<00:02, 13.70it/s] 40%|████      | 18/45 [00:02<00:01, 15.02it/s] 47%|████▋     | 21/45 [00:02<00:01, 15.73it/s] 53%|█████▎    | 24/45 [00:02<00:01, 15.03it/s] 71%|███████   | 32/45 [00:02<00:00, 25.65it/s] 80%|████████  | 36/45 [00:02<00:00, 23.79it/s] 89%|████████▉ | 40/45 [00:03<00:00, 20.15it/s]100%|██████████| 45/45 [00:03<00:00, 14.29it/s]
5640 images processed, 3.166457176208496 seconds used

22.963855266571045
eval.sh: line 48: eval_cifar.py: command not found
