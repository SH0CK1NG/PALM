nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.1, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_center_set='all', forget_lambda=1.0, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [01:06<54:33, 66.80s/it]  4%|▍         | 2/50 [02:02<48:23, 60.49s/it]  6%|▌         | 3/50 [02:57<45:24, 57.96s/it]  8%|▊         | 4/50 [03:53<43:49, 57.16s/it] 10%|█         | 5/50 [04:49<42:32, 56.72s/it] 12%|█▏        | 6/50 [05:45<41:16, 56.28s/it] 14%|█▍        | 7/50 [06:39<39:53, 55.66s/it] 16%|█▌        | 8/50 [07:35<39:02, 55.77s/it][loss] ep 0 it 0 total=13.4199 mle=1.4970 pcon=5.2950 forget=6.6278 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 50 total=13.4477 mle=1.4709 pcon=5.2879 forget=6.6888 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 100 total=13.5020 mle=1.5968 pcon=5.2809 forget=6.6243 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 150 total=13.6314 mle=1.7521 pcon=5.2738 forget=6.6055 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 200 total=13.5352 mle=1.6198 pcon=5.2670 forget=6.6484 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 250 total=13.3386 mle=1.4373 pcon=5.2603 forget=6.6410 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 300 total=13.3811 mle=1.4844 pcon=5.2541 forget=6.6426 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 0 it 350 total=13.4971 mle=1.5892 pcon=5.2476 forget=6.6603 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 1 it 10 total=13.5409 mle=1.5754 pcon=5.2409 forget=6.7246 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 60 total=13.4008 mle=1.5657 pcon=5.2346 forget=6.6005 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 110 total=13.3311 mle=1.4497 pcon=5.2284 forget=6.6529 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 160 total=13.5478 mle=1.6637 pcon=5.2224 forget=6.6616 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 210 total=13.5129 mle=1.6529 pcon=5.2167 forget=6.6433 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 260 total=13.3434 mle=1.5303 pcon=5.2112 forget=6.6019 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 310 total=13.4532 mle=1.6296 pcon=5.2056 forget=6.6180 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 1 it 360 total=13.5241 mle=1.6851 pcon=5.2003 forget=6.6387 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 2 it 20 total=13.3064 mle=1.4936 pcon=5.1950 forget=6.6178 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 70 total=13.5029 mle=1.7524 pcon=5.1899 forget=6.5607 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 120 total=13.4413 mle=1.6372 pcon=5.1847 forget=6.6194 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 170 total=13.2328 mle=1.4588 pcon=5.1796 forget=6.5944 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 220 total=13.3321 mle=1.5212 pcon=5.1745 forget=6.6363 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 270 total=13.5350 mle=1.7609 pcon=5.1699 forget=6.6042 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 320 total=13.2531 mle=1.5193 pcon=5.1652 forget=6.5687 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 2 it 370 total=13.4532 mle=1.7165 pcon=5.1604 forget=6.5762 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 3 it 30 total=13.3769 mle=1.6248 pcon=5.1559 forget=6.5963 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 80 total=13.3578 mle=1.5784 pcon=5.1518 forget=6.6276 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 130 total=13.3899 mle=1.6597 pcon=5.1474 forget=6.5828 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 180 total=13.5043 mle=1.7921 pcon=5.1434 forget=6.5688 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 230 total=13.2085 mle=1.5001 pcon=5.1394 forget=6.5690 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 280 total=13.4173 mle=1.7224 pcon=5.1352 forget=6.5597 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 330 total=13.3536 mle=1.6105 pcon=5.1310 forget=6.6121 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 3 it 380 total=13.3349 mle=1.5924 pcon=5.1273 forget=6.6152 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 4 it 40 total=13.2077 mle=1.5628 pcon=5.1235 forget=6.5214 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 90 total=13.2996 mle=1.6330 pcon=5.1194 forget=6.5472 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 140 total=13.2675 mle=1.5738 pcon=5.1157 forget=6.5781 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 190 total=13.0960 mle=1.4068 pcon=5.1122 forget=6.5771 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 240 total=13.3254 mle=1.6707 pcon=5.1082 forget=6.5465 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 290 total=13.0901 mle=1.4385 pcon=5.1046 forget=6.5470 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 4 it 340 total=13.4344 mle=1.7739 pcon=5.1011 forget=6.5594 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 5 it 0 total=13.4045 mle=1.7697 pcon=5.0976 forget=6.5371 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 50 total=13.2989 mle=1.6956 pcon=5.0939 forget=6.5095 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 100 total=13.1510 mle=1.5228 pcon=5.0905 forget=6.5377 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 150 total=13.1339 mle=1.5206 pcon=5.0869 forget=6.5265 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 200 total=13.1814 mle=1.6070 pcon=5.0837 forget=6.4906 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 250 total=13.2248 mle=1.6769 pcon=5.0805 forget=6.4674 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 300 total=13.0772 mle=1.5238 pcon=5.0771 forget=6.4763 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 5 it 350 total=13.1951 mle=1.6447 pcon=5.0739 forget=6.4765 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 6 it 10 total=12.9950 mle=1.3784 pcon=5.0706 forget=6.5460 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 60 total=12.9692 mle=1.4823 pcon=5.0674 forget=6.4195 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 110 total=13.0745 mle=1.5336 pcon=5.0643 forget=6.4767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 160 total=13.1194 mle=1.6078 pcon=5.0610 forget=6.4506 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 210 total=13.0535 mle=1.5465 pcon=5.0582 forget=6.4487 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 260 total=13.2224 mle=1.6991 pcon=5.0549 forget=6.4684 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 310 total=13.0562 mle=1.4942 pcon=5.0520 forget=6.5100 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 6 it 360 total=13.1090 mle=1.5900 pcon=5.0490 forget=6.4700 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 7 it 20 total=13.0747 mle=1.5739 pcon=5.0460 forget=6.4548 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 70 total=13.1592 mle=1.6615 pcon=5.0433 forget=6.4544 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 120 total=13.0680 mle=1.5555 pcon=5.0404 forget=6.4722 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 170 total=13.0274 mle=1.5078 pcon=5.0377 forget=6.4819 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 220 total=13.1369 mle=1.5712 pcon=5.0355 forget=6.5302 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 270 total=13.2898 mle=1.6941 pcon=5.0332 forget=6.5625 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 320 total=13.2399 mle=1.6434 pcon=5.0306 forget=6.5659 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 7 it 370 total=13.1639 mle=1.5763 pcon=5.0285 forget=6.5591 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 30 total=13.1394 mle=1.5002 pcon=5.0266 forget=6.6126 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 80 total=13.1557 mle=1.5276 pcon=5.0247 forget=6.6035 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 130 total=13.0951 mle=1.4637 pcon=5.0226 forget=6.6089 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 180 total=13.2832 mle=1.6448 pcon=5.0207 forget=6.6177 nr=64 nf=64 protos=540 dmin_norm=NA
 18%|█▊        | 9/50 [08:30<37:57, 55.55s/it] 20%|██        | 10/50 [09:24<36:46, 55.16s/it] 22%|██▏       | 11/50 [10:20<35:58, 55.35s/it] 24%|██▍       | 12/50 [11:16<35:04, 55.38s/it] 26%|██▌       | 13/50 [12:11<34:04, 55.25s/it] 28%|██▊       | 14/50 [13:05<33:03, 55.11s/it] 30%|███       | 15/50 [14:01<32:15, 55.31s/it] 32%|███▏      | 16/50 [14:56<31:13, 55.11s/it] 34%|███▍      | 17/50 [15:50<30:09, 54.84s/it][loss] ep 8 it 230 total=13.1149 mle=1.4782 pcon=5.0193 forget=6.6174 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 280 total=13.2615 mle=1.6219 pcon=5.0174 forget=6.6222 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 330 total=13.3776 mle=1.6644 pcon=5.0155 forget=6.6977 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 8 it 380 total=13.1302 mle=1.4495 pcon=5.0137 forget=6.6671 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 40 total=13.2274 mle=1.5679 pcon=5.0119 forget=6.6476 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 90 total=13.3125 mle=1.6199 pcon=5.0099 forget=6.6827 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 140 total=13.4430 mle=1.7063 pcon=5.0085 forget=6.7282 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 190 total=13.2216 mle=1.5363 pcon=5.0069 forget=6.6784 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 240 total=13.2212 mle=1.5059 pcon=5.0054 forget=6.7099 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 290 total=13.2250 mle=1.5098 pcon=5.0034 forget=6.7119 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 9 it 340 total=13.2039 mle=1.5144 pcon=5.0018 forget=6.6876 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 0 total=13.2608 mle=1.5597 pcon=4.9999 forget=6.7012 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 50 total=13.2409 mle=1.5280 pcon=4.9979 forget=6.7150 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 100 total=13.3534 mle=1.6779 pcon=4.9961 forget=6.6794 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 150 total=13.3780 mle=1.7276 pcon=4.9944 forget=6.6560 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 200 total=13.4003 mle=1.7537 pcon=4.9925 forget=6.6541 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 250 total=13.1840 mle=1.5363 pcon=4.9908 forget=6.6568 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 300 total=13.1447 mle=1.5169 pcon=4.9892 forget=6.6385 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 10 it 350 total=13.2729 mle=1.5836 pcon=4.9874 forget=6.7019 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 10 total=13.1536 mle=1.5089 pcon=4.9855 forget=6.6593 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 60 total=13.1724 mle=1.5701 pcon=4.9836 forget=6.6186 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 110 total=13.1029 mle=1.5281 pcon=4.9818 forget=6.5930 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 160 total=13.1934 mle=1.5944 pcon=4.9797 forget=6.6193 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 210 total=13.2837 mle=1.6910 pcon=4.9780 forget=6.6147 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 260 total=13.1375 mle=1.5439 pcon=4.9765 forget=6.6171 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 310 total=13.4405 mle=1.8548 pcon=4.9745 forget=6.6111 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 11 it 360 total=13.1586 mle=1.6152 pcon=4.9727 forget=6.5707 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 20 total=13.1295 mle=1.5525 pcon=4.9707 forget=6.6063 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 70 total=13.1770 mle=1.6141 pcon=4.9689 forget=6.5940 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 120 total=13.1028 mle=1.5156 pcon=4.9671 forget=6.6201 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 170 total=13.2087 mle=1.6811 pcon=4.9654 forget=6.5623 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 220 total=13.0782 mle=1.5351 pcon=4.9635 forget=6.5796 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 270 total=13.0647 mle=1.4986 pcon=4.9621 forget=6.6039 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 320 total=13.0114 mle=1.4734 pcon=4.9604 forget=6.5775 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 12 it 370 total=13.2970 mle=1.7516 pcon=4.9587 forget=6.5867 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 30 total=12.9401 mle=1.4001 pcon=4.9571 forget=6.5829 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 80 total=13.0475 mle=1.4383 pcon=4.9554 forget=6.6538 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 130 total=13.0287 mle=1.5039 pcon=4.9536 forget=6.5711 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 180 total=13.0301 mle=1.5382 pcon=4.9522 forget=6.5397 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 230 total=13.1301 mle=1.6162 pcon=4.9507 forget=6.5632 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 280 total=13.0129 mle=1.5244 pcon=4.9491 forget=6.5394 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 330 total=13.0523 mle=1.5525 pcon=4.9474 forget=6.5523 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 13 it 380 total=13.0364 mle=1.5630 pcon=4.9459 forget=6.5274 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 14 it 40 total=13.1663 mle=1.7067 pcon=4.9441 forget=6.5155 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 90 total=13.1824 mle=1.7046 pcon=4.9428 forget=6.5349 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 140 total=13.0017 mle=1.5289 pcon=4.9417 forget=6.5311 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 190 total=13.2459 mle=1.7935 pcon=4.9401 forget=6.5123 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 240 total=13.0219 mle=1.5795 pcon=4.9388 forget=6.5036 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 290 total=13.0252 mle=1.6066 pcon=4.9373 forget=6.4813 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 14 it 340 total=13.0576 mle=1.6350 pcon=4.9357 forget=6.4869 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 15 it 0 total=13.0872 mle=1.6461 pcon=4.9343 forget=6.5068 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 50 total=12.8685 mle=1.4595 pcon=4.9325 forget=6.4764 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 100 total=12.9563 mle=1.5392 pcon=4.9310 forget=6.4862 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 150 total=13.0702 mle=1.6406 pcon=4.9294 forget=6.5003 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 200 total=12.9859 mle=1.6054 pcon=4.9277 forget=6.4527 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 250 total=13.2143 mle=1.8306 pcon=4.9260 forget=6.4576 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 300 total=12.9285 mle=1.5362 pcon=4.9246 forget=6.4677 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 15 it 350 total=12.9258 mle=1.4999 pcon=4.9228 forget=6.5031 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 16 it 10 total=12.9158 mle=1.5437 pcon=4.9210 forget=6.4511 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 60 total=12.8466 mle=1.4891 pcon=4.9193 forget=6.4382 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 110 total=12.8810 mle=1.5249 pcon=4.9177 forget=6.4384 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 160 total=12.9649 mle=1.6063 pcon=4.9156 forget=6.4431 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 210 total=12.8838 mle=1.5505 pcon=4.9134 forget=6.4199 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 260 total=13.1896 mle=1.8370 pcon=4.9112 forget=6.4414 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 310 total=13.0595 mle=1.7073 pcon=4.9091 forget=6.4430 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 16 it 360 total=12.8947 mle=1.5596 pcon=4.9070 forget=6.4282 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 17 it 20 total=13.0537 mle=1.7015 pcon=4.9045 forget=6.4478 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 70 total=13.0817 mle=1.7513 pcon=4.9025 forget=6.4279 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 120 total=12.8962 mle=1.5491 pcon=4.9000 forget=6.4471 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 170 total=12.9174 mle=1.5729 pcon=4.8973 forget=6.4473 nr=64 nf=64 protos=540 dmin_norm=NA
 36%|███▌      | 18/50 [16:45<29:18, 54.96s/it] 38%|███▊      | 19/50 [17:40<28:24, 54.99s/it] 40%|████      | 20/50 [18:36<27:39, 55.30s/it] 42%|████▏     | 21/50 [19:30<26:31, 54.87s/it] 44%|████▍     | 22/50 [20:25<25:36, 54.86s/it] 46%|████▌     | 23/50 [21:21<24:48, 55.14s/it] 48%|████▊     | 24/50 [22:16<23:51, 55.05s/it] 50%|█████     | 25/50 [23:11<22:58, 55.13s/it] 52%|█████▏    | 26/50 [24:06<21:59, 54.97s/it][loss] ep 17 it 220 total=12.9619 mle=1.6016 pcon=4.8947 forget=6.4656 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 270 total=12.7724 mle=1.4523 pcon=4.8925 forget=6.4276 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 320 total=13.0695 mle=1.7535 pcon=4.8899 forget=6.4260 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 17 it 370 total=12.9932 mle=1.6793 pcon=4.8870 forget=6.4268 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 18 it 30 total=12.8326 mle=1.5307 pcon=4.8847 forget=6.4172 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 80 total=12.8873 mle=1.5846 pcon=4.8820 forget=6.4206 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 130 total=12.9271 mle=1.6028 pcon=4.8793 forget=6.4451 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 180 total=12.8313 mle=1.5387 pcon=4.8765 forget=6.4160 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 230 total=12.8982 mle=1.5940 pcon=4.8737 forget=6.4305 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 280 total=12.9055 mle=1.6073 pcon=4.8710 forget=6.4272 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 330 total=12.9616 mle=1.6961 pcon=4.8682 forget=6.3973 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 18 it 380 total=12.9982 mle=1.6874 pcon=4.8656 forget=6.4452 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 19 it 40 total=12.8248 mle=1.4960 pcon=4.8630 forget=6.4658 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 90 total=12.9776 mle=1.6380 pcon=4.8604 forget=6.4792 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 140 total=12.8624 mle=1.5545 pcon=4.8575 forget=6.4504 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 190 total=12.9062 mle=1.6261 pcon=4.8547 forget=6.4254 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 240 total=13.0889 mle=1.8199 pcon=4.8520 forget=6.4170 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 290 total=12.9187 mle=1.6247 pcon=4.8495 forget=6.4444 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 19 it 340 total=12.8399 mle=1.5350 pcon=4.8470 forget=6.4578 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 20 it 0 total=12.8912 mle=1.6214 pcon=4.8443 forget=6.4255 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 50 total=12.8999 mle=1.6220 pcon=4.8417 forget=6.4362 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 100 total=13.0277 mle=1.6960 pcon=4.8392 forget=6.4925 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 150 total=13.0740 mle=1.7850 pcon=4.8364 forget=6.4526 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 200 total=12.8572 mle=1.5683 pcon=4.8336 forget=6.4552 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 250 total=13.1552 mle=1.8613 pcon=4.8310 forget=6.4630 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 300 total=13.0669 mle=1.7512 pcon=4.8283 forget=6.4874 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 20 it 350 total=12.7901 mle=1.4782 pcon=4.8257 forget=6.4862 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 10 total=12.7693 mle=1.4603 pcon=4.8233 forget=6.4857 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 60 total=12.9574 mle=1.6395 pcon=4.8208 forget=6.4972 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 110 total=12.8800 mle=1.5533 pcon=4.8185 forget=6.5082 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 160 total=12.8648 mle=1.5823 pcon=4.8162 forget=6.4662 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 210 total=13.0758 mle=1.7456 pcon=4.8139 forget=6.5163 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 260 total=12.9543 mle=1.6376 pcon=4.8116 forget=6.5051 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 310 total=12.8882 mle=1.5652 pcon=4.8092 forget=6.5138 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 21 it 360 total=12.9284 mle=1.5556 pcon=4.8068 forget=6.5660 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 20 total=12.9565 mle=1.6307 pcon=4.8044 forget=6.5214 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 70 total=12.9916 mle=1.7112 pcon=4.8021 forget=6.4783 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 120 total=12.9014 mle=1.5676 pcon=4.7997 forget=6.5340 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 170 total=12.8974 mle=1.5923 pcon=4.7976 forget=6.5076 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 220 total=12.8908 mle=1.5917 pcon=4.7955 forget=6.5036 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 270 total=12.8310 mle=1.5253 pcon=4.7934 forget=6.5123 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 320 total=12.9432 mle=1.6656 pcon=4.7914 forget=6.4862 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 22 it 370 total=13.1835 mle=1.8895 pcon=4.7892 forget=6.5048 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 30 total=12.7980 mle=1.5243 pcon=4.7875 forget=6.4863 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 80 total=12.9201 mle=1.6426 pcon=4.7854 forget=6.4921 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 130 total=12.8185 mle=1.5550 pcon=4.7833 forget=6.4802 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 180 total=12.9475 mle=1.7145 pcon=4.7812 forget=6.4518 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 230 total=12.8456 mle=1.6004 pcon=4.7793 forget=6.4659 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 280 total=12.8567 mle=1.5937 pcon=4.7771 forget=6.4859 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 330 total=12.8299 mle=1.6069 pcon=4.7751 forget=6.4479 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 23 it 380 total=12.8260 mle=1.5805 pcon=4.7732 forget=6.4724 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 24 it 40 total=12.7577 mle=1.5581 pcon=4.7714 forget=6.4282 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 90 total=12.8558 mle=1.6095 pcon=4.7696 forget=6.4766 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 140 total=12.8103 mle=1.5830 pcon=4.7677 forget=6.4595 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 190 total=12.8586 mle=1.6533 pcon=4.7661 forget=6.4393 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 240 total=12.7550 mle=1.5303 pcon=4.7644 forget=6.4603 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 290 total=12.9345 mle=1.7129 pcon=4.7627 forget=6.4589 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 24 it 340 total=12.8217 mle=1.6271 pcon=4.7610 forget=6.4336 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 25 it 0 total=12.7963 mle=1.5855 pcon=4.7593 forget=6.4515 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 50 total=12.9642 mle=1.7354 pcon=4.7578 forget=6.4710 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 100 total=12.7938 mle=1.6093 pcon=4.7563 forget=6.4283 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 150 total=12.9426 mle=1.7619 pcon=4.7550 forget=6.4257 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 200 total=12.9833 mle=1.7762 pcon=4.7534 forget=6.4537 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 250 total=12.9092 mle=1.6973 pcon=4.7518 forget=6.4600 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 300 total=12.8037 mle=1.6275 pcon=4.7504 forget=6.4259 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 25 it 350 total=12.7383 mle=1.5619 pcon=4.7493 forget=6.4271 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 26 it 10 total=12.7738 mle=1.5930 pcon=4.7479 forget=6.4329 nr=64 nf=64 protos=540 dmin_norm=NA
 54%|█████▍    | 27/50 [25:00<21:02, 54.90s/it] 56%|█████▌    | 28/50 [25:55<20:06, 54.83s/it] 58%|█████▊    | 29/50 [26:50<19:11, 54.82s/it] 60%|██████    | 30/50 [27:45<18:18, 54.91s/it] 62%|██████▏   | 31/50 [28:41<17:29, 55.23s/it] 64%|██████▍   | 32/50 [29:35<16:30, 55.00s/it] 66%|██████▌   | 33/50 [30:30<15:35, 55.00s/it] 68%|██████▊   | 34/50 [31:26<14:45, 55.34s/it] 70%|███████   | 35/50 [32:22<13:50, 55.38s/it][loss] ep 26 it 60 total=12.7629 mle=1.5758 pcon=4.7467 forget=6.4404 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 110 total=12.8528 mle=1.6943 pcon=4.7454 forget=6.4130 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 160 total=12.7508 mle=1.5588 pcon=4.7441 forget=6.4480 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 210 total=12.8260 mle=1.6431 pcon=4.7426 forget=6.4402 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 260 total=12.6993 mle=1.5146 pcon=4.7415 forget=6.4432 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 310 total=13.0247 mle=1.8578 pcon=4.7403 forget=6.4265 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 26 it 360 total=12.7210 mle=1.5877 pcon=4.7389 forget=6.3944 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 27 it 20 total=12.7830 mle=1.6280 pcon=4.7378 forget=6.4172 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 70 total=12.7426 mle=1.5903 pcon=4.7364 forget=6.4159 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 120 total=12.6820 mle=1.5508 pcon=4.7352 forget=6.3960 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 170 total=12.7074 mle=1.5458 pcon=4.7339 forget=6.4277 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 220 total=12.6875 mle=1.5187 pcon=4.7326 forget=6.4362 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 270 total=12.7430 mle=1.5920 pcon=4.7313 forget=6.4196 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 320 total=12.8420 mle=1.6952 pcon=4.7303 forget=6.4165 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 27 it 370 total=12.8849 mle=1.7163 pcon=4.7292 forget=6.4394 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 28 it 30 total=12.7765 mle=1.6486 pcon=4.7282 forget=6.3996 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 80 total=12.8478 mle=1.6823 pcon=4.7273 forget=6.4382 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 130 total=12.7473 mle=1.5845 pcon=4.7264 forget=6.4364 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 180 total=12.7424 mle=1.6007 pcon=4.7254 forget=6.4163 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 230 total=12.5979 mle=1.4469 pcon=4.7242 forget=6.4268 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 280 total=12.7326 mle=1.5775 pcon=4.7231 forget=6.4320 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 330 total=12.9745 mle=1.7939 pcon=4.7219 forget=6.4587 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 28 it 380 total=12.8605 mle=1.6989 pcon=4.7208 forget=6.4408 nr=64 nf=64 protos=540 dmin_norm=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
[loss] ep 29 it 40 total=12.8331 mle=1.6920 pcon=4.7196 forget=6.4214 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 90 total=12.7049 mle=1.5762 pcon=4.7185 forget=6.4103 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 140 total=12.7971 mle=1.6369 pcon=4.7175 forget=6.4426 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 190 total=12.7850 mle=1.6215 pcon=4.7166 forget=6.4469 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 240 total=12.7305 mle=1.5554 pcon=4.7158 forget=6.4593 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 290 total=12.8938 mle=1.7407 pcon=4.7150 forget=6.4381 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 29 it 340 total=12.7233 mle=1.5719 pcon=4.7143 forget=6.4371 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 0 total=12.8002 mle=1.6459 pcon=4.7134 forget=6.4409 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 50 total=12.8436 mle=1.6642 pcon=4.7127 forget=6.4667 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 100 total=12.7636 mle=1.5825 pcon=4.7119 forget=6.4691 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 150 total=12.9232 mle=1.7744 pcon=4.7111 forget=6.4377 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 200 total=12.7057 mle=1.5101 pcon=4.7102 forget=6.4853 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 250 total=12.9613 mle=1.7701 pcon=4.7095 forget=6.4818 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 300 total=12.7015 mle=1.5192 pcon=4.7088 forget=6.4736 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 30 it 350 total=12.9079 mle=1.7416 pcon=4.7081 forget=6.4581 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 10 total=12.7815 mle=1.6275 pcon=4.7075 forget=6.4465 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 60 total=12.7271 mle=1.5653 pcon=4.7069 forget=6.4549 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 110 total=12.7847 mle=1.6134 pcon=4.7063 forget=6.4650 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 160 total=12.7449 mle=1.5796 pcon=4.7056 forget=6.4598 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 210 total=12.6958 mle=1.5683 pcon=4.7049 forget=6.4226 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 260 total=12.6880 mle=1.5237 pcon=4.7042 forget=6.4601 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 310 total=12.7778 mle=1.5998 pcon=4.7035 forget=6.4745 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 31 it 360 total=12.7112 mle=1.5574 pcon=4.7028 forget=6.4510 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 20 total=12.8487 mle=1.7029 pcon=4.7021 forget=6.4436 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 70 total=12.7251 mle=1.5777 pcon=4.7014 forget=6.4460 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 120 total=12.8092 mle=1.6112 pcon=4.7007 forget=6.4972 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 170 total=12.7550 mle=1.5729 pcon=4.7002 forget=6.4818 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 220 total=12.8605 mle=1.6910 pcon=4.6997 forget=6.4698 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 270 total=12.7384 mle=1.5711 pcon=4.6993 forget=6.4681 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 320 total=12.6722 mle=1.5269 pcon=4.6986 forget=6.4467 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 32 it 370 total=12.6496 mle=1.4870 pcon=4.6983 forget=6.4642 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 30 total=12.8229 mle=1.6481 pcon=4.6978 forget=6.4770 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 80 total=13.0011 mle=1.8813 pcon=4.6973 forget=6.4225 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 130 total=12.6594 mle=1.5105 pcon=4.6968 forget=6.4522 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 180 total=12.9034 mle=1.7174 pcon=4.6963 forget=6.4897 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 230 total=12.8016 mle=1.6337 pcon=4.6959 forget=6.4720 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 280 total=12.8289 mle=1.6565 pcon=4.6954 forget=6.4770 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 330 total=12.8234 mle=1.6859 pcon=4.6950 forget=6.4426 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 33 it 380 total=12.7953 mle=1.6071 pcon=4.6944 forget=6.4938 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 40 total=12.8597 mle=1.7086 pcon=4.6938 forget=6.4573 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 90 total=12.6754 mle=1.5277 pcon=4.6932 forget=6.4545 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 140 total=12.7445 mle=1.6324 pcon=4.6928 forget=6.4193 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 190 total=12.8337 mle=1.6839 pcon=4.6924 forget=6.4575 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 240 total=12.8608 mle=1.7094 pcon=4.6919 forget=6.4595 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 290 total=12.7804 mle=1.6264 pcon=4.6913 forget=6.4627 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 34 it 340 total=12.8057 mle=1.6048 pcon=4.6908 forget=6.5101 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 0 total=12.8004 mle=1.6334 pcon=4.6903 forget=6.4767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 50 total=12.7875 mle=1.6088 pcon=4.6899 forget=6.4888 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 100 total=12.9838 mle=1.7827 pcon=4.6893 forget=6.5118 nr=64 nf=64 protos=540 dmin_norm=NA
 72%|███████▏  | 36/50 [33:16<12:49, 55.00s/it] 74%|███████▍  | 37/50 [34:11<11:55, 55.04s/it] 76%|███████▌  | 38/50 [35:06<11:00, 55.07s/it] 78%|███████▊  | 39/50 [36:01<10:03, 54.87s/it] 80%|████████  | 40/50 [36:56<09:10, 55.06s/it] 82%|████████▏ | 41/50 [37:51<08:14, 54.96s/it] 84%|████████▍ | 42/50 [38:46<07:20, 55.01s/it] 86%|████████▌ | 43/50 [39:41<06:25, 55.08s/it] 88%|████████▊ | 44/50 [40:36<05:30, 55.05s/it] 90%|█████████ | 45/50 [41:31<04:35, 55.04s/it][loss] ep 35 it 150 total=12.7766 mle=1.6362 pcon=4.6888 forget=6.4515 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 200 total=12.7285 mle=1.5669 pcon=4.6885 forget=6.4732 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 250 total=12.8552 mle=1.7100 pcon=4.6879 forget=6.4572 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 300 total=12.6843 mle=1.5568 pcon=4.6875 forget=6.4400 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 35 it 350 total=12.8477 mle=1.7115 pcon=4.6871 forget=6.4490 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 10 total=12.8928 mle=1.7376 pcon=4.6867 forget=6.4684 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 60 total=12.7245 mle=1.5717 pcon=4.6865 forget=6.4664 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 110 total=12.7256 mle=1.5759 pcon=4.6861 forget=6.4637 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 160 total=12.8184 mle=1.6523 pcon=4.6857 forget=6.4805 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 210 total=12.6892 mle=1.5314 pcon=4.6854 forget=6.4724 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 260 total=12.7870 mle=1.6028 pcon=4.6852 forget=6.4990 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 310 total=12.8658 mle=1.6828 pcon=4.6847 forget=6.4982 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 36 it 360 total=12.8105 mle=1.6435 pcon=4.6843 forget=6.4826 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 20 total=12.7020 mle=1.5218 pcon=4.6838 forget=6.4964 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 70 total=12.9335 mle=1.7395 pcon=4.6836 forget=6.5104 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 120 total=12.7920 mle=1.6152 pcon=4.6832 forget=6.4936 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 170 total=12.6935 mle=1.5551 pcon=4.6828 forget=6.4556 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 220 total=12.8946 mle=1.7246 pcon=4.6823 forget=6.4877 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 270 total=12.7719 mle=1.6199 pcon=4.6819 forget=6.4702 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 320 total=12.7913 mle=1.6234 pcon=4.6815 forget=6.4864 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 37 it 370 total=12.8830 mle=1.6527 pcon=4.6813 forget=6.5490 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 30 total=12.8721 mle=1.6772 pcon=4.6811 forget=6.5138 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 80 total=12.6764 mle=1.4937 pcon=4.6810 forget=6.5017 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 130 total=12.8193 mle=1.6449 pcon=4.6806 forget=6.4937 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 180 total=12.7597 mle=1.6038 pcon=4.6803 forget=6.4755 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 230 total=12.7353 mle=1.5502 pcon=4.6801 forget=6.5051 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 280 total=12.8591 mle=1.7145 pcon=4.6798 forget=6.4648 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 330 total=12.7741 mle=1.6095 pcon=4.6794 forget=6.4852 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 38 it 380 total=12.6754 mle=1.5080 pcon=4.6793 forget=6.4880 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 40 total=12.8912 mle=1.7304 pcon=4.6792 forget=6.4816 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 90 total=12.8560 mle=1.6468 pcon=4.6790 forget=6.5302 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 140 total=12.7869 mle=1.6335 pcon=4.6788 forget=6.4746 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 190 total=12.6687 mle=1.5000 pcon=4.6785 forget=6.4902 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 240 total=12.8459 mle=1.6535 pcon=4.6783 forget=6.5141 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 290 total=12.6846 mle=1.5114 pcon=4.6782 forget=6.4951 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 39 it 340 total=12.7888 mle=1.5935 pcon=4.6780 forget=6.5172 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 0 total=12.7462 mle=1.5573 pcon=4.6777 forget=6.5113 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 50 total=12.8180 mle=1.6172 pcon=4.6774 forget=6.5234 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 100 total=12.8133 mle=1.6401 pcon=4.6770 forget=6.4961 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 150 total=12.7006 mle=1.5273 pcon=4.6769 forget=6.4965 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 200 total=12.9681 mle=1.7796 pcon=4.6766 forget=6.5119 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 250 total=13.0192 mle=1.7984 pcon=4.6763 forget=6.5444 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 300 total=12.7212 mle=1.5609 pcon=4.6762 forget=6.4841 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 40 it 350 total=12.6431 mle=1.4700 pcon=4.6761 forget=6.4970 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 10 total=12.6991 mle=1.5287 pcon=4.6759 forget=6.4945 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 60 total=13.0567 mle=1.8395 pcon=4.6759 forget=6.5413 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 110 total=12.8255 mle=1.6154 pcon=4.6756 forget=6.5344 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 160 total=12.8031 mle=1.6057 pcon=4.6756 forget=6.5219 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 210 total=12.8615 mle=1.6649 pcon=4.6754 forget=6.5213 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 260 total=12.7103 mle=1.5381 pcon=4.6755 forget=6.4966 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 310 total=12.7244 mle=1.5341 pcon=4.6755 forget=6.5148 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 41 it 360 total=12.8922 mle=1.6860 pcon=4.6755 forget=6.5307 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 20 total=12.8704 mle=1.6757 pcon=4.6754 forget=6.5193 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 70 total=12.8441 mle=1.6360 pcon=4.6751 forget=6.5330 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 120 total=13.0944 mle=1.8591 pcon=4.6749 forget=6.5604 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 170 total=12.7624 mle=1.5977 pcon=4.6748 forget=6.4899 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 220 total=12.8050 mle=1.6281 pcon=4.6748 forget=6.5021 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 270 total=12.8922 mle=1.7006 pcon=4.6747 forget=6.5169 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 320 total=12.9052 mle=1.6982 pcon=4.6747 forget=6.5323 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 42 it 370 total=12.8017 mle=1.5980 pcon=4.6746 forget=6.5291 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 30 total=12.8508 mle=1.6056 pcon=4.6745 forget=6.5707 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 80 total=12.8339 mle=1.6129 pcon=4.6744 forget=6.5466 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 130 total=12.8853 mle=1.6653 pcon=4.6743 forget=6.5456 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 180 total=12.8150 mle=1.5397 pcon=4.6742 forget=6.6011 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 230 total=12.7531 mle=1.5726 pcon=4.6740 forget=6.5064 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 280 total=12.7580 mle=1.5541 pcon=4.6740 forget=6.5299 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 330 total=12.7988 mle=1.5487 pcon=4.6737 forget=6.5763 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 43 it 380 total=12.6913 mle=1.5217 pcon=4.6736 forget=6.4960 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 40 total=12.9209 mle=1.7149 pcon=4.6735 forget=6.5325 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 90 total=12.8133 mle=1.5948 pcon=4.6733 forget=6.5452 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 140 total=12.8984 mle=1.6503 pcon=4.6733 forget=6.5749 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 190 total=12.7682 mle=1.5440 pcon=4.6732 forget=6.5509 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 240 total=12.7966 mle=1.5550 pcon=4.6732 forget=6.5685 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 290 total=13.0412 mle=1.8062 pcon=4.6731 forget=6.5619 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 44 it 340 total=13.0249 mle=1.7751 pcon=4.6731 forget=6.5767 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 0 total=12.8486 mle=1.5802 pcon=4.6729 forget=6.5955 nr=64 nf=64 protos=540 dmin_norm=NA
 92%|█████████▏| 46/50 [42:27<03:41, 55.26s/it] 94%|█████████▍| 47/50 [43:21<02:44, 54.91s/it] 96%|█████████▌| 48/50 [44:16<01:50, 55.02s/it] 98%|█████████▊| 49/50 [45:11<00:54, 54.93s/it]100%|██████████| 50/50 [46:05<00:00, 54.74s/it]100%|██████████| 50/50 [46:05<00:00, 55.32s/it]
[loss] ep 45 it 50 total=12.7985 mle=1.5795 pcon=4.6729 forget=6.5461 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 100 total=12.8127 mle=1.5761 pcon=4.6727 forget=6.5638 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 150 total=12.7936 mle=1.5595 pcon=4.6726 forget=6.5615 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 200 total=12.8109 mle=1.5901 pcon=4.6726 forget=6.5482 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 250 total=12.8455 mle=1.5819 pcon=4.6725 forget=6.5911 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 300 total=12.8629 mle=1.6617 pcon=4.6722 forget=6.5290 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 45 it 350 total=12.7411 mle=1.5402 pcon=4.6722 forget=6.5287 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 10 total=12.7582 mle=1.5302 pcon=4.6722 forget=6.5559 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 60 total=12.8370 mle=1.5455 pcon=4.6720 forget=6.6194 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 110 total=12.9483 mle=1.6925 pcon=4.6719 forget=6.5838 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 160 total=12.7057 mle=1.5061 pcon=4.6718 forget=6.5277 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 210 total=12.9557 mle=1.7514 pcon=4.6717 forget=6.5326 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 260 total=12.8977 mle=1.6930 pcon=4.6715 forget=6.5331 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 310 total=12.8070 mle=1.5515 pcon=4.6715 forget=6.5840 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 46 it 360 total=12.9806 mle=1.7208 pcon=4.6714 forget=6.5884 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 20 total=12.8208 mle=1.5800 pcon=4.6712 forget=6.5696 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 70 total=12.7586 mle=1.5537 pcon=4.6711 forget=6.5338 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 120 total=12.8896 mle=1.6504 pcon=4.6709 forget=6.5683 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 170 total=12.8314 mle=1.5478 pcon=4.6707 forget=6.6129 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 220 total=12.6695 mle=1.4761 pcon=4.6707 forget=6.5228 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 270 total=12.9269 mle=1.6271 pcon=4.6706 forget=6.6292 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 320 total=12.8904 mle=1.5854 pcon=4.6705 forget=6.6344 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 47 it 370 total=12.9004 mle=1.6427 pcon=4.6705 forget=6.5873 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 30 total=12.9054 mle=1.5905 pcon=4.6705 forget=6.6444 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 80 total=12.8759 mle=1.6067 pcon=4.6704 forget=6.5989 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 130 total=12.8819 mle=1.6748 pcon=4.6704 forget=6.5367 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 180 total=13.0019 mle=1.6557 pcon=4.6704 forget=6.6758 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 230 total=12.8935 mle=1.6462 pcon=4.6704 forget=6.5769 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 280 total=12.7664 mle=1.5871 pcon=4.6703 forget=6.5091 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 330 total=12.7810 mle=1.5844 pcon=4.6702 forget=6.5264 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 48 it 380 total=12.8769 mle=1.5773 pcon=4.6701 forget=6.6295 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 40 total=12.9095 mle=1.5752 pcon=4.6700 forget=6.6643 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 90 total=12.9179 mle=1.6223 pcon=4.6700 forget=6.6256 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 140 total=12.9186 mle=1.6294 pcon=4.6699 forget=6.6193 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 190 total=13.0428 mle=1.7657 pcon=4.6697 forget=6.6074 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 240 total=12.8749 mle=1.6771 pcon=4.6695 forget=6.5282 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 290 total=12.8942 mle=1.6206 pcon=4.6694 forget=6.6042 nr=64 nf=64 protos=540 dmin_norm=NA
[loss] ep 49 it 340 total=12.8107 mle=1.5439 pcon=4.6695 forget=6.5974 nr=64 nf=64 protos=540 dmin_norm=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:01,  3.21it/s]  1%|▏         | 5/391 [00:00<00:27, 14.00it/s]  2%|▏         | 9/391 [00:00<00:18, 20.33it/s]  3%|▎         | 13/391 [00:00<00:15, 24.57it/s]  4%|▍         | 16/391 [00:00<00:14, 25.14it/s]  5%|▍         | 19/391 [00:00<00:15, 24.39it/s]  6%|▌         | 22/391 [00:01<00:15, 24.23it/s]  6%|▋         | 25/391 [00:01<00:14, 24.91it/s]  7%|▋         | 28/391 [00:01<00:14, 24.71it/s]  8%|▊         | 32/391 [00:01<00:13, 27.24it/s]  9%|▉         | 36/391 [00:01<00:12, 29.20it/s] 10%|█         | 40/391 [00:01<00:11, 29.71it/s] 11%|█▏        | 44/391 [00:01<00:10, 32.16it/s] 12%|█▏        | 48/391 [00:01<00:10, 31.38it/s] 13%|█▎        | 52/391 [00:01<00:10, 32.66it/s] 14%|█▍        | 56/391 [00:02<00:10, 32.59it/s] 16%|█▌        | 61/391 [00:02<00:09, 35.90it/s] 17%|█▋        | 66/391 [00:02<00:08, 39.35it/s] 18%|█▊        | 72/391 [00:02<00:07, 42.79it/s] 20%|█▉        | 77/391 [00:02<00:07, 43.64it/s] 21%|██        | 83/391 [00:02<00:06, 46.17it/s] 23%|██▎       | 88/391 [00:02<00:07, 42.47it/s] 24%|██▍       | 93/391 [00:03<00:08, 36.22it/s] 25%|██▍       | 97/391 [00:03<00:08, 32.87it/s] 26%|██▌       | 101/391 [00:03<00:09, 31.23it/s] 27%|██▋       | 105/391 [00:03<00:08, 32.80it/s] 28%|██▊       | 109/391 [00:03<00:08, 32.07it/s] 29%|██▉       | 113/391 [00:03<00:08, 31.94it/s] 30%|██▉       | 117/391 [00:03<00:08, 33.33it/s] 31%|███       | 121/391 [00:03<00:08, 32.93it/s] 32%|███▏      | 125/391 [00:04<00:07, 33.38it/s] 33%|███▎      | 129/391 [00:04<00:07, 32.76it/s] 34%|███▍      | 133/391 [00:04<00:07, 33.09it/s] 35%|███▌      | 137/391 [00:04<00:07, 33.31it/s] 36%|███▌      | 141/391 [00:04<00:07, 33.15it/s] 37%|███▋      | 145/391 [00:04<00:07, 33.11it/s] 38%|███▊      | 149/391 [00:04<00:07, 32.91it/s] 39%|███▉      | 153/391 [00:04<00:07, 33.22it/s] 40%|████      | 157/391 [00:04<00:06, 34.22it/s] 41%|████      | 161/391 [00:05<00:06, 32.89it/s] 42%|████▏     | 165/391 [00:05<00:07, 29.69it/s] 43%|████▎     | 169/391 [00:05<00:07, 28.42it/s] 44%|████▍     | 172/391 [00:05<00:07, 27.41it/s] 45%|████▍     | 175/391 [00:05<00:08, 26.87it/s] 46%|████▌     | 178/391 [00:05<00:07, 27.34it/s] 47%|████▋     | 182/391 [00:05<00:07, 28.41it/s] 48%|████▊     | 186/391 [00:06<00:06, 30.85it/s] 49%|████▊     | 190/391 [00:06<00:06, 30.98it/s] 50%|████▉     | 194/391 [00:06<00:06, 31.99it/s] 51%|█████     | 198/391 [00:06<00:05, 32.57it/s] 52%|█████▏    | 202/391 [00:06<00:05, 31.96it/s] 53%|█████▎    | 206/391 [00:06<00:05, 33.40it/s] 54%|█████▎    | 210/391 [00:06<00:05, 34.03it/s] 55%|█████▍    | 214/391 [00:06<00:05, 33.43it/s] 56%|█████▌    | 218/391 [00:06<00:05, 33.58it/s] 57%|█████▋    | 222/391 [00:07<00:05, 33.18it/s] 58%|█████▊    | 226/391 [00:07<00:05, 32.78it/s] 59%|█████▉    | 230/391 [00:07<00:04, 33.86it/s] 60%|█████▉    | 234/391 [00:07<00:04, 33.18it/s] 61%|██████    | 238/391 [00:07<00:04, 31.47it/s] 62%|██████▏   | 242/391 [00:07<00:05, 28.70it/s] 63%|██████▎   | 245/391 [00:07<00:05, 27.94it/s] 63%|██████▎   | 248/391 [00:07<00:05, 27.54it/s] 64%|██████▍   | 251/391 [00:08<00:05, 26.11it/s] 65%|██████▌   | 255/391 [00:08<00:04, 27.76it/s] 66%|██████▌   | 259/391 [00:08<00:04, 30.14it/s] 67%|██████▋   | 263/391 [00:08<00:04, 30.91it/s] 68%|██████▊   | 267/391 [00:08<00:03, 31.21it/s] 69%|██████▉   | 271/391 [00:08<00:03, 31.71it/s] 70%|███████   | 275/391 [00:08<00:03, 32.98it/s] 71%|███████▏  | 279/391 [00:08<00:03, 33.47it/s] 72%|███████▏  | 283/391 [00:09<00:03, 32.94it/s] 73%|███████▎  | 287/391 [00:09<00:03, 32.51it/s] 74%|███████▍  | 291/391 [00:09<00:02, 33.56it/s] 75%|███████▌  | 295/391 [00:09<00:02, 33.46it/s] 76%|███████▋  | 299/391 [00:09<00:02, 34.45it/s] 77%|███████▋  | 303/391 [00:09<00:02, 33.08it/s] 79%|███████▊  | 307/391 [00:09<00:02, 32.59it/s] 80%|███████▉  | 311/391 [00:09<00:02, 34.35it/s] 81%|████████  | 315/391 [00:10<00:02, 30.78it/s] 82%|████████▏ | 319/391 [00:10<00:02, 28.90it/s] 82%|████████▏ | 322/391 [00:10<00:02, 27.67it/s] 83%|████████▎ | 325/391 [00:10<00:02, 26.29it/s] 84%|████████▍ | 328/391 [00:10<00:02, 26.89it/s] 85%|████████▍ | 332/391 [00:10<00:02, 29.13it/s] 86%|████████▌ | 336/391 [00:10<00:01, 30.32it/s] 87%|████████▋ | 340/391 [00:10<00:01, 31.35it/s] 88%|████████▊ | 344/391 [00:11<00:01, 31.58it/s] 89%|████████▉ | 348/391 [00:11<00:01, 32.13it/s] 90%|█████████ | 352/391 [00:11<00:01, 33.48it/s] 91%|█████████ | 356/391 [00:11<00:01, 32.70it/s] 92%|█████████▏| 360/391 [00:11<00:00, 33.08it/s] 93%|█████████▎| 364/391 [00:11<00:00, 33.04it/s] 94%|█████████▍| 368/391 [00:11<00:00, 33.40it/s] 95%|█████████▌| 372/391 [00:11<00:00, 33.52it/s] 96%|█████████▌| 376/391 [00:12<00:00, 32.51it/s] 97%|█████████▋| 380/391 [00:12<00:00, 34.15it/s] 98%|█████████▊| 384/391 [00:12<00:00, 33.58it/s] 99%|█████████▉| 388/391 [00:12<00:00, 33.83it/s]100%|██████████| 391/391 [00:12<00:00, 31.36it/s]
50000 images processed, 12.551933765411377 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:25,  3.07it/s]  6%|▋         | 5/79 [00:00<00:05, 13.26it/s] 11%|█▏        | 9/79 [00:00<00:03, 19.88it/s] 16%|█▋        | 13/79 [00:00<00:02, 24.07it/s] 22%|██▏       | 17/79 [00:00<00:02, 27.07it/s] 27%|██▋       | 21/79 [00:00<00:01, 29.04it/s] 32%|███▏      | 25/79 [00:01<00:01, 29.88it/s] 37%|███▋      | 29/79 [00:01<00:01, 31.21it/s] 42%|████▏     | 33/79 [00:01<00:01, 31.63it/s] 47%|████▋     | 37/79 [00:01<00:01, 33.04it/s] 52%|█████▏    | 41/79 [00:01<00:01, 32.64it/s] 57%|█████▋    | 45/79 [00:01<00:01, 32.31it/s] 62%|██████▏   | 49/79 [00:01<00:00, 32.56it/s] 67%|██████▋   | 53/79 [00:01<00:00, 32.86it/s] 72%|███████▏  | 57/79 [00:02<00:00, 33.19it/s] 77%|███████▋  | 61/79 [00:02<00:00, 29.66it/s] 82%|████████▏ | 65/79 [00:02<00:00, 28.03it/s] 86%|████████▌ | 68/79 [00:02<00:00, 27.53it/s] 90%|████████▉ | 71/79 [00:02<00:00, 26.87it/s] 94%|█████████▎| 74/79 [00:02<00:00, 26.64it/s] 99%|█████████▊| 78/79 [00:02<00:00, 28.71it/s]100%|██████████| 79/79 [00:02<00:00, 27.90it/s]
10000 images processed, 2.853174924850464 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<00:59,  3.43it/s]  2%|▏         | 4/204 [00:00<00:16, 11.90it/s]  4%|▍         | 8/204 [00:00<00:10, 19.20it/s]  5%|▌         | 11/204 [00:00<00:09, 21.38it/s]  7%|▋         | 14/204 [00:00<00:08, 21.56it/s]  8%|▊         | 17/204 [00:00<00:08, 21.39it/s] 10%|▉         | 20/204 [00:01<00:08, 22.10it/s] 11%|█▏        | 23/204 [00:01<00:08, 22.03it/s] 13%|█▎        | 26/204 [00:01<00:07, 23.04it/s] 15%|█▍        | 30/204 [00:01<00:06, 25.42it/s] 17%|█▋        | 34/204 [00:01<00:06, 26.96it/s] 18%|█▊        | 37/204 [00:01<00:06, 27.51it/s] 20%|██        | 41/204 [00:01<00:05, 28.10it/s] 22%|██▏       | 44/204 [00:01<00:05, 28.40it/s] 24%|██▍       | 49/204 [00:02<00:04, 32.00it/s] 26%|██▌       | 53/204 [00:02<00:04, 30.86it/s] 28%|██▊       | 57/204 [00:02<00:04, 30.60it/s] 30%|██▉       | 61/204 [00:02<00:04, 29.59it/s] 32%|███▏      | 65/204 [00:02<00:04, 29.97it/s] 34%|███▍      | 69/204 [00:02<00:04, 30.56it/s] 36%|███▌      | 73/204 [00:02<00:04, 29.62it/s] 37%|███▋      | 76/204 [00:02<00:04, 28.72it/s] 39%|███▊      | 79/204 [00:03<00:04, 25.89it/s] 40%|████      | 82/204 [00:03<00:04, 24.70it/s] 42%|████▏     | 85/204 [00:03<00:04, 24.07it/s] 43%|████▎     | 88/204 [00:03<00:04, 23.35it/s] 45%|████▌     | 92/204 [00:03<00:04, 26.55it/s] 47%|████▋     | 95/204 [00:03<00:04, 26.56it/s] 49%|████▊     | 99/204 [00:03<00:03, 27.56it/s] 50%|█████     | 103/204 [00:04<00:03, 28.13it/s] 52%|█████▏    | 107/204 [00:04<00:03, 28.94it/s] 54%|█████▍    | 111/204 [00:04<00:03, 29.54it/s] 56%|█████▌    | 114/204 [00:04<00:03, 29.36it/s] 57%|█████▋    | 117/204 [00:04<00:02, 29.31it/s] 59%|█████▉    | 120/204 [00:04<00:02, 28.85it/s] 61%|██████    | 124/204 [00:04<00:02, 29.17it/s] 63%|██████▎   | 128/204 [00:04<00:02, 30.11it/s] 65%|██████▍   | 132/204 [00:04<00:02, 29.26it/s] 67%|██████▋   | 136/204 [00:05<00:02, 30.21it/s] 69%|██████▊   | 140/204 [00:05<00:02, 27.95it/s] 70%|███████   | 143/204 [00:05<00:02, 26.67it/s] 72%|███████▏  | 146/204 [00:05<00:02, 24.47it/s] 73%|███████▎  | 149/204 [00:05<00:02, 23.47it/s] 75%|███████▍  | 152/204 [00:05<00:02, 24.17it/s] 76%|███████▌  | 155/204 [00:05<00:01, 25.01it/s] 77%|███████▋  | 158/204 [00:06<00:01, 26.20it/s] 79%|███████▉  | 162/204 [00:06<00:01, 27.22it/s] 81%|████████  | 165/204 [00:06<00:01, 27.77it/s] 83%|████████▎ | 169/204 [00:06<00:01, 28.85it/s] 84%|████████▍ | 172/204 [00:06<00:01, 29.13it/s] 86%|████████▌ | 175/204 [00:06<00:01, 28.80it/s] 88%|████████▊ | 179/204 [00:06<00:00, 28.99it/s] 89%|████████▉ | 182/204 [00:06<00:00, 29.26it/s] 91%|█████████ | 186/204 [00:06<00:00, 30.69it/s] 93%|█████████▎| 190/204 [00:07<00:00, 29.24it/s] 95%|█████████▍| 193/204 [00:07<00:00, 28.90it/s] 97%|█████████▋| 197/204 [00:07<00:00, 29.49it/s] 98%|█████████▊| 200/204 [00:07<00:00, 29.60it/s]100%|█████████▉| 203/204 [00:07<00:00, 27.01it/s]100%|██████████| 204/204 [00:07<00:00, 26.80it/s]
26032 images processed, 7.679060697555542 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.39it/s]  6%|▋         | 5/79 [00:00<00:06, 11.41it/s] 10%|█         | 8/79 [00:00<00:04, 15.90it/s] 15%|█▌        | 12/79 [00:00<00:03, 20.83it/s] 19%|█▉        | 15/79 [00:00<00:03, 20.73it/s] 23%|██▎       | 18/79 [00:01<00:02, 20.71it/s] 27%|██▋       | 21/79 [00:01<00:02, 21.77it/s] 30%|███       | 24/79 [00:01<00:02, 21.68it/s] 34%|███▍      | 27/79 [00:01<00:02, 22.49it/s] 39%|███▉      | 31/79 [00:01<00:01, 24.61it/s] 44%|████▍     | 35/79 [00:01<00:01, 26.97it/s] 49%|████▉     | 39/79 [00:01<00:01, 27.92it/s] 53%|█████▎    | 42/79 [00:01<00:01, 28.41it/s] 57%|█████▋    | 45/79 [00:02<00:01, 28.60it/s] 61%|██████    | 48/79 [00:02<00:01, 28.36it/s] 66%|██████▌   | 52/79 [00:02<00:00, 29.15it/s] 71%|███████   | 56/79 [00:02<00:00, 29.93it/s] 75%|███████▍  | 59/79 [00:02<00:00, 29.39it/s] 78%|███████▊  | 62/79 [00:02<00:00, 29.33it/s] 84%|████████▎ | 66/79 [00:02<00:00, 29.55it/s] 87%|████████▋ | 69/79 [00:02<00:00, 29.50it/s] 92%|█████████▏| 73/79 [00:02<00:00, 29.74it/s] 96%|█████████▌| 76/79 [00:03<00:00, 28.30it/s]100%|██████████| 79/79 [00:03<00:00, 27.81it/s]100%|██████████| 79/79 [00:03<00:00, 24.56it/s]
10000 images processed, 3.2539849281311035 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:22,  3.40it/s]  6%|▋         | 5/79 [00:00<00:05, 14.44it/s] 10%|█         | 8/79 [00:00<00:03, 19.04it/s] 14%|█▍        | 11/79 [00:00<00:03, 21.87it/s] 19%|█▉        | 15/79 [00:00<00:02, 24.60it/s] 23%|██▎       | 18/79 [00:00<00:02, 25.88it/s] 27%|██▋       | 21/79 [00:00<00:02, 26.89it/s] 30%|███       | 24/79 [00:01<00:01, 27.64it/s] 34%|███▍      | 27/79 [00:01<00:01, 27.77it/s] 39%|███▉      | 31/79 [00:01<00:01, 28.96it/s] 43%|████▎     | 34/79 [00:01<00:01, 28.42it/s] 48%|████▊     | 38/79 [00:01<00:01, 29.74it/s] 52%|█████▏    | 41/79 [00:01<00:01, 29.14it/s] 56%|█████▌    | 44/79 [00:01<00:01, 28.83it/s] 61%|██████    | 48/79 [00:01<00:01, 29.37it/s] 65%|██████▍   | 51/79 [00:02<00:01, 26.18it/s] 68%|██████▊   | 54/79 [00:02<00:01, 24.73it/s] 72%|███████▏  | 57/79 [00:02<00:00, 24.07it/s] 76%|███████▌  | 60/79 [00:02<00:00, 22.78it/s] 81%|████████  | 64/79 [00:02<00:00, 25.85it/s] 85%|████████▍ | 67/79 [00:02<00:00, 26.66it/s] 89%|████████▊ | 70/79 [00:02<00:00, 27.00it/s] 94%|█████████▎| 74/79 [00:02<00:00, 27.76it/s] 99%|█████████▊| 78/79 [00:03<00:00, 29.94it/s]100%|██████████| 79/79 [00:03<00:00, 26.00it/s]
10000 images processed, 3.0598576068878174 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:26,  2.63it/s]  6%|▌         | 4/70 [00:00<00:06,  9.78it/s] 10%|█         | 7/70 [00:00<00:04, 15.18it/s] 16%|█▌        | 11/70 [00:00<00:02, 20.53it/s] 20%|██        | 14/70 [00:00<00:02, 21.26it/s] 24%|██▍       | 17/70 [00:00<00:02, 21.46it/s] 29%|██▊       | 20/70 [00:01<00:02, 21.02it/s] 33%|███▎      | 23/70 [00:01<00:02, 21.24it/s] 37%|███▋      | 26/70 [00:01<00:01, 22.78it/s] 46%|████▌     | 32/70 [00:01<00:01, 31.81it/s] 59%|█████▊    | 41/70 [00:01<00:00, 46.75it/s] 71%|███████▏  | 50/70 [00:01<00:00, 57.82it/s] 83%|████████▎ | 58/70 [00:01<00:00, 60.18it/s] 93%|█████████▎| 65/70 [00:01<00:00, 53.77it/s]100%|██████████| 70/70 [00:02<00:00, 33.42it/s]
8925 images processed, 2.1242873668670654 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:34,  1.28it/s]  4%|▍         | 2/45 [00:00<00:17,  2.51it/s] 13%|█▎        | 6/45 [00:01<00:04,  8.82it/s] 20%|██        | 9/45 [00:01<00:03, 11.08it/s] 24%|██▍       | 11/45 [00:01<00:03, 10.32it/s] 31%|███       | 14/45 [00:01<00:02, 13.87it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.73it/s] 42%|████▏     | 19/45 [00:01<00:02, 11.63it/s] 49%|████▉     | 22/45 [00:02<00:01, 14.20it/s] 58%|█████▊    | 26/45 [00:02<00:01, 13.40it/s] 64%|██████▍   | 29/45 [00:02<00:01, 15.94it/s] 73%|███████▎  | 33/45 [00:02<00:00, 14.17it/s] 78%|███████▊  | 35/45 [00:03<00:00, 13.37it/s] 84%|████████▍ | 38/45 [00:03<00:00, 15.79it/s] 91%|█████████ | 41/45 [00:03<00:00, 15.50it/s] 96%|█████████▌| 43/45 [00:03<00:00, 11.20it/s]100%|██████████| 45/45 [00:03<00:00, 11.85it/s]
5640 images processed, 3.8227925300598145 seconds used

36.90956211090088
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
Evaluating forget
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           6.03  98.68
places365     78.67  78.10
LSUN          30.71  94.47
iSUN          80.13  79.28
dtd           47.39  89.17
forget        43.20  91.49
AVG           47.69  88.53
Forget-Acc: 0.7890 | Retain-Acc: 0.7374
Forget-as-OOD (retain known vs forget novel):
  FPR: 43.20 AUROC: 91.49 AUIN: 98.89
9.512479066848755
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl1-lora_r8a32d0.05_rf.png
