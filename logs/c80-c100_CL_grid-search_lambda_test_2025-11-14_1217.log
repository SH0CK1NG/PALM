nohup: ignoring input
[Grid Search Continual] Searching over: lambda_pcon(0.1) × lrs(0.001) × epochs(1) × lora_r(8)
[Grid Search Continual] Stages: 0,8,11,40,51 66,67,88,94,57 59,58,44,93,10 64,22,42,9,90

==========================================
[Run] lambda_pcon=0.1 lr=0.001 epochs=1 lora_r=8
==========================================
==== Stage 1: inc={0,8,11,40,51}; seen={}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', adapter_load_path=None, lora_stack=False, lora_orth_enable=False, lora_orth_lambda=0.1, lora_orth_ref_paths=None, forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='0,8,11,40,51', forget_classes_seen=None, retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
100%|██████████| 1/1 [00:17<00:00, 17.67s/it]100%|██████████| 1/1 [00:17<00:00, 17.67s/it]
[loss] ep 0 it 0 total=4.6430 mle=4.0804 pcon=0.5626 forget=0.0000 orth=0.0000 favg=0.0000 nr=122 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=5.0013 mle=4.4385 pcon=0.5628 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=5.0626 mle=4.4997 pcon=0.5629 forget=0.0000 orth=0.0000 favg=0.0000 nr=123 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=5.6153 mle=5.0522 pcon=0.5631 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=4.3043 mle=3.7410 pcon=0.5634 forget=0.0000 orth=0.0000 favg=0.0000 nr=118 nf=10 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=4.8996 mle=4.3361 pcon=0.5635 forget=0.0000 orth=0.0000 favg=0.0000 nr=124 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=4.5205 mle=3.9568 pcon=0.5637 forget=0.0000 orth=0.0000 favg=0.0000 nr=120 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=4.9444 mle=4.3806 pcon=0.5638 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=4.8929 mle=4.3289 pcon=0.5640 forget=0.0000 orth=0.0000 favg=0.0000 nr=117 nf=11 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
==== Stage 2: inc={66,67,88,94,57}; seen={0,8,11,40,51}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='66,67,88,94,57', forget_classes_seen='0,8,11,40,51', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:21<00:00, 21.13s/it]100%|██████████| 1/1 [00:21<00:00, 21.13s/it]
[loss] ep 0 it 0 total=5.9808 mle=4.0774 pcon=0.8978 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3370 mle=4.4333 pcon=0.8980 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4000 mle=4.4961 pcon=0.8983 forget=0.0000 orth=1.0056 favg=0.0000 nr=114 nf=9 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=6.9514 mle=5.0474 pcon=0.8984 forget=0.0000 orth=1.0056 favg=0.0000 nr=118 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.6407 mle=3.7366 pcon=0.8985 forget=0.0000 orth=1.0056 favg=0.0000 nr=117 nf=1 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2341 mle=4.3299 pcon=0.8987 forget=0.0000 orth=1.0055 favg=0.0000 nr=116 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.8548 mle=3.9505 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=114 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.2799 mle=4.3756 pcon=0.8988 forget=0.0000 orth=1.0055 favg=0.0000 nr=110 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2261 mle=4.3218 pcon=0.8989 forget=0.0000 orth=1.0054 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
==== Stage 3: inc={59,58,44,93,10}; seen={0,8,11,40,51,66,67,88,94,57}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='59,58,44,93,10', forget_classes_seen='0,8,11,40,51,66,67,88,94,57', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:21<00:00, 21.38s/it]100%|██████████| 1/1 [00:21<00:00, 21.38s/it]
[loss] ep 0 it 0 total=6.0451 mle=4.0710 pcon=0.9689 forget=0.0000 orth=1.0052 favg=0.0000 nr=112 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.3983 mle=4.4240 pcon=0.9691 forget=0.0000 orth=1.0052 favg=0.0000 nr=111 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4636 mle=4.4891 pcon=0.9694 forget=0.0000 orth=1.0052 favg=0.0000 nr=109 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0129 mle=5.0382 pcon=0.9696 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=11 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7032 mle=3.7283 pcon=0.9698 forget=0.0000 orth=1.0051 favg=0.0000 nr=109 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.2929 mle=4.3179 pcon=0.9699 forget=0.0000 orth=1.0051 favg=0.0000 nr=111 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9132 mle=3.9381 pcon=0.9701 forget=0.0000 orth=1.0051 favg=0.0000 nr=107 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3397 mle=4.3645 pcon=0.9701 forget=0.0000 orth=1.0050 favg=0.0000 nr=105 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2798 mle=4.3046 pcon=0.9702 forget=0.0000 orth=1.0049 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
==== Stage 4: inc={64,22,42,9,90}; seen={0,8,11,40,51,66,67,88,94,57,59,58,44,93,10}; all(union)={0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94} ====
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-110', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=1, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=0.1, epsilon=0.05, palm_enable=True, palm_mle_mode='all', palm_retain_only=False, pcon_inc='split', incremental=True, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4', adapter_load_path='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', lora_stack=False, lora_orth_enable=True, lora_orth_lambda=1.0, lora_orth_ref_paths='checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage1,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage2,checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3', forget_classes='0,8,9,10,11,22,40,42,44,51,57,58,59,64,66,67,88,90,93,94', forget_list_path=None, forget_classes_inc='64,22,42,9,90', forget_classes_seen='0,8,11,40,51,66,67,88,94,57,59,58,44,93,10', retain_exclude_csv=None, forget_csv=None, forget_lambda=0.0, forget_margin=100.0, forget_strategy='proto', centers_path=None, precision_path=None, batch_forget_mode='none', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=False, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
[peft] adapter loaded from checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage3
[peft] active adapters set to: default
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
[trainable] param_count=238592 tensors=16
[incremental] resumed from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-upper-retain-c80.pt
  0%|          | 0/1 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/home/shaokun/PALM/trainer.py:271: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
100%|██████████| 1/1 [00:20<00:00, 20.51s/it]100%|██████████| 1/1 [00:20<00:00, 20.51s/it]
[loss] ep 0 it 0 total=6.0701 mle=4.0564 pcon=1.0090 forget=0.0000 orth=1.0048 favg=0.0000 nr=105 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 50 total=6.4172 mle=4.4032 pcon=1.0092 forget=0.0000 orth=1.0047 favg=0.0000 nr=103 nf=8 protos=None fproto_sim=NA
[loss] ep 0 it 100 total=6.4853 mle=4.4711 pcon=1.0094 forget=0.0000 orth=1.0047 favg=0.0000 nr=105 nf=4 protos=None fproto_sim=NA
[loss] ep 0 it 150 total=7.0302 mle=5.0158 pcon=1.0096 forget=0.0000 orth=1.0047 favg=0.0000 nr=100 nf=7 protos=None fproto_sim=NA
[loss] ep 0 it 200 total=5.7242 mle=3.7098 pcon=1.0098 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=3 protos=None fproto_sim=NA
[loss] ep 0 it 250 total=6.3044 mle=4.2898 pcon=1.0099 forget=0.0000 orth=1.0047 favg=0.0000 nr=106 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 300 total=5.9253 mle=3.9106 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=102 nf=5 protos=None fproto_sim=NA
[loss] ep 0 it 350 total=6.3521 mle=4.3374 pcon=1.0101 forget=0.0000 orth=1.0046 favg=0.0000 nr=99 nf=6 protos=None fproto_sim=NA
[loss] ep 0 it 400 total=6.2749 mle=4.2602 pcon=1.0102 forget=0.0000 orth=1.0045 favg=0.0000 nr=97 nf=9 protos=None fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-b128-e1-lr0.001-wd1e-4-ltboth-bfmnone-pcon0.1-lora_r8a32d0.05-temp0.08-ol1-continual-from-c80-to-CIFAR-110-palm_mle_all-pcon_split-stack/stage4
[DEBUG] Eval output (last 30 lines):
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:44,  1.77it/s] 10%|█         | 8/79 [00:00<00:04, 15.27it/s] 19%|█▉        | 15/79 [00:00<00:02, 26.98it/s] 29%|██▉       | 23/79 [00:00<00:01, 38.81it/s] 38%|███▊      | 30/79 [00:00<00:01, 45.70it/s] 47%|████▋     | 37/79 [00:01<00:00, 51.15it/s] 56%|█████▌    | 44/79 [00:01<00:00, 55.06it/s] 65%|██████▍   | 51/79 [00:01<00:00, 58.86it/s] 73%|███████▎  | 58/79 [00:01<00:00, 61.32it/s] 84%|████████▎ | 66/79 [00:01<00:00, 63.93it/s] 94%|█████████▎| 74/79 [00:01<00:00, 66.14it/s]100%|██████████| 79/79 [00:01<00:00, 46.29it/s]
10000 images processed, 1.7272155284881592 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:39,  1.76it/s] 11%|█▏        | 8/70 [00:00<00:04, 15.37it/s] 21%|██▏       | 15/70 [00:00<00:02, 27.14it/s] 31%|███▏      | 22/70 [00:00<00:01, 36.47it/s] 41%|████▏     | 29/70 [00:00<00:00, 44.54it/s] 51%|█████▏    | 36/70 [00:01<00:00, 50.31it/s] 61%|██████▏   | 43/70 [00:01<00:00, 54.76it/s] 73%|███████▎  | 51/70 [00:01<00:00, 58.92it/s] 84%|████████▍ | 59/70 [00:01<00:00, 62.26it/s] 96%|█████████▌| 67/70 [00:01<00:00, 63.81it/s]100%|██████████| 70/70 [00:01<00:00, 43.83it/s]
8925 images processed, 1.633244276046753 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<00:51,  1.16s/it]  7%|▋         | 3/45 [00:01<00:14,  2.91it/s] 18%|█▊        | 8/45 [00:01<00:04,  9.10it/s] 33%|███▎      | 15/45 [00:01<00:01, 18.61it/s] 44%|████▍     | 20/45 [00:01<00:01, 17.98it/s] 53%|█████▎    | 24/45 [00:01<00:01, 19.16it/s] 71%|███████   | 32/45 [00:02<00:00, 28.82it/s] 82%|████████▏ | 37/45 [00:02<00:00, 18.89it/s] 98%|█████████▊| 44/45 [00:02<00:00, 25.65it/s]100%|██████████| 45/45 [00:02<00:00, 16.77it/s]
5640 images processed, 2.7033181190490723 seconds used

23.662078857421875
/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/CILPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN           4.18  98.70  84.51
places365     73.27  79.67  48.99
LSUN          49.13  88.47  71.16
iSUN          50.80  88.26  71.62
dtd           41.08  90.05  77.99
AVG           43.69  89.03  70.85
[incremental] Overall: 0.6220 New: 0.6220 Old: 0.6220
[incremental] Final(Top-1): 0.6220  Average: 0.6220
17.480865716934204
[DEBUG] Parsed: avg_fpr=43.69 avg_auroc=89.03 final_top1=0.6220 average=0.6220
[Result] AVG-AUROC=89.03 AVG-FPR=43.69 Final-Top1=0.6220 Average=0.6220 Score=67.44

[Grid Search Continual] Completed. Results saved to: evaluation_results/CIFAR-110-resnet34-top5-palm-cache6-ema0.999-continual-continual-grid_runs.csv
