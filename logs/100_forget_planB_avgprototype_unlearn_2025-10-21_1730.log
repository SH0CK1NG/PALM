nohup: ignoring input
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/PALM/main.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Namespace(in_dataset='CIFAR-100', out_datasets=['inat', 'sun50', 'places50', 'dtd'], backbone='resnet34', method='top5-palm-cache6-ema0.999', seed=1, gpu='0', epochs=50, batch_size=128, lr=0.001, weight_decay=0.0001, print_every=50, fine_tune=False, temp=0.08, cosine=True, warm=False, lr_decay_epochs='700,800,900', lr_decay_rate=0.1, layers=100, depth=40, width=4, growth=12, droprate=0.0, save_path='CIFAR-10-ResNet18.pt', load_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt', reduce=0.5, score='mahalanobis', threshold=1.0, k=5, momentum=0.9, proto_m=0.999, cache_size=6, nviews=2, lambda_pcon=1.0, epsilon=0.05, incremental=False, use_lora=True, lora_impl='peft', lora_r=8, lora_alpha=32, lora_dropout=0.05, lora_target='both', adapter_save_path='checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter', adapter_load_path=None, forget_classes='0,8,11,40,51,66,67,88,94,57', forget_list_path=None, forget_lambda=0.2, forget_margin=100.0, centers_path=None, precision_path=None, batch_forget_mode='balanced', forget_proto_enable=False, forget_attr_w=1.0, forget_proto_rep_w=1.0, forget_avgproto_enable=True, forget_avgproto_w=1.0, umap_enable=False, umap_by='domain', umap_max_points=20000, umap_neighbors=15, umap_min_dist=0.05, umap_metric='cosine', umap_save_path=None, umap_rf_only=False, keep_cache=False, argument=True)
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
resnet34-top5-palm-cache6-ema0.999: Number of model parameters: 21843904
[debug] trainable_count = 16
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.1.conv2.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv1.lora_B.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_A.default.weight
[debug] trainable: base_model.model.encoder.layer4.2.conv2.lora_B.default.weight
[debug] trainable: base_model.model.head.2.lora_A.default.weight
[debug] trainable: base_model.model.head.2.lora_B.default.weight
[debug][warn] non-LoRA trainables detected: ['base_model.model.encoder.layer4.0.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.0.conv2.lora_B.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_A.default.weight', 'base_model.model.encoder.layer4.0.shortcut.0.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv1.lora_B.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_A.default.weight', 'base_model.model.encoder.layer4.1.conv2.lora_B.default.weight']
  0%|          | 0/50 [00:00<?, ?it/s]/home/shaokun/PALM/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  2%|▏         | 1/50 [00:35<28:39, 35.08s/it]  4%|▍         | 2/50 [01:04<25:21, 31.69s/it]  6%|▌         | 3/50 [01:33<23:56, 30.57s/it]  8%|▊         | 4/50 [02:01<22:45, 29.68s/it] 10%|█         | 5/50 [02:30<21:49, 29.11s/it] 12%|█▏        | 6/50 [02:57<20:59, 28.63s/it] 14%|█▍        | 7/50 [03:27<20:43, 28.92s/it] 16%|█▌        | 8/50 [03:58<20:45, 29.65s/it] 18%|█▊        | 9/50 [04:26<19:51, 29.06s/it][loss] ep 0 it 0 total=9.0015 mle=1.5709 pcon=5.2950 forget=1.3755 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 50 total=8.9348 mle=1.5423 pcon=5.2879 forget=1.4013 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 100 total=9.0162 mle=1.7004 pcon=5.2809 forget=1.3740 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 150 total=9.0939 mle=1.8997 pcon=5.2738 forget=1.3696 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 200 total=9.1299 mle=1.7130 pcon=5.2670 forget=1.3826 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 250 total=8.9041 mle=1.5021 pcon=5.2603 forget=1.3783 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 300 total=8.9650 mle=1.5597 pcon=5.2540 forget=1.3818 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 0 it 350 total=9.0124 mle=1.6811 pcon=5.2476 forget=1.3895 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 1 it 10 total=9.0260 mle=1.6720 pcon=5.2409 forget=1.4098 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 60 total=8.9813 mle=1.6371 pcon=5.2346 forget=1.3668 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 110 total=8.9103 mle=1.5167 pcon=5.2284 forget=1.3891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 160 total=9.1507 mle=1.7805 pcon=5.2224 forget=1.3887 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 210 total=9.0582 mle=1.7652 pcon=5.2166 forget=1.3846 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 260 total=9.0223 mle=1.6039 pcon=5.2111 forget=1.3669 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 310 total=9.0790 mle=1.7227 pcon=5.2055 forget=1.3761 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 1 it 360 total=8.9965 mle=1.7935 pcon=5.2000 forget=1.3832 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 2 it 20 total=8.6949 mle=1.5526 pcon=5.1947 forget=1.3728 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 70 total=8.9506 mle=1.8862 pcon=5.1894 forget=1.3508 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 120 total=8.9815 mle=1.7492 pcon=5.1839 forget=1.3667 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 170 total=8.3536 mle=1.5290 pcon=5.1784 forget=1.3485 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 220 total=8.2559 mle=1.5998 pcon=5.1728 forget=1.3830 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 270 total=8.2793 mle=1.8651 pcon=5.1674 forget=1.3646 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 320 total=7.8336 mle=1.5770 pcon=5.1617 forget=1.3780 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 2 it 370 total=7.8340 mle=1.8152 pcon=5.1560 forget=1.4072 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 3 it 30 total=7.6297 mle=1.7398 pcon=5.1504 forget=1.4477 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 80 total=7.4977 mle=1.7287 pcon=5.1453 forget=1.4839 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 130 total=7.5167 mle=1.7827 pcon=5.1400 forget=1.5021 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 180 total=7.7072 mle=1.9783 pcon=5.1353 forget=1.5217 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 230 total=7.4914 mle=1.6326 pcon=5.1306 forget=1.5514 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 280 total=9.0176 mle=1.9385 pcon=5.1259 forget=1.5949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 330 total=11.1027 mle=1.8392 pcon=5.1210 forget=1.6345 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 3 it 380 total=11.1847 mle=1.7503 pcon=5.1167 forget=1.6161 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 40 total=10.9448 mle=1.6289 pcon=5.1121 forget=1.5617 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 90 total=10.8350 mle=1.7338 pcon=5.1074 forget=1.5207 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 140 total=10.4697 mle=1.6657 pcon=5.1033 forget=1.4661 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 190 total=9.8758 mle=1.4494 pcon=5.0994 forget=1.4264 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 240 total=9.9614 mle=1.7683 pcon=5.0953 forget=1.3879 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 290 total=9.5962 mle=1.5018 pcon=5.0915 forget=1.3770 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 4 it 340 total=10.0576 mle=1.9112 pcon=5.0879 forget=1.3896 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 0 total=9.6479 mle=1.8739 pcon=5.0844 forget=1.3787 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 50 total=9.3006 mle=1.7822 pcon=5.0806 forget=1.3582 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 100 total=8.5243 mle=1.6261 pcon=5.0772 forget=1.3880 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 150 total=7.9430 mle=1.6583 pcon=5.0734 forget=1.4115 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 200 total=10.7662 mle=1.7928 pcon=5.0703 forget=1.4310 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 250 total=10.3356 mle=1.8873 pcon=5.0671 forget=1.3943 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 300 total=9.0674 mle=1.6714 pcon=5.0638 forget=1.3612 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 5 it 350 total=8.6008 mle=1.7527 pcon=5.0607 forget=1.3604 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 10 total=8.0091 mle=1.4117 pcon=5.0576 forget=1.3846 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 60 total=7.9060 mle=1.5576 pcon=5.0545 forget=1.3692 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 110 total=8.0893 mle=1.6482 pcon=5.0515 forget=1.4269 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 160 total=9.5252 mle=1.7829 pcon=5.0485 forget=1.4494 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 210 total=10.3429 mle=1.6442 pcon=5.0458 forget=1.4377 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 260 total=10.4557 mle=1.8016 pcon=5.0425 forget=1.4226 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 310 total=9.7353 mle=1.5384 pcon=5.0397 forget=1.4001 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 6 it 360 total=9.2853 mle=1.6753 pcon=5.0370 forget=1.3651 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 20 total=8.7266 mle=1.6655 pcon=5.0342 forget=1.3541 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 70 total=8.2453 mle=1.8159 pcon=5.0316 forget=1.3718 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 120 total=10.2475 mle=1.7188 pcon=5.0289 forget=1.4025 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 170 total=10.0658 mle=1.6161 pcon=5.0264 forget=1.3809 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 220 total=9.0240 mle=1.6346 pcon=5.0244 forget=1.3657 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 270 total=8.6321 mle=1.7722 pcon=5.0223 forget=1.3765 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 320 total=8.1841 mle=1.7403 pcon=5.0200 forget=1.3781 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 7 it 370 total=8.1216 mle=1.6412 pcon=5.0179 forget=1.3800 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 30 total=8.5101 mle=1.6113 pcon=5.0159 forget=1.4393 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 80 total=9.0061 mle=1.6058 pcon=5.0138 forget=1.4365 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 130 total=9.1323 mle=1.5100 pcon=5.0115 forget=1.4169 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 180 total=9.0142 mle=1.7390 pcon=5.0094 forget=1.3737 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 230 total=8.7823 mle=1.5646 pcon=5.0077 forget=1.3761 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 280 total=9.8588 mle=1.7478 pcon=5.0058 forget=1.3948 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 330 total=9.6552 mle=1.7675 pcon=5.0037 forget=1.3965 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 8 it 380 total=8.5261 mle=1.4985 pcon=5.0014 forget=1.3502 nr=64 nf=64 protos=540 fproto_sim=NA
 20%|██        | 10/50 [04:50<18:20, 27.50s/it] 22%|██▏       | 11/50 [05:18<18:07, 27.87s/it] 24%|██▍       | 12/50 [05:48<17:53, 28.24s/it] 26%|██▌       | 13/50 [06:18<17:48, 28.88s/it] 28%|██▊       | 14/50 [06:48<17:35, 29.32s/it] 30%|███       | 15/50 [07:19<17:17, 29.65s/it] 32%|███▏      | 16/50 [07:48<16:44, 29.55s/it] 34%|███▍      | 17/50 [08:17<16:11, 29.45s/it] 36%|███▌      | 18/50 [08:47<15:44, 29.51s/it][loss] ep 9 it 40 total=7.9821 mle=1.6318 pcon=4.9991 forget=1.3318 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 90 total=7.6215 mle=1.6820 pcon=4.9965 forget=1.3689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 140 total=8.1855 mle=1.8472 pcon=4.9948 forget=1.3974 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 190 total=10.1170 mle=1.6515 pcon=4.9932 forget=1.3896 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 240 total=10.4073 mle=1.5796 pcon=4.9920 forget=1.3837 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 290 total=10.0241 mle=1.5640 pcon=4.9904 forget=1.3726 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 9 it 340 total=9.5587 mle=1.5989 pcon=4.9890 forget=1.3597 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 0 total=9.0797 mle=1.6079 pcon=4.9873 forget=1.3552 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 50 total=8.3765 mle=1.5949 pcon=4.9853 forget=1.3640 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 100 total=7.9098 mle=1.7434 pcon=4.9834 forget=1.3518 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 150 total=9.7966 mle=1.7947 pcon=4.9816 forget=1.3626 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 200 total=9.9197 mle=1.8521 pcon=4.9798 forget=1.3890 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 250 total=9.0883 mle=1.6186 pcon=4.9784 forget=1.3899 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 300 total=8.6519 mle=1.6090 pcon=4.9774 forget=1.3755 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 10 it 350 total=8.6040 mle=1.6893 pcon=4.9764 forget=1.3846 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 10 total=8.2497 mle=1.5789 pcon=4.9755 forget=1.3662 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 60 total=8.1056 mle=1.6829 pcon=4.9748 forget=1.3366 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 110 total=8.2780 mle=1.6173 pcon=4.9743 forget=1.3491 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 160 total=9.6519 mle=1.6734 pcon=4.9733 forget=1.3807 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 210 total=10.4307 mle=1.7472 pcon=4.9725 forget=1.3947 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 260 total=10.1781 mle=1.6273 pcon=4.9717 forget=1.4048 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 310 total=9.8837 mle=1.9648 pcon=4.9702 forget=1.3821 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 11 it 360 total=8.5132 mle=1.6886 pcon=4.9685 forget=1.3410 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 20 total=7.6782 mle=1.6048 pcon=4.9666 forget=1.3245 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 70 total=7.6362 mle=1.7796 pcon=4.9651 forget=1.3214 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 120 total=7.7808 mle=1.6993 pcon=4.9636 forget=1.3377 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 170 total=8.6604 mle=1.7910 pcon=4.9624 forget=1.3366 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 220 total=9.2857 mle=1.6917 pcon=4.9612 forget=1.3433 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 270 total=9.5796 mle=1.5957 pcon=4.9605 forget=1.3627 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 320 total=9.6899 mle=1.5428 pcon=4.9592 forget=1.3794 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 12 it 370 total=10.0288 mle=1.8454 pcon=4.9579 forget=1.3943 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 30 total=9.6326 mle=1.4700 pcon=4.9565 forget=1.3944 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 80 total=9.6744 mle=1.5103 pcon=4.9551 forget=1.3963 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 130 total=9.6434 mle=1.5930 pcon=4.9534 forget=1.3736 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 180 total=9.5551 mle=1.6050 pcon=4.9520 forget=1.3593 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 230 total=9.4192 mle=1.7216 pcon=4.9505 forget=1.3564 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 280 total=9.0008 mle=1.5704 pcon=4.9490 forget=1.3449 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 330 total=8.6690 mle=1.6195 pcon=4.9475 forget=1.3470 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 13 it 380 total=8.2740 mle=1.6509 pcon=4.9460 forget=1.3331 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 40 total=8.0407 mle=1.8036 pcon=4.9443 forget=1.3182 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 90 total=7.8989 mle=1.7860 pcon=4.9432 forget=1.3073 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 140 total=8.0296 mle=1.6629 pcon=4.9421 forget=1.3135 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 190 total=9.0438 mle=1.8255 pcon=4.9405 forget=1.3327 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 240 total=9.6622 mle=1.6932 pcon=4.9391 forget=1.3612 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 290 total=9.9898 mle=1.6556 pcon=4.9373 forget=1.3797 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 14 it 340 total=10.1098 mle=1.7300 pcon=4.9352 forget=1.3946 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 0 total=9.9718 mle=1.7174 pcon=4.9330 forget=1.4011 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 50 total=9.4722 mle=1.4972 pcon=4.9301 forget=1.3861 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 100 total=9.0480 mle=1.5763 pcon=4.9272 forget=1.3521 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 150 total=8.5960 mle=1.6903 pcon=4.9241 forget=1.3392 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 200 total=7.9578 mle=1.6424 pcon=4.9208 forget=1.3078 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 250 total=7.9049 mle=2.0165 pcon=4.9174 forget=1.3029 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 300 total=7.4880 mle=1.6544 pcon=4.9142 forget=1.3080 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 15 it 350 total=7.8942 mle=1.6128 pcon=4.9111 forget=1.3231 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 10 total=8.8828 mle=1.6191 pcon=4.9081 forget=1.3245 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 60 total=9.7063 mle=1.6103 pcon=4.9053 forget=1.3288 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 110 total=10.0052 mle=1.6204 pcon=4.9026 forget=1.3437 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 160 total=10.0303 mle=1.5683 pcon=4.8995 forget=1.3584 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 210 total=10.0112 mle=1.6042 pcon=4.8963 forget=1.3677 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 260 total=10.1599 mle=1.8496 pcon=4.8929 forget=1.3769 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 310 total=9.8840 mle=1.7834 pcon=4.8895 forget=1.3783 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 16 it 360 total=9.4866 mle=1.6471 pcon=4.8858 forget=1.3736 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 20 total=9.2772 mle=1.7570 pcon=4.8817 forget=1.3556 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 70 total=8.8549 mle=1.7786 pcon=4.8776 forget=1.3254 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 120 total=8.4677 mle=1.7213 pcon=4.8732 forget=1.3116 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 170 total=8.0581 mle=1.6162 pcon=4.8685 forget=1.3040 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 220 total=7.9749 mle=1.6769 pcon=4.8641 forget=1.3097 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 270 total=8.0490 mle=1.6038 pcon=4.8604 forget=1.3106 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 320 total=8.8220 mle=1.9092 pcon=4.8567 forget=1.3176 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 17 it 370 total=9.2316 mle=1.8339 pcon=4.8532 forget=1.3219 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 30 total=9.2788 mle=1.6239 pcon=4.8506 forget=1.3236 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 80 total=9.4533 mle=1.7031 pcon=4.8481 forget=1.3360 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 130 total=9.4613 mle=1.7321 pcon=4.8458 forget=1.3403 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 180 total=9.2706 mle=1.6192 pcon=4.8434 forget=1.3301 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 230 total=9.2022 mle=1.6869 pcon=4.8410 forget=1.3310 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 280 total=8.9932 mle=1.6883 pcon=4.8385 forget=1.3328 nr=64 nf=64 protos=540 fproto_sim=NA
 38%|███▊      | 19/50 [09:17<15:16, 29.57s/it] 40%|████      | 20/50 [09:46<14:47, 29.60s/it] 42%|████▏     | 21/50 [10:13<13:53, 28.75s/it] 44%|████▍     | 22/50 [10:36<12:35, 26.99s/it] 46%|████▌     | 23/50 [10:56<11:09, 24.81s/it] 48%|████▊     | 24/50 [11:15<10:03, 23.22s/it] 50%|█████     | 25/50 [11:43<10:17, 24.72s/it] 52%|█████▏    | 26/50 [12:11<10:17, 25.72s/it] 54%|█████▍    | 27/50 [12:39<10:07, 26.39s/it] 56%|█████▌    | 28/50 [13:07<09:51, 26.90s/it][loss] ep 18 it 330 total=8.8799 mle=1.7702 pcon=4.8360 forget=1.3205 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 18 it 380 total=8.5787 mle=1.7162 pcon=4.8335 forget=1.3185 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 40 total=8.2961 mle=1.6116 pcon=4.8308 forget=1.3095 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 90 total=8.1797 mle=1.6561 pcon=4.8281 forget=1.3088 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 140 total=8.3110 mle=1.6581 pcon=4.8252 forget=1.3021 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 190 total=8.8622 mle=1.7365 pcon=4.8225 forget=1.3085 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 240 total=9.6347 mle=1.8877 pcon=4.8199 forget=1.3245 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 290 total=9.9059 mle=1.7723 pcon=4.8180 forget=1.3414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 19 it 340 total=9.8486 mle=1.6294 pcon=4.8161 forget=1.3551 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 0 total=9.8162 mle=1.6772 pcon=4.8144 forget=1.3568 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 50 total=9.6327 mle=1.7221 pcon=4.8128 forget=1.3560 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 100 total=9.3476 mle=1.7771 pcon=4.8114 forget=1.3524 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 150 total=9.0311 mle=1.8373 pcon=4.8097 forget=1.3314 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 200 total=8.4036 mle=1.6223 pcon=4.8078 forget=1.3076 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 250 total=8.2823 mle=1.9504 pcon=4.8058 forget=1.2886 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 300 total=7.7621 mle=1.7893 pcon=4.8036 forget=1.2840 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 20 it 350 total=7.2440 mle=1.5635 pcon=4.8013 forget=1.2716 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 10 total=7.1215 mle=1.5773 pcon=4.7989 forget=1.2750 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 60 total=7.4245 mle=1.7045 pcon=4.7964 forget=1.2909 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 110 total=8.0074 mle=1.6331 pcon=4.7940 forget=1.3136 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 160 total=9.2778 mle=1.6494 pcon=4.7918 forget=1.3362 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 210 total=10.1601 mle=1.7875 pcon=4.7897 forget=1.3640 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 260 total=10.3113 mle=1.7104 pcon=4.7876 forget=1.3844 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 310 total=10.2489 mle=1.6246 pcon=4.7854 forget=1.3999 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 21 it 360 total=10.0996 mle=1.5948 pcon=4.7835 forget=1.4135 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 20 total=9.8530 mle=1.6842 pcon=4.7815 forget=1.3978 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 70 total=9.2526 mle=1.6768 pcon=4.7795 forget=1.3689 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 120 total=8.3323 mle=1.6345 pcon=4.7772 forget=1.3383 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 170 total=7.4468 mle=1.6146 pcon=4.7749 forget=1.2891 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 220 total=7.0420 mle=1.6077 pcon=4.7727 forget=1.2693 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 270 total=6.9150 mle=1.5885 pcon=4.7704 forget=1.2795 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 320 total=7.3134 mle=1.7697 pcon=4.7685 forget=1.2887 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 22 it 370 total=8.7032 mle=1.9572 pcon=4.7667 forget=1.3126 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 23 it 30 total=9.8251 mle=1.5863 pcon=4.7657 forget=1.3321 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 80 total=10.3429 mle=1.6658 pcon=4.7645 forget=1.3574 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 130 total=10.4781 mle=1.6932 pcon=4.7635 forget=1.3774 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 180 total=10.4643 mle=1.7406 pcon=4.7625 forget=1.3948 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 230 total=10.2351 mle=1.6082 pcon=4.7617 forget=1.4153 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 280 total=9.9797 mle=1.5872 pcon=4.7606 forget=1.4293 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 330 total=9.6698 mle=1.6458 pcon=4.7592 forget=1.4426 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 23 it 380 total=9.0706 mle=1.6166 pcon=4.7576 forget=1.4367 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 40 total=8.2628 mle=1.5688 pcon=4.7558 forget=1.3949 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 90 total=7.6528 mle=1.6316 pcon=4.7536 forget=1.3353 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 140 total=7.0396 mle=1.6138 pcon=4.7509 forget=1.2869 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 190 total=6.6486 mle=1.6523 pcon=4.7482 forget=1.2508 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 240 total=6.4526 mle=1.5701 pcon=4.7453 forget=1.2512 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 290 total=6.6919 mle=1.7598 pcon=4.7427 forget=1.2664 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 24 it 340 total=6.8821 mle=1.6516 pcon=4.7402 forget=1.2795 nr=64 nf=64 protos=540 fproto_sim=NA
[peft] adapter saved to checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
[loss] ep 25 it 0 total=8.1667 mle=1.6925 pcon=4.7379 forget=1.3031 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 50 total=9.7367 mle=1.7588 pcon=4.7362 forget=1.3353 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 100 total=10.0666 mle=1.6255 pcon=4.7346 forget=1.3452 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 150 total=10.3568 mle=1.7730 pcon=4.7333 forget=1.3607 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 200 total=10.3987 mle=1.8446 pcon=4.7320 forget=1.3774 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 250 total=10.1050 mle=1.7042 pcon=4.7306 forget=1.3907 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 300 total=9.8350 mle=1.6345 pcon=4.7294 forget=1.3812 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 25 it 350 total=9.4478 mle=1.5251 pcon=4.7284 forget=1.3796 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 10 total=9.1814 mle=1.6338 pcon=4.7270 forget=1.3672 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 60 total=8.7941 mle=1.6678 pcon=4.7255 forget=1.3558 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 110 total=8.3748 mle=1.6968 pcon=4.7240 forget=1.3363 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 160 total=7.9226 mle=1.5809 pcon=4.7223 forget=1.3200 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 210 total=8.0104 mle=1.7628 pcon=4.7205 forget=1.3159 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 260 total=7.6347 mle=1.5865 pcon=4.7189 forget=1.3258 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 310 total=8.2565 mle=1.9918 pcon=4.7174 forget=1.3333 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 26 it 360 total=8.5384 mle=1.6538 pcon=4.7159 forget=1.3664 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 20 total=8.9774 mle=1.6892 pcon=4.7147 forget=1.3766 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 70 total=9.0086 mle=1.6376 pcon=4.7134 forget=1.3702 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 120 total=8.9625 mle=1.6008 pcon=4.7123 forget=1.3602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 170 total=8.8820 mle=1.5853 pcon=4.7113 forget=1.3540 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 220 total=8.6798 mle=1.5380 pcon=4.7102 forget=1.3498 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 270 total=8.6471 mle=1.5955 pcon=4.7091 forget=1.3422 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 320 total=8.6711 mle=1.7509 pcon=4.7082 forget=1.3412 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 27 it 370 total=8.5722 mle=1.7539 pcon=4.7072 forget=1.3474 nr=64 nf=64 protos=540 fproto_sim=NA
 58%|█████▊    | 29/50 [13:36<09:37, 27.50s/it] 60%|██████    | 30/50 [14:05<09:16, 27.81s/it] 62%|██████▏   | 31/50 [14:33<08:48, 27.81s/it] 64%|██████▍   | 32/50 [15:02<08:28, 28.24s/it] 66%|██████▌   | 33/50 [15:30<07:59, 28.21s/it] 68%|██████▊   | 34/50 [15:58<07:31, 28.21s/it] 70%|███████   | 35/50 [16:27<07:05, 28.38s/it] 72%|███████▏  | 36/50 [16:52<06:21, 27.25s/it] 74%|███████▍  | 37/50 [17:13<05:30, 25.46s/it][loss] ep 28 it 30 total=8.4154 mle=1.6699 pcon=4.7063 forget=1.3430 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 80 total=8.3781 mle=1.6999 pcon=4.7053 forget=1.3487 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 130 total=8.3360 mle=1.6278 pcon=4.7043 forget=1.3493 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 180 total=8.3978 mle=1.6560 pcon=4.7033 forget=1.3480 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 230 total=8.4116 mle=1.4865 pcon=4.7021 forget=1.3549 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 280 total=8.8432 mle=1.6185 pcon=4.7009 forget=1.3671 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 330 total=9.3401 mle=1.8045 pcon=4.6997 forget=1.3682 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 28 it 380 total=9.6808 mle=1.7441 pcon=4.6986 forget=1.3745 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 40 total=10.0568 mle=1.7661 pcon=4.6976 forget=1.3798 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 90 total=10.1436 mle=1.6426 pcon=4.6966 forget=1.3834 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 140 total=10.3131 mle=1.7023 pcon=4.6959 forget=1.3922 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 190 total=10.2779 mle=1.6386 pcon=4.6953 forget=1.3989 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 240 total=10.2190 mle=1.5906 pcon=4.6947 forget=1.4084 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 290 total=10.2519 mle=1.7510 pcon=4.6943 forget=1.4034 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 29 it 340 total=9.9292 mle=1.5853 pcon=4.6939 forget=1.4160 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 0 total=9.7016 mle=1.6535 pcon=4.6933 forget=1.3987 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 50 total=9.1633 mle=1.6241 pcon=4.6927 forget=1.3890 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 100 total=8.4225 mle=1.5809 pcon=4.6919 forget=1.3538 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 150 total=7.8328 mle=1.7985 pcon=4.6907 forget=1.3033 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 200 total=7.2851 mle=1.5021 pcon=4.6895 forget=1.2992 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 250 total=7.2849 mle=1.8074 pcon=4.6883 forget=1.2764 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 300 total=6.9039 mle=1.5231 pcon=4.6871 forget=1.2826 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 30 it 350 total=7.1593 mle=1.7804 pcon=4.6861 forget=1.2920 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 10 total=7.3867 mle=1.6783 pcon=4.6852 forget=1.3065 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 60 total=7.8975 mle=1.5937 pcon=4.6845 forget=1.3341 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 110 total=8.6182 mle=1.7161 pcon=4.6840 forget=1.3602 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 160 total=8.9815 mle=1.6102 pcon=4.6835 forget=1.3823 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 210 total=9.1807 mle=1.6051 pcon=4.6832 forget=1.4054 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 260 total=9.2178 mle=1.5658 pcon=4.6829 forget=1.4127 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 310 total=9.3288 mle=1.6552 pcon=4.6826 forget=1.4282 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 31 it 360 total=9.1977 mle=1.5809 pcon=4.6821 forget=1.4207 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 20 total=9.2830 mle=1.7287 pcon=4.6817 forget=1.4217 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 70 total=8.9754 mle=1.5679 pcon=4.6811 forget=1.4068 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 120 total=8.8901 mle=1.6098 pcon=4.6805 forget=1.3991 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 170 total=8.7639 mle=1.5686 pcon=4.6801 forget=1.3870 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 220 total=8.7963 mle=1.6847 pcon=4.6795 forget=1.3572 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 270 total=8.6904 mle=1.6350 pcon=4.6789 forget=1.3465 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 320 total=8.6250 mle=1.5292 pcon=4.6781 forget=1.3401 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 32 it 370 total=8.6474 mle=1.5391 pcon=4.6776 forget=1.3358 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 30 total=8.8916 mle=1.6787 pcon=4.6770 forget=1.3421 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 80 total=9.2431 mle=1.8827 pcon=4.6764 forget=1.3403 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 130 total=9.0660 mle=1.6103 pcon=4.6758 forget=1.3480 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 180 total=9.3220 mle=1.6874 pcon=4.6752 forget=1.3723 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 230 total=9.4300 mle=1.6685 pcon=4.6747 forget=1.3822 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 280 total=9.6359 mle=1.7738 pcon=4.6742 forget=1.3894 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 330 total=9.7167 mle=1.7670 pcon=4.6738 forget=1.4097 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 33 it 380 total=9.6071 mle=1.6708 pcon=4.6734 forget=1.4251 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 40 total=9.6672 mle=1.7777 pcon=4.6729 forget=1.4259 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 90 total=9.3232 mle=1.5575 pcon=4.6724 forget=1.4266 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 140 total=9.3261 mle=1.6858 pcon=4.6721 forget=1.4121 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 190 total=9.0699 mle=1.6665 pcon=4.6717 forget=1.3989 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 240 total=8.9426 mle=1.7224 pcon=4.6713 forget=1.3873 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 290 total=8.7416 mle=1.6687 pcon=4.6707 forget=1.3724 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 34 it 340 total=8.6068 mle=1.6510 pcon=4.6704 forget=1.3641 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 0 total=8.5702 mle=1.6331 pcon=4.6699 forget=1.3477 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 50 total=8.5848 mle=1.6346 pcon=4.6695 forget=1.3460 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 100 total=8.9118 mle=1.8167 pcon=4.6691 forget=1.3629 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 150 total=8.8611 mle=1.6866 pcon=4.6687 forget=1.3604 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 200 total=8.8488 mle=1.6197 pcon=4.6685 forget=1.3728 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 250 total=8.9611 mle=1.7145 pcon=4.6681 forget=1.3774 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 300 total=8.7734 mle=1.5936 pcon=4.6678 forget=1.3809 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 35 it 350 total=8.8639 mle=1.7357 pcon=4.6675 forget=1.3840 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 10 total=8.8408 mle=1.8005 pcon=4.6672 forget=1.3893 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 60 total=8.4641 mle=1.6046 pcon=4.6669 forget=1.3694 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 110 total=8.3464 mle=1.6303 pcon=4.6665 forget=1.3697 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 160 total=8.2477 mle=1.6522 pcon=4.6660 forget=1.3500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 210 total=8.0063 mle=1.5722 pcon=4.6656 forget=1.3371 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 260 total=8.0763 mle=1.6282 pcon=4.6654 forget=1.3492 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 310 total=8.0216 mle=1.6746 pcon=4.6648 forget=1.3389 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 36 it 360 total=7.9890 mle=1.6715 pcon=4.6643 forget=1.3235 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 20 total=7.8662 mle=1.5178 pcon=4.6638 forget=1.3187 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 70 total=8.2012 mle=1.7775 pcon=4.6635 forget=1.3220 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 120 total=8.1958 mle=1.6546 pcon=4.6630 forget=1.3244 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 170 total=8.1957 mle=1.6303 pcon=4.6627 forget=1.3150 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 220 total=8.4188 mle=1.7576 pcon=4.6623 forget=1.3286 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 270 total=8.3472 mle=1.6173 pcon=4.6620 forget=1.3179 nr=64 nf=64 protos=540 fproto_sim=NA
 76%|███████▌  | 38/50 [17:37<05:00, 25.01s/it] 78%|███████▊  | 39/50 [18:06<04:47, 26.15s/it] 80%|████████  | 40/50 [18:34<04:28, 26.80s/it] 82%|████████▏ | 41/50 [19:02<04:03, 27.03s/it] 84%|████████▍ | 42/50 [19:30<03:40, 27.55s/it] 86%|████████▌ | 43/50 [19:58<03:14, 27.72s/it] 88%|████████▊ | 44/50 [20:27<02:47, 27.98s/it] 90%|█████████ | 45/50 [20:56<02:21, 28.29s/it] 92%|█████████▏| 46/50 [21:23<01:51, 27.82s/it] 94%|█████████▍| 47/50 [21:49<01:22, 27.46s/it][loss] ep 37 it 320 total=8.5338 mle=1.7004 pcon=4.6618 forget=1.3232 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 37 it 370 total=8.6093 mle=1.6690 pcon=4.6617 forget=1.3441 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 30 total=8.7838 mle=1.7554 pcon=4.6617 forget=1.3474 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 80 total=8.6152 mle=1.5183 pcon=4.6617 forget=1.3473 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 130 total=8.7860 mle=1.6510 pcon=4.6616 forget=1.3541 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 180 total=8.7833 mle=1.6179 pcon=4.6615 forget=1.3587 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 230 total=8.7464 mle=1.5328 pcon=4.6614 forget=1.3696 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 280 total=8.9467 mle=1.7342 pcon=4.6613 forget=1.3698 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 330 total=8.7538 mle=1.5739 pcon=4.6610 forget=1.3811 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 38 it 380 total=8.7142 mle=1.5448 pcon=4.6610 forget=1.3836 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 40 total=8.8966 mle=1.7671 pcon=4.6609 forget=1.3898 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 90 total=8.7317 mle=1.6332 pcon=4.6608 forget=1.4027 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 140 total=8.6964 mle=1.6380 pcon=4.6605 forget=1.4053 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 190 total=8.4469 mle=1.5033 pcon=4.6602 forget=1.4035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 240 total=8.5038 mle=1.6408 pcon=4.6599 forget=1.4131 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 290 total=8.2943 mle=1.5340 pcon=4.6596 forget=1.4047 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 39 it 340 total=8.2963 mle=1.5802 pcon=4.6592 forget=1.4058 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 0 total=8.2527 mle=1.5528 pcon=4.6587 forget=1.4036 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 50 total=8.3234 mle=1.6439 pcon=4.6583 forget=1.3985 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 100 total=8.4035 mle=1.6345 pcon=4.6577 forget=1.3901 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 150 total=8.4864 mle=1.4818 pcon=4.6574 forget=1.3820 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 200 total=9.2200 mle=1.7743 pcon=4.6570 forget=1.3923 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 250 total=9.6488 mle=1.8167 pcon=4.6567 forget=1.3904 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 300 total=9.6949 mle=1.6134 pcon=4.6566 forget=1.3876 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 40 it 350 total=9.6700 mle=1.4938 pcon=4.6566 forget=1.3945 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 10 total=9.7397 mle=1.5382 pcon=4.6566 forget=1.3953 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 60 total=10.0436 mle=1.8805 pcon=4.6568 forget=1.4147 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 110 total=9.6241 mle=1.5924 pcon=4.6568 forget=1.4121 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 160 total=9.5283 mle=1.6104 pcon=4.6571 forget=1.4204 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 210 total=9.4490 mle=1.6882 pcon=4.6572 forget=1.4249 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 260 total=9.1653 mle=1.5549 pcon=4.6575 forget=1.4104 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 310 total=9.0181 mle=1.5402 pcon=4.6577 forget=1.4155 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 41 it 360 total=9.0455 mle=1.7001 pcon=4.6578 forget=1.4092 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 20 total=8.9468 mle=1.6791 pcon=4.6578 forget=1.4236 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 70 total=8.7144 mle=1.6003 pcon=4.6576 forget=1.4135 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 120 total=8.8991 mle=1.8657 pcon=4.6574 forget=1.4082 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 170 total=8.4997 mle=1.5976 pcon=4.6572 forget=1.3901 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 220 total=8.4712 mle=1.6244 pcon=4.6570 forget=1.3907 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 270 total=8.4642 mle=1.7129 pcon=4.6568 forget=1.3793 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 320 total=8.3972 mle=1.6933 pcon=4.6566 forget=1.3700 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 42 it 370 total=8.2228 mle=1.5889 pcon=4.6563 forget=1.3713 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 30 total=8.2413 mle=1.6616 pcon=4.6560 forget=1.3658 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 80 total=8.2075 mle=1.6239 pcon=4.6556 forget=1.3675 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 130 total=8.2639 mle=1.6806 pcon=4.6553 forget=1.3669 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 180 total=8.1320 mle=1.5172 pcon=4.6550 forget=1.3648 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 230 total=8.1152 mle=1.5524 pcon=4.6546 forget=1.3472 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 280 total=8.1335 mle=1.5268 pcon=4.6543 forget=1.3537 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 330 total=8.2272 mle=1.5415 pcon=4.6539 forget=1.3573 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 43 it 380 total=8.2163 mle=1.5161 pcon=4.6535 forget=1.3500 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 40 total=8.6553 mle=1.7480 pcon=4.6532 forget=1.3681 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 90 total=8.5161 mle=1.5612 pcon=4.6529 forget=1.3605 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 140 total=8.7664 mle=1.6724 pcon=4.6526 forget=1.3718 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 190 total=8.8199 mle=1.5144 pcon=4.6524 forget=1.3696 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 240 total=9.0019 mle=1.5304 pcon=4.6522 forget=1.3941 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 290 total=9.4413 mle=1.7879 pcon=4.6521 forget=1.3756 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 44 it 340 total=9.6273 mle=1.8000 pcon=4.6520 forget=1.3819 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 0 total=9.6224 mle=1.5583 pcon=4.6518 forget=1.3935 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 50 total=9.7965 mle=1.6047 pcon=4.6518 forget=1.3832 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 100 total=9.9886 mle=1.5593 pcon=4.6517 forget=1.3926 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 150 total=10.1222 mle=1.5400 pcon=4.6516 forget=1.4099 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 200 total=10.2614 mle=1.6186 pcon=4.6516 forget=1.4064 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 250 total=10.3346 mle=1.5681 pcon=4.6516 forget=1.4088 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 300 total=10.4533 mle=1.6468 pcon=4.6515 forget=1.4137 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 45 it 350 total=10.3987 mle=1.5164 pcon=4.6516 forget=1.4138 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 10 total=10.3931 mle=1.5215 pcon=4.6517 forget=1.4238 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 60 total=10.4289 mle=1.5149 pcon=4.6518 forget=1.4424 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 110 total=10.5685 mle=1.6864 pcon=4.6519 forget=1.4414 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 160 total=10.4287 mle=1.4846 pcon=4.6520 forget=1.4417 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 210 total=10.6555 mle=1.7627 pcon=4.6521 forget=1.4366 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 260 total=10.6280 mle=1.6586 pcon=4.6523 forget=1.4407 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 310 total=10.4674 mle=1.5489 pcon=4.6525 forget=1.4586 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 46 it 360 total=10.7310 mle=1.7469 pcon=4.6527 forget=1.4661 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 20 total=10.5680 mle=1.5769 pcon=4.6527 forget=1.4800 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 70 total=10.5019 mle=1.5643 pcon=4.6529 forget=1.4740 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 120 total=10.6828 mle=1.6997 pcon=4.6530 forget=1.4821 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 170 total=10.4697 mle=1.5487 pcon=4.6532 forget=1.4865 nr=64 nf=64 protos=540 fproto_sim=NA
 96%|█████████▌| 48/50 [22:16<00:54, 27.11s/it] 98%|█████████▊| 49/50 [22:41<00:26, 26.44s/it]100%|██████████| 50/50 [23:03<00:00, 25.36s/it]100%|██████████| 50/50 [23:03<00:00, 27.68s/it]
[loss] ep 47 it 220 total=10.3994 mle=1.5042 pcon=4.6535 forget=1.4827 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 270 total=10.5220 mle=1.5860 pcon=4.6538 forget=1.4960 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 320 total=10.5605 mle=1.6235 pcon=4.6540 forget=1.5045 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 47 it 370 total=10.6104 mle=1.6656 pcon=4.6542 forget=1.5026 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 30 total=10.5356 mle=1.5858 pcon=4.6545 forget=1.5203 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 80 total=10.4962 mle=1.5798 pcon=4.6547 forget=1.5162 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 130 total=10.6163 mle=1.6691 pcon=4.6550 forget=1.5035 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 180 total=10.5399 mle=1.6495 pcon=4.6554 forget=1.5119 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 230 total=10.6125 mle=1.6837 pcon=4.6556 forget=1.5024 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 280 total=10.5153 mle=1.5956 pcon=4.6559 forget=1.5122 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 330 total=10.4842 mle=1.5876 pcon=4.6562 forget=1.5105 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 48 it 380 total=10.4759 mle=1.5606 pcon=4.6564 forget=1.5241 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 40 total=10.5598 mle=1.6024 pcon=4.6566 forget=1.5426 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 90 total=10.5357 mle=1.6199 pcon=4.6569 forget=1.5314 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 140 total=10.5152 mle=1.6185 pcon=4.6572 forget=1.5308 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 190 total=10.6516 mle=1.7424 pcon=4.6573 forget=1.5370 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 240 total=10.5919 mle=1.7034 pcon=4.6575 forget=1.5241 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 290 total=10.5983 mle=1.6082 pcon=4.6576 forget=1.5432 nr=64 nf=64 protos=540 fproto_sim=NA
[loss] ep 49 it 340 total=10.4361 mle=1.5498 pcon=4.6580 forget=1.5416 nr=64 nf=64 protos=540 fproto_sim=NA
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Files already downloaded and verified
Files already downloaded and verified
ckpt loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-with-prototypes.pt
[peft] adapter loaded from checkpoints/CIFAR-100-resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0-forget_avgproto_enable-planB_adapter
resnet34-top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0: Number of model parameters: 21843904
Processing in-distribution CIFAR-100 images
  0%|          | 0/391 [00:00<?, ?it/s]  0%|          | 1/391 [00:00<02:18,  2.82it/s]  3%|▎         | 10/391 [00:00<00:14, 26.64it/s]  5%|▍         | 19/391 [00:00<00:08, 43.15it/s]  7%|▋         | 27/391 [00:00<00:06, 52.78it/s]  9%|▉         | 36/391 [00:00<00:05, 62.91it/s] 11%|█▏        | 44/391 [00:00<00:05, 67.28it/s] 13%|█▎        | 52/391 [00:00<00:04, 70.26it/s] 16%|█▌        | 61/391 [00:01<00:04, 74.10it/s] 18%|█▊        | 70/391 [00:01<00:04, 78.31it/s] 20%|██        | 79/391 [00:01<00:03, 81.06it/s] 23%|██▎       | 88/391 [00:01<00:03, 81.45it/s] 25%|██▍       | 97/391 [00:01<00:03, 81.16it/s] 27%|██▋       | 106/391 [00:01<00:03, 83.32it/s] 29%|██▉       | 115/391 [00:01<00:03, 85.01it/s] 32%|███▏      | 124/391 [00:01<00:03, 84.68it/s] 34%|███▍      | 133/391 [00:01<00:03, 83.50it/s] 36%|███▋      | 142/391 [00:02<00:02, 84.87it/s] 39%|███▊      | 151/391 [00:02<00:02, 86.08it/s] 41%|████      | 160/391 [00:02<00:02, 87.04it/s] 43%|████▎     | 169/391 [00:02<00:02, 85.72it/s] 46%|████▌     | 178/391 [00:02<00:02, 85.53it/s] 48%|████▊     | 187/391 [00:02<00:02, 86.37it/s] 50%|█████     | 196/391 [00:02<00:02, 86.94it/s] 52%|█████▏    | 205/391 [00:02<00:02, 87.54it/s] 55%|█████▍    | 214/391 [00:02<00:02, 83.96it/s] 57%|█████▋    | 223/391 [00:03<00:02, 82.27it/s] 59%|█████▉    | 232/391 [00:03<00:01, 82.69it/s] 62%|██████▏   | 241/391 [00:03<00:01, 83.13it/s] 64%|██████▍   | 250/391 [00:03<00:01, 80.20it/s] 66%|██████▌   | 259/391 [00:03<00:01, 79.87it/s] 69%|██████▊   | 268/391 [00:03<00:01, 82.37it/s] 71%|███████   | 277/391 [00:03<00:01, 84.16it/s] 73%|███████▎  | 286/391 [00:03<00:01, 84.75it/s] 75%|███████▌  | 295/391 [00:03<00:01, 80.66it/s] 78%|███████▊  | 304/391 [00:03<00:01, 82.26it/s] 80%|████████  | 313/391 [00:04<00:00, 84.16it/s] 82%|████████▏ | 322/391 [00:04<00:00, 84.70it/s] 85%|████████▍ | 331/391 [00:04<00:00, 79.84it/s] 87%|████████▋ | 340/391 [00:04<00:00, 79.88it/s] 89%|████████▉ | 349/391 [00:04<00:00, 82.35it/s] 92%|█████████▏| 358/391 [00:04<00:00, 83.96it/s] 94%|█████████▍| 367/391 [00:04<00:00, 84.04it/s] 96%|█████████▌| 376/391 [00:04<00:00, 81.00it/s] 98%|█████████▊| 385/391 [00:04<00:00, 83.50it/s]100%|██████████| 391/391 [00:05<00:00, 77.49it/s]
50000 images processed, 5.144985675811768 seconds used

Processing in-distribution CIFAR-100 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.37it/s] 11%|█▏        | 9/79 [00:00<00:03, 21.98it/s] 22%|██▏       | 17/79 [00:00<00:01, 36.89it/s] 32%|███▏      | 25/79 [00:00<00:01, 48.53it/s] 43%|████▎     | 34/79 [00:00<00:00, 59.07it/s] 54%|█████▍    | 43/79 [00:00<00:00, 66.21it/s] 66%|██████▌   | 52/79 [00:01<00:00, 72.05it/s] 77%|███████▋  | 61/79 [00:01<00:00, 74.12it/s] 89%|████████▊ | 70/79 [00:01<00:00, 77.58it/s]100%|██████████| 79/79 [00:01<00:00, 78.82it/s]100%|██████████| 79/79 [00:01<00:00, 57.38it/s]
10000 images processed, 1.398432731628418 seconds used

Processing out-of-distribution SVHN images
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<01:09,  2.92it/s]  5%|▍         | 10/204 [00:00<00:06, 28.25it/s]  9%|▉         | 19/204 [00:00<00:04, 45.35it/s] 14%|█▎        | 28/204 [00:00<00:03, 58.10it/s] 18%|█▊        | 37/204 [00:00<00:02, 66.58it/s] 23%|██▎       | 46/204 [00:00<00:02, 72.47it/s] 27%|██▋       | 55/204 [00:00<00:02, 74.18it/s] 31%|███▏      | 64/204 [00:01<00:01, 76.71it/s] 36%|███▌      | 73/204 [00:01<00:01, 77.40it/s] 40%|████      | 82/204 [00:01<00:01, 79.80it/s] 45%|████▍     | 91/204 [00:01<00:01, 80.39it/s] 49%|████▉     | 100/204 [00:01<00:01, 80.52it/s] 53%|█████▎    | 109/204 [00:01<00:01, 78.89it/s] 58%|█████▊    | 118/204 [00:01<00:01, 80.67it/s] 62%|██████▏   | 127/204 [00:01<00:00, 82.45it/s] 67%|██████▋   | 136/204 [00:01<00:00, 82.93it/s] 71%|███████   | 145/204 [00:02<00:00, 81.85it/s] 75%|███████▌  | 154/204 [00:02<00:00, 77.57it/s] 80%|███████▉  | 163/204 [00:02<00:00, 79.18it/s] 84%|████████▍ | 172/204 [00:02<00:00, 80.60it/s] 89%|████████▊ | 181/204 [00:02<00:00, 80.24it/s] 93%|█████████▎| 190/204 [00:02<00:00, 82.17it/s] 98%|█████████▊| 199/204 [00:02<00:00, 84.02it/s]100%|██████████| 204/204 [00:02<00:00, 72.78it/s]
26032 images processed, 2.850919485092163 seconds used

Processing out-of-distribution places365 images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:38,  2.01it/s] 11%|█▏        | 9/79 [00:00<00:04, 17.43it/s] 22%|██▏       | 17/79 [00:00<00:02, 26.71it/s] 32%|███▏      | 25/79 [00:01<00:01, 31.65it/s] 42%|████▏     | 33/79 [00:01<00:01, 35.93it/s] 52%|█████▏    | 41/79 [00:01<00:00, 39.07it/s] 62%|██████▏   | 49/79 [00:01<00:00, 41.57it/s] 72%|███████▏  | 57/79 [00:01<00:00, 43.83it/s] 82%|████████▏ | 65/79 [00:01<00:00, 44.19it/s] 92%|█████████▏| 73/79 [00:02<00:00, 44.88it/s]100%|██████████| 79/79 [00:02<00:00, 37.43it/s]
10000 images processed, 2.145120620727539 seconds used

Processing out-of-distribution LSUN images
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:00<00:32,  2.40it/s] 13%|█▎        | 10/79 [00:00<00:02, 24.15it/s] 23%|██▎       | 18/79 [00:00<00:01, 37.87it/s] 34%|███▍      | 27/79 [00:00<00:01, 50.44it/s] 46%|████▌     | 36/79 [00:00<00:00, 59.13it/s] 56%|█████▌    | 44/79 [00:00<00:00, 63.57it/s] 66%|██████▌   | 52/79 [00:01<00:00, 67.37it/s] 77%|███████▋  | 61/79 [00:01<00:00, 72.21it/s] 89%|████████▊ | 70/79 [00:01<00:00, 76.64it/s]100%|██████████| 79/79 [00:01<00:00, 57.49it/s]
10000 images processed, 1.3967664241790771 seconds used

Processing out-of-distribution iSUN images
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [00:00<00:26,  2.59it/s] 13%|█▎        | 9/70 [00:00<00:02, 22.77it/s] 26%|██▌       | 18/70 [00:00<00:01, 40.37it/s] 39%|███▊      | 27/70 [00:00<00:00, 53.67it/s] 51%|█████▏    | 36/70 [00:00<00:00, 63.15it/s] 63%|██████▎   | 44/70 [00:00<00:00, 67.58it/s] 74%|███████▍  | 52/70 [00:01<00:00, 69.82it/s] 87%|████████▋ | 61/70 [00:01<00:00, 74.11it/s]100%|██████████| 70/70 [00:01<00:00, 77.24it/s]100%|██████████| 70/70 [00:01<00:00, 56.75it/s]
8925 images processed, 1.2659227848052979 seconds used

Processing out-of-distribution dtd images
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:00<00:35,  1.22it/s]  4%|▍         | 2/45 [00:00<00:17,  2.44it/s] 16%|█▌        | 7/45 [00:01<00:03, 10.39it/s] 22%|██▏       | 10/45 [00:01<00:03,  9.44it/s] 31%|███       | 14/45 [00:01<00:02, 11.98it/s] 38%|███▊      | 17/45 [00:01<00:01, 14.23it/s] 42%|████▏     | 19/45 [00:01<00:01, 14.13it/s] 47%|████▋     | 21/45 [00:02<00:02, 10.22it/s] 58%|█████▊    | 26/45 [00:02<00:01, 15.85it/s] 64%|██████▍   | 29/45 [00:02<00:01, 12.73it/s] 73%|███████▎  | 33/45 [00:02<00:00, 15.63it/s] 80%|████████  | 36/45 [00:03<00:00, 16.19it/s] 89%|████████▉ | 40/45 [00:03<00:00, 19.97it/s] 96%|█████████▌| 43/45 [00:03<00:00, 11.14it/s]100%|██████████| 45/45 [00:03<00:00, 11.92it/s]
5640 images processed, 3.799095630645752 seconds used

19.726725339889526
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/shaokun/anaconda3/envs/PPALM/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Evaluating SVHN
Evaluating places365
Evaluating LSUN
Evaluating iSUN
Evaluating dtd
 OOD detection method: SSD+
              FPR    AUROC  AUIN  
SVHN          19.33  96.57
places365     85.28  76.22
LSUN          85.42  85.33
iSUN          81.75  79.01
dtd           64.89  86.68
AVG           67.34  84.76
Retain-Acc: 0.7189
Forget-as-OOD (retain known vs forget novel):
  FPR: 68.50 AUROC: 86.90 AUIN: 98.35
29.1920063495636
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0_domain.png
[umap] saved to figs/umap_CIFAR-100_resnet34_top5-palm-cache6-ema0.999-b128-e50-lr0.001-wd1e-4-ltboth-bfmbalanced-fl0.2-lora_r8a32d0.05-temp0.08-fpw1.0_rf.png
